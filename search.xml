<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[19、加权中位数]]></title>
    <url>%2F2017%2F09%2F11%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D19%E3%80%81%E5%8A%A0%E6%9D%83%E4%B8%AD%E4%BD%8D%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目 方法一：推导仓储的位置 1，2，3，……，n权重（仓库中的物品数量） w1，w2，w3，……，wn d(x，y)表示仓库x与仓库y之间的距离 现将仓库的位置选在i，总的移动代价是Li L[i] = w1·d(i,1) + w2·d(i,2) + .... + wn·d(i,n) L[i-1] = w1·d(i-1,1) + w2·d(i-1,2) + ... + wn·d(i-1,n) 两者相减 L[i] - L[i-1] = w1·[d(i,1) - d(i-1,1)] + w2·[d(i,2) - d(i-1,2)] + ... +wi-1·[d(i,i-1) - d(i-1,i-1)] +wi·[d(i,i) - d(i-1,i)] +wi+1·[d(i,i+1) - d(i-1,i+1)] ... +wn·[d(i,n) - d(i-1,n)] 注意到d(x,y) - d(x’,y’)的值有可能是1，有可能是-1 分析得到： 下标 &lt;i 时，d(x,y) - d(x&apos;,y&apos;)的值是1 下标 &gt;=i 时，d(x,y) - d(x&apos;,y&apos;)的值是-1 所以得到（1）： L[i] - L[i-1] = w1 + w2 + ... + wi-1 - wi - wi+1 -....-wn 更改下标（2）： L[i-1] - L[i-2] = w1 + w2 + ... + wi-2 - wi-1 - wi - wi+1 - ... -wn （1）-（2）得： L[i] - 2L[i-1] + L[i-2] = 2·wi-1 整理得： L[i] = 2L[i-1] -L[i-2] + 2·wi-1 = 2·(L[i-1] + wi-1) + L[i-2] 得到递推式后，算出所有的值，然后取最小值，复杂度O(n) 方法二：加权中位数http://www.xuebuyuan.com/853325.html 求两个有序数组的中位数-算法导论http://www.acmerblog.com/median-of-two-sorted-arrays-5967.html]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18、丑数]]></title>
    <url>%2F2017%2F09%2F10%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D18%E3%80%81%E4%B8%91%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目 思路1是第一个丑数，可以通过将已知的丑数，分别乘以2，乘以3，乘以5推出下一个丑数 最简单的思路是将已经生成的所有丑数，全部乘以2，乘以3，乘以5，取最小的，将会是下一个丑数 如何优化？ 分别保存乘以2，乘以3，乘以5后将会大于当前最大丑数的丑数位置，设为p2、p3、p5，初始化时为1，1，1 取min（2 result[p2]，3 result[p3]，5 * result[p5]），并且移动p2、p3、p5的位置 代码public class Main { public static void main(String[] args) { Scanner in = new Scanner(System.in); int index = in.nextInt(); if (index == 0) { System.out.println(0); } int[] result = new int[index + 1]; //1是第一个丑数 result[1] = 1; //2的 int p2 = 1; int p3 = 1; int p5 = 1; //第2个~第n个丑数 for (int i = 2; i &lt;= index; i++) { int tmp = Math.min(2 * result[p2], 3 * result[p3]); result[i] = Math.min(tmp, 5 * result[p5]); if (2 * result[p2] &lt;= result[i]) p2++; if (3 * result[p3] &lt;= result[i]) p3++; if (5 * result[p5] &lt;= result[i]) p5++; } System.out.println(result[index]); } }]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17、求异或为0的区间个数]]></title>
    <url>%2F2017%2F09%2F10%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D17%E3%80%81%E6%B1%82%E5%BC%82%E6%88%96%E4%B8%BA0%E7%9A%84%E5%8C%BA%E9%97%B4%E4%B8%AA%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目在序列中进行划分，要求每个区间内的元素异或结果为0，求满足的区间数 思路1、记录前缀异或和，并放入set中保存2、如果当前计算的异或和出现在set中，说明存在一段区间满足异或为0，count++，set清空3、如果遇到0，直接count++，set清空（QM认为，没有验证） 对于一个序列a[0]、a[1]….a[j]，如果存在一个连续区间a[i]..a[j]的异或值为0，那么a[0]..a[j]的异或值为a[0]..a[i-1] 如1、2、3、2、3，因为 2^3^2^3 的值为0，我们想要找到这个区间当计算到1^2^3^2^3时得到的结果是1，而且存在1，则说明存在一个区间，满足异或值为0 代码import java.util.*; public class Main { public static void main(String[] args) { Scanner in = new Scanner(System.in); int n = in.nextInt(); int res = 0, count = 0; Set&lt;Integer&gt; array = new HashSet(); array.add(res); for (int j = 0; j &lt; n; j++) { res = res ^ (in.nextInt()); if (array.contains(res)) { count++; array.clear(); } array.add(res); System.out.println(array); } System.out.print(count); } }]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程面试题]]></title>
    <url>%2F2017%2F09%2F04%2F%5BJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%5DJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[synchronized 和 lock 的区别1、synchronized在JVM层面上实现，隐式加锁、释放锁，执行完同步代码或者出现异常都会自动释放锁，lock是代码显式加锁，释放锁，如果要保证锁定一定会被释放，就必须将unLock()放到finally{}中 2、ReentrantLock 拥有 Synchronized 相同的并发性和内存语义，此外还多锁投票，定时锁等候和中断锁等候； 线程A和B都要获取对象O的锁定，假设A获取了对象O锁，B将等待A释放对O的锁定， 如果使用 synchronized ，如果A不释放，B将一直等下去，不能被中断 如果 使用ReentrantLock，如果A不释放，可以使B在等待了足够长的时间以后，中断等待，而干别的事情 3、在资源竞争不是很激烈的情况下，Synchronized的性能要优于ReetrantLock，但是在资源竞争很激烈的情况下，Synchronized的性能会下降几十倍，但是ReetrantLock的性能能维持常态 悲观锁和乐观锁1、悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁2、乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号、预期值等机制 两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 乐观锁怎么实现（自旋锁和轻量级锁的机制）数据库乐观锁实现使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据 CAS机制CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。 线程池线程池的好处1、减少在创建和销毁线程上所花的时间以及系统资源的开销2、方便线程资源的管理3、Executor框架把任务的提交和执行进行解耦，只需要定义好任务，然后提交给线程池，而不用关心该任务是如何执行、被哪个线程执行，以及什么时候执行 线程池的流程 线程池在启动的时候初使化一定数量的线程 有任务过来的时候，先检测初使化的线程还有空的没有，如果有就取一个线程执行任务；没有就再看当前运行中的线程数是不是已经达到了最大数，如果没有，就新分配一个线程去处理；但如果已经达到了最大数，任务就只有等待了 四种线程池newCachedThreadPool 线程池中如果有闲置的线程将重用，没有可用的线程，则创建一个新线程并添加到池中（无上限） 自动回收不使用的线程（终止并从缓存中移除那些已有 60 秒钟未被使用的线程） newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 new Thread 与 newSingleThreadPool 的区别 对于单个、确定的任务，使用new Thread 如果线程异常结束，newSingleThreadPool会重新创建一个新的线程继续执行任务，更可靠 对于多个任务，并且要求FIFO执行，使用SingleThreadPool 因为执行多任务，new Thread 无法复用线程，需要频繁的创建、销毁线程，耗费系统资源 对于单一确定的任务，使用SingleThreadPool效率比new Thread低，因为SingleThreadPool需要维护任务队列等其他开销 参考：http://bbs.csdn.net/topics/391830535 JAVA 线程池的实现原理http://www.jianshu.com/p/87bff5cc8d8c]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16、快速排序.]]></title>
    <url>%2F2017%2F08%2F28%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D16%E3%80%81%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序import java.util.Arrays; public class Solution { //区间划分，l，r public void quickSort(int[] a, int l, int r) { //递归出口容易出错 if (l &gt;= r) { return; } int mid = partition(a, l, r); quickSort(a, l, mid - 1); quickSort(a, mid + 1, r); } public int partition(int[] a, int l, int r) { //left做为分割，&lt;=left的元素比锚点小 int left = l - 1;//(容易出错) for (int i = l; i &lt; r; i++) { if (a[i] &lt; a[r]) { swap(a, ++left, i);//(++left容易出错) } } swap(a, ++left, r);//(++left容易出错) return left; } private void swap(int[] a, int i, int j) { int t = a[i]; a[i] = a[j]; a[j] = t; } public static void main(String[] args) { int[] a = {3, 2, 6, 7, 2, 4, 1, 5, 733, 2, 2}; Solution s = new Solution(); s.quickSort(a, 0, a.length - 1); System.out.println(Arrays.toString(a)); } } 随机选取基准/*随机选择枢轴的位置，区间在low和high之间*/ int SelectPivotRandom(int arr[],int low,int high) { //产生枢轴的位置 srand((unsigned)time(NULL)); int pivotPos = rand()%(high - low) + low; //把枢轴位置的元素和low位置元素互换，此时可以和普通的快排一样调用划分函数 swap(arr[pivotPos],arr[low]); return arr[low]; } 三数取中（median-of-three）分析：最佳的划分是将待排序的序列分成等长的子序列，最佳的状态我们可以使用序列的中间的值，也就是第N/2个数。可是，这很难算出来，并且会明显减慢快速排序的速度。这样的中值的估计可以通过随机选取三个元素并用它们的中值作为枢纽元而得到。事实上，随机性并没有多大的帮助，因此一般的做法是使用左端、右端和中心位置上的三个元素的中值作为枢纽元。显然使用三数中值分割法消除了预排序输入的不好情形，并且减少快排大约14%的比较次数 /*函数作用：取待排序序列中low、mid、high三个位置上数据，选取他们中间的那个数据作为枢轴*/ int SelectPivotMedianOfThree(int arr[],int low,int high) { int mid = low + ((high - low) &gt;&gt; 1);//计算数组中间的元素的下标 //使用三数取中法选择枢轴 if (arr[mid] &gt; arr[high])//目标: arr[mid] &lt;= arr[high] { swap(arr[mid],arr[high]); } if (arr[low] &gt; arr[high])//目标: arr[low] &lt;= arr[high] { swap(arr[low],arr[high]); } if (arr[mid] &gt; arr[low]) //目标: arr[low] &gt;= arr[mid] { swap(arr[mid],arr[low]); } //此时，arr[mid] &lt;= arr[low] &lt;= arr[high] return arr[low]; //low的位置上保存这三个位置中间的值 //分割时可以直接使用low位置的元素作为枢轴，而不用改变分割函数了 } QM注释，怎么交换： 如果目标是low &lt; mid，low &lt; high，mid &gt; high，这样high是中位数 如果low &gt; mid则交换，如果low &gt; high则交换，如果mid &lt; high则交换 其他优化优化1：当待排序序列的长度分割到一定大小后，使用插入排序。 原因：对于很小和部分有序的数组，快排不如插排好。当待排序序列的长度分割到一定大小后，继续分割的效率比插入排序要差，此时可以使用插排而不是快排 if (high - low + 1 &lt; 10) { InsertSort(arr,low,high); return; }//else时，正常执行快排 优化2：在一次分割结束后，可以把与Key相等的元素聚在一起，继续下次分割时，不用再对与key相等元素分割 第一步，在划分过程中，把与key相等元素放入数组的两端 第二步，划分结束后，把与key相等的元素移到枢轴周围 优化3：优化递归操作 结论概括：这里效率最好的快排组合是：三数取中+插排+聚集相等元素,它和STL中的Sort函数效率差不多]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15、求带环的链表入口位置]]></title>
    <url>%2F2017%2F08%2F21%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D15%E3%80%81%E6%B1%82%E5%B8%A6%E7%8E%AF%E7%9A%84%E9%93%BE%E8%A1%A8%E5%85%A5%E5%8F%A3%E4%BD%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[如何判断链表有环一开始设置两个指针都指向表头，其中一个每次（一步）前进一个节点的叫p1，另外那个每次（一步）前进两个节点的叫p2 。p1和p2同时走，当其中有一个遇到null，就证明链表没有环。如何某个时刻（假设走了n步之后），p1和p2指向的地址相同，那么链表就是有环的。 如何得到环入口在p1和p2重合后，设置一个p3指向表头，然后p1和p3每次同时行走一步，每步前进一个节点，等到p1和p3重合时，重合的位置就是环的入口 证明 参考http://www.cnblogs.com/snake-hand/p/3148328.html]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux IO模式]]></title>
    <url>%2F2017%2F08%2F20%2F%5BNIO%5DLinux%20IO%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[用户空间和内核空间操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间 针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换过程 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 （QM注释：观察对象有两个，一个是旧进程，一个是新进程） 进程的阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 IO模式的阻塞与非阻塞（针对I/O） 阻塞是如果数据没有准备好，进程必须等待，也不能处理其他任务 非阻塞是如果没数据准备，立刻返回一个error，不需要等待，所以一般需要多次轮训来判断数据是否准备好 IO模式的同步与异步（针对进程） 同步：进程需要不断去轮训判断数据是否准备好 异步：进程发起read后立刻返回，当数据准备好kernel会给用户进程发送一个signal，告诉它read操作完成了 IO多路复用select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会”监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 IO多路复用是否一定比多线程更好？ 如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。 select当用户进程调用了select，那么整个进程会被block，而同时，kernel会”监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 select/poll与epoll的区别 select目前几乎在所有的平台上支持 select单个进程能够监视的文件描述符的数量存在最大限制1024，poll没有最大数量限制，epoll监视的描述符数量不受限制 select/poll需要轮训查看数据是否准备好，epoll当文件准备好会自定调用回调函数 如果空闲文件特别多，使用epoll会更效 其他select的最大缺点就是进程打开的fd是有数量限制的。这对于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的) 参考Linux IO模式及 select、poll、epoll详解https://segmentfault.com/a/1190000003063859]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14、判断是否是平衡二叉树]]></title>
    <url>%2F2017%2F08%2F20%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D14%E3%80%81%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%98%AF%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[题目输入一棵二叉树，判断该二叉树是否是平衡二叉树。 思路定义平衡树： 1、平衡二叉树的左、右子树的高度不超过12、而且左右子树必须同时也是平衡树 函数设计： 1、需要返回子树的高度2、子树是否是平衡树 可以合并成一个参数，如果不是平衡树，直接返回null，否则返回高度 代码public class Solution { public boolean IsBalanced_Solution(TreeNode root) { if (f(root) != null) { return true; } return false; } //如果是平衡树，则返回高度；否则返回null public Integer f(TreeNode root) { if (root == null) { return 0; } Integer left = f(root.left); Integer right = f(root.right); if (left != null &amp;&amp; right != null &amp;&amp; Math.abs(left - right) &lt;= 1) { return Math.max(left, right) + 1; } else { return null; } } }]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4、Mysql面试题.]]></title>
    <url>%2F2017%2F07%2F29%2F%5B%E6%95%B0%E6%8D%AE%E5%BA%93%5D4%E3%80%81Mysql%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[事务ACID属性 原子性（Atomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态（如转账钱不会少）。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。 隔离性（Isolation）：并发事务之间互相影响的程度，适当的破坏一致性来提升性能与并行度。数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 一致性理解： 数据操作后前后一致，A账户增加100，B账户就减少100，总数没少，一致的专业术语是：状态A，经过事务的操作B，转移到状态C，B的操作完全应用在A上，产生的结果B是准确得准确是指什么准确不是有可能操作B中断，这些异常，可能B的操作是加10，但是分为10个+1的中间操作，但是操作B中断了可能 A 经过操作B 得到结果C 是 +1，而不是+10 一致性要求保证操作B的中间结果对外是不可见的要不就是全部执行，要不就不执行就回到刚才那里例子，银行转账这不还是原子性么……原子性是一致性的保障哈原子性、一致性和持久性是通过redo 和 undo 日志文件实现的所以你看他们的实现都在一起 事务隔离等级并发时出现的问题及解决方案 事务隔离级别选择 1、事务隔离级别越严格，并发副作用越小，对系统的性能影响越大，因为事务隔离实质上使事务在一定程度上”串行化”执行，与并发是矛盾的2、不同的应用对读一致性和隔离程度是不同的，比如许多应用对”不可重复读”和”幻影读”并不敏感，可能更关注数据并发访问能力 Mysql默认事务隔离等级innoDB是MySQL默认的存储引擎，默认的隔离级别是RR，并且在RR的隔离级别下更进一步，通过多版本并发控制（MVCC，Multiversion Concurrency Control ）解决不可重复读问题，加上间隙锁（也就是并发控制）解决幻读问题。因此innoDB的RR隔离级别其实实现了串行化级别的效果，而且保留了比较好的并发性能。 如何实现事务隔离1、读取数据前，加锁（悲观锁）2、不加任何锁，在数据请求点生成一个快照，并用这个快照来提供一定级别的一致性读取（乐观锁） MVCCMVCC是一种多版本并发控制机制 锁机制可以控制并发操作，但是其系统开销较大，而MVCC可以在大多数情况下代替行级锁，使用MVCC，能降低其系统开销 InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现的，这两个列，分别保存了这个行的创建时间，一个保存的是行的删除时间。这里存储的并不是实际的时间值，而是系统版本号(可以理解为事务的ID)，没开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID。 SELECT1、InnoDB只会查找版本早于当前事务版本的数据行(也就是,行的系统版本号小于或等于事务的系统版本2、行的删除版本要么未定义,要么大于当前事务版本号,这可以确保事务读取到的行，在事务开始之前未被删除. DELETEInnoDB会为删除的每一行保存当前系统的版本号(事务的ID)作为删除标识. UPDATEInnoDB执行UPDATE，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要UPDATE的行的删除时间. 详细：http://blog.csdn.net/whoamiyang/article/details/51901888 InnoDB和MyISAM区别MySQL数据库分为Innodb和Myisam两类。两者最主要的区别是：Innodb支持事务处理、外键和行级锁.而MyISAM不支持，所以如果CUD比较频繁或要求事务一致性的，使用Innodb比较好，反之使用Myisam比较好。具体区别如下： 1、索引：MyISAM的索引和数据是分开的，并且索引是有压缩的，而Innodb是索引和数据放在一起，且没有使用压缩，因而Innodb比MyISAM体积更大。MyISAM每张表都包括三种文件：表定义文件（.frm）、数据文件（.myd)和索引文件（.myi)，而Innodb通常许多表保存在同一个文件中。此外，如果表数据非常大，通常也使用MyISAM。2、InnoDB不支持FULLTEXT类型的索引。3、对于AUTO_INCREMENT类型的字段，InnoDB中必须单独建索引，而在MyISAM中可以和其他字段一起建立联合索引。4、没有where的SELECT COUNT(*)：MyISAM始终保留一张表的行数，因此这条语句几乎瞬间就可以执行完，而Innodb会一行行的累加。5、锁：MyISAM表锁，Innodb行锁 索引索引类型1、普通索引 这是最基本的索引，它没有任何限制，比如上文中为title字段创建的索引就是一个普通索引，MyIASM中默认的BTREE类型的索引，也是我们大多数情况下用到的索引。 2、唯一索引 与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值（注意和主键不同）。如果是组合索引，则列值的组合必须唯一，创建方法和普通索引类似。 3、全文索引（FULLTEXT） MySQL从3.23.23版开始支持全文索引和全文检索，FULLTEXT索引仅可用于 MyISAM 表；他们可以从CHAR、VARCHAR或TEXT列中作为CREATE TABLE语句的一部分被创建，或是随后使用ALTER TABLE 或CREATE INDEX被添加。////对于较大的数据集，将你的资料输入一个没有FULLTEXT索引的表中，然后创建索引，其速度比把资料输入现有FULLTEXT索引的速度更为快。不过切记对于大容量的数据表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法。 单列索引、多列索引单列索引 考虑使用索引的主要有两种类型的列：在Where子句中出现的列，在join子句中出现的列 那么，我们是否可以简单地认为应该索引Where子句和join子句中出现的每一个列呢？差不多如此，但并不完全。我们还必须考虑到对列进行比较的操作符类型。MySQL只有对以下操作符才使用索引：&lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN，以及某些时候的LIKE。 多列索引 多个单列索引与单个多列索引的查询效果不同，因为执行查询时，MySQL只能使用一个索引，会从多个索引中选择一个限制最为严格的索引。 Select peopleid FROM people Where firstname=&apos;Mike&apos; AND lastname=&apos;Sullivan&apos; AND age=17; 为了提高搜索效率，我们需要考虑运用多列索引。如果为firstname、lastname和age这三个列创建一个多列索引，MySQL只需一次检索就能够找出正确的结果 多列索引中最左前缀（Leftmost Prefixing） 现在我们有一个firstname、lastname、age列上的多列索引，我们称这个索引为fname_lname_age。当搜索条件是以下各种列的组合时，MySQL将使用fname_lname_age索引： firstname，lastname，age firstname，lastname firstname 详细：http://greatwqs.iteye.com/blog/1897118 聚簇索引和非聚簇索引聚集索引 1、表中行的物理存储顺序按照”索引键值顺序排列”，该索引称为”聚集索引”2、每个表只能有一个聚集索引，因为数据只能按照一种方法进行排序。但该索引可以包含多个列（组合索引），就像电话簿按姓氏和名字进行组织一样3、聚簇索引的叶节点就是数据节点 优点：聚集索引对于那些经常要搜索范围值的列特别有效。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻。 非聚集索引 1、索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同（目录纯粹是目录，正文纯粹是正文的排序方式称为”非聚集索引”，查找记录时需要通过目录索引找到正文）2、非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块 总结 1、聚簇索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块 2、聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快 详细： http://www.cnblogs.com/aspnethot/articles/1504082.html &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 索引优化1、何时使用聚集索引或非聚集索引？2、索引不会包含有NULL值的列，使用默认值3、使用短索引 什么情况下设置了索引但无法使用，索引无效1) 以”%”开头的LIKE语句，模糊匹配：红色标识位置的百分号会导致相关列的索引无法使用2) Or语句前后没有同时使用索引3) 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型，会使索引无效，产生全表扫描。）4) 在索引列上使用IS NULL 或IS NOT NULL操作。索引是不索引空值的，所以这样的操作不能使用索引，可以用其他的办法处理，例如：数字类型，判断大于0，字符串类型设置一个默认值，判断是否等于默认值即可5) 在索引字段上使用not，&lt;&gt;，!=，eg&lt;&gt; 操作符（不等于）：不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。 用其它相同功能的操作运算代替，如 a&lt;&gt;0 改为 a&gt;0 or a&lt;06) 对索引字段进行计算操作 7) 在索引字段上使用函数Mysql 日志事务的隔离用是通过锁机制实现的，原子性、一致性和持久性是通过redo 和 undo 日志文件实现的 概述 1、当开始一个事务时候，会纪录该事务的一个日志序列号2、当事务执行时候，在写数据之前，需要先写日志，这种方式称为预写日志方式WAL（Write-Ahead Logging）。3、undo记录了数据在事务开始之前的值，当事务执行失败或者ROLLBACK时可以通过undo记录的值来恢复数据 =&gt; 缺点：单纯使用undo保证原子性和持久性需要在事务提交之前将数据写到磁盘，浪费大量I/O。4、引入redo日志记录数据修改后的值，可以避免数据在事务提交之前必须写入到磁盘的需求，减少I/O。 undo undo记录了数据在事务开始之前的值，当事务执行失败或者ROLLBACK时可以通过undo记录的值来恢复数据。例如 AA和BB的初始值分别为3，5。 A 事务开始 B 记录AA=3到undo_buf C 修改AA=1 D 记录BB=5到undo_buf E 修改BB=7 F 将undo_buf写到undo(磁盘) G 将data_buf写到datafile(磁盘) H 事务提交 如果事务在F之前崩溃由于数据还没写入磁盘，所以数据不会被破坏。如果事务在G之前崩溃或者回滚则可以根据undo恢复到初始状态。数据在任务提交之前写到磁盘保证了持久性。但是单纯使用undo保证原子性和持久性需要在事务提交之前将数据写到磁盘，浪费大量I/O。 思考题：为什么要将undo_buf写到磁盘，而不是直接执行G 如果G崩溃如果不将undo写入磁盘就没法回滚，所以需要进行undo的持续化，所以使用undo来保证原子性和持久性会大量浪费IO，主要体现在多谢了undo的操作 redo： 引入redo日志记录数据修改后的值，可以避免数据在事务提交之前必须写入到磁盘的需求，减少I/O。通过undo保证事务的原子性，redo保证持久性。 A 事务开始 B 记录AA=3到undo_buf C 修改AA=1 记录redo_buf D 记录BB=5到undo_buf E 修改BB=7 记录redo_buf F 将redo_buf写到redo（磁盘） G 事务提交 F之前崩溃由于所有数据都在内存，恢复后重新冲磁盘载入之前的数据，数据没有被破坏。FG之间的崩溃可以使用redo来恢复。G之前的回滚都可以使用undo来完成。 两个概念 1、崩溃：操作失败，开机后需要继续执行2、回滚：取消之前的执行结果然后用redo可以解决崩溃问题用undo可以回滚 qm总结：1、undo：宕机恢复时，如果undo日志没有commit，则进行回滚操作步骤：持久化undo日志，数据库持久化，commit缺点：commit前完成数据持久化，同步IO 2、redo：宕机恢复时，如果redo日志已经commit，将数据库数据持久化到磁盘操作步骤：持久化redo日志，commit之后在适当时间进行数据库持久化优点：解决同步IO 3、undo/redo：事务执行时持久化undo/redo日志，宕机恢复时，如果没有commit，则利用undo回滚；如果已经commit，则恢复执行redo操作，持久化到磁盘 详细：http://blog.csdn.net/sk199048/article/details/50596092http://blog.csdn.net/mchdba/article/details/12242685http://blog.chinaunix.net/uid-20196318-id-3812190.html 63b271e37efb23df61727e260c18db29cb801183 分页查询 参考从特性说起，漫谈MySQL中的事务及其实现http://dbaplus.cn/news-11-515-1.html?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13、交互字符串使之有序的最小次数]]></title>
    <url>%2F2017%2F07%2F26%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D13%E3%80%81%E4%BA%A4%E4%BA%92%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%BD%BF%E4%B9%8B%E6%9C%89%E5%BA%8F%E7%9A%84%E6%9C%80%E5%B0%8F%E6%AC%A1%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目字符序列交换（阿里巴巴笔试题） 若初始序列为gbfcdae，那么至少需要多少次两两交换，才能使该序列变为abcdefg？ 注意不是相邻两两交换 思路参考bcbb的回答http://mp.weixin.qq.com/s/Kie8QP6Vq0Th-bP2Yjwx8A 我要怼第一个人了，说是只能相邻两个交换了吗？这题例子中有两个环一个是 b b，另一个是 g a f c d e g，所以答案是字符串长度7减环的个数2等于5。★★★因为长度为n的每一个环，都能n-1次交换满足条件。★★★而这个例子中可以证明环不可能相交。也一不难证明一定有环。 判断环的个数x，次数就是字符串长度减环的个数。 参考POJ类似题的思路和解法http://m.blog.csdn.net/x___song/article/details/16884075 实现重点在于如果角标不同 那就一直循环做 swap(a[i], a[a[i]]); 常规设计思路 ★★★更优雅的方法——根据环的思路直接计算交换次数，参考POJ类似题的解法实现重点在于如果角标不同 那就一直循环做 swap(a[i], a[a[i]]); 核心思想： 1、如果当前位置的元素不是目标元素，则将当前元素与目标位置的元素进行交换（需要维护 key：目标位置，value：目标元素） 2、这样当前指向的是之前目标位置的元素，再将目标元素放到合适的位置；一直交换，直到当前位置的元素等于目标元素，即成一个完整的环，记录交换的次数 3、有两种计算方式，一种是直接计算交换次数，另外一种是字符串的个数 - 环的个数；笔试题建议采用第二种方式，画图直观；程序题采用第一种方式，计算直观；为了方便记忆，之后做这种题都采用第二种的方式 POJ参考代码，思路类似，题目不一样： #include #define MAX 10000 + 10 int a[MAX]; void swap( int i, int j) { int temp = a[i]; a[i] = a[j]; a[j] = temp; return ; } int main() { int t; scanf("%d", &t); while ( t --){ int n; scanf("%d", &n); for ( int i = 0; i < n; i ++){ scanf("%d", &a[i + 1]); } int ans = 0; for ( int i = 1; i]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试总结]]></title>
    <url>%2F2017%2F07%2F22%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Spring：什么是Spring？spring是一个轻量级的控制反转（IOC）和面向切面编程（AOP）的框架 什么是IOC/AOP?IOC是控制反转，就是将创建对象的工作从程序中转移出来，交由Spring框架完成对象的创建和装配工作AOP是面向切面编程，将共有的代码抽离出来，放在一个地方进行维护，在程序运行的时候由框架将切面切入到目标对象上，程序员只需要专注业务逻辑的开发 什么是依赖注入？在创建对象的时候，由框架将依赖的对象实例注入到当前对象中 什么是Bean？ Spring管理的对象为Bean Bean可以是任意对象，包括javabean、service、dao、数据源 Bean必须由一个无参的构造器，通过get/set方法访问参数，支持序列化 原理： 1、配置文件中定义的 bean 可以全部都可以抽象为一个 Bean 对象，字段包括ID、类名、依赖属性 &lt;bean id = &quot;person&quot; class = &quot;Person&quot;&gt; &lt;preperty name = &quot;name&quot; value = &quot;Alan&quot;/&gt; &lt;/bean&gt; =&gt; 抽象 Bean{ /* Bean Id */ private String id; /* Bean Class */ private String type; /* Bean Property */ private Map&lt;String, Object&gt; properties = new HashMap&lt;String, Object&gt;(); } 2、接下来 Spring 就开始加载我们的配置文件了，将我们配置的信息保存在一个 HashMap 中，HashMap 的 key 就是 Bean 的 Id ，HasMap 的value是这个Bean，只有这样我们才能通过context.getBean(“user”)这个方法获得Animal这个类 3、依赖注入，在实例化一个类时，它通过反射调用类中 set 方法将事先保存在 HashMap 中的类属性注入到类中 如何启动Spring？ ApplicationContext context = new ClasspathXMLApplicationContext(&quot;application.xml&quot;); #在web.xml的监听器标签中配置ContextLoaderListener，并在全局参数中配置Spring配置文件 &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext*.xml&lt;/param-value&gt; &lt;/context-param&gt; 注解依赖注入： 1、注解的方式引入bean：@Service(value = ‘a’)、@Component(value = ‘b’)2、依赖注入：Autoware：按类型；Autoware+Qualifier(value=’b’)：按名称 AOP：AOP容器会将切面切入到目标对象的连接点上，动态创建一个代理对象供使用者调用 切面：共有功能的实现，包括通知和切入点，如日志切面、事务切面通知：切面的具体实现，包括前置通知、后置通知、环绕通知、异常通知、最终通知切入点：定义将通知切入到哪些连接点上 连接点：能够插入切面的地点目标对象：需要被动态功能加强的对象代理对象：将切面切入到目标对象后，动态创建的对象 织入：将切面切入到目标对象的连接点上，创建一个新的代理对象的过程 AOP底层实现？1、JDK动态代理：必须针对接口进行代理，通过Proxy类，传入类加载器、接口和InvocationHandler类，返回代理对象2、CGLIB：如果目标对象没有接口，无法使用JDK动态代理，则可以使用CGLIB 动态代理原理： 使用：1、创建目标对象 2、自定义类实现InvocationHandler接口，构造函数中传入目标对象，在实现的接口方法Invoke中对根据选择对方法进行代理 3、调用Proxy.newProxyInstance方法中传入是三个参数，分别是类加载器，代理的接口和自定义InvocationHandler实例，返回代理对象 原理：1、调用ProxyGenerator的generateProxyClass方法产生ProxySubject.class的二进制数据，代理类实现接口中的方法，方法体中都是调用成员变量InvocationHandler的invoke方法，需要传入参数类名和实现接口，生成的代理类在调用接口方法时，会调用传入的InvocationHandler的invoke方法 2、利用反射创建代理对象的实例，并且传入InvocationHandler参数，返回代理对象实例 3、执行代理类的对象时都会执行InvocationHandler的invoke方法 基于注解的AOP：AspectJ 1、开启注解&lt;aop:aspectj-autoproxy/&gt;1、定义一个类作为切面，用@Aspect注解，并在配置文件中配置切面2、定义切入点和通知 环绕通知和前置、后置区别：spring 的环绕通知和前置通知，后置通知有着很大的区别，主要有两个重要的区别： 1） 目标方法的调用由环绕通知决定，即你可以决定是否调用目标方法，而前置和后置通知是不能决定的，他们只是在方法的调用前后执行通知而已，即目标方法肯定是要执行的。 2） 环绕通知可以控制返回对象，即你可以返回一个与目标对象完全不同的返回值，虽然这很危险，但是你却可以办到。而后置方法是无法办到的，因为他是在目标方法返回值后调用 总结：1、前置通知是在方法调用前执行，后置通知在方法调用后执行，但是方法都必须执行，但环绕通知可以决定是否调用该方法 2、环绕通知可以修改方法的返回值，但后置通知办不到，因为他是在目标方法返回值后调用 通知执行顺序： ·环绕前置通知 前置通知 具体业务方法 异常通知 ·环绕后置通知 后置通知 当目标方法抛出异常时，后置方法不再执行 Spring MVC：什么是Spring MVC？Spring MVC是一个基于MVC设计理念的web框架 SpringMVC运行原理：1、DispatcherServlet 拦截所有请求2、从HandlerMapping 查找 Handler，返回执行链（Handler和拦截器集合）3、DispatcherServlet 调用 HandlerAdapter，HandlerAdapter 调用 Handler，Handler处理具体的业务逻辑。Handler处理完业务逻辑后返回ModelAndView给HandlerAdapter，其中View是视图名称，Modal是数据模型。HandlerAdapter再返回给DispatcherServlet。4、DispatcherServlet通过ModelView的视图名称在视图解析器中查找视图，视图解析器返回真正的View视图对象5、渲染视图 HandlerMapping作用？ RequestMappingHandlerMapping处理请求映射的，根据用户的请求URL，查找@RequestMapping，找出匹配的Handler（URL-&gt;Handler） HandlerAdapter作用？ HandlerAdapter的handler方法处理注解和准备handler方法中的参数（这就是SpringMVC如何将request中的参数编程输入参数的地方），最终调用实际的Handler method Restful风格API？ （1）每一个URI代表一种资源(只能有名词)（2）客户端通过四个HTTP动词(get/post/put/delete)，对服务器端资源进行操作（3）客户端和服务器之间，传递这种资源的某种表现层 url示例： get /board/xxxx.html post /board?title=xx delete /board?id=xxx put /board?id=xx&amp;title=xx API: @Requestmapping(value = &quot;/board/{id}.html&quot; method = RequestMethod.GET) public String getBoard(@Pathvariable(&quot;id&quot;) String id){ server.get(id); } 消息转换： 使用：用@RequestBody标注，并在Domain对象中标注注解@XmlRootElement，将XML字符串转换为Domain对象用@ResponseBody标注，将 原理： HttpMessageConvert 自动将http消息转化为对象，将对象转化http消息 1、Spring MVC 配置了默认转换器，在类加载的时候尝试加载一些默认转换类，如jackson、jaxb，如果加载抛出异常说明没有引入类，否则来实例化响应的消息转换器类。当返回 HandlerAdapter时，为之设置转换器列表2、根据请求体的类型，如text/xml，遍历所有的消息转换器，看是否支持请求体类型；最终调用jaxb消息转换器，进行转换 WebMvcConfigurationSupport：Spring MVC主要配置类，包括messageConverters、url匹配等 为什么转化为XML而不是JSON？ mybatis mybatis优势： 什么是SOA？面向服务的架构，强调的是一种架构思想，将系统划分为多个模块，各模块之间以标准服务的方式进行交互，强调组件化的灵活开发方式 （将系统划分为多个模块，也称为服务，这些服务之间通过接口和协议联系起来，接在一起以实现特定的功能。） 什么是RPC框架？RPC框架：远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议 http://www.jianshu.com/p/0f4113d6ec4b 什么是Thrifit：Thrift最初由Facebook研发，主要用于各个服务之间的RPC通信，采用接口描述语言定义服务，支持跨语言，数据传输采用二进制，能够快速构建服务 接口描述语言：客户端和服务端能使用不同的语言开发，那么一定就要有一种中间语言来关联客户端和服务端的语言，没错，这种语言就是IDL（Interface Description Language）。 基本数据类型： byte: 有符号字节 i16: 16位有符号整数 i32: 32位有符号整数 i64: 64位有符号整数 double: 64位浮点数 string: 字符串 容器类型： list: 一系列由T类型的数据组成的有序列表，元素可以重复 set: 一系列由T类型的数据组成的无序集合，元素不可重复 map: 一个字典结构，key为K类型，value为V类型，相当于Java中的HMap 结构体：（记得写参数编号） struct People { 1: string name; 2: i32 age; 3: string sex; } 枚举(enum)： enum Sex { MALE, FEMALE } 异常(exception)： exception RequestException { 1: i32 code; 2: string reason; } 服务(service):thrift定义服务相当于Java中创建Interface一样，创建的service经过代码生成命令之后就会生成客户端和服务端的框架代码 service HelloWordService { // service中定义的函数，相当于Java interface中定义的函数 string doAction(1: string name, 2: i32 age); } 注释：thrift注释方式支持shell风格的注释，支持C/C++风格的注释，即#和//开头的语句都单当做注释，/**/包裹的语句也是注释。 服务描述文件示例： namespace java com.winwill.thrift enum RequestType { SAY_HELLO, //问好 QUERY_TIME, //询问时间 } struct Request { 1: required RequestType type; // 请求的类型，必选 2: required string name; // 发起请求的人的名字，必选 3: optional i32 age; // 发起请求的人的年龄，可选 } exception RequestException { 1: required i32 code; 2: optional string reason; } // 服务名（类似于接口名） service HelloWordService { string doAction(1: Request request) throws (1:RequestException qe); // 可能抛出异常。 } 使用Thrift开发流程为： 编写接口文件（IDL：Interface Description Language） 经过Thrift工具编译后，生成一个个Java类 实现Service类 Thrift框架原理; 服务器启动后处于监听状态，当接收到客户端的消息后，服务器发起一个线程处理该消息请求，原线程再次进入阻塞状态 新线程根据协议读取消息，调用请求方法，并将结果写入到结果，传回客户端 Thrift传输协议：协议类别总体上划分为：文本、二进制，但为节省带宽，提高传输效率，一般使用二进制类型的传输协议 Thrift客户端、服务端：有阻塞，非阻塞，线程池，半同步半异步，Selector多种服务端实现模式。 TSimpleServer – 简单的单线程服务模型，常用于测试 TThreadedServer – 多线程服务模型，使用阻塞式IO，每个请求创建一个线程。(java 不支持) TThreadPoolServer – 多线程服务模型，使用标准的阻塞式IO，预先创建一组线程处理请求。 TThreadedSelectorServer 允许你用多个线程来处理网络I/O。它维护了两个线程池，一个用来处理网络I/O，另一个用来进行请求的处理 TNonblockingServer – 多线程服务模型，使用非阻塞式IO（需使用TFramedTransport数据传输方式）,只有一个线程来处理消息 THsHaServer - 半同步半异步的服务模型，一个单独的线程用来处理网络I/O，一个worker线程池用来进行消息的处理 客户端包括同步，异步两种形式 Thrifit优势：使用二进制数据格式传输， JSP：Java Servlet Page 动态生成网页的技术在第一次访问JSP的时候，会将JSP文件翻译成一个Servlet文件，然后将Servlet编译成class文件，并加载进内存，创建一个Servlet实例，调用其init方法，其中init方法只有在第一次访问时调用，然后调用其service方法。第二次之后直接访问其service方法，所以第一次加载速度比较慢，之后就比较快了 123&lt;c:forEach items=&quot;$&#123;a&#125;&quot; var=&quot;fuwa&quot;&gt; &lt;c:out value=&quot;$&#123;fuwa&#125;&quot;/&gt;&lt;br&gt;&lt;/c:forEach&gt; 内置对象：request、response、session、application、page、out、config、exception、pageContext 装修计算器：主要有两大功能，装修规划及预算报价， mybatis： 园区网用户行为审计系统项目介绍：本项目为解决园区网络内部的安全问题，对园区网络的内网用户访问外部网络的行为进行监控和审计，并将网络上发生的事件记录下来以便事后追查主要负责： 1、利用华为二层、三层交换机组建园区网络：接入层采用二层交换机，骨干网采用高性能的三层交换机，在二层交换机中划分VLAN，隔离广播域（VLAN是虚拟的局域网）。在三层交换机配置SVI接口，在能够实现不同VLAN之间的通信（不同VLAN之间的通信相当于不同的广播域进行通信，要采用路由的方式，三层交换机一般处于骨干网络，能够记录下IP地址与交换机端口之间的映射关系，在园区网络内实现互联互通） 2、基于SNMP协议审计虚假路由攻击：实时监测园区网络中路由表的变化，SNMP是简单网络管理协议，可以获得设备的基本信息；使用UDP作为传输层；用161端口接收get/set报文，用162接收trap报文；当系统启动时主动获取路由器中的路由表，当路由表发生变化时，会向管理主机发送一个trap报文，查询路由表并与之间的对比，如果路由表发生变化则认为发生虚假路由攻击 3、利用Jpcap抓包对网络流量监控：Java语言对网络层以下的控制无能为力，Jpcap是一个中间件，JPCAP调用wincap，对数据链路层的控制；利用Java第三方类库Jpcap抓取网络数据包，统计单位时间网络传输的字节速率，具体方案是维护{bytes = 0，开始时间}，当时间小于一秒钟，累计字节数；如果超过1秒就记录下当时的字节数，得到的结果就是一秒内传输的字节速率 这是一个网络监控软件，解析各种常见的协议，如HTTP、SMTP、Telnet等，分析用户行为，能够知道用户在什么时候做了什么事情； 整个系统分为多个模块，每个模块是一个线程，各个模块间通过队列的方式协调运行1、采集模块：因为 Java 程序没法操作链路层，所以采用 JPCAP 中间件从底层抓取数据包，放到队列中2、分派模块：分派模块根据不同的数据包类型，将TCP数据包放到TCP队列，UDP数据包放到UDP队列，ARP数据包放到ARP队列4、TCP重组模块：从TCP队列中取出数据包，根据TCP重组算法建立完整的TCP会话连接，并放入解析队列4、解析模块：从解析队列中取出数据，根据使用的端口，进行协议解析：如果80端口解析HTTP报文，25端口是SMTP协议，110是POP3协议 TCP重组算法：根据源地址、目的地址、源端口、目的端口确定一条TCP连接，从TCP三次握手开始到TCP四次挥手，维护客户端和服务器的状态机，当出现SYN数据包时，客户端的状态由关闭状态变为SYN Send，当接收到 SYN+ACK，服务器端的状态由监听状态变为SYN Received；当接收到ACK，客户端的状态变为Established，服务器端的状态变为Established。之后接收到数据包，如果正式当前缓存队列中期待的数据包，则加入队列，否则放入乱序的队列；接下来到四次挥手，当接收到Fin数据包，客户端的状态变为Fin Wait1，接受都 Fin+ACK 服务器端的状态变为Close Wait;当接收到服务器端的Fin，服务器的状态变为Last ACK，当接收到ACK时，客户端的状态变为Fin Wait2 JVM性能调优1、jstat -gcutil 首先看存在占用100%或90以上的，增大堆3g -Xms -Xmx2、可能会太大了，回缩，jstat -gc 设置堆为老年堆占用量的4倍3、设置新生代和持久代为老年堆使用量的1.5倍-Xmn-XX:PermSize-XX:MaxPermSize 热点 POI 预测近期新增的 POI 中筛选出一批数据，预测其在未来的一段时间内会成为热点数据，并且这些POI是错误的，这样可以在这些POI累计到一定量前，及时发现并进行修正，减少对用户的伤害 指标：1、错误率：预测出的POI是错误的2、热度：如果这个POI是错误的，但是如果热度不高，这些POI不为用户所知，即使POI是错的，对用户影响也不大，工作意义不大。所以需要保证热度 如何从热度从50%上升到70%？之前以历史三天的作为参考，后来以历史7天的作为参考 如何从错误率从20%上升到40%？筛掉可信源，包括众包，室内地图；还有多来源，并且提供坐标 计算机网络三次握手 首先客户端向服务端发送SYN报文（seq = client_isn），服务端收到后发送ACK（client_isn+1），和SYN报文（seq = server_isn），客户端再发送ACK（server_isn+1），TCP连接建立 当双方建立 TCP 连接以后，就可以传输数据了，传输过程中发送方每发送一个数据包 ，接收方都要给予一个应答。 TCP 断开连接建立一个连接需要 3 次握手，而终止一个连接要经过 4 次握手（如图 2 ）。这是因为一个 TCP 连接是全双工（即数据在两个方向上能同时传递），每个方向必须单独地进行关闭。4 次握手实际上就是双方单独关闭的过程。 为什么是三次握手，二次可以吗？ 三次握手的核心是什么？三次握手是为了交换客户端和服务器各自的初始序列号，这样双方都知道对方的初始序列，从而判断哪些TCP数据包是合法的，哪些不合法 两次握手的时候，客户端向服务器端发送同步包。服务器接收到后，知道客户端的初始序列，分配资源建立连接，发送同步包和确认包，客户端接收到后，知道服务器的初始序列，于是分配资源连接建立，正常情况下是没有问题的 可能服务器发送的ACK丢失，客户端以为服务器没有接收到SYN，然后重新发送同步报，但是此时服务器已经打开连接了，会忽略客户端发送的同步包，这样客户端就永远不会获得服务器端的初始序列号，两者无法建立连接，但服务器端已经分配了资源，从而造成资源浪费 采用三次握手的时候，当接收到客户端的同步包的时候，建立半连接，当接收到客户端的响应时才打开连接 此时如果客户端打开连接了，但是第三次ACK丢了，会造成客户端的资源浪费吗？ 服务器会重新发送SYN+ACK，直到接收到ACK，这样客户端和服务器都建立了连接，不会造成任何一方的资源浪费 为什么不是四次握手？ 三次握手已经能够建立可靠连接，第四次握手就多余了，在通信理论上，三次握手是不可靠信道上，进行建立可靠连接的最小次数，所以采用过三次握手可以提高连接的效率 四次挥手 FIN-ACK-FIN-ACK客户端状态：Fin-Wait1，Fin-Wait2，Time-Wait，close服务器状态：Clost-Wait，Last-ACK，close TCP细节： 发送缓存： [0，base-1]内的序号已经发送并确认过的序列，[base，nextSeqnum-1]对应已经发送但未被确认的分组，[nextSeqnum，base+N-1]内的序号为要被立刻发送的分组，数据来自上层，大于bast+N的序号不能使用，直到流水线中未被确认的分组得到确认为止 回退N步（GBN）： 发送方如果出现超时事件，将重传所有已发送但未被确认的分组 接收方需要维护下一个按需接收的分组序号，如果按序到达，将数据提交给上层；如果失序，直接丢弃，不进行任何缓存 选择重传： 每个分组发送后启动定时器，发送方会重传未被确认分组中序列号最小的的分组 在接受方失序的分组将被缓存 TCP可靠数据传输： 发送方：1、从上层应用程序接收数据 2、定时器超时 3、收到ACK报文 发送数据包时启动定时器；定时器超时，重发未被确认分组中序列号最小的分组，并开启定时器；接收到ACK，而且ACK大于当前未被确认的序列，更新已经确认的序列，重启定时器；如果小于的话，直接忽略 公众号开发项目介绍：马可波罗瓷砖莞深销售中心公众号，用于解决分公司日常的销售业务中存在大量的信息沟通需要 编码转换（已删）utf8-latin1-gbk String content content = new String(temp.getBytes(“gbk”),”iso-8859-1”); 问题转换为如何将gbk编码的字节正确传输；1、new String(temp.getBytes(“gbk”),”iso-8859-1”)：获得gbk编码的字节流，用lain1字节解码，获得字符串，任务转换为传输该字符串，只要发送方和接收方一致就行，2、接收方接收到字节流，直接用gbk解码 RedisTemplate1、底层采用Jedis访问redis，包括一些set/get/expire命令2、RedisTemplate 加上一层连接池3、对于每次操作都是打开链接，执行操作；为了简洁，设计成execute（callback）的方式，不同的操作只是callback中的内容不一样4、使用jdk序列化工作执行对象的序列化 动态数据源切换之前开发了一个微信公众号，后来提出了一个需求，需要开发5个分公司的微信公众号，有两种方案： 1、每个公众号设置不同的端口运行在服务器上，反向代理根据域名定位到个自己的服务器上2、使用同一个应用，根据不同的公众号，动态切换数据源 由于每个公众号采用的操作都是一样的，就是数据不一样，于是采用方案二 如何分别不同的公众号？两种方案： 1、采用一级域名，二级域名的方式/mk/bu1/o/get=&gt;相当于寻找/bu1/o/get，找不到重定向带/o/get =&gt; 原来的不用改 2、采用标记 公众号1：flag = 1公众号2：flag = 2 因为微信重定向时只能带一个参数，所以采用一级、二级域名的方式 具体方案： 1、重写DispatcherServlet的doDispatch方法，利用线程局部变量ThreadLocal记录前缀，然后重定向 2、继承AbstractRoutingDataSource，重写determineCurrentLookupKey的方法，这个方法在调用数据源的getConnection方法时需要选择数据源的名称，这是我们返回ThreadLocal的值就行了，完成了动态数据源 在Spring中配置数据源时，对应的class是咱么自己重写的数据源，然后改数据源管理了一些需要切换的数据源，用map保存 源码分析：http://www.cnblogs.com/davidwang456/p/4318303.html#top 数据结构与算法单向链表头插法： t = first; first = new Node(); first.next = t; 这种写法对first是否为null都不影响，但是对last指针有影响：当first为空时，last=first，否则last不变，完整写法： t = first; first = new Node(); first.next = t; if(t == null){ last = first; }else{ //不操作 } 双向链表头插法： 不考虑特殊情况的写法： t = first; first = new Node(); first.next = t; first.pre = null; t.pre = first; 但当first为null的时候，t.pre=first会报空指针异常，修正： t = first; first = new Node(); first.next = t; first.pre = null; if(t == null){ last = first; }else{ t.pre = first; } 总结：头插法和尾插法思考方法1、保存first或last的指针2、first或last指向新new出来的对象，维护其与前后节点之间的关系3、当first或last为空时，分别使last或first执行new的对象，如果是双向链表，还需维持new出来对象前后之间的关联 头插法双向链表： private void linkFirst(E e) { final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; //易错点 if (f == null) last = newNode; else f.prev = newNode; size++; modCount++; } 尾插法双向链表： void linkLast(E e) { final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; //易错点 if (l == null) first = newNode; else l.next = newNode; size++; modCount++; } Thrifthttp://www.jianshu.com/p/0f4113d6ec4b# Thrift最初由Facebook研发，主要用于各个服务之间的RPC通信，支持跨语言 既然客户端和服务端能使用不同的语言开发，那么一定就要有一种中间语言来关联客户端和服务端的语言，没错，这种语言就是IDL（Interface Description Language）接口描述语言 支持数据类型： byte: 有符号字节 i16: 16位有符号整数 i32: 32位有符号整数 i64: 64位有符号整数 double: 64位浮点数 string: 字符串 结构体 struct People { 1: string name; 2: i32 age; 3: string sex; } 异常 exception RequestException { 1: i32 code; 2: string reason; } OOP三大特性：继承，多态，封装，抽象记忆：jdcf（京东程飞） 继承http://yunnigu.dropsec.xyz/2016/09/25/Java%E4%B9%8B%E7%BB%A7%E6%89%BF%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%E9%87%8D%E5%86%99%E4%B8%8E%E5%B1%9E%E6%80%A7%E8%A6%86%E7%9B%96/# 在父类中定义这些相同的当多个类存在相同的属性和方法，所有的子类不需要重新定义这些属性和方法，只需要继承父类,这样子类就会自动拥有父类定义的某些属性和方法 1、Java继承中的属性覆盖 父类哪些属性、方法被子类继？除了private修饰的属性和方法都能都能被子类继承 继承中的属性覆盖结论： 由于private变量受访问权限的限制，它不能被覆盖 属性的值取父类还是子类并不取决于我们创建对象的类型，而是取决于我们定义的变量的类型 friendly、protected和public修饰符并不影响属性的覆盖 静态变量和静态常量属于类，不属于对象，因此它们不能被覆盖 常量可以被覆盖 对于基本类型和对象，它们适用同样的覆盖规律 2、Java方法重写 重载时只与方法特征有关，重写时会进一步检查两个方法的返回类型是否相同、访问修饰权限是否缩小和抛出的异常范围是否扩大 非私有非静态方法不能被任何静态方法覆写 非私有静态方法不能被任何非静态方法覆写 子类与父类中有方法特征相同的静态方法时，覆写规则与非静态方法覆写规则一样，但一般我们不把静态方法的覆写叫覆写，虽然语法规则上与非静态方法相同。不存在多态 私有方法对子类同名方法不产生任何影响，也就是说私有方法不能被重写，即使试着在子类覆写了父类的私有方法，不管访问权限修饰符是什么，在编译时也不会报错。原因就是私有方法对子类也是不可见的。 多态就是指一个引用(类型)在不同情况下的多种状态，实现多态有两种方式：1、继承；2、接口 方法重写与方法重载： 方法重载：在一个类中有多个相同名字的方法，但具有不同的参数表（参数类型、个数、顺序），返回值类型、方法的修饰符可以不同，如果只是返回类型或方法的修饰符不一样，不能构成重载，，调用方法时通过传递给它们的不同参数个数和参数类型来决定具体使用哪个方法, 这就是多态性。 方法重写： 子类有一个方法，和父类的某个方法的返回类型、方法名、参数表一样，子类方法不能缩小父类方法的访问权限，可以放大访问权限；不能扩大异常范围，可以不抛异常 抽象定义一个类时候，实际上就是把一类事物的共有的属性和行为提取出来，形成一个类 封装封装就是把抽象出来的数据和对数据的操作封装在一起。数据被保护在内部，程序的其它部分只有通过被授权的操作(成员方法)，才能对数据进行操作。 访问控制修饰符 设计模式设计模式原则总的原则：可维护，复用，易扩展 SOLIDcl：（泥土 蔡磊）s单一职责原则o开闭原则：对扩展开放，对修改关闭l里式替换：父类可以引用子类i接口隔离原则：使用多个专门的接口，而不是用单一的总接口d依赖倒转：面向接口编程c合成复用：尽量使用对象组合，而不是继承达到复用的目的l迪米特：一个软件实体尽可能少与其他实体耦合 单例模式：确保一个类只有一个实例1、构造方法私有，外部不能通过new创建对象2、静态变量保存唯一实例3、静态的getInstance方法，是外部能够访问 饿汉模式:在类加载的时候已经创建了单例对象 //staic final静态常量 private static final Singleton instance = new Singleton(); private Singleton(){} public static Singleton getInstance(){return instance;} 懒汉模式：第一次调用的时候创建对象实例 private static Singleton instatnce = null; private Singleton(){} //注意同步控制关键字 Synchronized synchronized public Singleton getInstance(){ if(instance == null){ instance = new Singleton(); } return instance; } 方法二：synchronized同步控制代码块，双重检查锁定（单次判断实例不为空，如果一个线程正在创建对象但还未创建完成，另一个线程进入实例不为空的判断，最终产生两个实例，未被单一对象的原则） //使用volatile保证可见性 private volatile static Singleton instatnce = null; private Singleton(){} public static Singleton getInstance(){ //第一重判断 if(instance == null){ synchronized(Singleton.class){ //第二重判断 if(instance == null){ instance = new Singleton(); } } } return instance; } 为什么需要使用volatile？不是同步快结束完之后，会将instance对象写入内存？ 答：主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 instance 分配内存 调用 Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了） 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 解析： 线程1创建调用getInstance（）方法执行到instance=new Singleton()，但是这条语句不是原子性的，他分为三个步骤：1、分配内存 2、初始化 3、instance对象指向内存空间，执行完这步后instance为非空了。 但是jvm存在指令重排序的优化，如果指令按照1，3，2的执行方式，但是线程1在执行3之后，但未执行2之前，此时instance已经不为null了，这时候线程2调用getInstance（）方法（注意这时线程2可以调拥这个方法，因为只有进入一重检查锁之后才是临界区。）执行第一重判断if(instance == null){，此时instance不为null，直接调用return instance语句返回对象，但对象并没有真正得实例化完毕，调用就会出现错误 我们只需要将 instance 变量声明成 volatile 就可以了。 有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，读操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。 方法三（最优）：静态内部类中保持对象的实例，在第一次调用的时候创建单例对象 private static class Hold{ private static final Singleton instance = new Singleton(); } private Singleton(){} public static Singleton getInstance(){ return Hold.inistance; } 饿汉式和懒汉式对比：饿汉式在类加载的时候创建，不管用不用，都占据内存；懒汉式在第一次使用的时候创建，必须加锁，多线程时性能受影响 集中式工厂——简单工厂模式定义产品接口，抽象产品类实现接口，加入一些共有方法和抽象方法，具体产品类继承抽象产品类，实现方法 工厂类包括一个静态的getProduct方法，参数为具体产品名，返回值为产品接口，根据传入的产品名，返回不同的具体产品类 调用方法: Product a = Factory.getInstance(&quot;A&quot;); Product b = Factory.getInstance(&quot;B&quot;); 缺点：增加一个新的产品时必须修改工厂类 多台工厂——工厂方法模式定义产品接口，抽象产品类实现接口，加入一些共有方法和抽象方法，具体产品类继承抽象产品类，实现方法 定义工厂接口，有个一getInstance方法。对于每一个具体的产品，都对应一个具体的工厂类，重新getInstance方法中实例化具体产品 调用方法： Factory factory = new AFactory(); ProductA = (ProductA)factory.getInstance(); 缺点：每个工厂只生产一种产品，工厂类太多 产品族的创建——抽象工厂相关的产品组成一个”产品族”，由同一个工厂来统一生产 1、工厂方法中有多个方法，用来创建不同的产品 public interfact Factory{ ProductA createA(); ProductB createB(); } 2、对于一个产品族，对应一个具体的工厂方法 class SpringFactory implements Factory{ ProductA createA(){return new SpringProductA();} ProductB createB(){return new SpringProductB();} } class SummerFactory implements Factory{ ProductA createA(){return new SummerProductA();} ProductB createB(){return new SummerProductB();} } 外观模式n客户端通过一个统一的外观角色与子系统进行通信，降低客户端的使用难度 外观类接收客户端的请求，并将请求委派到相应的子系统中处理，最终返回结果 具体实现：外观类中保持自己子系统的 观察者模式代理模式Linux命令：wget 要下载文件的urltail 查看日志tar -zxvf 解压zip xx 压缩 mount 挂载unmount 卸载 make 根据makefile进行编译make install 根据makefile进行安装 rpm 查看软件 yum install 安装软件 mkdir 建立文件夹rmdir 删除空文件rm -rf 删除文件夹 mv 移动cp 复制 netstat -anp | grep 8080 查询端口 sudo 命令/ sudo su #管理员权限 service mysqld start 启动mysql数据库service mysqld stop 停止 ps -aux 进程列表kill -9 pid 杀进程 权限：chmod 777 文件名 #！！！！！！！！！！chown 用户名 文件名 #修改文件所有者chgrp 组名 文件名 #修改文件所有组 /etc/profile #系统整体配置文件 df 系统分区情况 数据库数据库优化方案单机：（单从数据库本身）Mysql换成Oracle，因为Oracle具有更大的存储空间，更安全，稳定表优化：大表变小表，分库分表 （数据库之上）读写分离：主从数据库 数据库连接池 （引入缓存）缓存 分布式集群+负载均衡：mysql集群、数据库操作中间件、redis集群 连接池连接池的作用： 用户请求一次查询的时候就会向数据库发起一次连接，执行完后就断开连接，而创建连接、释放连接都很耗费资源和时间，数据库的连接资源并没有得到很好的重复利用。使用连接池后直接从连接池中获取已经创建的连接，使用完之后放回连接池中 如果有很多用户同时在线，开发者不好控制数据库的连接数，很有可能因为分配的连接过多而导致内存耗尽。使用连接池可以控制最小连接数、最大连接数，可以根据连接的使用率进行增大或减少 数据库引擎Mysql中MyISAM引擎和InnoDB引擎的比较 事务：InnoDB类型支持事务等高级处理，MyISAM不支持 并发：在执行数据库写入的操作（insert,update,delete）的时候，mysiam表会锁表，而innodb表会锁行 查询速度：MyISAM记录行数 选择： MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。 InnoDB适合：(1)可靠性要求比较高，或者要求事务；(2)表更新和查询都相当的频繁，并且表锁定的机会比较大的情况。 Java基础intern方法解法：new string的都是指向堆中的地址，intern返回的都是常量池记录的地址，但要注意常量池的地址是否是指向堆中的地址；只有第一次通过new String创建某一字符串时，而之前这个字符串没有以字符串常量的形式（引号的形式）放入常量池，那么常量池将会引用第一次new String时指向堆的地址 小心：JDK1.6之前保存的都是字符串的字面值JDK1.7之后可能会保存字符串的引用 实例： 1、调用toString（内部是调用new String的方式）之前常量池没有计算机软件变量，所以调用new String时放入常量池，常量池中的字符串指向堆中的地址 String s = new StringBuilder(&quot;计算机&quot;).append(&quot;软件&quot;).toString(); System.out.println(s.intern() == s);//返回true 2、”计算机软件”放入常量池，调用toString时发现常量池已经存在该字符，不放入常量池 String s = new StringBuilder(&quot;计算机软件&quot;).toString(); System.out.println(s.intern() == s);//返回false 3、常量池计算机软件指向的是第一次new String时堆中的地址，即s1的地址；s2又是一个新的地址，所以第二个返回false String s1 = new StringBuilder(&quot;计算机&quot;).append(&quot;软件&quot;).toString(); String s2 = new StringBuilder(&quot;计算机&quot;).append(&quot;软件&quot;).toString(); System.out.println(s1.intern() == s1);//返回true System.out.println(s2.intern() == s2);//返回false 参考http://blog.csdn.net/u013066244/article/details/53575281http://blog.csdn.net/u010697982/article/details/45696989 注解注解作用： 生成文档，通过代码里标识的元数据生成javadoc文档。 编译检查，通过代码里标识的元数据让编译器在编译期间进行检查验证。 编译时动态处理，编译时通过代码里标识的元数据动态处理，例如动态生成代码。 运行时动态处理，运行时通过代码里标识的元数据动态处理，例如使用反射注入实例。 元注释： @Retention用于标明注解被保留的阶段 SOURCE：被编译器丢弃 ——&gt; 编译检查、生成doc文档 CLASS：被编译器写入class文件中，但虚拟机无法获取到 ——&gt; 动态生成代码 RUNTIME：被编译器写入class文件中，运行时通过反射访问 ——&gt; 依赖注入 @Target用于标明注解使用的范围 TYPE：类、接口、枚举 FLED：成员变量 METHOD：方法 PARAMETER：方法参数 CONSTRUCTOR：构造器 LOCAL_VARIABLE：局部变量 ANNOTATION_TYPE：注解类型 PACKAGE：包 @Inherited用于标明注解可继承，@Documented用于标明是否生成javadoc文档。 注解原理： 1、注解是在编译时由编译器进行处理，编译器会对注解符号处理并附加到class结构中2、通过反射方法 Class.getAnnotation(Test.class) 获取到 Test 注解对象，进而再通过Test注解对象获取到Test里面的属性值 Test.java @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) public @interface Test { String value(); } Main.java @Test(value = &quot;qm&quot;) public class Main { public static void main(String[] args) throws ClassNotFoundException { Class&lt;?&gt; clazz = Class.forName(&quot;Annotation.Main&quot;); Test annotation = clazz.getAnnotation(Test.class); System.out.println(annotation.value()); } } 注解对象是什么？其实注解被编译后的本质就是一个继承 Annotation 接口的接口，所以@Test其实就是”public interface Test extends Annotation”，当我们通过AnnotationTest.class.getAnnotation(Test.class)调用时，JDK会通过动态代理生成一个实现了Test接口的对象，并把将RuntimeVisibleAnnotations属性值设置进此对象中，此对象即为Test注解对象，通过它的value()方法就可以获取到注解值。 Java中static作用static表示”全局”或者”静态”的意思，用来修饰成员变量和成员方法，也可以形成静态static代码块，但是Java语言中没有全局变量的概念 被static修饰的成员变量和成员方法独立于该类的任何对象，被类的所有实例共享。 public修饰的static成员变量和成员方法本质是全局变量和全局方法，当声明它类的对象市，不生成static变量的副本，而是类的所有实例共享同一个static变量。 static变量前可以有private修饰，表示这个变量可以在类的静态代码块中，或者类的其他静态成员方法中使用（当然也可以在非静态成员方法中使用–废话），但是不能在其他类中通过类名来直接引用，这一点很重要 总结： static表示静态的，修饰变量、方法后叫做静态变量和静态方法，在加载类的过程中完成静态变量的内存分配，为所有对象所共有，通过类直接方法 static块在类加载的时候执行 HashMap底层http://yikun.github.io/2015/04/01/Java-HashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/ 定义： 基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。 记忆：定义（Map接口）、特点（无序、null）、线程同步（非同步） 两个重要的参数：容量(Capacity)和负载因子(Load factor) 简单的说，Capacity就是bucket的大小，Load factor就是bucket填满程度的最大比例。如果对迭代性能要求很高的话不要把capacity设置过大，也不要把load factor设置过小。当bucket中的entries的数目大于capacity*load factor时就需要调整bucket的大小为当前的2倍。 记忆：容量（桶的数量）、负载因子（衡量桶装满程度，当桶中的entries的数目大于capacity*load factor时就需要调整bucket的大小为当前的2倍） put函数的实现： 对key的hashCode()做hash，然后再计算index; 如果没碰撞（数组上的值为null）直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket的容量超过阈值(超过capacity * loadFactor)，就要resize。 记忆：1、key做hash计算数组下标，2、是否碰撞（不碰撞，直接放入篮子；否则以链表形式放入篮子），3、如果碰撞导致链表长度过长，就把链表转成红黑树；4、如果节点存在则替换（key相等，替换值），5、如果bucket满了则resize get函数的实现： bucket里的第一个节点，直接命中；如果有冲突，则通过key.equals(k)去查找对应的entry若为树，则在树中通过key.equals(k)查找，O(logn)；若为链表，则在链表中通过key.equals(k)查找，O(n)。 hash函数的实现： 高16bit不变，低16bit和高16bit做了一个异或 获取桶下标：table长度n为2的幂，h&amp;(length - 1)相当于直接取模 如何解决频繁碰撞：首先在获取HashMap的元素时，基本分两步：1、首先根据hashCode()做hash，然后确定bucket的index；2、如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。 在Java 8之前的实现中是用链表解决冲突的，在Java 8中，利用红黑树替换链表 扩容：我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成”原索引+oldCap” 线程局部变量1、Thread中有一个ThreadLocalMap属性，存放线程局部变量，是键值对的存储方式，以ThreadLocal对象为键，要保存的变量为值（ThreadLocalMap.Entry是保存键值对的对象） 2、ThreadLocal可以看做是ThreadLocalMap的操作类，在当前线程中通过ThreadLocal的set/get操作，对当前线程中的ThreadLocalMap进行操作 set方法：首先获取当前线程的ThreadLocalMap的引用，然后以ThreadLocal实例作为key，保存的变量为value，保存到当前线程的ThreadLocalMap中 get方法：以当前ThreadLocal实例作为key，取出当前线程的ThreadLocalMap变量中该key的值 3、每个线程都拥有自己的ThreadLocalMap属性，每个线程都是从自己的ThreadLocalMap中取值，所以互不影响 4、作用：可以实现线程范围内的单例、线程范围内数据共享 hashCode() 和equals() 区别和作用规范1：如果两个对象相同，那么他们的hashcode必须相等规范2：如果两个对象不相同，他们的hashcode可能相同 这样我们就可以推断Java运行时环境是怎样判断HashSet和HastMap中的两个对象相同或不同了。我的推断是：先判断hashcode是否相等，再判断是否equals。 数据库中char, varchar, nvarchar的差异char固定字符，varchar可变字符（根据实际所占的空间，char浪费空间，但效率略高） varchar：按字节存储数据nvarchar：按字符存储数据（如果用nvchar存储英文，会造成空间浪费） char和varchar的性能差距是很小的，可以考虑忽略不计。 在大数据量应用中，使用char和nvarchar有可能导致大量的存储空间的浪费。 建议实际中用varvhar mysql中int、bigint、smallint 和 tinyint的区别与长度的含义bigint从 -2^63 (-9223372036854775808) 到 2^63-1 (9223372036854775807) 的整型数据（所有数字）。存储大小为 8 个字节。 P.S. bigint已经有长度了，在mysql建表中的length，只是用于显示的位数 int从 -2^31 (-2,147,483,648) 到 2^31 – 1 (2,147,483,647) 的整型数据（所有数字）。存储大小为 4 个字节。int 的 SQL-92 同义字为 integer。 smallint从 -2^15 (-32,768) 到 2^15 – 1 (32,767) 的整型数据。存储大小为 2 个字节。 tinyint从 0 到 255 的整型数据。存储大小为 1 字节。 分析MySQL数据类型的长度（1）CHAR、VARCAHR的长度是指字符的长度，例如CHAR[3]则只能放字符串”123”，如果插入数据”1234”，则从高位截取，变为”123”。 VARCAHR同理。（2）TINYINT、SMALLINT、MEDIUMINT、INT和BIGINT的长度，其实和数据的大小无关！Length指的是显示宽度，举个例子： 普通数组和ArrayList的差别动态数组、get/set等一系列方法、基本类型/引用类型、泛型 动态绑定Java的动态绑定又称为运行时绑定。意思就是说，程序会在运行的时候自动选择调用哪个方法。（重载） RESTFUL API1、url代表一个资源2、http的get/post/update/delete 表示对资源的操作，进行状态转换3、文本类型：xml、json进行数据传递 StringBuilder，StringBuffer都是字符串操作类，StringBuilder非线程安全，适合在单线程的情况下使用，效率比较高；StringBuffer是线程安全的，适合在多线程条件下使用，效率略低 判断对象是否相等推荐使用java.util.Objects#equals （JDK7引入的工具类） public static boolean equals(Object a, Object b) { return (a == b) || (a != null &amp;&amp; a.equals(b)); } 类加载器类加载器的作用是把类的字节码文件加载进内存中 类加载器的层次关系：Bootstrap、ExtClassLoader、AppClassLoader、用户自定义的类加载器 类加载器的委托机制： 1、当Java虚拟机要加载一个类时，到底派出哪个类加载器去加载呢? ①首先 当前线程的类加载器 去加载线程中的第一个类. ②如果类A中引用了类B，Java虚拟机将使用加载类A的类加载器加载类B ③还可以直接调用ClassLoader.loadClass()方法来指定某个类加载器去加载某个类. 2、每个类加载器加载类时，又先委托给其上级类加载器 当所有祖宗类加载器没有加载到类，回到发起者类加载器，如果还加载不了，则抛出ClassNotFoundException异常。它不会去找发起者类加载器的儿子，因为没有getChild()方法，即使有，有那么多的儿子交给那一个呢?所以干脆就不交给儿子处理了。 ArrayList和LinkedList和Vector1、ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构2、对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针3、对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据 Vector和ArrayList几乎是完全相同的，唯一的区别在于Vector是同步类(synchronized).因此,开销就比ArrayList要大.正常情况下,大多数的Java程序员使用ArrayList而不是Vector,因为同步完全可以由程序员自己来控制 HashMap和HashTable 1、历史原因 Hashtable是基于陈旧的Dictionary类的，HashMap是java 1.2引进的Map接口的一个实现 2、同步性 Hashtable是线程同步的。这个类中的一些方法保证了Hashtable中的对象是线程安全的（Synchronized）。而HashMap则是线程异步的，因此HashMap中的对象并不是线程安全的。因为同步的要求会影响执行的效率，所以如果你不需要线程安全的集合那么使用HashMap是一个很好的选择，这样可以避免由于同步带来的不必要的性能开销，从而提高效率 3、值 HashMap可以让你将空值作为一个表的条目的key或value但是Hashtable是不能放入空值的(null) HashMap底层实现http://zhangshixi.iteye.com/blog/672697 HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap的数据结构： 在Java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个”链表散列”的数据结构，即数组和链表的结合体。 从上图中可以看出，HashMap底层就是一个数组结构，数组中的每一项又是一个链表，链表的每一个元素是键-值对。当新建一个HashMap的时候，就会初始化一个数组。 transient Entry[] table; static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; Entry&lt;K,V&gt; next; final int hash; …… } 可以看出，Entry就是数组中的元素，每个 Map.Entry 其实就是一个key-value对，它持有一个指向下一个元素的引用，这就构成了链表。 HashMap的存取实现： 1) 存储： public V put(K key, V value) { // HashMap允许存放null键和null值。 // 当key为null时，调用putForNullKey方法，将value放置在数组第一个位置。 if (key == null) return putForNullKey(value); // 根据key的keyCode重新计算hash值。 int hash = hash(key.hashCode()); // 搜索指定hash值在对应table中的索引。 int i = indexFor(hash, table.length); // 如果 i 索引处的 Entry 不为 null，通过循环不断遍历 e 元素的下一个元素。 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } // 如果i索引处的Entry为null，表明此处还没有Entry。 modCount++; // 将key、value添加到i索引处。 addEntry(hash, key, value, i); return null; } 从上面的源代码中可以看出：当我们往HashMap中put元素的时候，先根据key的hashCode重新计算hash值，根据hash值得到这个元素在数组中的位置（即下标），如果数组该位置上已经存放有其他元素了，那么在这个位置上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。如果数组该位置上没有元素，就直接将该元素放到此数组中的该位置上。 动态代理1、必须针对接口进行代理2、生成代理对象，通过Proxy类进行代理，传入目标对象类加载器、目标对象接口 、处理类3、自己实现InvocationHandler 接口 多线程1、thread与runnable 如果改写thread的run方法和传入runnable类，使用的是那个run？ Thread的run方法，如果runnable对象不为空，去执行runnable中的run方法，但是如果Thread的run方法被重写，则使用改写的Thread中的run方法 public void run() { if (target != null) { target.run(); } } 2、synchronized，使用的对象锁必须同一个对象，可以this或字符串常量 Synchronized(){ //保护一段代码 } 也可以修饰方法，来保护整个方法（默认对象锁是this） 如果修饰静态方法，静态对象对应的对象锁是类的字节码 Spring MVC 和 Struts2的区别 Struts2的入口是filter，Spring MVC的入口是Servlet，两者的实现机制不同 Struts2是基于类设计的，参数绑定到类的属性，所有的方法都可以使用；Spring MVC是基于方法设计的，参数绑定到方法的形参，并且只有一个方法可以使用 Struts2必须是多例的（Struts2传递到的参数绑定到类的属性，如果是单例会导致不同用户数据的冲突），Spring MVC默认是单例的，所以Spring MVC的性能比Struts2好 重定向与转发的区别 浏览器中的url：转发仍是原来的url，重定向为新的url 重定向发生在浏览器，由浏览器重新发出http请求，转发发生web服务器，请求在web服务器转发 重定向可以到外部网站，重定向只能访问WEB应用个资源 SesssionSession的生命周期 Session存储在服务器端，一般为了防止在服务器的内存中（为了高速存取），Sessinon在用户访问第一次访问服务器时创建，需要注意只有访问JSP、Servlet等程序时才会创建Session，只访问HTML、IMAGE等静态资源并不会创建Session，可调用request.getSession(true)强制生成Session Session什么时候失效？ 1、服务器会把长时间没有活动的Session从服务器内存中清除，此时Session便失效。Tomcat中Session的默认失效时间为30分钟。2、调用Session的invalidate方法。 分布式Session同步1、cookie存储方式。把session数据做加密，然后存储到cookie中。用户请求到了，就直接从cookie读取，然后做解密。这种方式真是把分布式思想发挥到了一个相当的高度。他把用户也当做分布式的一员，你要访问数据，那你就自己携带着他，每次到服务器的时候，我们的服务器就只负责解密…… 对于session里只存放小数据，并且加密做的比较好（防止碰撞做暴力破解）的系统来讲，这是一个比较好的选择。他实现超级简单，而且不用考虑数据的同步。 不过如果要往session里存放大数据的情况就不是太好处理。或者安全性要求很高的系统，也不是太好的一个方式（数据有被破解的风险） 2、cache集群或者数据库做session管理。我们也可以采用另外一种架构来解决session同步问题，那就是引入统一session接入点。 把session放入到cache集群或者数据库中，每次请求的时候，都从他们中来获取。这样，所有的机器都能获取到最新的session数据。这种方案也是很多中大型网站采用的解决方案。他实现起来相对简单（利用cache集群或者主从数据库自身的管理来实现多机的互备），而且效率很高，安全性也不错。 3、还有一种方式是从上面这种方式延展出来的，就是提供session服务。这个服务负责管理session，其他服务器每次从这个服务处获取session数据，从而达到数据的共享。 这种方式的好处就在于： A、可以非常方便的扩展用户登录的数量以及存储数据的大小。当时在x度的时候，N亿用户的session都在这个系统里进行管理； B、方便做性能优化。如果用cache集群的方案，如果cache有机器坏掉，那么就会造成一部分用户session失效；如果用数据库方案，如果量太大，有可能会出现性能问题。而这种方案在实现的时候，可以用cache和数据库结合的实现方式，保证高效和稳定。同时，针对一些接口，可以做性能的优化，提升查询效率； C、对外封闭，保证数据安全。这种方式还有一个好处，就是可以将加密算法、密钥等封闭在系统内部，对外只暴露接口，使得数据安全性更有保障。（涉及到用户信息的，都是隐私！） 不过，这种方式也有自己的问题，就是运维相对更复杂，有可能需要专门的团队去管理这些系统。 参考：http://blog.csdn.net/zgwangbo/article/details/51636721 负载均衡DNS负载均衡反向代理负载均衡IP负载均衡 http://www.cnblogs.com/itfly8/p/5043435.htmlhttp://lobert.iteye.com/blog/2159970 ConcurrentHashmap详细见 Java - ConcurrentHashmap ConcurrentHashMap 的高并发性主要来自于三个方面： 用分离锁实现多个线程间的更深层次的共享访问。（Segment继承重入锁，并且管理一定范围的数组） 用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。（就是说当需要对链表结构进行改变时，对链表进行复制，先不更改原来的链表，然后操作完成之后再把table切换过去，在put/remove中体现） 通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。 put/get：1、key存在：value是volatile保证可见，并且写在读之前 2、key不存在，需要插入：头插法，不影响读线程的遍历remove/get：删除节点后面的不变，删除节点的前面节点头插法，复制完之后切换table，不影响读线程的遍历clear/get：将table的置空，读线程仍可以访问原来的链表 get： 1、首先HashEntry对象必须用volatile修饰，否则可能会出现返回结果不为null，但是对象不可用；原因和双重检查锁定时必须将实例设为volatile一样，查看ConcurrentHashMap文章或设计模式的艺术之道笔记 2、如果的得到结果不为null，直接返回3、如果得到的结果为null，1、可能对象不存在 2、对象刚被put线程放进去，写线程的确获取不到，读的是脏数据 =&gt; 这两种情况返回节点都指向table，如果查询的结果的确是刚插入的元素，释放锁后就能得到刚插入的结果，否则还是返回null 另一个考点： ConcurrentHashMap的key和value不能为null happen before① 程序次序法则：线程中的每个动作A都happens-before于该线程中的每一个动作B，其中，在程序中，所有的动作B都能出现在A之后。② 监视器锁法则：对一个监视器锁的解锁 happens-before于每一个后续对同一监视器锁的加锁。③ volatile变量法则：对volatile域的写入操作happens-before于每一个后续对同一个域的读写操作。④ 线程启动法则：在一个线程里，对Thread.start的调用会happens-before于每个启动线程的动作。⑤ 线程终结法则：线程中的任何动作都happens-before于其他线程检测到这个线程已经终结、或者从Thread.join调用中成功返回，或Thread.isAlive返回false。⑥ 中断法则：一个线程调用另一个线程的interrupt happens-before于被中断的线程发现中断。⑦ 终结法则：一个对象的构造函数的结束happens-before于这个对象finalizer的开始。⑧ 传递性：如果A happens-before于B，且B happens-before于C，则A happens-before于C 我们重点关注的是②，③，这两条也是我们通常编程中常用的。 volatile作用： 1、可见性：共享变量直接在主存操作，保证可见性2、禁止指令重排：对变量进行写操作后，会产生一个内存栅栏，保证读操作必须在写操作之后，且写操作对读操作可见 应用： 1、单线程写，多线程读2、多线程写，但是写入的值不依赖于原值 为什么用volatile修饰，多线程i++的时候计数失败？ i++不是原子操作，分为三步：1、读取 2、修改 3、写入 volatile 操作保证读操作在写操作之后，如果按以下操作： 1、读取 2、读取 1、修改 1、写入 即多线程会对共享变量进行多次读，造成脏读；如果多线程写入不依赖原值，那么volatile可以保持同步 生产者消费者wait和sleep的区别(释放锁)A类B类C类IP地址]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis底层数据结构]]></title>
    <url>%2F2017%2F07%2F17%2F%5BRedis%5DRedis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Redis单进程单线程执行速度快的原因总体来说快速的原因如下： 1）绝大部分请求是纯粹的内存操作（非常快速）2）采用单线程,避免了不必要的上下文切换和竞争条件3）非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间 这3个条件不是相互独立的，特别是第一条，如果请求都是耗时的，采用单线程吞吐量及性能可想而知了。应该说redis为特殊的场景选择了合适的技术方案。 Redis数据结构总体设计首先，Redis没有MySQL那样的索引机制，因为其内建一个基于hash的字典，如下图： Redis 计算哈希值和索引值的方法如下： # 使用字典设置的哈希函数，计算键 key 的哈希值hash = dict-&gt;type-&gt;hashFunction(key); # 使用哈希表的 sizemask 属性和哈希值，计算出索引值# 根据情况不同， ht[x] 可以是 ht[0] 或者 ht[1]index = hash &amp; dict-&gt;ht[x].sizemask;插入数据时，根据以上算出index，然后根据index值放入table表中相应位置即可。 QM注释：1、每个dictht为一个map结构，字典dict中有两个map2、map为key、value的结构，value可以为各种数据类型，包括字符串、链表… 字符串例如：Set hello world 字符串类似Java中的String对象，存储类似HashMap，key为字符串的名字，value为String对象 list类型例如：Lpush list aaaa bbb ccc // 双向链表 typedef struct listNode { struct listNode *prev; struct listNode *next; void *value; } listNode; //数据结构 + 操作 typedef struct list { listNode *head; listNode *tail; ... } list; 链表类似Java中的LinkedList，定义每个链表时取一个名称；存储类似HashMap，key为链表的名称，value为list对象 hash类型例如：Hset test hello world 存储类似HashMap，key为hash表的名称，value为hash表 注：新建一个hash对象时开始是用zipmap(又称为small hash)来存储的。这个zipmap其实并不是hash table，但是zipmap相比正常的hash实现可以节省不少hash本身需要的一些元数据存储开销。尽管zipmap的添加，删除，查找都是O(n)，但是由于一般对象的field数量都不太多。所以使用zipmap也是很快的,也就是说添加删除平均还是O(1)。如果field或者value的大小超出一定限制后，Redis会在内部自动将zipmap替换成正常的hash实现（一个key对应一个hash表）。 Set集合，常用来存储不重复数据的数据结构，底层基于hashtable；在redis中为了优化存储，set的编码类型可以为：intset，hashtable。 Sorted Set(ZSet)链表+跳跃表 https://mp.weixin.qq.com/s/RDHebf6IfLWfw38dPvfiZQ 参考http://www.cnblogs.com/renzherushe/p/4779390.html Redis过期检测Redis对于过期检测，有2种方式，一个主动检测，一个是被动检测；在redis和client交互过程中，对于任何数据的操作，都会首先检测key是否已经过期，这是被动检测；主动检测是Redis启动的后台线程中，不间断的随机扫描一定量的key（randomKey），并对key进行过期检测]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap]]></title>
    <url>%2F2017%2F06%2F29%2F%5BJDK%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%5DLinkedHashMap%2F</url>
    <content type="text"><![CDATA[设计1、Entry节点增加了after、before两个指针，组成双向链表，记录节点插入顺序 private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; { Entry&lt;K,V&gt; before, after; } 2、LinkedHashMap保存头节点指针，插入的方式都采用头插法，因为是双向链表，可以轻易插在头部和尾部 public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; { private transient Entry&lt;K,V&gt; header; } 3、LinkHashMap有一个成员变量accessOrder，表示链表的保存顺序，默认是false，按照插入顺序保存。 private final boolean accessOrder; 注意：因为插入时采用的是头插法，所以链表的存储顺序是逆序的，即先插入的在尾部，但是迭代器在遍历的时候从尾到头的顺序，所以不影响 如果想实现LRU的方式，按照访问顺序的方式存储节点，构造LinkedHashMap的时候accessOrder设为true public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder; } 源码关键//LinkedHashMap方法 public V get(Object key) { Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; e.recordAccess(this); return e.value; } //HashMap方法 public V put(K key, V value) { if (key == null) return putForNullKey(value); int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null; } 1、当调用get或者put方法的时候，如果K-V已经存在，会回调Entry.recordAccess()方法 当 accessOrder 为 true，即按LRU的策略存储，会先调用 remove 清除的当前首尾元素的指向关系，之后调用addBefore方法，将当前元素加入header之前。 /** * This method is invoked by the superclass whenever the value * of a pre-existing entry is read by Map.get or modified by Map.set. * If the enclosing Map is access-ordered, it moves the entry * to the end of the list; otherwise, it does nothing. */ void recordAccess(HashMap&lt;K,V&gt; m) { LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) { lm.modCount++; remove(); addBefore(lm.header); } } /** * Remove this entry from the linked list. */ private void remove() { before.after = after; after.before = before; } /** * Insert this entry before the specified existing entry in the list. */ private void addBefore(Entry&lt;K,V&gt; existingEntry) { after = existingEntry; before = existingEntry.before; before.after = this; after.before = this; } 2、put操作时，如果key不存在，当有新元素加入 Ma p的时候会调用 Entry 的 addEntry 方法，会调用 removeEldestEntry 方法，这里就是实现LRU元素过期机制的地方，默认的情况下removeEldestEntry方法只返回false表示元素永远不过期。 /** * This override alters behavior of superclass put method. It causes newly * allocated entry to get inserted at the end of the linked list and * removes the eldest entry if appropriate. */ void addEntry(int hash, K key, V value, int bucketIndex) { createEntry(hash, key, value, bucketIndex); // Remove eldest entry if instructed, else grow capacity if appropriate Entry eldest = header.after; if (removeEldestEntry(eldest)) { removeEntryForKey(eldest.key); } else { if (size >= threshold) resize(2 * table.length); } } /** * This override differs from addEntry in that it doesn't resize the * table or remove the eldest entry. */ void createEntry(int hash, K key, V value, int bucketIndex) { HashMap.Entry old = table[bucketIndex]; Entry e = new Entry(hash, key, value, old); table[bucketIndex] = e; e.addBefore(header); size++; } protected boolean removeEldestEntry(Map.Entry eldest) { return false; } 实现LRULRU缓存LinkedHashMap(inheritance)实现 采用inheritance方式实现比较简单，而且实现了Map接口，在多线程环境使用时可以使用 Collections.synchronizedMap()方法实现线程安全操作 1、构造函数中调用父类的构造函数，accessOrder设置为true2、重写removeEldestEntry，当元素数量大于缓存最大数量时，删除 import java.util.LinkedHashMap; import java.util.Map; public class LRUCache2 extends LinkedHashMap { private final int MAX_CACHE_SIZE; public LRUCache2(int cacheSize) { super ((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); MAX_CACHE_SIZE = cacheSize; } @Override protected boolean removeEldestEntry(Map.Entry eldest) { return size() > MAX_CACHE_SIZE; } @Override public String toString() { StringBuilder sb = new StringBuilder(); for (Map.Entry entry : entrySet()) { sb.append(String.format("%s:%s ", entry.getKey(), entry.getValue())); } return sb.toString(); } } 实现FIFO1、只需重写removeEldestEntry就行，默认accessOrder就是false2、重写removeEldestEntry方法，当缓存个数大于最大个数时，删除最先放进去的元素 final int cacheSize = 5; LinkedHashMap&lt;Integer, String&gt; lru = new LinkedHashMap&lt;Integer, String&gt;() { @Override protected boolean removeEldestEntry(Map.Entry&lt;Integer, String&gt; eldest) { return size() &gt; cacheSize; } }; 参考LRU缓存实现(Java) http://transcoder.tradaquan.com/from=1086k/bd_page_type=1/ssid=0/uid=0/pu=usm%401%2Csz%40320_1002%2Cta%40iphone_2_5.1_2_6.0/baiduid=99806F566512D4B5CD2F1444260EE0C9/w=0_10_/t=iphone/l=3/tc?ref=www_iphone&amp;lid=7454783636244085594&amp;order=1&amp;fm=alop&amp;h5ad=1&amp;srd=1&amp;dict=32&amp;tj=www_normal_1_0_10_title&amp;url_mf_score=4&amp;vit=osres&amp;m=8&amp;cltj=cloud_title&amp;asres=1&amp;title=LRU%E7%BC%93%E5%AD%98%E5%AE%9E%E7%8E%B0%28Java%29-%E6%87%92%E6%83%B0%E7%9A%84%E8%82%A5%E5%85%94-%E5%8D%9A%E5%AE%A2%E5%9B%AD&amp;w_qd=IlPT2AEptyoA_yitJU7mHiU5vhXPLqCyZhaDQ_&amp;sec=22108&amp;di=8c5570f1d6ae3a47&amp;bdenc=1&amp;nsrc=IlPT2AEptyoA_yixCFOxXnANedT62v3IEQGG_ytK1DK6mlrte4viZQRAXinhMXmYGlGwdoSOxBt8w83c_79j7QwTaP1s&amp;clk_info=%7B%22srcid%22%3A%221599%22%2C%22tplname%22%3A%22www_normal%22%2C%22t%22%3A1498709801466%2C%22sig%22%3A%221646%22%2C%22xpath%22%3A%22div-a-h3%22%7D 基于LinkedHashMap实现LRU缓存调度算法原理及应用 http://woming66.iteye.com/blog/1284326]]></content>
      <categories>
        <category>JDK源码阅读</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12、迷宫问题-最短路径]]></title>
    <url>%2F2017%2F06%2F28%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D12%E3%80%81%E8%BF%B7%E5%AE%AB%E9%97%AE%E9%A2%98-%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[题目从（0，0）开始，目的地是（5，7），0表示可以走，1表示不可走，要求最短路径 几个重点0、广度优先搜索找到的是最短路径 上次提交的层次遍历就是广度优先搜索 //层次遍历模版 Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); //将根元素放入队列 queue.offer(root); while(!queue.isEmpty()){ //从队头取出元素，并访问 TreeNode node = queue.poll(); result.add(node.val); //将左右节点放入队列 if(node.left != null){ queue.offer(node.left); } if(node.right != null){ queue.offer(node.right); } } 1、运行8个方向：上、右上、右、右下、下、左下、左、左上 int[] x = {0, 1, 1, 1, 0, -1, -1, -1}; int[] y = {1, 1, 0, -1, -1, -1, 0, 1}; 2、记录已经访问过 0表示可以访问，访问之后变成1，这样每个点只被访问一下 3、如何记录路径 Point[][] pre = new Point[map.length][map[0].length]; 一个二维数组，（i，j）记录上一个路径 4、注意点： 开始节点访问之后，记得标注为1 代码import java.util.ArrayList; import java.util.Collections; import java.util.LinkedList; import java.util.Queue; public class Solution { public void BFS(int[][] map, Point start, Point end) { //基于当前节点上一个路径 Point[][] pre = new Point[map.length][map[0].length]; pre[start.x][start.y] = start; //队列 Queue&lt;Point&gt; queue = new LinkedList&lt;Point&gt;(); queue.offer(start); map[start.x][start.y] = 1; //遍历方向 int[] x = {0, 1, 1, 1, 0, -1, -1, -1}; int[] y = {1, 1, 0, -1, -1, -1, 0, 1}; while (!queue.isEmpty()) { Point current = queue.poll(); //8个方向遍历 for (int i = 0; i &lt; x.length; i++) { //判断是否越界，是否已经访问 Point next = new Point(current.x + x[i], current.y + y[i]); //达到目录 if (next.x == end.x &amp;&amp; next.y == end.y) { System.out.println(next); for (Point t = current; current != pre[current.x][current.y]; current = pre[current.x][current.y]) { System.out.println(current); } System.out.println(start); return; } if (next.x &gt;= 0 &amp;&amp; next.x &lt;= end.x &amp;&amp; next.y &gt;= 0 &amp;&amp; next.y &lt;= end.y &amp;&amp; map[next.x][next.y] == 0) {//0表示可以访问 queue.offer(next); map[next.x][next.y] = 1;//标记已经访问过了 pre[next.x][next.y] = current;//记录路径 } } } } public static void main(String[] args) { int[][] map = { {0, 1, 0, 1, 0, 0, 0, 1}, {1, 0, 0, 1, 1, 0, 1, 0}, {0, 1, 1, 0, 0, 1, 1, 1}, {1, 0, 0, 1, 1, 0, 0, 1}, {1, 0, 0, 0, 1, 1, 0, 1}, {0, 1, 1, 1, 0, 0, 0, 0} }; Solution s = new Solution(); s.BFS(map, new Point(0, 0), new Point(map.length - 1, map[0].length - 1)); } } class Point { int x; int y; public Point(int x, int y) { this.x = x; this.y = y; } @Override public String toString() { return &quot;Point{&quot; + &quot;x=&quot; + x + &quot;, y=&quot; + y + &apos;}&apos;; } }]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11、深度优先搜索、广度优先搜索]]></title>
    <url>%2F2017%2F06%2F28%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D11%E3%80%81%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E3%80%81%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[迷宫问题（深度优先搜索解法）题目从（0，0）开始，目的地是（5，7），0表示可以走，1表示不可走，求所有路径 几个关键点： 1、深度优先模版 如果下一个路径没有越界，而且可以访问（数组中的值是0），那么继续在下一个节点上继续进行深度优先搜索 public void DFS(int[][] map, Point current, Point start, Point end) { //遍历方向 int[] x = {0, 1, 1, 1, 0, -1, -1, -1}; int[] y = {1, 1, 0, -1, -1, -1, 0, 1}; for (int i = 0; i &lt; x.length; i++) { Point next = new Point(current.x + x[i], current.y + y[i]); //剪枝 if (next.x &gt;= 0 &amp;&amp; next.x &lt;= end.x &amp;&amp; next.y &gt;= 0 &amp;&amp; next.y &lt;= end.y &amp;&amp; map[next.x][next.y] == 0) { DFS(map, next, start, end); } } } 运行程序的时候发现一个问题，会出现相邻路径来回走，导致栈溢出，所以需要设置在当前遍历的路径中做上标记，在往前搜索的过程中不走回头路 2、标记访问路径 上图所示的就是来回走的一个案例，这个的解决方法就是在访问到节点后，设置标志位为1。 但是这会出现一个问题：如果这条路不通，换条路径访问的时候这个节点应该还是需要可以访问的，所以在这条路径回溯的时候，需要重新标注节点为未访问 貌似标记的地方每次都是的DFS（）这个函数之前、之后 map[next.x][next.y] = 1; DFS(map, next, start, end); map[next.x][next.y] = 0; 3、记录路径 貌似每次也都是在DFS之前添加路径，在DFS之后删除路径 path.add(next); DFS(map, next, start, end); path.remove(path.size() - 1); 4、 5、小技巧，防止起始点和终点被遍历到，初始化时将开头和结尾置为1 int[][] map = { {0, 1, 0, 1, 0, 0, 0, 1}, {1, 0, 0, 1, 1, 0, 1, 0}, {0, 1, 1, 0, 0, 1, 1, 1}, {1, 0, 0, 1, 1, 0, 0, 1}, {1, 0, 0, 0, 1, 1, 0, 1}, {0, 1, 1, 1, 0, 0, 0, 0} }; map[0][0] = 1; map[5][7] = 1; 完整代码 //current参数是重点，别的只是信息传递 public void DFS(int[][] map, Point current, Point start, Point end) { //遍历方向 int[] x = {0, 1, 1, 1, 0, -1, -1, -1}; int[] y = {1, 1, 0, -1, -1, -1, 0, 1}; for (int i = 0; i &lt; x.length; i++) { Point next = new Point(current.x + x[i], current.y + y[i]); //找到了 if (next.x == end.x &amp;&amp; next.y == end.y) { System.out.println(&quot;找到了：&quot; + ++count); System.out.println(path); continue; } //剪枝 if (next.x &gt;= 0 &amp;&amp; next.x &lt;= end.x &amp;&amp; next.y &gt;= 0 &amp;&amp; next.y &lt;= end.y &amp;&amp; map[next.x][next.y] == 0) { System.out.println(next); path.add(next); map[next.x][next.y] = 1; DFS(map, next, start, end); map[next.x][next.y] = 0; path.remove(path.size() - 1); } } } public static void main(String[] args) { int[][] map = { {0, 1, 0, 1, 0, 0, 0, 1}, {1, 0, 0, 1, 1, 0, 1, 0}, {0, 1, 1, 0, 0, 1, 1, 1}, {1, 0, 0, 1, 1, 0, 0, 1}, {1, 0, 0, 0, 1, 1, 0, 1}, {0, 1, 1, 1, 0, 0, 0, 0} }; Solution s = new Solution(); //s.BFS(map, new Point(0, 0), new Point(map.length - 1, map[0].length - 1)); map[0][0] = 1; map[5][7] = 1; s.DFS(map, new Point(0, 0), new Point(0, 0), new Point(map.length - 1, map[0].length - 1)); } 迷宫问题（广度优先搜索解法）]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10、全排列（DFS+剪枝）]]></title>
    <url>%2F2017%2F06%2F28%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D10%E3%80%81%E5%85%A8%E6%8E%92%E5%88%97%EF%BC%88DFS%2B%E5%89%AA%E6%9E%9D%EF%BC%89%2F</url>
    <content type="text"><![CDATA[题目：全排列例如ABC，全排列的结果是ABC、ACB、BAC、BCA、CAB、CBA 递归穷举1、穷举，遍历出所有结果。因为对于长度为n的字符串，需要n层for循环，代码没法写，所以需要利用递归实现 for(int i = 0; i &lt; str.length(); i++){ for(int i = 0; i &lt; str.length(); i++){ for(int i = 0; i &lt; str.length(); i++){ .....长度为n的字符串需要写n个for，代码没法写了 } } } 写成递归的形式： public void DFS(int step) { //递归结束 if(step &gt;= str.length()){ return; } for (int i = 0; i &lt; str.length(); i++) { System.out.println(str.charAt(i)); DFS(step + 1);//进去都是for循环，和多个嵌套for一样，要注意结束点 } } 遍历结果： a、a、a、b、c、b、a、b、c、c、a、b、cb、a、a、b、c、b、a、b、c、c、a、b、cc、a、a、b、c、b、a、b、c、c、a、b、c 参照画的图，结果一致： 记录路径还是以循环的形式考虑，这个很容易理解 List&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); for (int i = 0; i &lt; str.length(); i++) { path.add(i); for (int j = 0; j &lt; str.length(); j++) { path.add(j); for (int k = 0; k &lt; str.length(); k++) { path.add(k); //输出 System.out.println(path); path.remove(path.size() - 1); } path.remove(path.size() - 1); } path.remove(path.size() - 1); } 输出结果： [0, 0, 0] [0, 0, 1] [0, 0, 2] [0, 1, 0] [0, 1, 1] [0, 1, 2] [0, 2, 0] [0, 2, 1] [0, 2, 2] [1, 0, 0] [1, 0, 1] [1, 0, 2] [1, 1, 0] [1, 1, 1] [1, 1, 2] [1, 2, 0] [1, 2, 1] [1, 2, 2] [2, 0, 0] [2, 0, 1] [2, 0, 2] [2, 1, 0] [2, 1, 1] [2, 1, 2] [2, 2, 0] [2, 2, 1] [2, 2, 2] 现在改成递归的方式应该很容易了吧，你知道哪里应该add，哪里应该remove了 public class Permutation { String str; List&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); public void DFS(int step) { if (step &gt;= str.length()) { return; } for (int i = 0; i &lt; str.length(); i++) { path.add(i); if(path.size() == str.length()){ System.out.println(path); } DFS(step + 1); path.remove(path.size() - 1); } } public static void main(String[] args) { String str = &quot;abc&quot;; Permutation s = new Permutation(); s.str = str; s.DFS(0); } } 有个问题：输出是放在DFS（step + 1）前还是后面？ if(path.size() == str.length()){ System.out.println(path); } 如果到达最后一层循环，这个DFS（step+1）相当于空函数！！，所以输出放在DFS(step + 1)前或者后都一样 for (int i = 0; i &lt; str.length(); i++) { //System.out.println(str.charAt(i)); path.add(i); if(path.size() == str.length()){ System.out.println(path); } DFS(step + 1); path.remove(path.size() - 1); } 剪枝 红色描绘的路径是符合条件的全排列，观察后发现： 访问的路径节点之前已经存在，那么就需要剪枝 路径刚才我们已经保存了，所以可以做到 加入节点前需要判断这个节点是否已经存在 if(path.contains(i)){ continue; } 完整代码递归完整版 public class Permutation { String str; List&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); public void DFS(int step) { if (step &gt;= str.length()) { return; } for (int i = 0; i &lt; str.length(); i++) { if(path.contains(i)){ continue; } path.add(i); //输出 if(path.size() == str.length()){ //System.out.println(path); for(Integer t : path){ System.out.print(str.charAt(t) + &quot; &quot;); } System.out.println(); } DFS(step + 1); path.remove(path.size() - 1); } } public static void main(String[] args) { String str = &quot;abc&quot;; Permutation s = new Permutation(); s.str = str; s.DFS(0); } } 循环完整版 List&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); for (int i = 0; i &lt; str.length(); i++) { if(path.contains(i)){ continue; } path.add(i); for (int j = 0; j &lt; str.length(); j++) { if(path.contains(j)){ continue; } path.add(j); for (int k = 0; k &lt; str.length(); k++) { if(path.contains(k)){ continue; } path.add(k); //输出 //System.out.println(path); for(Integer t : path){ System.out.print(str.charAt(t) + &quot; &quot;); } System.out.println(); path.remove(path.size() - 1); } path.remove(path.size() - 1); } path.remove(path.size() - 1); } } 如果有重复如果输入aac，将会输出 a a c a c a a a c a c a c a a c a a 有重复，为什么？为了区分用a1，a2表示 下图为按照未重复的时候的结果进行遍历、剪枝，打钩的即为需要保留的元素，与程序运行的一致 下图中圈出来的路径需要被剪去，思考一下有什么特征？ a2、a1、c a2、c、a1 c、a2、a1 如果之前路径有相同的元素（这里是判断值相等，刚才是判断下标是否相等），而且当前下标比之前的小，则剪去 代码如下： //重复元素 boolean flag = false; for(Integer t : path){ if(str.charAt(t) == str.charAt(i) &amp;&amp; i &lt; t){ flag = true; break; } } if(flag){ continue; } 完整代码： public class Permutation { String str; List&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); public void DFS(int step) { if (step &gt;= str.length()) { return; } for (int i = 0; i &lt; str.length(); i++) { if(path.contains(i)){ continue; } //重复元素 boolean flag = false; for(Integer t : path){ if(str.charAt(t) == str.charAt(i) &amp;&amp; i &lt; t){ flag = true; break; } } if(flag){ continue; } path.add(i); //输出 if(path.size() == str.length()){ //System.out.println(path); for(Integer t : path){ System.out.print(str.charAt(t) + &quot; &quot;); } System.out.println(); } DFS(step + 1); path.remove(path.size() - 1); } } public static void main(String[] args) { String str = &quot;aaaa&quot;; Permutation s = new Permutation(); s.str = str; s.DFS(0); } }]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap★★★（Happen Before、Volatile）]]></title>
    <url>%2F2017%2F06%2F27%2F%5BJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%5DConcurrentHashMap%E2%98%85%E2%98%85%E2%98%85%EF%BC%88Happen%20Before%E3%80%81Volatile%EF%BC%89%2F</url>
    <content type="text"><![CDATA[结构 Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护其（成员对象 table 中）包含的若干个桶。 并发读写考虑1、非结构性修改操作只是更改某个 HashEntry 的 value 域的值。由于对 Volatile 变量的写入操作将与随后对这个变量的读操作进行同步。当一个写线程修改了某个 HashEntry 的 value 域后，另一个读线程读这个值域，Java 内存模型能够保证读线程读取的一定是更新后的值。所以，写线程对链表的非结构性修改能够被后续不加锁的读线程”看到”。 2、put-读 情况一：key已经存在，put操作为非结构性修改，查看1 情况二：新插入节点 put 操作如果需要插入一个新节点到链表中时 , 会在链表头部插入这个新节点。此时，链表中的原有节点的链接并没有被修改。 采用头插法插入节点不影响读，每次遍历都是从头结点table[x]开始，即不影响读的遍历 3、remove-读 和 get 操作一样，首先根据散列码找到具体的链表；然后遍历这个链表找到要删除的节点；最后把待删除节点之后的所有节点原样保留在新链表中，把待删除节点之前的每个节点克隆到新链表中，直到复制完之后将table引用过去 下面通过图例来说明 remove 操作。假设写线程执行 remove 操作，要删除链表的 C 节点，另一个读线程同时正在遍历这个链表 在执行 remove 操作时，原始链表并没有被修改，也就是说：读线程不会受同时执行 remove 操作的并发写线程的干扰。 4、clear-读 void clear() { if (count != 0) { lock(); try { HashEntry&lt;K,V&gt;[] tab = table; for (int i = 0; i &lt; tab.length ; i++) tab[i] = null; ++modCount; count = 0; // write-volatile } finally { unlock(); } } } clear 操作只是把 ConcurrentHashMap 中所有的桶”置空”，每个桶之前引用的链表依然存在，只是桶不再引用到这些链表（所有链表的结构并没有被修改）。正在遍历某个链表的读线程依然可以正常执行对该链表的遍历。 ConcurrentHashMap的get操作(volatile)★★★★★get操作的高效之处在于整个get过程不需要加锁，除非读到的值是空的才会加锁重读？，我们知道HashTable容器的get方法是需要加锁的，那么ConcurrentHashMap的get操作是如何做到不加锁的呢？ 原因是它的get方法里将要使用的共享变量都定义成volatile，如用于统计当前Segement大小的 count 字段和用于存储值的 HashEntry 的 value。 定义成volatile的变量，能够在线程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，就是写入的值不依赖于原值），在get操作里只需要读不需要写共享变量count和value，所以可以不用加锁。 之所以不会读到过期的值，是根据 java 内存模型的 happen before 原则，对 volatile 字段的写入操作先于读操作，即使两个线程同时修改和获取volatile变量，get操作也能拿到最新的值，这是用volatile替换锁的经典应用场景。 源码分析： V get(Object key, int hash) { if (count != 0) { // read-volatile // ① HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null) { if (e.hash == hash &amp;&amp; key.equals(e.key)) { V v = e.value; if (v != null) // ② 注意这里 return v; return readValueUnderLock(e); // recheck } e = e.next; } } return null; } 第一步，先判断一下 count != 0；count变量表示segment中存在entry的个数。如果为0就不用找了。 假设这个时候恰好另一个线程put或者remove了这个segment中的一个entry，会不会导致两个线程看到的count值不一致呢？ 看一下count变量的定义： transient volatile int count; 它使用了volatile来修改。我们前文说过，Java5之后，JMM实现了对volatile的保证：对volatile域的写入操作happens-before于每一个后续对同一个域的读写操作。所以，每次判断count变量的时候，即使恰好其他线程改变了segment也会体现出来。 第二步，获取到要该key所在segment中的索引地址，如果该地址有相同的hash对象，顺着链表一直比较下去找到该entry。当找到entry的时候，先做了一次比较： if(v != null) ，这是为何呢？即如果get得到的结果是null，需要加锁读，否则直接返回 考虑一下，如果这个时候，另一个线程恰好新增/删除了entry，或者改变了entry的value，会如何？ 1) 在get代码的①和②之间，另一个线程新增了一个entry 因为每个HashEntry中的next也是final的，没法对链表最后一个元素增加一个后续entry所以新增一个entry的实现方式只能通过头结点来插入了。 newEntry对象是通过 new HashEntry(K k , V v, HashEntry next) 来创建的。如果另一个线程刚好 new 这个对象时，当前线程来 get 它。因为没有同步，就可能会出现当前线程得到的newEntry对象是一个没有完全构造好的对象引用。 回想一下我们之前讨论的DCL的问题，这里也一样，没有锁同步的话，new 一个对象对于多线程看到这个对象的状态是没有保障的，这里同样有可能一个线程new这个对象的时候还没有执行完构造函数就被另一个线程得到这个对象引用。 所以才需要判断一下：if (v != null) 如果确实是一个不完整的对象，则使用锁的方式再次get一次。 有没有可能会put进一个value为null的entry？ 不会的，已经做了检查，这种情况会抛出异常，所以 ②处的判断完全是出于对多线程下访问一个new出来的对象的状态检测。 注意：是否会出现 v！=null，但是返回的对象没有初始化，存在隐患？ 如果对象HashEntry没有被volatile修饰，会出现这种情况。但是查看定义，HashEntry[]被volatile修饰。 那么为什么不被volatile修饰，new HashEntry会出现引用不为null，但是对象未被初始化？ 因为new的操作不是原子操作，分为1、分配内存 2、实例化 3、引用指向内存（此时不为null） 但是指令重排序后，可能会出现1，3，2，此时在3是时候读取对象时不为null，但是对象未被初始化，出现隐患 使用volatile修饰后，根据happen before原则，读操作必须在写之后，而且读线程是可见的 所以，如果得到对象！=null，说明找到对象了，如果=null，可能是不存在，也可能是刚刚添加进去，等到put线程更新table指针，注意此时返回的元素是头指针，如果查找的就是刚刚添加的元素，释放锁后就能返回插入的结果 2) 在get代码的①和②之间，另一个线程修改了一个entry的value value是用volitale修饰的，可以保证读取时获取到的是修改后的值。 3) 在get代码的①之后，另一个线程删除了一个entry 假设我们的链表元素是：e1-&gt; e2 -&gt; e3 -&gt; e4 我们要删除 e3这个entry，因为HashEntry中next的不可变，所以我们无法直接把e2的next指向e4，而是将要删除的节点之前的节点复制一份，形成新的链表。 它的实现大致如下图所示： 如果我们get的也恰巧是e3，可能我们顺着链表刚找到e1，这时另一个线程就执行了删除e3的操作，而我们线程还会继续沿着旧的链表找到e3返回。这里没有办法实时保证了。 我们第①处就判断了count变量，它保障了在 ① 处能看到其他线程修改后的。①之后到②之间，如果再次发生了其他线程再删除了entry节点，就没法保证看到最新的了。 不过这也没什么关系，即使我们返回e3的时候，它被其他线程删除了，暴漏出去的e3也不会对我们新的链表造成影响。 这其实是一种乐观设计，设计者假设 ① 之后到 ② 之间发生被其它线程增、删、改的操作可能性很小，所以不采用同步设计，而是采用了事后（其它线程这期间也来操作，并且可能发生非安全事件）弥补的方式。 而因为其他线程的”改”和”删”对我们的数据都不会造成影响，所以只有对”新增”操作进行了安全检查，就是②处的非null检查，如果确认不安全事件发生，则采用加锁的方式再次get。 总结★★★★★ConcurrentHashMap 的高并发性主要来自于三个方面： 用分离锁实现多个线程间的更深层次的共享访问。 用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。（就是说当需要对链表结构进行改变时，对链表进行复制，先不更改原来的链表，然后操作完成之后再把table切换过去，在put/remove中体现） 通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。 Happen-Before① 程序次序法则：线程中的每个动作A都happens-before于该线程中的每一个动作B，其中，在程序中，所有的动作B都能出现在A之后。② 监视器锁法则：对一个监视器锁的解锁 happens-before于每一个后续对同一监视器锁的加锁。③ volatile变量法则：对volatile域的写入操作happens-before于每一个后续对同一个域的读写操作。④ 线程启动法则：在一个线程里，对Thread.start的调用会happens-before于每个启动线程的动作。⑤ 线程终结法则：线程中的任何动作都happens-before于其他线程检测到这个线程已经终结、或者从Thread.join调用中成功返回，或Thread.isAlive返回false。⑥ 中断法则：一个线程调用另一个线程的interrupt happens-before于被中断的线程发现中断。⑦ 终结法则：一个对象的构造函数的结束happens-before于这个对象finalizer的开始。⑧ 传递性：如果A happens-before于B，且B happens-before于C，则A happens-before于C 我们重点关注的是②，③，这两条也是我们通常编程中常用的。 加锁使用锁方式实现”Happens-before”是最简单，容易理解的。 早期Java中的锁只有最基本的synchronized，它是一种互斥的实现方式。在Java5之后，增加了一些其它锁，比如ReentrantLock，它基本作用和synchronized相似，但提供了更多的操作方式，比如在获取锁时不必像synchronized那样只是傻等，可以设置定时，轮询，或者中断，这些方法使得它在获取多个锁的情况可以避免死锁操作。 VolatileJMM对Volatile的定义是：保证读写volatile都直接发生在main memory中，线程的working memory不进行缓存。它只承诺了读和写过程的可见性 Volatile可以看做一种轻量级的锁，但又和锁有些不同。 a) 它对于多线程，不是一种互斥（mutex）关系。b) 用volatile修饰的变量，不能保证该变量状态的改变对于其他线程来说是一种”原子化操作”。 那对于”原子化操作”怎么理解呢？看下面例子： private static volatile int nextSerialNum = 0; public static int generateSerialNumber(){ return nextSerialNum++; } 上面代码中对nextSerialNum使用了volatile来修饰，根据前面”Happens-Before”法则的第三条Volatile变量法则，看似不同线程都会得到一个新的serialNumber 问题出在了 nextSerialNum++ 这条语句上，它不是一个原子化的，实际上是read-modify-write三项操作，这就有可能使得在线程1在write之前，线程2也访问到了nextSerialNum，造成了线程1和线程2得到一样的serialNumber。所以，在使用Volatile时，需要注意 使用场景： 单线程写 被多线程写，就是写入的值不依赖于原值 final关键字不变模式（immutable）是多线程安全里最简单的一种保障方式。因为你拿他没有办法，想改变它也没有机会。 不变模式主要通过final关键字来限定的。在JMM中final关键字还有特殊的语义。Final域使得确保初始化安全性（initialization safety）成为可能，初始化安全性让不可变形对象不需要同步就能自由地被访问和共享。 用Happens-Before规则理解一个经典问题：双重检测锁(DCL)为什么在java中不适用？public class LazySingleton { private static LazySingleton instance; private LazySingleton(){} public static LazySingleton getInstance() { if (instance == null) {// (2) synchronized (LazySingleton.class) { // (3) if (instance == null) { // (4) instance = new LazySingleton(); // (5) } } } return instance; // (6) } } 假设线程1执行完(5)时，线程2正好执行到了(2)； 看看 new LazySingleton(); 这个语句的执行过程： 它不是一个原子操作，实际是由多个步骤，我们从我们关注的角度简化一下，简单的认为它主要有2步操作好了： a） 在内存中分配空间，并将引用指向该内存空间。b） 执行对象的初始化的逻辑(和操作)，完成对象的构建。 此时因为线程1和线程2没有用同步，他们之间不存在”Happens-Before”规则的约束，所以在线程1创建LazySingleton对象的 a),b)这两个步骤对于线程2来说会有可能出现a)可见，b)不可见造成了线程2获取到了一个未创建完整的lazySingleton对象引用，为后边埋下隐患。 思考多线程程序设计时需要考虑读-读、读-写、写-写 可以并发读：读不加锁不能并发写：写加锁写的时候不能影响正在读，或从头开始遍历的读 参考http://blog.csdn.net/jianghuxiaojin/article/details/52006110 http://blog.csdn.net/seapeak007/article/details/53409618]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建高可用的系统]]></title>
    <url>%2F2017%2F06%2F26%2F%5B%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%5D%E6%9E%84%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[负载均衡负载均衡分为硬件负载均衡和软件负载均衡 防止单点负载均衡为避免自己成为单点，通常由两台机器构成，但只有一台处于服务状态，另一台则处于standby状态。一旦处于服务的那台机器出现问题，standby这台会自动接管 负载均衡策略用户发送请求到负载均衡机器，负载均衡机器再将请求转发给实际的业务处理机器，通常负载均衡机器知道实际业务处理机器的IP地址，选择的方式如下： 1、随机选择2、Hash选择。对应用层的请求信息做hash，这样可以保证每次请求的都是同一台机器，命中缓存。如查询图片3、Round-Robin选择。按照处理机器的IP地址列表顺序选择，为了保持顺序选择时需要同步操作，但由于操作时间段性能损失很小，这种方式硬件负载和软件负载都支持，实际中使用最多4、按权重选择。根据每个地址的权重进行选择5、按负载选择。根据实际业务处理机器的负载来选择，选择负载相对较低的机器来处理6、按连接选择，让连接数相对较少的机器来处理业务，如果重启一台机器，可能会瞬间接收到大量请求，造成机器宕掉，这种方式实际应用很少 跳过问题机器为保证访问时跳过出问题的机器，通常采用的方法是负载均衡机器定时和实际的业务处理机器进行心跳（ping、端口检测、url侦测），发现心跳失败的机器并将它从可用地址列表中拿掉，在心跳成功后再重新加入可用列表中 响应返回方式业务处理机器处理完毕后，要将响应返回给用户，通常有两种返回方式： 1、响应通过负载均衡机器返回 基于NAT实现，当请求从客户端发送至负载均衡机器时，负载均衡机器选择一台实际的业务处理机器，然后将请求报文的目标地址和端口改为实际业务处理机器的IP地址和端口，并将报文发送出去。当响应回到负载均衡机器上时，将报文的源地址和端口修改为负载均衡机器的VIP地址和端口 2、响应直接返回至请求发起方 响应直接返回至请求发起方可将请求包和响应包分开处理，以分散负载均衡机器的压力，使负载均衡机器可以支撑更大的请求量。要达到响应直接返回的效果，须要采用IP Tunneling或DR（Direct Routing，硬件负载设备中又简写为DSR：Direct Service Routing），这两种方式对负载均衡机器和实际业务处理机器的系统环境都有要求 ①IP Tunneling 当采用IP Tunneling方式时，请求从客户端发送至负载均衡机器，负载均衡机器首先选择一台实际的业务处理机器，然后将请求的IP报文基于IP封装技术封装成另外一个IP报文，在做完以上处理后将报文发送出去，实际的业务处理机器收到报文后，先将报文解开获得目标地址为VIP的报文，处理完毕请求后，处理机器发现此VIP地址配置在本地的IP隧道设备上，则根据路由表将响应报文直接返回至请求方。IP Tunneling方式要求负载均衡机器和实际的业务处理机器的os都支持IP Tunneling，并将VIP地址同时配置在实际业务处理机器的IP隧道设备上 ②Direct Routing 当采用Direct Routing方式时，请求从客户端发送至负载均衡机器，负载均衡机器首先选择一台实际的业务处理机器，然后将请求数据帧的MAC地址修改为此业务处理机器的MAC地址，并发送出去，实际的业务处理机器收到请求后，获取IP报文，当发现IP报文中的目标地址VIP配置在本地的网络设备上时，根据路由表将响应报文直接返回给用户。Direct Routing方式要求负载均衡机器和实际的业务处理机器在同一个物理网段中，并且不响应ARP 根据上面的描述可以看出，IP Tunneling方式对系统环境的要求并不高，目前大部分的OS都支持IP Tunneling，Direct Routing方式对系统环境的要求则比较高，因此IP Tunneling方式更适合实现将响应直接返回给请求发起方，从而大幅度提升负载均衡机器所能支撑的请求量。 软件负载1、LVS+KeepAlived 软件负载方案中最常用的为LVS（Linux Virtual Server），多数情况下采取LVS+Keepalived来避免负载均衡机器的单点，实现负载均衡机器的自动接管。 Keepalived基于VRRP（Virtual Router Redundancy Protocol）协议实现，在VRRP协议中，由一个Master的VRRP路由器和多个Backup的VRRP路由器构成VRRP虚拟路由器，但Master并不是永远不变的，Master的VRRP路由器会每隔一段时间发送广播包。当Backup VRRP路由器在连续三个周期内都收不到广播包时，即认为Master VRRP路由器出现问题，或收到优先级为0的广播包后，所有Backup VRRP路由器都发送VRRP广播信息，声称自己是Master，并将虚拟IP增加到当前机器上，从而保持对外提供的IP地址及MAC地址不变。Backup VRRP路由器收到VRRP广播信息后，首先比较优先级，如优先级比收到的VRRP广播信息中的优先级低，则重新将状态置为BACKUP。如优先级相等，则比较IP地址，IP值小的则重新将状态恢复为BACKUP，整个切换过程对于请求端而言是透明的。但由于VRRP方式依靠广播信息来确认是否健康，如网络上出现异常，有可能会出现多个Master的现象，这个时候会出现一些问题，因此当使用VRRP方式时要特别监测是否出现此类现象，一旦出现就要迅速人工介入处理。 2、硬件负载设备 除了采用Keepalived方式实现自动接管外，也可采用类似硬件负载设备的方式来实现，即采用心跳线+高可用软件来实现。在linux目前使用范畴最广的高可用软件为heartbeat，默认情况下heartbeat通过UDP方式来监测。 除LVS外，软件负载方案中还有像HAProxy这样的佼佼者，在考察采用哪种软件负载方案时，则要从应用场景、系统环境等多方面考虑。 故障传播在系统从单机演变为集群后，可用性确实会得到一定提升，但随着系统功能的不断丰富，会出现多个系统访问同一系统提供的功能的情况，在这种情况下有可能会出现其中某个系统的访问导致其他系统故障。 对于以上这种故障传播的现象，通常会根据应用性质的不同做隔离的方案，通常采取配置多个不同的VIP的方法，各个系统通过域名访问，通过dns等方法使域名根据不同的系统解析为不同的VIP，从而实现根据应用性质不同来隔离，避免故障传播。 热备热备通常对程序的要求不高，热备的情况下真正对外服务的机器只有一台，其他机器处于standby状态。standby机器通过心跳机制检查对外服务机器的健康状况，当出现问题时，其中一台standby机器即进行接管，机器间的状态同步至其他standby机器或写入一个集中存储设备，例如上述章节中LVS+Keepalived实现自动接管的方式 对于大型应用而言，除了单机故障外，还须考虑整个机房出现不可用的情况。如所有的应用都部署在单个机房，也可以认为是单点现象，一旦发生机房断电或机房出现不可抗力的灾难性事故时，整个系统的可用性就完全无法保障了，对于此类现象，通常采用多个机房的方法来避免，一方面可以做到其中一个机房出现问题时对整个系统不会产生太大的影响，另一方面也可以分流，提升性能。 使用多机房——保持一致性❶、主从同步 数据库数据的同步通常采用 单master、多slave 或 多master方案。单master方案只有一个写入点，其主要解决的是master同步到slave的问题，通常采取的是数据库自带的同步方案，例如oracle standby方案或mysql replication方案。 ❷、分布式同步 多master方案有多个写入点，相对单master方案就复杂多了，通常采取的两阶段提交、三阶段提交或基于Paxos的方式来保持多master数据的一致性。 1、两阶段提交（2PC）保持一致性 在采用两阶段提交保证多master数据的一致性时，步骤为： 1）开启事务； 2）通知每个master执行某操作； 3）所有master在接到请求后，锁定执行此操作需要的资源，例如假设是个扣款动作，那么先冻结相应的款项，冻结完毕后返回； 4）在收到所有master的反馈后，如均为可执行此操作，则继续之后的步骤，如有一个master反馈不能执行或一段时间内无反馈，则通知所有master回滚操作； 5）通知所有master完成操作。 两阶段提交方式相对而言比较易于实现，但问题在于所有的master都要冻结资源，而且一旦有一个master出现问题就要全部回滚。 2、三阶段提交（3PC）保持一致性 为了避免在通知所有master提交时，其中一个master crash不一致时，就出现了三阶段提交的方式。三阶段提交在两阶段提交的基础上增加了preCommit的过程，当所有master收到preCommit后，并不执行动作，直到收到commit或超过一定时间后才完成操作。 在实现两阶段或三阶段提交时，为了避免通知所有master时出现问题，通常会借助消息中间件或让任意的一个master能够接管成为通知者。 3、基于Paxos保持一致性 Paxos最大的改变在于不要求所有master都反馈成功，只须有大多数反馈成功就执行了，更多具体的细节请参考相关文献。 总结： 文件的同步和内存数据的同步采取的方案和数据库数据同步的方案基本相同。总的来说，由于采用多机房后带来的网络延时问题，技术上会出现不少的挑战，不过对于要求高可用的应用，采用多机房还是很有必要的。 分布式文件系统分布式文件系统采用的方法由众多普通PC Server机器构成巨大的存储池，每台机器只存储一部分数据，其本身通常可非常好地支持水平伸缩。例如一台机器能存储500GB数据，那么当要存储2000GB数据时，只要增加到四台机器即可 当Node A要上传文件时，Node A上的GFS Client会将文件按固定大小划分，并向主服务器提交文件名和块索引信息，从而得到要存储的目标机器及位置，主服务器根据目前各存储机器的存活状态、硬件使用率等来决定块需要存储到的目标机器，之后Node A将数据存储到目标机器的相应位置上。主服务器负责记录文件和块的命名空间、文件到块的映射及每个块副本的位置。 为了保证安全可靠，同时将数据复制到多个存储机器上，复制的份数可在主服务器上进行设置，当Node B要读取此文件时，则只要从主服务器上获取此文件划分的存储位置列表，然后随机挑选机器进行读取，最后根据块的索引进行合并即可。 应用水平伸缩在系统建设初期，会采用将各种业务都放在同一个系统的方式，这会导致这个系统日渐庞大，所需的资源（CPU、内存、数据库连接）越来越多，在进行水平伸缩时要考虑系统里各种业务会造成的资源增加的现象，这种状况会导致水平伸缩很难进行。例如增加机器后就造成了多个数据库连接的增加，对于这样的状况，通常采取拆分应用的方式来解决。 拆分应用通常按照业务领域来划分，即将原在同一系统中处理的功能拆分到各个不同的业务系统中，例如eBay将其业务系统拆分为商品、用户、评价、交易等]]></content>
      <categories>
        <category>分布式架构</category>
      </categories>
      <tags>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[索引、高级树结构]]></title>
    <url>%2F2017%2F06%2F25%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D%E7%B4%A2%E5%BC%95%E3%80%81%E9%AB%98%E7%BA%A7%E6%A0%91%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[索引索引是把一个关键码与它对应的数据记录的位置相关联的过程 索引文件记录了&lt;关键码，指针&gt;对，指针指向了文件的真实地址 线性索引数据库中的记录是不等长的，而且无需存储的。但建立的索引文件是等长（Key，Point对）、按照关键字有序存储的，这样可以方便进行二分查找；索引文件的指针指向磁盘文件的地址 如果线性索引太大，可以存储在磁盘中。但是一次检索过程中会有多次访问磁盘，从而影响检索的效率，可以使用二级线性索引 二级线性索引如果一级索引太大无法直接读入内存，可以存入磁盘中，存在连续的磁盘块中。二级线性对磁盘块进行索引 二级线性索引能快速索引到磁盘块： 二级线性索引的关键码与磁盘块第一条记录的值相等 指针指向响应磁盘块的其实位置 、、 倒排索引对某属性按属性值建立索引；因为不是由记录关键码来确定属性值，而是由属性值来确定记录的位置，因此成为倒排索引 这些属性往往是离散型的，对于连续型的用B树 举个例子，假设EMP是主键，其余的是属性。如果不建立属性倒排索引，如果需要查找属性为某个值的记录，那么需要从头开始读取记录，判断每条记录的属性是否是查询的值，非常耗时 倒排文件的索引项是（key，point[]）： 一个具体的索引值 一组指针（因为属性值不是唯一的，一个属性会对应多条记录） 对上述记录建立的倒排文件如下，可以根据属性获得主键ID，然后再通过主键查询记录 正文索引对文本内容进行快速检索 词索引：从正文中抽出关键词，对关键词进行快速索引 全文索引：把正文看做一个长的字符串，对每一个字符建立索引，使查找不再限于关键词，需要更大的空间 建立正文倒排索引步骤： 1、把正文分成多条记录2、每条记录赋予一个关键词3、建立正文倒排文件 倒排文件的索引结构： 高级树结构Trie树Trie来源于retrieval，即检索 基于关键码分解的数据结构，常应用于信息检索、存储英文字符串 下面展示的Trie结构的树，人为指定左右节点的范围，使树的分布相对均匀；如在根节点，将小于32的树放在左子树，大于32的树放入右子树 英文字符树按照英文字幕的索引建立索引，即前缀树 对于不等长的字符串，比如规定字符串的长度是3，那么对于字符串an，可以转换成an*；检索时检索到*表示检索结束 平衡的二叉搜索树（AVL）平衡的二叉搜索树定义：左右节点的高度小于等于1 插入节点后，根节点的变化大致有三类： 原来节点时平衡的，现在成为左重或右重的 节点原来是某一边重，而现在成为平衡的了 节点原来是左重或右重的，又加到重的一边，现在不平衡了，需要进行调整！！！ 举个例子： 如下图，插入17前是平衡树，节点2的平衡因子是+1，即右子树比左子树高度大1；节点15是平衡的；插入17后，节点2的平衡因子变成2，节点1的平衡因子变成1，失衡了，需要调整节点2，节点15，节点7之间的关系 很简单，用中间值15作为根节点，12小于15作为左节点，17大于15作为右节点，调整后如下： 可以发现，调整之前，节点2的高度是2，调整之后，节点2的高度还是2，没有变化，所以不影响其他节点 插入节点时平衡因子变化 不平衡的情况发生在插入新节点后 BST把新节点插入到叶结点★★★（根节点与叶节点交换，然后插入） 假设a是离插入节点最近，且平衡因子绝对值不等于0的节点（如果节点的平衡因子等于0不需要调整结构） 插入的关键码要么在它的左子树中，要么在其右子树中 假设插入在右边，此时a的平衡因子有三种情况：-1，0，1，如下图 1、原来a的平衡因子是-1，即左子树的高度比右子树的高度大1。右边插入节点后，平衡因子变成0，左右子树高度相等，变平衡了2、原来a的平衡因子是0，左右子树高度相等。右边插入节点后，右子树的高度比左子树高度大1，平衡因子变为13、左图a的平衡因子变成2，b的平衡因子为1，需要调整；右图a的平衡因子变成，b的平衡因子编程-1，需要调整； 不平衡的情况总结★★★★ 分为四种：LL，LR，RL，RR，其中LL和RR比较相似，LR和RL相似 LL 如下图有一颗平衡树，其中T1、T2、T3都表示子树，他们的高度都是h。那么节点B的平衡因子是0，节点A的平衡因子是-1，中序遍历的结果是：T1、B、T2、A、T3 此时如果在A的左子树中插入一个节点，会造成节点A的平衡因子变成-2，造成树不平衡 LL主要节点是A、B、T1，三者的大小关系是T1&lt;B&lt;A， B为A和T1的分割节点，调整时保持B不变，将A右旋 先确定T、B、A的位置，T1和A各自的子节点保持不变；在A右旋的时候，替换了B的右节点，所以将B的有节点T2挂载挂在A的左节点上 调整后中序遍历结果没有变化，树保持平衡 RL]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5、B数、B+数、红黑树]]></title>
    <url>%2F2017%2F06%2F24%2F%5B%E6%95%B0%E6%8D%AE%E5%BA%93%5D5%E3%80%81B%E6%95%B0%E3%80%81B%2B%E6%95%B0%E3%80%81%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[2-3树 关键字 1-2 个子节点 2-3 个 平衡树：子节点的高度一致 B树（Balacned Tree）一种平衡的多分树 平衡：所有的叶结点在同一层，所以每个子节点的高度一致 m阶B树的结构定义1、每个结点至多有m个子结点2、除根节点和叶节点外，其他每个结点至少有m/2（向上取整）个结点3、根结点至少有两个子结点 唯一例外的是根节点就是叶结点时没有子结点 此时B树只包含一个结点 4、所有的叶结点在同一层（平衡）5、有k个子节点的非根节点恰好包含k-1个关键码 B树的性质1、树高平衡，所有叶结点都在同一层2、关键码没有重复，父结点中的关键码是其子结点的分界3、B树把（值接近）相关记录放在同一个磁盘页中，从而利用局部性原理4、B树保证树中至少有一定比例的结点是满的（每个结点有至少有m/2个子节点，半满） 这样能改进空间的利用率（如果每个节点只有1个子节点，BST，树高会很高，空间利用率低） 减少索引和更新操作的磁盘读取数目（如果每个节点有m个子节点，全满，那么每次插入的时候没处插了） QM总结： 除根节点和叶节点外，M阶B树每个节点有m/2~m个结点，根节点至少有两个子节点（插入时多次分裂） 有k个子节点的非根节点恰好包含k-1个关键码 父结点中的关键码是其子结点的分界 B树的节点结构B树的一个包含j个关键码，j+1个指针的节点的一般形式为： P0，K1，P1，K2，P2....Kj，Pj #j个关键码，j+1个指针指向子节点 其中ki是关键码值，K1&lt;K2&lt;….&lt;KjPi是指向Ki到Ki+1之间的关键码的子树的指针 QM总结： 如果有j个关键字，那么有可以表示j+1个区间，即有j+1个子节点 关键词下标从1开始，P从0开始，Pi是指向Ki到Ki+1之间的关键码的子树的指针 举个例子：P0指向K0到K1之间，即小于K1的，P1指向K1到K2 B树结点抽象数据类型class BNode{ int n;//子节点的个数 BNode&lt;Key&gt; *parent;//指向父节点的指针（可有可不有） Key key[MAXREC];//存储关键码的数组，最多有MAXREC个关键码 BNode&lt;Key&gt; *ptr[MAXREC+1];//指向子节点的指针，最多有MAXREC+1个指针 } B树的查找1、把根节点读出来，在根节点所包含的关键码K1…Kj中查找给定的关键码值。当关键码不多时，就用顺序检索，当节点包含的关键码较多时，可以用二分检索。如果找到则检索成功 2、否则，确定要查的关键码指在某个Ki和Ki+1之间，那么去Pi所指向的节点继续查找 下图为查找24的过程 如果树高为h，则查找时访问外存的次数是h 注意：每个关键码表示索引，找到索引后，每个关键码还对应一个指向外存的指针，这样通过索引才可以访问到完整的记录 B树的插入（分裂向上生长）情况1： 首先判断关键码14是否存在，按照图中的轨迹查找，此时到15所在的节点，遍历后发现没有14，则在该节点中插入 此时外存读的次数是3，写的次数是1 情况2： 插入可能导致B树朝着根的方向生长，即当插入位置超过关键字的最大个数，节点需要进行分裂 如插入55，但2-3树要求关键字数只由1~2个，此时插入节点50，52已经达到个数，55无法直接插入，需要进行分裂 50 52 55如何拆分？ 父节点需要增加一个节点进行区分子节点拆分后的节点，采用二分的方法，将中间的52送到父节点，得到结果： 此时读的次数3，写的次数3（申请两个节点，并分别写入，这里包含两次写，还有在父节点中写入1次） 情况3： 多次分裂，树向上生长 最终的结果是： B数的删除（向左或向右合并）6阶B树删除45 对于6阶B树，子节点树要求m/2~m，即 3~6，关键码的个数为2~5，在删除的过程中需要防止下溢出，即关键码的数量小于规定的个数 在删除掉45后，当前节点只有110一个关键字，下溢出了。其中一种方案是向左右节点借关键码，同时要将父节点拉下来，这里演示向右节点借关键码。此时合并的关键码有110，112，135，143，212，需要进行分裂，根据二分分裂的方式，将135移到父节点，即用135替换123，然后子节点分裂，反别是110，112和142，212，结果是： 给出一个极限情况下删除的例子： 删除的时候如果发生下溢出，即当前关键码个数小于定义的个数，则需要进行合并，向左节点或有节点合并 如果删除后，节点为0仍保持0的状态，按照向左向右合并的方式进行操作 B+树B+树是B树的一种变形，是在叶结点上存储信息的树： 所有的管家那么均出现在叶结点上 各层节点中的关键码均是下一层相应节点中最大关键码（或最小关键码）的复写 B+树的结构定义 每个节点至多有m个子节点 每个结点（除根外）至少有m/2（向上取整）个子结点 根节点至少有两个子结点 有k个子结点的必有k个关键码（这个是与B树的差别） QM总结： 根节点有2~m个子节点 除根节点外有m/2（向上取整）~m个子结点 有k个子结点的节点有k个关键字（这是与B树的结构差别，B树有k-1个关键字） m阶B+树有m个子节点，也有m个关键字 m个关键字是子结点的复写，当前层的关键码是其每个子结点关键码的最大关键码（也可以是最小） 根节点是线性索引，可以顺序查找；再加上多分树形查找 树形索引中不包含指向真实数据位置的指针，必须索引到树的叶子节点才算找到；好处是可以提高树的阶数，降低树的高度，加速索引速度 B+树的插入如下3阶B+树，节点最多有3个关键码，当插入15后，查询到10 23这个节点，插入15。父节点不需要重写 3阶B+树插入16后，叶子节点的关键为16超过最大阶3，所以需要分类成10、15和16、23，并增加分类节点之间的线性链接，修改父节点的关键码，每个关键码是子结点关键码最大值的复写 多次分裂 B+树的删除如下B+树删除23，首先需要查找23；第一个节点判断，23&lt;=35，到第二个子结点查找；23&lt;=23，在第一个子结点中查找；删除关键码23； 此时父节点中的23能够正确标识父节点的区间，所以不进行更新（类似线段树中的延迟更新） B树与B+树的区别节点结构： 当前节点有k个子结点，B树有k-1个关键码，B+树有k个关键码 B树当前节点的关键码类似BST是子结点关键码的分割，B+树当前节点的关键码是子结点的复写（子结点关键码的最大值或最小值） 查找： B树每个节点保存了指向真实位置的指针，找到关键码就能找到真实位置；B+树必须索引到叶子节点；B+树提供了索性查找和顺序查找两种方式 实际中使用B+树特别多 参考第10章 索引——2（B树,B树） 标清https://www.youtube.com/watch?v=vBD6Ve8VryY]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO快速入门]]></title>
    <url>%2F2017%2F06%2F23%2F%5BNIO%5DNIO%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[为什么需要NIO1、Java I/O是阻塞的，当线程调用read（）或write（）时，线程是阻塞的，直到数据读取、写入完毕，在此期间线程不能再干其他任何事情了。 2、这种方式对于小规模的程序非常方便，但是对于存在大量并发连接的时候，需要为每一个连接建立一个线程来操作，这种做法存在以下缺陷： 并发数与线程数成正比，线程是宝贵的系统资源，当线程数过大会导致系统的性能急剧下降，并发量有限 NIO和IO的区别1、面向流与面向缓冲xxxxxxxxxxxx IO是面向流的，NIO是面向缓冲区的。Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方；NIO的将数据存放到一个缓冲区，当缓冲区中包含需要处理的数据 2、阻塞与非阻塞IOxxxxxxxxxxxxxxxxxx Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入，该线程在此期间不能再干任何事情了。Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 NIO原理除了普通的Socket与ServerSocket实现的阻塞式通信外，Java提供了非阻塞式通信的NIO API。先看一下NIO的实现原理，NIO中三个重要的类：Selector、Channel、Buffer 从图中可以看出，服务器上所有Channel（包括ServerSocketChannel和SocketChannel）都需要向Selector注册，而该Selector则负责监视这些Socket的IO状态，当其中任意一个或者多个Channel具有可用的IO操作时，该Selector的select()方法将会返回大于0的整数，该整数值就表示该Selector上有多少个Channel具有可用的IO操作，并提供了selectedKeys（）方法来返回这些Channel对应的SelectionKey集合。正是通过Selector，使得服务器端只需要不断地调用Selector实例的select()方法即可知道当前所有Channel是否有需要处理的IO操作。 总结： 1、所有 Channel 需要向 Selector 注册2、Selector 监听 Socket 的 IO 状态，当其中任意一个 Channel 具有可用的 IO 操作时，Selector 的 select（）方法返回大于0的整数，表示有多少个 Channel 具有可用的 IO 操作，并提供 selectedKeys 返回这些 Channel 对应的 SelectionKey 集合 ServerClient参考Java网络编程——使用NIO实现非阻塞Socket通信http://blog.csdn.net/yanmei_yao/article/details/8586199 Java NIO 网络编程https://my.oschina.net/gaoguofan/blog/753213]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka分布式消息系统]]></title>
    <url>%2F2017%2F06%2F22%2F%5B%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%5DKafka%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Kafka与Zoopkeeper关系 ZooKeeper用于管理、协调Kafka代理。当Kafka系统中新增了代理或者某个代理故障失效时，ZooKeeper服务将通知生产者和消费者，生产者和消费者据此开始与其它代理协调工作 参考http://www.infoq.com/cn/articles/apache-kafka]]></content>
      <categories>
        <category>分布式架构</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务发现与负载均衡]]></title>
    <url>%2F2017%2F06%2F22%2F%5B%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%5D%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[集中式负载均衡网络架构 1、在客户端和服务提供者之间有一个独立的负载均衡，通常采用Nginx负载均衡服务器 2、负载均衡维护了所有服务的地址映射表，通常由运维配置注册，当客户端调用某个目标服务时，它向负载均衡发起请求，由负载均衡以某种策略(比如Round-Robin)做负载均衡后将请求转发到目标服务 3、服务提供方的变更对客户端来说是透明的，客户端只需要关注和负载均衡服务器的交互 负载均衡算法A、随机算法 算法描述：随机产生一个数，人为划定在数字位于某个区间，将请求转发到哪个服务提供方 评论：随机算法是我们最最最最最最常用的算法，绝大多数情况都使用他。首先，从概率上讲，它能保证我们的请求基本是分散的，从而达到我们想要的均衡效果；其次，他又是无状态的，不需要维持上一次的选择状态，也不需要均衡因子等等。总体上，方便实惠又好用，我们一直用他！ B、轮训算法（Round-Robin） 算法描述：轮训算法就像是挨个数数一样（123-123-123……），一个个的轮着来。需要维护一个指针 idx，当一个请求来的时候，我们就把指针对应的机器选取出来，并且指针加一，挪到下一个位置。 这样能保证每个机器的负载均衡，如果想人为得控制不同主机的访问量，可以给两台机器做个排序的数组：array = [ABBABBABBB]，人为控制主机的访问量 C、一致哈希算法 将[0,2^32)所有的整数投射到一个圆上，然后再将你的机器的唯一编码（比如：IP）通过hash运算得到的整数也投射到这个圆上（Node-A、Node-B）。如果一个请求来了，就将这个请求的唯一编码（比如：用户id）通过hash算法运算得到的整数也投射到这个圆上（request-1、request-2），通过顺时针方向，找到第一个对应的机器 实际上，一致Hash要解决的是两个问题： 1、散列的不变性：就是同一个请求（比如：同一个用户id，源地址）尽量的落入到一台机器，不要因为时间等其他原因，落入到不同的机器上了；2、异常以后的分散性：当某些机器坏掉（或者增加机器），原来落到同一台机器的请求（比如：用户id为1，101，201），尽量分散到其他机器，不要都落入其他某一台机器。这样对于系统的冲击和影响最小。 一致Hash算法用的最多的场景，就是分配cache服务。将某一个用户的数据缓存在固定的某台服务器上，那么我们基本上就不用多台机器都缓存同样的数据，这样对我们提高缓存利用率有极大的帮助。 不过硬币都是有两面的，一致Hash也不例外。当某台机器出问题以后，这台机器上的cache失效，原先压倒这台机器上的请求，就会压到其他机器上。由于其他机器原先没有这些请求的缓存，就有可能直接将请求压到数据库上，造成数据库瞬间压力增大。如果压力很大的话，有可能直接把数据库压垮。 所以，在考虑用一致Hash算法的时候，一定要估计一下如果有机器宕掉后，后端系统是否能承受对应的压力。如果不能，则建议浪费一点内存利用率，使用随机算法。 健康检查他的作用就是对所有的服务进行存活和健康检测，看是否需要提供给负载均衡做选择。如果一台机器的服务出现了问题，健康检查就会将这台机器从服务列表中去掉，让负载均衡算法看不到这台机器的存在。 客户端如何发现负载均衡通常的做法是通过DNS，运维人员为服务配置一个DNS域名，这个域名指向集中式负载均衡。方案实现简单，在负载均衡上也容易做集中式的访问控制，这一方案目前还是业界主流 负载均衡单点问题参考http://www.v4.cc/News-938747.html]]></content>
      <categories>
        <category>分布式架构</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9、动态规划]]></title>
    <url>%2F2017%2F06%2F20%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D9%E3%80%81%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[动态规划入门https://mp.weixin.qq.com/s/0AgJmQNYAKzVOyigXiKQhA 爬楼梯问题有一座高度是10级台阶的楼梯，从下往上走，每跨一步只能向上1级或者2级台阶。要求用程序来求出一共有多少种走法。 思路： 假设只差最后一步就走到第10级台阶，这个时候会出现几种情况？当然是两种，因为每一步只许走一级或是两级台阶，第一种是从9级走到10级，第二种是从8级走到10级 得到公式: F（1）= 1 F（2）= 2 F（n） = F（n-1）+F(n-2)（n&gt;=3） 方法一：递归解法 import java.util.*; public class Solution { private int f(int n){ if(n &lt; 1){ return 0; } if(n == 1){ return 1; } if(n == 2){ return 2; } return f(n-1) + f(n-2); } public static void main(String[] args){ Solution s = new Solution(); System.out.println(s.f(10));//89 } } 求递归的时间复杂度，分析递归方法所走过的路径，归纳成以下图： 这是一个二叉树，树的节点个数就是我们的递归方法所需要计算的次数，不难看出二叉树的高度是N-1，节点个数接近2的N-1次方，所以方法的时间复杂度可以近似得看做是O（2^N） 方法二：备忘录算法，暂存计算结果 递归图中有些相同的参数被计算了，越往下走，重复的越多，所以用缓存，创造一个哈希表存起来，当遇到相同的参数时，从哈希表中取出，不用重复计算了 import java.util.*; public class Solution { Map&lt;Integer,Integer&gt; map = new HashMap&lt;Integer,Integer&gt;(); private int f(int n){ if(n &lt; 1){ return 0; } if(n == 1){ return 1; } if(n == 2){ return 2; } if(map.containsKey(n)){ return map.get(n); }else{ int value = f(n-1) + f(n-2); map.put(n, value); return value; } } public static void main(String[] args){ Solution s = new Solution(); System.out.println(s.f(10)); } } 这个算法只要计算F（1）到F（N），时间复杂度是O（N），哈希表中除了N-2个结果，所以空间复杂度也是O（N） 方法三：动态规划求解 自底向下进行迭代得到结果，画一下计算的表格： F（3） = F（2） + F（1），即F（3）只依赖F（1）和F（2） F（4） = F（3） + F（2），即F（4）只依赖F（3）和F（2） 可见每一次迭代过程中，只需保留之前的两个状态，就可以推到出新的状态，不需要备忘录算法那样保留全部的子状态，这才是真正的动态规划的实现 import java.util.*; public class Solution { private int f(int n){ if(n &lt; 1){ return 0; } if(n == 1){ return 1; } if(n == 2){ return 2; } int a = 1; int b = 2; for(int i = 3; i &lt;= n; i++){ int t = a; a = b; b = t + b; } return b; } public static void main(String[] args){ Solution s = new Solution(); System.out.println(s.f(10));//89 } } 时间复杂度是O（N），空间复杂度是O（1） 国王和金矿]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis源码分析]]></title>
    <url>%2F2017%2F06%2F20%2F%5Bmybatis%5Dmybatis%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[摘自：http://blog.csdn.net/luanlouis/article/details/40422941 mybatis优势 面向接口编程，定义接口通过动态代理的方式生成一个mapper实例 参数映射和动态SQL语句生成： 动态语句生成是 MyBatis 通过传入的参数值，使用 Ognl 来动态地构造SQL语句；参数映射指的是对于Java 数据类型和jdbc数据类型之间的转换 SQL语句的执行以及封装查询结果集成List 事务管理、连接池管理机制、缓存机制、QL语句的配置方式 动态代理生成mapperMyBatis和数据库的交互有两种方式： 1、使用传统的MyBatis提供的API； 创建一个和数据库打交道的SqlSession对象，然后根据Statement Id 和参数来操作数据库 2、使用Mapper接口 根据 MyBatis 的配置规范配置好后，通过SqlSession.getMapper(XXXMapper.class) 方法，MyBatis 会根据相应的接口声明的方法信息，通过动态代理机制生成一个 Mapper 实例，我们使用Mapper 接口的某一个方法时，MyBatis 会根据这个方法的方法名和参数类型，确定Statement Id，底层还是通过SqlSession.select(“statementId”,parameterObject);或者SqlSession.update(“statementId”,parameterObject); 等 SqlSession 的增删改查方法来实现对数据库的操作 SqlSession 的工作过程分析1、开启一个数据库访问会话—创建SqlSession对象： SqlSession sqlSession = factory.openSession(); MyBatis封装了对数据库的访问，把对数据库的会话和事务控制放到了SqlSession对象中。 2、为SqlSession传递一个配置的Sql语句 的Statement Id和参数，然后返回结果： List&lt;Employee&gt; result = sqlSession.selectList(&quot;com.louis.mybatis.dao.EmployeesMapper.selectByMinSalary&quot;,params); MyBatis在初始化的时候，会将MyBatis的配置信息全部加载到内存中，使用 org.apache.ibatis.session.Configuration 实例来维护。使用者可以使用sqlSession.getConfiguration() 方法来获取 &lt;select id=&quot;selectByMinSalary&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;java.util.Map&quot; &gt; select EMPLOYEE_ID, FIRST_NAME, LAST_NAME, EMAIL, SALARY from LOUIS.EMPLOYEES &lt;if test=&quot;min_salary != null&quot;&gt; where SALARY &lt; #{min_salary,jdbcType=DECIMAL} &lt;/if&gt; &lt;/select&gt; 加载到内存中会生成一个对应的 MappedStatement 对象，然后会以key=”com.louis.mybatis.dao.EmployeesMapper.selectByMinSalary” ，value为MappedStatement对象的形式维护到Configuration的一个Map中。当以后需要使用的时候，只需要通过Id值来获取就可以了。 从上述的代码中我们可以看到SqlSession的职能是： SqlSession根据Statement ID, 在mybatis配置对象Configuration中获取到对应的MappedStatement对象，然后调用mybatis执行器来执行具体的操作。 SqlSession的作用： 作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能 3、MyBatis执行器Executor根据SqlSession传递的参数执行query()方法 Executor.query()方法几经转折，最后会创建一个StatementHandler对象，然后将必要的参数传递给StatementHandler，使用StatementHandler来完成对数据库的查询，最终返回List结果集。 Executor的功能和作用是： (1、根据传递的参数，完成SQL语句的动态解析，生成BoundSql对象，供StatementHandler使用；(2、为查询创建缓存，以提高性能(3、创建JDBC的Statement连接对象，传递给StatementHandler对象，返回List查询结果。 4、StatementHandler对象负责设置Statement对象中的查询参数、处理JDBC返回的resultSet，将resultSet加工为List 集合返回： StatementHandler对象主要完成两个工作： (1、对于JDBC的PreparedStatement类型的对象，创建的过程中，我们使用的是SQL语句字符串会包含若干个 ? 占位符，我们其后再对占位符进行设值。StatementHandler通过parameterize(statement)方法对Statement进行设值；(2、StatementHandler通过List query(Statement statement, ResultHandler resultHandler)方法来完成执行Statement，和将Statement对象返回的resultSet封装成List； 对StatementHandler的query分析： StatementHandler 的 List query(Statement statement, ResultHandler resultHandler)方法的实现，是调用了ResultSetHandler的handleResultSets(Statement) 方法。ResultSetHandler的handleResultSets(Statement) 方法会将Statement语句执行后生成的resultSet 结果集转换成List 结果集： 参考http://www.cnblogs.com/luoxn28/p/5932648.html]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8、递归]]></title>
    <url>%2F2017%2F06%2F15%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D8%E3%80%81%E9%80%92%E5%BD%92%2F</url>
    <content type="text"><![CDATA[全排列OJ：https://www.nowcoder.com/practice/fe6b651b66ae47d7acce78ffdd9a96c7?tpId=13&amp;tqId=11180&amp;tPage=2&amp;rp=2&amp;ru=%2Fta%2Fcoding-interviews&amp;qru=%2Fta%2Fcoding-interviews%2Fquestion-ranking 求整个字符串的排序可以分成两份： 首先求可能出现在第一个位置的字符。怎么做？把第一个字符和后面所有的字符交换 固定第一个字符，求后面所有字符的全排列（后面也是步骤1的操作，所以是递归） 注意事项：1、为了保证不会重复，两个字符交换后，在子序列全排列完毕后，需要调换回来 2、字符串中包含相同字符的，排列时不要重复输出。如果对aa进行，值输出aa解决方法：在交换字符时，如果交换的字符和首字母一样，就跳过，即不对子序列进行全排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.ArrayList;import java.util.Collections;public class Solution &#123; ArrayList&lt;String&gt; result = new ArrayList&lt;String&gt;(); public ArrayList&lt;String&gt; Permutation(String str) &#123; if(str == null || str.length() == 0)&#123; return result; &#125; //划分子问题：固定第一个字符，然后对后面字符进行全排序 //做法：第一个字符分别于后面的字符交换，然后对后面字符递归全排序 char[] c = str.toCharArray(); doPermutation(c, 0, c.length - 1); //坑爹，需要排序输出 Collections.sort(result); return result; &#125; public void doPermutation(char[] c, int l, int r) &#123; if(l &gt;= r)&#123; result.add(new String(c)); return; &#125; for (int i = l; i &lt;= r; i++) &#123; //重复的就不要交换了 if(i != l &amp;&amp; c[i] == c[l])&#123; continue; &#125; //后面的字符与第一个交换 swap(c, l, i); doPermutation(c, l + 1, r); //记得交换回来 swap(c, i, l); &#125; &#125; public void swap(char[] c, int i, int j) &#123; char t = c[i]; c[i] = c[j]; c[j] = t; &#125; public static void main(String[] args) &#123; Solution s = new Solution(); String str = &quot;abc&quot;; System.out.println(s.Permutation(str));//abc,acb,bac,bca,cab和cba &#125;&#125; 根据先序遍历、中序遍历得到后序遍历题目 1 / \ 2 3 / \ / \ 4 5 6 7 先序遍历的结果是 1 2 4 5 3 6 7中序遍历的结果是 4 2 5 1 6 3 7那么得到的中序遍历的结果应该是：4 5 2 6 7 3 1 思路： 1、先序遍历序列和中序遍历序列可以确定一颗树 2、先序遍历序列的第一个节点为根节点，之后的节点先是左子树节点，然后是右子树节点，左、右子树的序列分别都是连续的如1 2 4 5 3 6 7，那么可以判断1是根节点；根据图观察 2 4 5 是左子树，3 6 7 是右子树；这需要利用中序遍历的结果才能判断哪些节点时左节点，哪些是右节点 3、中序遍历是先访问左子树，访问根，再访问右子树；由于已经根据先序遍历获得了根节点，在中序遍历中找到根节点可以确定哪些节点时属于左、右子树 4、上述是树解析的过程，需要递归解析 设计：1、自顶向下解析前序、中序序列，用如下四个参数记录，int[] pre, int pre_start, int pre_end, int[] mid, int mid_start, int mid_end 2、解析过程：a、前序的第一个节点是root b、在中序中查找root，划分出左右子树 c、计算出子树的区间 d、对于新确定的子树，仍旧按照这种该方法解析，所以这是递归操作 3、先把1,2两步解析的架子打起来，然后考虑什么时候打印后序结果 a、考虑叶子节点，他的左右节点都是null，为了程序的统一性，直到访问到null才递归结束，先访问左节点，再访问右节点，最后输出根，即子节点。所以判断条件是mid_end - mid_start &lt; 0，没有等于 if(mid_end - mid_start &lt; 0){ return; } b、对于叶子节点，解析左子树的DFS为空语句，解析右子树的DFS为空语句，然后这时候打印出叶子节点，即System.out.println(mid[partion]);在回溯的时候也是这个顺序；这个很难想象，可以先考虑叶子节点，然后再验证结果是否正确 //解析左子树 DFS(pre, pre_start + 1, pre_start + left_length, mid, mid_start, partion - 1); //解析右子树 DFS(pre, pre_start + left_length + 1, pre_end, mid, partion + 1, mid_end); System.out.println(mid[partion]); 代码 /** * Created by qianming.qm on 2017/7/18. */ public class Solution { //根据前序序列、中序序列解析一棵树，自顶向下 private void DFS(int[] pre, int pre_start, int pre_end, int[] mid, int mid_start, int mid_end) { //遍历到叶子节点，这里要注意是小于0，即到了叶子节点时还不返回，直到叶子节点的两个null子节点时返回，然后回溯 if(mid_end - mid_start &lt; 0){ return; } int root = pre[pre_start]; int partion = -1; for (int i = mid_start; i &lt;= mid_end; i++) { if (mid[i] == root) { partion = i; break; } } //左右子树序列长度 int left_length = partion - mid_start; int right_length = mid_end - partion; //解析左子树 DFS(pre, pre_start + 1, pre_start + left_length, mid, mid_start, partion - 1); //解析右子树 DFS(pre, pre_start + left_length + 1, pre_end, mid, partion + 1, mid_end); System.out.println(mid[partion]); } public static void main(String[] args) { Solution s = new Solution(); int[] pre = {1, 2, 4, 5, 3, 6, 7}; int[] mid = {4, 2, 5, 1, 6, 3, 7}; s.DFS(pre, 0, pre.length - 1, mid, 0, mid.length - 1);//4 5 2 6 7 3 1 } }]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7、稳定排序与不稳定排序]]></title>
    <url>%2F2017%2F06%2F14%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D7%E3%80%81%E7%A8%B3%E5%AE%9A%E6%8E%92%E5%BA%8F%E4%B8%8E%E4%B8%8D%E7%A8%B3%E5%AE%9A%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[稳定排序和不稳定排序 转自：http://www.cnblogs.com/codingmylife/archive/2012/10/21/2732980.html 这几天笔试了好几次了，连续碰到一个关于常见排序算法稳定性判别的问题，往往还是多选，对于我以及和我一样拿不准的同学可不是一个能轻易下结论的题目，当然如果你笔试之前已经记住了数据结构书上哪些是稳定的，哪些不是稳定的，做起来应该可以轻松搞定。本文是针对老是记不住这个或者想真正明白到底为什么是稳定或者不稳定的人准备的。 首先，排序算法的稳定性大家应该都知道，通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。在简单形式化一下，如果Ai = Aj，Ai原来在位置前，排序后Ai还是要在Aj位置前。 其次，说一下稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所用。基数排序就是这样，先按低位排序，逐次按高位排序，低位相同的元素其顺序再高位也相同时是不会改变的。另外，如果排序算法稳定，对基于比较的排序算法而言，元素交换的次数可能会少一些（个人感觉，没有证实）。 回到主题，现在分析一下常见的排序算法的稳定性，每个都给出简单的理由。 (1)冒泡排序 冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。 (2)选择排序 选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n - 1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。比较拗口，举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。 (3)插入排序插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。 (4)快速排序快速排序有两个方向，左边的i下标一直往右走，当a[i] &lt;= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] &gt; a[center_index]。如果i和j都走不动了，i &lt;= j，交换a[i]和a[j],重复上面的过程，直到i &gt; j。 交换a[j]和a[center_index]，完成一趟快速排序。在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为5 3 3 4 3 8 9 10 11，现在中枢元素5和3（第5个元素，下标从1开始计）交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j] 交换的时刻。 (5)归并排序归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素（认为直接有序）或者2个序列（1次比较和交换），然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定性。那么，在短的有序序列合并的过程中，稳定是是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。 (6)基数排序基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以其是稳定的排序算法。 (7)希尔排序(shell)希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 (8)堆排序我们知道堆的结构是节点i的孩子为2 i和2 i + 1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n 的序列，堆排序的过程是从第n / 2开始和其子节点共3个值选择最大（大顶堆）或者最小（小顶堆），这3个元素之间的选择当然不会破坏稳定性。但当为n / 2 - 1， n / 2 - 2， … 1这些个父节点选择元素时，就会破坏稳定性。有可能第n / 2个父节点交换把后面一个元素交换过去了，而第n / 2 - 1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法。 综上，得出结论: 选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，而冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6、求逆序数]]></title>
    <url>%2F2017%2F06%2F13%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D6%E3%80%81%E6%B1%82%E9%80%86%E5%BA%8F%E6%95%B0%2F</url>
    <content type="text"><![CDATA[归并排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.util.*;public class Solution &#123; private int[] temp; public void mergeSort(int[] a, int l, int r) &#123; //递归结束 if (l &gt;= r) &#123; return; &#125; //防止溢出，或者也可以写int mid = l + (r - l) &gt;&gt;1 ，是1哦 int mid = l + (r - l) / 2; //分治 mergeSort(a, l, mid); mergeSort(a, mid + 1, r); //两个有序数组l..mid，mid+1..r,合并成一个有序数组 merge(a, l, mid, r); &#125; public void merge(int[] a, int l, int mid, int r) &#123; if (temp == null) &#123; temp = new int[a.length]; &#125; //先复制原数据至临时数组temp，接下来对temp进行操作，排序后覆写数组a for (int i = l; i &lt;= r; i++) &#123; temp[i] = a[i]; &#125; //双指针,不要忘记指针++ int lp = l, rp = mid + 1; for (int i = l; i &lt;= r; i++) &#123; if (lp &gt; mid) &#123; a[i] = temp[rp++]; &#125; else if (rp &gt; r) &#123; a[i] = temp[lp++]; &#125; else &#123; if (temp[lp] &lt; temp[rp]) &#123; a[i] = temp[lp++]; &#125; else &#123; a[i] = temp[rp++]; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Solution s = new Solution(); int[] array = &#123;1, 2, 3, 4, 5, 6, 7, 0&#125;; s.mergeSort(array, 0, array.length - 1); for (int i = 0; i &lt; array.length; i++) &#123; System.out.print(array[i] + &quot; &quot;); &#125; &#125;&#125; 归并排序的基础上求逆序数(推荐从后往前)OJ：https://www.nowcoder.com/practice/96bd6684e04a44eb80e6a68efc0ec6c5?tpId=13&amp;tqId=11188&amp;tPage=2&amp;rp=2&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking 1、两个有序数组从前往后合并成一个有序数组 如果A&lt;=B，A指针往后移：因为A、B都是有序的，A&lt;=B之后的元素，相当于A与B之后的元素全部进行比较过 如果A&gt;B，B指针往后移：B比A之后的元素都小，根据数组有序的特点，可以减少比较次数 当A&gt;B时统计逆序数，B指针后移，此时A及A后面的元素组成逆序数对（A，B）、（A1，B）、（A2，B）… 综上所述，从前往后归并，是根据在前面查找比他大的数的个数 思考：从前往后合并，如果想要统计比A小的元素的个数？见leetcode那题，当A&lt;=B时，需要移动lp时，记录count；当A&gt;=B时，count++ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import java.util.*;public class Solution &#123; private int[] temp; private int inverseNum; public int InversePairs(int[] array) &#123; mergeSort(array, 0, array.length - 1); return inverseNum; &#125; public void mergeSort(int[] a, int l, int r) &#123; //递归结束 if (l == r) &#123; return; &#125; //防止溢出，或者也可以写int mid = l + (r - l) &gt;&gt;1 ，是1哦 int mid = l + (r - l) / 2; //分治 mergeSort(a, l, mid); mergeSort(a, mid + 1, r); //两个有序数组l..mid，mid+1..r,合并成一个有序数组 merge(a, l, mid, r); &#125; public void merge(int[] a, int l, int mid, int r) &#123; if (temp == null) &#123; temp = new int[a.length]; &#125; //先复制原数据至临时数组temp，接下来对temp进行操作，排序后覆写数组a for (int i = l; i &lt;= r; i++) &#123; temp[i] = a[i]; &#125; //双指针,不要忘记指针++ /*int lp = l, rp = mid + 1; for (int i = l; i &lt;= r; i++) &#123; if (lp &gt; mid) &#123; a[i] = temp[rp++]; &#125; else if (rp &gt; r) &#123; a[i] = temp[lp++]; &#125; else &#123; if (temp[lp] &lt; temp[rp]) &#123; a[i] = temp[lp++]; &#125; else &#123; a[i] = temp[rp++]; &#125; &#125; &#125;*/ //注释归并的部分。求逆序数，左右两个数组的每个数都要进行比较！！ int lp = l, rp = mid + 1; for (int i = l; i &lt;= r; i++) &#123; if (lp &gt; mid) &#123; a[i] = temp[rp++]; &#125; else if (rp &gt; r) &#123; a[i] = temp[lp++]; &#125; else &#123; if (temp[lp] &lt; temp[rp]) &#123; a[i] = temp[lp++]; &#125; else if (temp[lp] &gt; temp[rp]) &#123; //3,4 1,2 如果1比3小,那么3,4都比1大 inverseNum = (inverseNum + (mid - lp + 1)) % 1000000007; a[i] = temp[rp++]; &#125; else &#123; a[i] = temp[lp++]; &#125; &#125; &#125; &#125; /*public static void main(String[] args) &#123; Solution s = new Solution(); int[] array = &#123;1, 2, 3, 4, 5, 6, 7, 0, 1&#125;; System.out.println(s.InversePairs(array)); &#125;*/&#125; 2、两个有序数组从后往前合并成一个有序数组 如果A&gt;B，A指针往前移：因为A、B都是有序的，A&gt;B之前的元素，相当于A与B之前的元素全部进行比较过 如果A&lt;=B，B指针往前移：B比A之前的元素都大，根据数组有序的特点，可以减少比较次数 当A&gt;B时统计逆序数，A指针前移，此时B及B之前的元素组成逆序数对（A，B）、（A，B1）、（A，B2）… 综上所述，从后往前归并，是根据在后面查找比他小的数的个数 OJ:https://leetcode.com/problems/count-of-smaller-numbers-after-self/#/description import java.util.*; public class Solution { private int[] nums; private int[] new_indexs; private List result = new ArrayList(); /** * 对下标进行归并排序，原数组不变化 */ public List countSmaller(int[] nums) { //初始化result for (int i = 0; i < nums.length; i++) { result.add(0); } //原数组的下标，对下标进行归并排序 int[] indexs = new int[nums.length]; for (int i = 0; i < indexs.length; i++) { indexs[i] = i; } this.nums = nums; mergeSort(indexs, 0, indexs.length - 1); return result; } public void mergeSort(int[] indexs, int l, int r) { //递归结束，必须是l>=r，如果数组为空会造成递归不停止 if (l >= r) { return; } //防止溢出，或者也可以写int mid = l + (r - l) >>1 ，是1哦 int mid = l + (r - l) / 2; //分治 mergeSort(indexs, l, mid); mergeSort(indexs, mid + 1, r); //两个有序数组l..mid，mid+1..r,合并成一个有序数组 merge(indexs, l, mid, r); } public void merge(int[] indexs, int l, int mid, int r) { if (new_indexs == null) { new_indexs = new int[indexs.length]; } //先复制原数据至临时数组，接下来对temp进行操作，排序后覆写数组 for (int i = l; i = l; i--) { if (lp < l) { indexs[i] = new_indexs[rp--]; } else if (rp < mid + 1) { indexs[i] = new_indexs[lp--]; } else { if (nums[new_indexs[lp]] > nums[new_indexs[rp]]) { //移动lp之前，统计比lp小的个数 result.set(new_indexs[lp], result.get(new_indexs[lp]) + rp - mid); indexs[i] = new_indexs[lp--]; } else { indexs[i] = new_indexs[rp--]; } } } } /*public static void main(String[] args) { Solution s = new Solution(); int[] array = {1, 9, 7, 8, 5}; System.out.println(s.countSmaller(array));//03110 }*/ } LeetcodeThe basic idea is to do merge sort to nums[]. To record the result, we need to keep the index of each number in the original array. So instead of sort the number in nums, we sort the indexes of each number.Example: nums = [5,2,6,1], indexes = [0,1,2,3]After sort: indexes = [3,1,0,2] While doing the merge part, say that we are merging left[] and right[], left[] and right[] are already sorted. We keep a rightcount to record how many numbers from right[] we have added and keep an array count[] to record the result. When we move a number from right[] into the new sorted array, we increase rightcount by 1. When we move a number from left[] into the new sorted array, we increase count[ index of the number ] by rightcount. import java.util.*; public class Solution { private int[] nums; private int[] new_indexs; private List result = new ArrayList(); /** * 对下标进行归并排序，原数组不变化 */ public List countSmaller(int[] nums) { //初始化result for (int i = 0; i < nums.length; i++) { result.add(0); } //原数组的下标，对下标进行归并排序 int[] indexs = new int[nums.length]; for (int i = 0; i < indexs.length; i++) { indexs[i] = i; } this.nums = nums; mergeSort(indexs, 0, indexs.length - 1); return result; } public void mergeSort(int[] indexs, int l, int r) { //递归结束，必须是l>=r，如果数组为空会造成递归不停止 if (l >= r) { return; } //防止溢出，或者也可以写int mid = l + (r - l) >>1 ，是1哦 int mid = l + (r - l) / 2; //分治 mergeSort(indexs, l, mid); mergeSort(indexs, mid + 1, r); //两个有序数组l..mid，mid+1..r,合并成一个有序数组 merge(indexs, l, mid, r); } public void merge(int[] indexs, int l, int mid, int r) { if (new_indexs == null) { new_indexs = new int[indexs.length]; } //先复制原数据至临时数组，接下来对temp进行操作，排序后覆写数组 for (int i = l; i r) { //lp移动的时候要加count result.set(new_indexs[lp], result.get(new_indexs[lp]) + count); indexs[i] = new_indexs[lp++]; } else { if (nums[new_indexs[lp]]]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性哈希算法]]></title>
    <url>%2F2017%2F06%2F11%2F%5B%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%5D%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一致性哈希算法在分布式集群中，对机器的添加、删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的： 1、环形Hash空间 按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图 2、把数据通过一定的hash算法处理后映射到环上 现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图： Hash(object1) = key1； Hash(object2) = key2； Hash(object3) = key3； Hash(object4) = key4； 3、将机器通过hash算法映射到环上 在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。 假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下： Hash(NODE1) = KEY1; Hash(NODE2) = KEY2; Hash(NODE3) = KEY3; 通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。 机器的删除与添加 1、节点（机器）的删除 如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动 2、节点（机器）的添加 如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中 通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。 通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。 虚拟主机是分布更加均匀 由于一致性hash算法采用对机器做hash，然后落在圆上，当节点较少时，有可能会出现这些机器节点是均匀分布的现象，这可以采用虚节点的方式来改进。例如现在有四个节点，直接按hash计算后，可能会出现某节点负责的区域更广，而其他区域更窄，虚节点的方式下则可划分为两百份，然后每五十个虚节点指向一个真实的节点机器，这样就可保证节点的均匀分布了。 Hash算法的好坏标准判定哈希算法好坏的四个定义： 1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 理解：增加、删除机器时，必然造成缓存分布变化，对于变化的缓存部分，需要进行移动，保证通过新的Hash算法能够找到缓存数据 3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 理解：相同的内容应尽量被分配到同一个缓存区，否则同一个内容分布在多个地方，会存在数据不一致问题 4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。]]></content>
      <categories>
        <category>分布式架构</category>
      </categories>
      <tags>
        <tag>一致性哈希算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5、素数筛法]]></title>
    <url>%2F2017%2F06%2F11%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D5%E3%80%81%E7%B4%A0%E6%95%B0%E7%AD%9B%E6%B3%95%2F</url>
    <content type="text"><![CDATA[判断一个数是否是素数，复杂度sqrt(n)1234567891011121314151617181920212223242526public class Demo&#123; //判断一个数是否是素数 /** 为什么只需要判断[2,sqrt(n)]？ ** 反证法，假设[2,sqrt(n)]不能整除n，但存在一个数a属于(sqrt(n),n-1]能够整除n，即n = ak。 ** 因为n = sqrt(n)*sqrt(n)，因为a &gt;= sqrt(n)，所以k&lt;=sqrt(n)。已知[2,sqrt(n)]不能整除n，矛盾。 **/ public boolean isPrime(int n)&#123; if(n &lt;= 1)&#123; return false; &#125; for(int i = 2; i*i &lt;= n; i++ )&#123; if(n%i == 0)&#123; return false; &#125; &#125; return true; &#125; public static void main(String[] args)&#123; Demo d = new Demo(); for(int i = 0; i &lt; 50; i++)&#123; System.out.println(i + &quot; &quot; + d.isPrime(i)); &#125; &#125;&#125; 埃氏筛法令A为素数，则A*N（N&gt;1;N为自然数）都不是素数。缺点是这种方法会造成重复筛除合数，影响效率，比如6会被2和3同时删除时间复杂度：O（nloglogn）???求讨论 import java.util.*; public class Demo{ //找出1~N之间所有的素数 public List getPrime(int n){ //保存素数 List result = new LinkedList(); //下标为数字，true为素数，false为合数 boolean[] primes = new boolean[n+1]; //默认都是素数，然后一个个筛掉 for(int i = 0; i]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>素数筛法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存更新的设计模式]]></title>
    <url>%2F2017%2F06%2F01%2F%5BRedis%5D%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[缓存更新的套路 http://coolshell.cn/articles/17416.html/comment-page-2#comments 数据库缓存的几种方式 http://www.jdon.com/repository/cache.html 缓存级别与缓存更新问题 http://www.importnew.com/23967.html 转：有關 Cache 的 read/write through/back/allocat http://blog.sina.com.cn/s/blog_537bca2a0100eyl8.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4、LCA 最近公共祖先问题]]></title>
    <url>%2F2017%2F05%2F26%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D4%E3%80%81LCA%20%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述最近公共祖先问题可以将树从下往上看，两个目标节点到树的根节点组成的两条链表，求两条链表第一次相遇的地方 如下图所示，求3，4的公共祖先，则目标节点到根的链表分别是：3——&gt;1、4——&gt;2——&gt;1，两条链表第一次相遇的地方是1，那么最近公共祖先就是1 另外，4 和 5 的最近公共祖先是2，5和3的最近公共祖先是1，2和1的最近公共祖先是1 Leetcodehttps://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree/description/ 转化成求两个链表的第一个交点思考： 1、深度优先搜索模板 注意递归结束条件 public void DFS(TreeNode root) { if (root == null) { return; } DFS(root.left); DFS(root.right); } 2、增加路径 第一次访问节点的时候将元素添加到栈中 访问完左右节点后，将该元素弹出 什么时候输出结果？访问到叶子节点时输出完整路径root.left=null&amp;&amp;root.right= null 输出结果放在什么位置？可以是第一次访问节点、访问左节点后、访问右节点后，一般在第一次访问时，在将元素放入栈之后输出 public void DFS(TreeNode root, List&lt;Integer&gt; path, int key) { if (root == null) { return; } path.add(root.val); if (root.left == null &amp;&amp; root.right == null) { System.out.println(path); } DFS(root.left, path, key); DFS(root.right, path, key); path.remove(path.size() - 1); } 3、如果找到路径后，停止搜索，输出路径 返回值：是否找到目标节点true/false 如果左边没有找到（返回false），继续搜索右边；如果左边找到了（返回true），不需要搜索右边。停止递归的关键是：如果找到元素后，不再进行递归深入 boolean find = DFS(root.left, path, key) || DFS(root.right, path, key); 本来只要return find即可，但是对于true/false，对于true，不需要pop（）路径，直接return true；如果是false，则需要pop（）当前元素 为什么add不用根据返回值控制？只要递归不深入，不会调用add方法 import java.util.ArrayList; import java.util.List; /** * 树的结构 * 1 * /\ * 2 3 * / \ /\ * 4 5 6 7 */ public class Solution { public boolean DFS(TreeNode root, List&lt;Integer&gt; path, int key) { if (root == null) { return false; } path.add(root.val); //如果找到目标节点后就不需要向下搜索，并且需要一个状态值向上传递，然每层循环都停止搜索 if (root.val == key) { return true; } //左边必须搜索，左边如果搜索到了，则右边可以不搜索（关键） boolean find = DFS(root.left, path, key) || DFS(root.right, path, key); //如果找到了直接返回 if (find) { return true; } else {//没找到，需要将当前节点弹出，并且返回false path.remove(path.size() - 1); return false; } } public static void main(String[] args) { TreeNode t4 = new TreeNode(4, null, null); TreeNode t5 = new TreeNode(5, null, null); TreeNode t6 = new TreeNode(6, null, null); TreeNode t7 = new TreeNode(7, null, null); TreeNode t2 = new TreeNode(2, t4, t5); TreeNode t3 = new TreeNode(3, t6, t7); TreeNode root = new TreeNode(1, t2, t3); Solution s = new Solution(); List&lt;Integer&gt; path = new ArrayList&lt;Integer&gt;(); s.DFS(root, path, 3); System.out.println(path); } } 关键点： 找到之后返回true 如果左边找到了，不需要找右边 如果已经找到了，不需要remove路径；没找到需要移出路径 4、最近公共祖先 import java.util.ArrayList; import java.util.List; /** * 树的结构 * 1 * /\ * 2 3 * / \ /\ * 4 5 6 7 */ public class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if (root == null || p == null || q == null) { return null; } List&lt;TreeNode&gt; path1 = new ArrayList&lt;TreeNode&gt;(); List&lt;TreeNode&gt; path2 = new ArrayList&lt;TreeNode&gt;(); boolean find1 = DFS(root, path1, p); boolean find2 = DFS(root, path2, q); TreeNode result = null; if (find1 &amp;&amp; find2) { int n = Math.min(path1.size(), path2.size()); for (int i = 0; i &lt; n; i++) { if (path1.get(i).val == path2.get(i).val) { result = path1.get(i); }else{ break; } } return result; } else { return null; } } //找路径 public boolean DFS(TreeNode root, List&lt;TreeNode&gt; path, TreeNode key) { if (root == null) { return false; } path.add(root); if (root == key) { return true; } boolean find = DFS(root.left, path, key) || DFS(root.right, path, key); if (find) { return true; } else { path.remove(path.size() - 1); return false; } } public static void main(String[] args) { TreeNode t4 = new TreeNode(4, null, null); TreeNode t5 = new TreeNode(5, null, null); TreeNode t6 = new TreeNode(6, null, null); TreeNode t7 = new TreeNode(7, null, null); TreeNode t2 = new TreeNode(2, t4, t5); TreeNode t3 = new TreeNode(3, t6, t7); TreeNode root = new TreeNode(1, t2, t3); Solution s = new Solution(); System.out.println(s.lowestCommonAncestor(root,t2,t4)); } } 参考http://www.acmerblog.com/lca-lowest-common-ancestor-5574.html 遍历一次public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { //异常输入 if(root == null || p == null || q == null){ return null; } //两个节点在同一侧 if(root == p || root == q){ return root; } //在不同侧 TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); if(left != null &amp;&amp; right != null){ return root; } if(left != null){ return left; } if(right != null){ return right; } return null; } 时间复杂度为O(n)，但是上面的方法还是有所局限的，必须保证两个要查找的节点n1和n2都出现在树中。如果n1不在树中，则会返回n2为LCA，理想答案应该为NULL。要解决这个问题，可以先查找下n1和n2是否出现在树中，然后加几个判断即可。 参考： http://www.acmerblog.com/lca-lowest-common-ancestor-5574.html Tarjan(离线)算法原理（最浅显易懂的描述） 用集合的角度去思考 LCA 问题： 10 与 1，2，5，6 的 LCA 都为 110 与 3，7 的 LCA 都为 310 与 8，9，11 的 LCA 都为 810 与 10，12 的 LCA 都为 12 Tarjan 算法可以批量查询，假设有求5，10的 LCA，3、10的LCA，9、10的LCA 当 DFS 遍历到节点 10 时，查看查询语句中是否有与10相关的：如果求 5、10 的 LCA，只要求当前5所在的集合的祖先就行了，结果就是8如果求 3、10 的 LCA，只要求3所在集合的祖先就行了，结果是3如果求 9、10 的 LCA，只要求9所在结合的祖先就行了，结果是8 那么问题的关键就是 集合怎么表示，集合如何构建？ 并查集可以发现，当 一个数A 与 集合中的元素B 求 LCA 时，结果都是指向同一个祖先，我们将设置一个数据结构将各个节点组成集合，并且能够根据集合中的点访问到祖先，可以使用 并查集 满足上述要求 。并查集维护了当前节点与父节点之间的关系，最终可以获得祖先节点 并查集是当前节点与father节点的映射关系，是一个Key-Value的结构，可以用数组的下标和数组的值作为存储结构，按照上图左子树举个例子： 初始化的时候每个节点的父节点都是自己，如果当前节点的father就是自己本身，那么他就是集合的根节点 并查集查集合根节点： public int find(int x) { int r = x; while(father[r] != r){ r = father[r]; } return r; } 并查集基本介绍完毕，现在可以用并查集来表示集合了，并且找到集合的根节点，接下来的问题，哪些节点可以归为同一个集合？ 算法描述（思路） 还是之前那张图，对于新搜索到的一个结点u，先创建由u构成的集合，再对u的每颗子树进行搜索，每搜索完一棵子树，将子节点归到集合u中 1.任选一个点为根节点，从根节点开始。2.遍历该点u所有子节点v，并标记这些子节点v已被访问过。3.若是v还有子节点，返回2，否则下一步。4.合并v到u上。5.寻找与当前点u有询问关系的点v。6.若是v已经被访问过了，则可以确认u和v的最近公共祖先为v被合并到的父亲节点a。 伪代码 Tarjan(u)//marge和find为并查集合并函数和查找函数 { for each(u,v) //访问所有u子节点v { Tarjan(v); //继续往下遍历 marge(u,v); //合并v到u上 标记v被访问过; } for each(u,e) //访问所有和u有询问关系的e { 如果e被访问过; u,e的最近公共祖先为find(e); } } 算法模拟http://www.cnblogs.com/JVxie/p/4854719.html 代码实现OJhttp://www.cnblogs.com/JVxie/p/4854719.html]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>LCA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1、Leetcode 简单题]]></title>
    <url>%2F2017%2F05%2F23%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D1%E3%80%81Leetcode%20%E7%AE%80%E5%8D%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[找出合理的IP地址 另外，生成符合要求的IP地址可以用StringBuilder的insert方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/**Given a string containing only digits, restore it by returning all possible valid IP address combinations.For example:Given&quot;25525511135&quot;,return[&quot;255.255.11.135&quot;, &quot;255.255.111.35&quot;]. (Order does not matter)**/import java.util.*; public class Solution &#123; private boolean isValid(String s, int i, int j, int k)&#123; if ( k &lt; s.length() - 4 || k &gt; s.length() - 2) return false; else if ( isRange(s, 0, i + 1) &amp;&amp; isRange(s, i + 1, j + 1) &amp;&amp; isRange(s, j + 1, k + 1) &amp;&amp; isRange(s, k + 1, s.length())) return true; return false; &#125; private boolean isRange(String s, int st, int end)&#123; int value = Integer.valueOf(s.substring(st, end)); if ( end - st &gt; 1 &amp;&amp; s.charAt(st) == &apos;0&apos;) return false; if ( value &gt;= 0 &amp;&amp; value &lt;= 255) return true; return false; &#125; private void storeIp(List&lt;String&gt; ipList, String s, int i, int j, int k)&#123; StringBuilder sb = new StringBuilder(s); sb.insert(i + 1, &quot;.&quot;); sb.insert(j + 2, &quot;.&quot;); sb.insert(k + 3, &quot;.&quot;); ipList.add(sb.toString()); &#125; public ArrayList&lt;String&gt; restoreIpAddresses(String s) &#123; ArrayList&lt;String&gt; ipList = new ArrayList&lt;&gt;(); if (s.length() &lt; 4) return ipList; for (int i = 0; i &lt; 3; i++) for (int j = i + 1; j &lt; i + 4; j++) for (int k = j + 1; k &lt; j + 4; k++)&#123; if (isValid(s, i, j, k)) storeIp(ipList, s, i, j, k); &#125; return ipList; &#125;&#125; 链表相加http://www.cnblogs.com/wuyuegb2312/p/3183214.html 证明链表第一次相遇的位置在入口处： 设p1在入口的时候，p2位于L处（入口处为0，顺时针增加）设p1行走x后，p2行走2x后在第一次相遇点相遇，则：x%R = (L + 2x)%r 则：x = kR，L+2x=k’R =&gt;L + x = (k’-k)R，即L+x为R的倍数，x位于入口处]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3、树状数组]]></title>
    <url>%2F2017%2F05%2F23%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D3%E3%80%81%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[树状数组作用如果给定一个数组，要你求里面所有数的和，一般都会想到累加。但是当那个数组很大的时候，累加就显得太耗时了，时间复杂度为O(n)，并且采用累加的方法还有一个局限，那就是，当修改掉数组中的元素后，仍然要你求数组中某段元素的和，就显得麻烦了。所以我们就要用到树状数组，他的时间复杂度为O（lgn），相比之下就快得多 总结：初始复杂度是nlogn，频繁对于单点和区间修改和查询操作，时间复杂度都是log(n)，空间复杂度是n 树状数组结构图 注意：下标从1开始，不要0 下面来分析一下上面那个图看能得出什么规律： c1（01） = a1c2（10） = a1 + a2c3（11） = a3c4（100） = a1 + a2 + a3 + a4c5（101） = a5c6（110） = a5 + a6c7（111） = a7c8（1000） = a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8c9（1001） = a9c10（1010） = a9 + a10c11（1011） = a11c12（1100） = a9 + a10 + a11 + a12c13（1101） = a13c14（1110） = a13 + a14c15（1111） = a15c16（10000） = a1 + a2 + a3 + a4 + a5 + ……. + a16…… 有公式：cn = a(n-a^k+1) + ……… + an（其中 k 为 n 的二进制表示中从右往左数的 0 的个数） k 为 二进制数从右往左数 0 的个数，那么 a^k 为从右往左数第一个非零位到最低位表示的数值 根据公式也可以看出a^k表示的cn由a^k个ai项相加 那么，如何求 a^k 呢？求法如下 1234int lowbit(int x)&#123; return x&amp;(-x); &#125; lowbit（）获取整数 x 的二进制数值中，从低位开始的第一个非零位开始到最低位的数值，即 2^k 次方的值，表示ci由多少个ai相加 1、求数组的和的算法如下： （1）首先，令sum=0，转向第二步；（2）接下来判断，如果 n&gt;0 的话，就令sum=sum+cn转向第三步，否则的话，终止算法，返回 sum 的值；（3）n = n - lowbit（n）（将n的二进制表示的最后一个零删掉），回第二步。 12345678int Sum(int n)&#123; int sum = 0; while(n &gt; 0)&#123; sum += c[n]; n = n-lowbit(n); &#125; return sum;&#125; c[n]维护区间a[n] - lowbit(n) + 1 ~ a[n] 的和，区间长度为lowbit(n)，数组求和即求a[1]~a[n]元素的和，树状数组下转变为区间和，区间间以lowbit(n)的间隔跳转 复杂度的话，lowbit（n）表示从右往左数第一个1到最低位的值，n - lowbit(n)相当于每次把最后一个1变为0，因为一个数二进制下只有log（n）位，所以复杂度是O(log(n))的 2、当数组中的元素有变更时，树状数组就发挥它的优势了，算法如下（修改为给某个节点 i 加上 x ） （1）当 i&lt;=n 时，执行下一步；否则的话，算法结束;（2）ci = ci+x ，i = i + lowbit（i）（在 i 的二进制表示的最后加零），返回第一步。 123456void change(int i, int x)&#123; while(i &lt;= n)&#123; c[i] = c[i] + x; i = i + lowbit(i); &#125;&#125; 应用树状数组求逆序数所谓逆序数，就是指一个序列S[i]，统计处于序列的每个数的比这个数大并且排在它前面的数的数目，然后对于所有数，把这个数目加起来求和就是了。比如 4 3 1 24第一个，所以数目为03的前面是4，大于3的数目为11的前面是4 3 ，大于1的数目为22的前面是4 3 1，大于2的数目为2所以逆序数为1+2+2 = 5 求逆序数的两种方法常规方法是按照逆序数的规则做，结果复杂度是O(n*n)，一般来说，有两种快速的求逆序数的方法，分别是归并排序和树状数组法 树状数组法 当数据的范围较小时，比如maxn=100000，那么我们可以开一个数组c[maxn]，来记录前面数据的出现情况，初始化为0；当数据a出现时，就令c[a]=1。这样的话，欲求某个数a的逆序数，只需要算出在当前状态下c[a+1,maxn]中有多少个1，因为这些位置的数在a之前出现且比a大。但是若每添加一个数据a时，就得从a+1到maxn搜一遍，复杂度太高了，树状数组却能很好的解决区间多次求和这个问题。同样开一个数组d[maxn]，初始化为0，d[i]记录下i结点所管辖范围内当前状态有多少个数；当添加数据a时，就向上更新d,这样一来，欲求a的逆序数时，只需要算sum(maxn)-sum(a)；sum(i)表示第i个位置之前出现了多少个1 举个例子：有5个数，分别为5 3 4 2 1，当读入数据a=5时，c为：0，0，0，0，1；d为：0，0，0，0，1；当读入数据a=3时，c为：0，0，1，0，1；d为：0，0，1，1，1；当读入数据a=4时，c为：0，0，1，1，1；d为：0，0，1，2，1；………… 此思想的关键在于，读入数据的最大值为maxn，由于maxn较小，所以可以用数组来记录状态。当maxn较大时，直接开数组显然是不行了，这是的解决办法就是离散化。所谓离散化，就是将连续问题的解用一组离散要素来表征而近似求解的方法，这个定义太抽象了，还是举个例子吧。 假如现在有一些数：1234 98756 123456 99999 56782，由于1234是第一小的数，所以num[1]=1;依此，有num[5]=2，num[2]=3，num[4]=4，num[3]=5;这样转化后并不影响原来数据的相对大小关系，何乐而不为呢！！！ 还有一点值得注意，当有数据0出现时，由于0&amp;0=0，无法更新，此时我们可以采取加一个数的方法将所有的数据都变成大于0的。 当maxn较小时直接开数组代码如下： public class InverseNumber { //索引0不存放数据 private int[] c = new int[10]; private int sum(int n) { int sum = 0; for (int i = n; i &gt; 0; i = i - lowbit(i)) { sum += c[i]; } return sum; } private void update(int i, int addVal) { for (int j = i; j &lt; c.length; j += lowbit(j)) { c[j] += addVal; } } private int lowbit(int i) { return i &amp; (-i); } /** * 求序列的逆序数 * 有两种方式，1、对于每个数，计算当前位置之前比它大的数的个数，求和（树状数组法） * 2、对于每个数，计算当前位置之后比它小的数的个数，求和 */ public int solve(int[] sequence) { Arrays.fill(c, 0); //初始化树状数组，因为要表示1~len，所以数组长度为len+1 int inverseNum = 0; for (int i = 0; i &lt; sequence.length; i++) { update(sequence[i], 1); inverseNum = inverseNum + sum(c.length - 1) - sum(sequence[i]); } return inverseNum; } public static void main(String[] args) { InverseNumber inverseNumber = new InverseNumber(); System.out.println(inverseNumber.solve(new int[]{1, 2, 3, 4, 5}) == 0); System.out.println(inverseNumber.solve(new int[]{1, 2, 3, 5, 4}) == 1); System.out.println(inverseNumber.solve(new int[]{1, 2, 4, 3, 5}) == 1); System.out.println(inverseNumber.solve(new int[]{1, 2, 4, 5, 3}) == 2); System.out.println(inverseNumber.solve(new int[]{1, 2, 5, 4, 3}) == 3); System.out.println(inverseNumber.solve(new int[]{1, 2, 5, 3, 4}) == 2); System.out.println(inverseNumber.solve(new int[]{1, 3, 2, 4, 5}) == 1); System.out.println(inverseNumber.solve(new int[]{1, 3, 2, 5, 4}) == 2); System.out.println(inverseNumber.solve(new int[]{1, 4, 2, 3, 5}) == 2); System.out.println(inverseNumber.solve(new int[]{1, 4, 2, 5, 3}) == 3); System.out.println(inverseNumber.solve(new int[]{1, 5, 2, 3, 4}) == 3); System.out.println(inverseNumber.solve(new int[]{1, 5, 2, 4, 3}) == 4); } } 采用离散化求逆序数： import java.util.*; public class Solution { BinaryIndexedTree binaryIndexedTree; class mapper { int val; int pos; public mapper(int val, int pos) { this.val = val; this.pos = pos; } } public int InversePairs(int[] array) { //异常条件 if (array == null || array.length == 0) { return 0; } //离散化，用mapper数组扩展array，记录了原数组的pos mapper[] map = new mapper[array.length]; for (int i = 0; i < array.length; i++) { map[i] = new mapper(array[i], i); } //按值升序排序，值相等按pos排序（元素相等时不影响逆序数计算） Arrays.sort(map, new Comparator() { @Override public int compare(mapper o1, mapper o2) { if (o1.val != o2.val) { return o1.val - o2.val; } return o1.pos - o2.pos; } }); //离散后数组 int[] after = new int[array.length]; for (int i = 0; i < map.length; i++) { //离散化关键，从小到大进行替换，根据pos找到原数组的位置 after[map[i].pos] = i + 1;//!!替换后不能出现0！！ } /*for (int i = 0; i < map.length; i++) { array[map[i].pos] = i + 1; }*/ //构建树状数组 binaryIndexedTree = new BinaryIndexedTree(new int[after.length + 1]); int inverseNum = 0; for (int i = 0; i < after.length; i++) { //数组下标为array[i]的值+1，并**计算在该数字插入前，之前已经插入比他大的个数** binaryIndexedTree.update(after[i], 1); //inverseNum += (i + 1 - binaryIndexedTree.sum(after[i])); inverseNum = (inverseNum + (i + 1 - binaryIndexedTree.sum(after[i])) % 1000000007) % 1000000007; } return inverseNum; } public static void main(String[] args) { Solution s = new Solution(); int[] array = {111111111, 222222222, 333333333, 444444444, 555555555, 666666666, 777777777, 0}; System.out.println(s.InversePairs(array));//7 } } /** * 树状数组工具类 */ class BinaryIndexedTree { int[] c; public BinaryIndexedTree(int[] a) { c = new int[a.length]; //c[i] = a[i-lowbit(i)+1] + ... + a[i-1] +a[i],c[i]为a[i]前长度为lowbit(i)的和 for (int i = 1; i < c.length; i++) { for (int j = i - lowbit(i) + 1; j 0; k -= lowbit(k)) { result += c[k]; } return result; } //第x位的数字加上add public void update(int x, int add) { for (int k = x; k < c.length; k += lowbit(k)) { c[k] += add; } } //一个数二进制表示，从右往左数碰到的第一个1位开始，一直往右组成的数，如1100->100 private int lowbit(int x) { return x & (-x); } public static void main(String[] args) { int[] array = {0, 1, 2, 3, 4, 5}; BinaryIndexedTree b = new BinaryIndexedTree(array); for (int i = 1; i < array.length; i++) { System.out.println(b.sum(i)); } b.update(3, 1); System.out.println("更新后"); for (int i = 1; i < array.length; i++) { System.out.println(b.sum(i)); } } } 参考树状数组http://m.baidu.com/from=1086k/bd_page_type=1/ssid=0/uid=0/pu=usm%401%2Csz%40320_1002%2Cta%40iphone_2_5.1_2_6.0/baiduid=99806F566512D4B5CD2F1444260EE0C9/w=0_10_/t=iphone/l=3/tc?ref=www_iphone&amp;lid=7403775788561080468&amp;order=5&amp;fm=alop&amp;tj=www_normal_5_0_10_title&amp;vit=osres&amp;m=8&amp;srd=1&amp;cltj=cloud_title&amp;asres=1&amp;nt=wnor&amp;title=%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84-%E6%9E%AB%E5%8F%B6%E9%A3%98%E6%B3%AA-%E5%8D%9A%E5%AE%A2%E5%9B%AD&amp;dict=30&amp;w_qd=IlPT2AEptyoA_ykz841awPKuClNUeYW&amp;sec=21209&amp;di=21497407b0f1efff&amp;bdenc=1&amp;tch=124.264.223.898.1.220&amp;nsrc=IlPT2AEptyoA_yixCFOxXnANedT62v3IEQGG_ytK1DK6mlrte4viZQRASDfuLnyJG6CwdoS4csxNaT0u3mRU7xJ_r0dmpWknznuPdPbhgK3AHBAQfApiNNbWVS7&amp;eqid=66bf7eda51d220001000000359231e3f&amp;wd=&amp;clk_info=%7B%22srcid%22%3A%221599%22%2C%22tplname%22%3A%22www_normal%22%2C%22t%22%3A1495474296937%2C%22sig%22%3A%22567989%22%2C%22xpath%22%3A%22div-a-h3%22%7D&amp;sfOpen=1 树状数组求逆序数的原理http://www.cnblogs.com/i-love-acm/p/3251036.html 逆序数及其求法http://www.cppblog.com/bennycen/archive/2011/11/17/160369.aspx]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统笔记]]></title>
    <url>%2F2017%2F05%2F22%2F%5B%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%5D%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[进程管理 进程与线程1、进程概念 进程几部分组成： 进程控制块（PCB）：标识进程的存在，描述进程的执行状态 程序段：能够被进程调度程序调度到CPU上执行的程序代码段 数据段：进程中处理的原始数据或者计算的中间结果、结果数据 进程控制块组成： 进程标识符（PID） 进程当前状态：就绪/执行/阻塞 进程队列指针：记录PCB队列中下一个PCB的地址。系统中可能会组织多个PCB队列，如就绪队列、阻塞队列 程序和数据地址 进程优先级 CPU现场保护 通信信息：记录进程执行过程中与别的进程发生的信息交换情况 家族联系：进程创建子进程，形成进程家族树。PCB中指明了子进程和父进程的标识 占有资源清单 为什么PCB是进程存在的标志？系统通过PCB对进程进行控制：1、当系统调度到某进程后，根据其PCB中保存的处理机状态信息，恢复运行的现场，并根据PCB中的程序和数据的内存地址，找到其程序和数据 2、 当进程暂停执行时，将处理机环境保存在PCB中 3、进程间同步、通信时都要访问PCB 2、进程状态与转换： 1、三种状态 就绪：获得除处理器之外的所有资源，一旦获得处理器就立刻可以执行 执行：进程在CPU上执行 阻塞：由于发生某事件（例如IO等待）而无法执行下去 就绪和阻塞的区别：处于就绪状态，当分配处理器时，进程能够立刻执行；阻塞状态时，即使把处理器分配给该进程，它也无法进行 2、进程状态的相互转换 注意：线程进行阻塞状态后，若等到期望的事件发生，先进入就绪状态，等调度程序选中该进程时，进程才能执行 3、进程控制 进程的控制包括进程的创建、撤销、阻塞和唤醒，这些功能一般由操作系统的内核来实现 操作系统内核：把一些与硬件紧密联系的模块，或运行频率较高的模块，以及许多公用的模块安排在靠近硬件的软件层次中，并使他们常驻内存，提高操作系统的效率 4、进程组织 5、进程通信：共享存储系统、消息传递系统、管道通信 6、进程概念与多线程模型 处理器调度1、调度的基本概念 2、调度时机、切换与过程 3、调度的基本原则 4、调度方式 5、典型调度算法 同步与互斥1、进程同步的基本概念 2、实现临界区互斥的基本方法 3、信号量 4、管程 5、经典同步问题 死锁1、死锁概念 2、死锁处理策略 3、死锁预防 4、死锁避免 死锁检测和解除中央处理器CPU由运算器、控制器、寄存器及高速缓存组成 CPU状态：1、内核态：运行操作系统程序2、用户态：运行用户程序 CPU状态转换：1、用户态——&gt;内核态：唯一途径是中断、异常、陷入机制2、内核态——&gt;用户态：设置程序状态字PSW 中断涉及到的对象：CPU、CPU正在处理的程序、事件、事件处理程序 定义：中断是CPU对某个事件的反应。CPU暂停正在执行的程序，保留现场自动转去执行事件的处理程序，完成后返回断点继续执行被打断的程序 作用： 1、支持CPU和设备之间的并行操作。当CPU启动设备进行输入输出后，设备可以独立工作，CPU转去处理其他事情。当设备完成输出/输出后，通过向CPU发中断报告此次输出/输出结果，让CPU决定如何处理以后的事情2、CPU执行指令时异常的引入。如果执行指令时出现算术溢出，除零等异常，硬件改变CPU的执行流程，转到相应的错误处理程序或异常处理程序 理解： 1、小明在看书，这时候电话来了，小明把书签放在书上，然后去接电话，回来后继续从刚才那个地方开始看，这个是中断的概念2、小明在看书，这时候有点口渴了，小明将书签放在书上，然后去喝口水，回来继续看书。口渴了相当于异常出现，去喝水相当于是异常处理程序 事件： 中断处理流程： CPU取出一条执行，并执行，如果检测到中断，获得中断码（处理器状态），并通过查中断向量表找到中断处理程序 中断向量表 中断向量表是中断码（处理器状态）与中断处理程序的映射。执行过程中按照中断号的不同，通过中断向量表执行不同的中断处理程序 系统调用定义：系统在编程时可以调用操作系统的功能 作用：1、系统调用是操作系统提供给编程人员的唯一接口2、使CPU的状态从用户态陷入内核态 系统调用、库函数、API、内核函数之间的关系： 应用程序可以直接执行系统调用，但一般应用调用调用C的函数库间接执行系统调用。C函数库是对系统调用的封装。内核函数中只是一部分开放出来允许开发人员进行调用 系统调用的执行过程： 当CPU执行到特殊的陷入指令时 1、中断/异常机制：硬件保护现场，通过查中断向量表将控制权转给系统调用总入口程序2、系统调用总入口程序：保存线程，将参数保存在内核的栈中，通过查系统调用表把控制权转给相应的系统调用处理3、执行系统调用4、恢复现场，返回用户程序 存储管理内存划分内存划分有6种方式，这里只给出3种，另外3种页式、段式、段页式下面介绍 1、单一连续区：一段时间内只有一个进程在内存，简单但内存利用率低2、固定分区：把内存空间分割成若干区域，每个分区大小可以相同也可以不同，分区大小固定不变，每个分区只能装一个进程3、可变分区：根据进程的需要，把内存空间空闲分割出一个分区，分配给该进程。缺点是在内存多次内存分配和回收后会留下很多碎片，可以采用紧缩技术解决（采用动态重定向方式时，只需要改变重定向寄存器地址） 记录内存划分结果的数据结构： 1、等长划分、单一内存：可以用位图表示，0表示空闲，1表示占用2、不等长划分 空闲区表，每个表项记录空闲的起始地址、长度、标志位（标志是否被分配）。内存回收时，设置标志为0，不进行前后内存合并时，采用空闲区表合适 空闲块链，将表项用链表的方式连接起来。当内存回收合并前后内存块时，需要增加、删除表项，使用空闲块链表比较合适 内存分配当一个进程需要分配内存时，采用什么内存分配算法： 1、首次适配：在空闲表中找到第一个满足进程要求的空闲区2、下次适配：在上次找到的空闲去后接着查找3、最佳适配：查找整个空闲区表，找到满足进程要求最小的空闲区 内存分配案例： 内存分配是需要维护两个表，分别是空闲区表和已分配表 内存回收算法当某一块归还后，前后空闲空间合并，并修改内存空闲表，分为四种情况： 1、上相邻2、下相邻3、上下都相邻4、上下都不相邻 伙伴系统：经典的内存划分、分配、回收算法主要思想：将内存按照2的幂进行划分，组成若干空闲块链表；查找该链表找到能满足进程需求的最佳匹配块 算法：1、首先将整个可用空间看做一块2、如果进程要求分配的大小大于可用空间的一半，小于剩余空间大小，则分配整个块。否则将块划分成两个大小相等的伙伴。一直划分下去，直到产生大于或等于分配大小的最小块 地址重定位逻辑地址：用户程序中采用的是相对地址的形式，其首地址为0，CPU执行过程中不能通过逻辑地址读取内存中的信息 物理地址：内存中存储单元的地址，可直接寻址 定义：CPU执行指令时，将用户程序中的逻辑地址转换为运行时可被直接寻址的物理地址，这一过程称为地址重定向 动态重定向实现： CPU在执行指令时，逻辑地址加上重定向寄存器中的地址得到物理地址，可被直接寻址 页式存储用户进程划分： 用户进程地址空间被划分成大小相等部分，称为页或者页面，从0开始编号 内存空间按相同大小划分成大小相等部分，称为块或内存块，从0开始编号 内存分配： 进程划分成若干页，以页为单位分配物理块 逻辑相邻的页，物理上不一定相邻 典型页面大小：4K 页表： 页表记录了页号与物理块的对应关系，每个进程一个页表 逻辑地址： 逻辑地址 = 页号（20位） + 页内偏移（4K = 12位） CPU取得逻辑地址，自动划分为页号和页内地址，用页号在页表中查找到物理块，再加上页内地址拼接成物理地址，即物理地址=物理块号+页内便宜 段式存储作业的地址空间被划分成若干段，如主程序段MAIN、子程序段X、数据段D及栈段S。每个段定义自己的逻辑信息，方便编程 用户进程划分： 用户进程地址按程序自身的逻辑关系划分成若干个程序段，每个程序段都有一个段名 内存空间动态划分成若干长度不相同的区域，称为物理段，每个物理段由起始地址和长度确定 内存分配：以段为单位进行分配，每段在程序中占据连续空间，但各段之间可以不相邻 段表： 记录了段号与物理段首地址及长度的对应关系，每个进程一个段表 逻辑地址： 逻辑地址 = 段号 + 段内偏移 CPU取到逻辑地址后，用段号查找段表，得到该段在内存中的起始地址，与段内偏移地址计算出物理地址 段页式存储★★★★★分页系统能有效提高内存的利用率，而分段系统能很好满足用户需求。段页式存储方式结合了两者的优点 用户进程划分： 将用户进程划分为若干段，把每个段划分成若干页 内存划分：同页式存储管理方案 内存分配：以页为单位进行分配 段表：用户进程划分为多个段，每个段表示一个逻辑地址区间；段表记录每一段表包括的逻辑地址范围，用页表地址和页表长度两个表示，引入页表长度防止寻址越界（段式存储中记录了物理段起始地址和长度，即段表记录的是起始地址+长度） 页表： 段中的一段逻辑地址区间按照页式存储的方式，因此需要一张页表，记录页号与物理页的映射关系 综上所述，使用段页式存储管理，一个进程有一张段表，多个页表 逻辑地址组成： CPU取到逻辑地址后，获得该地址所在的段号，在段表中查询到页表的起始地址和长度(因为每个段对应一个页表，需要获得页表位置)；根据逻辑地址中的段内页号，查找页表读到该页所在的物理块号；最后用块号+页内地址构成物理地址]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win7系统关闭135、137、138、139、445端口方法]]></title>
    <url>%2F2017%2F05%2F19%2F%5B%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%5Dwin7%E7%B3%BB%E7%BB%9F%E5%85%B3%E9%97%AD135%E3%80%81137%E3%80%81138%E3%80%81139%E3%80%81445%E7%AB%AF%E5%8F%A3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1、关闭139端口 ipc和RPC漏洞存在于此。鼠标右击”网络邻居”，选择”属性”，再鼠标右击”本地连接”，选择”属性”。选择”TCP/IP协议/属性/高级”，进入”高级TCP/IP设置”对话框，选择”WINS”标签，勾选”禁用TCP/IP上的NETBIOS”一项，关闭NETBIOS. 2、关闭445端口 修改注册表，添加一个键值（HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\NetBT\Parameters）在右面的窗口建立一个SMBDeviceEnabled为DWORD类型键值为0这样就ok了。 3、关闭3389端口 在我的电脑上点右键选”属性”–&gt;”远程”，将里面的远程协助和远程桌面两个选项框里的勾去掉。 （HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp）来到这里，找到PortNumber，十进制是3389的，你随意把它改成其它4个数字吧，我改成1314了。此外，还要禁用Telnet、Terminal Services这两个危险服务。 4、关闭135的经过注册表更改 （1）、HKEY_LOCAL_MACHINE→SOFTWARE→Microsoft→Ole→EnableDCOM的值改为”N” HKEY_LOCAL_MACHINE→SOFTWARE→Microsoft→Rpc→DCOM Protocols键值中删除”ncacn_ip_tcp” （2）、此外，还需要确认是否停用了”Distributed Transaction Coordinator”此项服务。 全部设置完成之后需要重启计算机，启动一下输入CMD，然后直接打入netstat -an这个命令，看端口是否已经全部关闭]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>勒索病毒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux软件安装目录选择]]></title>
    <url>%2F2017%2F05%2F16%2F%5BLinux%5DLinux%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E7%9B%AE%E5%BD%95%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[/usr：系统级的目录，可以理解为C:/Windows/，/usr/lib理解为C:/Windows/System32。/usr/local：用户级的程序目录，可以理解为C:/Progrem Files/。用户自己编译的软件默认会安装到这个目录下。/opt：用户级的程序目录，可以理解为D:/Software，opt有可选的意思，这里可以用于放置第三方大型软件（或游戏），当你不需要时，直接rm -rf掉即可。在硬盘容量不够时，也可将/opt单独挂载到其他磁盘上使用。 个人习惯让软件包管理器来管理/usr目录，而把自定义的脚本(scripts)、软件放到/usr/local目录下面。/opt存放测试软件，用完就把目录删除即可]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx反向代理、负载均衡]]></title>
    <url>%2F2017%2F05%2F16%2F%5BSSM%5DNginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E3%80%81%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[Nginx基本功能极速入门http://xxgblog.com/2015/05/17/nginx-start/ Gitlab 上nginx反向代理（下次继续研究）https://www.xiaohui.org/archives/1602.html]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>反向代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab安装配置]]></title>
    <url>%2F2017%2F05%2F16%2F%5BGit%5DGitlab%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装之前安装的时候忘记了，是通过官网的教程，遇到问题再去网上找的方式安装成功的，可以参考一下文档 http://skyao.github.io/2015/02/16/git-gitlab-setup/https://segmentfault.com/a/1190000002722631 配置文件配置文件位置： /etc/gitlab/gitlab.rb 配置生效： sudo gitlab-ctl reconfigure Nginx 运行目录： /opt/gitlab/embedded/sbin/nginx Nginx 配置文件(会被覆盖)： /var/opt/gitlab/nginx/etc/nginx.conf 在/var/opt/gitlab/nginx/etc/nginx.conf 开头处有这样的内容： # This file is managed by gitlab-ctl. Manual changes will be # erased! To change the contents below, edit /etc/gitlab/gitlab.rb # and run `sudo gitlab-ctl reconfigure`. 配置文件引用文件： /var/opt/gitlab/nginx/etc/gitlab-http.conf 原来可以通过修改/etc/gitlab/gitlab.rb来配置，我再折腾一下。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下安装Nexus]]></title>
    <url>%2F2017%2F05%2F16%2F%5BMaven%5DLinux%E4%B8%8B%E5%AE%89%E8%A3%85Nexus%2F</url>
    <content type="text"><![CDATA[Linux安装目录选择/usr：系统级的目录，可以理解为C:/Windows/，/usr/lib理解为C:/Windows/System32。/usr/local：用户级的程序目录，可以理解为C:/Progrem Files/。用户自己编译的软件默认会安装到这个目录下。/opt：用户级的程序目录，可以理解为D:/Software，opt有可选的意思，这里可以用于放置第三方大型软件（或游戏），当你不需要时，直接rm -rf掉即可。在硬盘容量不够时，也可将/opt单独挂载到其他磁盘上使用。 个人习惯让软件包管理器来管理/usr目录，而把自定义的脚本(scripts)、软件放到/usr/local目录下面。/opt存放测试软件，用完就把目录删除即可 Nexus安装注意Nexus对JDK版本有要求博主环境：JDK1.6.45 ，nexus-2.4-bundle.tar.gzNexus所有版本下载地址：http://www.sonatype.org/nexus/archived 1、下载Nexus后，在/usr/local/下创建nexus目录2、进入nexus目录，将下载文件nexus-2.4-bundle.tar.gz移动到该目录下，使用mv命令3、tar -zxvf nexus-2.4-bundle.tar.gz节解压，会生成nexus-2.4.0-09、sonatype-work两个目录4、编辑系统配置文件：vim /etc/profile，在文件的尾巴增加下面内容： # Nexus NEXUS_HOME=/usr/local/nexus-2.4.0-09 export NEXUS_HOME RUN_AS_USER=root export RUN_AS_USER 5、刷新配置：source /etc/profile6、开放防火墙端口： 添加规则：sudo iptables -I INPUT -p tcp -m tcp –dport 8081 -j ACCEPT 保存规则：sudo /etc/rc.d/init.d/iptables save 重启 iptables：sudo service iptables restart 7、启动nexus，进入/usr/local/nexus/nexus-2.4.0-09/bin目录，执行./nexus start8、访问http://115.159.84.37:8081/nexus 参考： https://tianweili.github.io/2015/03/17/Linux%E4%B8%8B%E4%BD%BF%E7%94%A8nexus%E6%90%AD%E5%BB%BAmaven%E7%A7%81%E6%9C%8D/https://github.com/judasn/Linux-Tutorial/blob/master/Nexus-Install-And-Settings.md 配置nexus、添加自定义jar包仓库地址： &lt;!-- 仓库地址 --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Team Nexus Repository&lt;/name&gt; &lt;url&gt;http://yourhostname:8081/nexus/content/groups/public&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; jar包依赖： &lt;!-- jar --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;de.innosystec&lt;/groupId&gt; &lt;artifactId&gt;java-unrar&lt;/artifactId&gt; &lt;version&gt;0.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; https://tianweili.github.io/2015/03/17/Linux%E4%B8%8B%E4%BD%BF%E7%94%A8nexus%E6%90%AD%E5%BB%BAmaven%E7%A7%81%E6%9C%8D/ 我搭建的maven仓库http://maven.qianmingxs.com:8081/nexus 仓库地址：http://maven.qianmingxs.com:8081/nexus/content/groups/public Nexus配置、部署http://aijezdm915.iteye.com/blog/1335025]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>Nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap]]></title>
    <url>%2F2017%2F05%2F10%2F%5BJDK%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%5DHashMap%2F</url>
    <content type="text"><![CDATA[存储结构 从图中可以看出 HashMap 的底层就是一个数组结构，数组中的每一项又是一个链表 1234567891011121314transient Entry&lt;K,V&gt;[] table; static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; //键 V value; //值 Entry&lt;K,V&gt; next; //指向下一个节点 int hash; //散列值 Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; &#125; HashMap有一个属性是Entry的数组table。Entry就是table数组中的元素，Map.Entry保存一个键值对和这个键值对持有指向下一个键值对的引用，如此就构成了链表了 构造方法一些属性： capacity：数组的长度，默认是16 loadFactor：HashMap元素的个数除以数组的长度，当元素个数大于threshold时，需要扩容。默认负载因子是0.75 threashold：数组的长度乘以负载因子，当元素大于threshold时，需要扩容。默认threshold = 16*0.75 = 12 size：HashMap中元素的个数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/**根据指定容量和负载因子构造HashMap*/ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); /** * 数组最大容量是 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30，即32位最大2的整数次 * 如果传入初始容量太大，真实设置的的最大 */ if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); /** * 找到大于给出的初始容量的2的乘方 */ // Find a power of 2 &gt;= initialCapacity int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; /** * 负载因子是链表的长度除以数组的长度，当链表的长度大于threshold时，需要扩容 */ this.loadFactor = loadFactor; threshold = (int)Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); /** * 初始化 Entry 数组 */ table = new Entry[capacity]; /** * 空函数，子类可扩展 */ init(); &#125; /**根据指定的容量和默认的负载因子构造HashMap*/ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; //默认的空的构造器 public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; /**通过指定一个Map对象进行构造*/ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); putAllForCreate(m); &#125; PUT方法当存入的key是null的时候将调用putForNUllKey方法，暂时将这段逻辑放一边，看key不为null的情况。先调用了hash(int h)方法获取了一个hash值。 遍历table[i]上的元素，如果存在键相等，则替换它的值。否则以头插法的方式插入链表 之后判断size是否到达了需要扩充table数组容量的界限并让size自增1，如果达到了则调用resize(int capacity)方法将数组容量拓展为原来的两倍。 public V put(K key, V value) { // HashMap允许存放null键和null值。 // 当key为null时，调用putForNullKey方法，将value放置在数组第一个位置。 if (key == null) return putForNullKey(value); // 根据key的keyCode重新计算hash值。 int hash = hash(key);//注意这里的实现是jdk1.7和以前的版本有区别的 // 搜索指定hash值在对应table中的索引。 int i = indexFor(hash, table.length); // 如果 i 索引处的 Entry 不为 null，通过循环不断遍历 e 元素的下一个元素。如果键的Hash值一样，而且equal相等 for (Entry e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash && ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } // 如果i索引处的Entry为null，表明此处还没有Entry。 modCount++; // 将key、value添加到i索引处。 addEntry(hash, key, value, i); return null; } /** * 采用头插法，即使头结点是空也没有关系！！ * 数组上的元素为刚插入的节点 */ void addEntry(int hash, K key, V value, int bucketIndex) { Entry e = table[bucketIndex]; table[bucketIndex] = new Entry(hash, key, value, e); if (size++ >= threshold) resize(2 * table.length); } 为什么要进行两次Hash？ 防止质量较差的哈希函数带来过多的冲突（碰撞）问题。Java中int值占4个字节，即32位。根据这32位值进行移位、异或运算得到一个值。 如何确定元素在数组的位置？ static int indexFor(int h, int length) { return h &amp; (length-1); } 这样可以保证结果的最大值是length-1，而且均匀分布在数组中，异或的操作效率比取余的效率高 HashMap中如何判断两个键相等？ 两个对象的HashCode相等， 而且equals相等。所以如果使用对象的作为键，需要重写HashCode和equals方法 String已经重写了HashCode，String中的数据结构是char[] s，Hash 值的计算方法是 s[0]31^(n-1) + s[1]31^(n-2) + ….. + s[0]*31^0 可以采用迭代的方法计算：h = h * 31 + s[i] int h = 0; for(int i = 0; i &lt; n; i++){ h = h * 31 + s[i]; } 链表扩容 当链表内元素大于threashold时，新建一个新的数组，数组长度变成原来的两倍，并将原来的元素复制到新数组上 void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; // 这个if块表明，如果容量已经到达允许的最大值，即MAXIMUN_CAPACITY，则不再拓展容量，而将装载拓展的界限值设为计算机允许的最大值。 // 不会再触发resize方法，而是不断的向map中添加内容，即table数组中的链表可以不断变长，但数组长度不再改变 if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } // 创建新数组，容量为指定的容量 Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; // 设置下一次需要调整数组大小的界限 threshold = (int)(newCapacity * loadFactor); } 将old数组上的元素复制到新数组上的操作在transfer上完成，主要步骤是： 遍历原来的Entry数组 遍历链表 将链表元素依次按照插入到新的数组中(头插法)，链表反置 void transfer(Entry[] newTable) { // 保留原数组的引用到src中， Entry[] src = table; // 新容量使新数组的长度 int newCapacity = newTable.length; // 遍历原数组 for (int j = 0; j < src.length; j++) { // 获取元素e Entry e = src[j]; if (e != null) { // 将原数组中的元素置为null src[j] = null; // 遍历原数组中j位置指向的链表 do { Entry next = e.next; // 根据新的容量计算e在新数组中的位置 int i = indexFor(e.hash, newCapacity); // 将e插入到newTable[i]指向的链表的头部 e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); } } } HashMap允许键null、值null，怎么处理？ 从源码可以看到，key为null的对象放在数组索引0的位置。put的方式和put普通元素一样，首先遍历链表，是否有相同key的元素，如果有则替换并返回原来的值。否则头插入的方式将元素插入链表 private V putForNullKey(V value) { for (Entry e = table[0]; e != null; e = e.next) { if (e.key == null) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(0, null, value, 0); return null; } GET方法12345678910111213141516public V get(Object key) &#123; /** * 如果key为null，从table[0]所在的链表进行搜索，如果存在元素且元素的key为null，返回元素的值；如果之前没有传入key为null的元素，那么返回null */ if (key == null) return getForNullKey(); int hash = hash(key.hashCode()); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; &#125; return null;&#125; 该方法分为key为null和不为null两块。先看不为null的情况。先获取key的hash值，之后通过hash值及table.length获取key对应的table数组的索引，遍历索引的链表，所找到key相同的元素，则返回元素的value，否者返回null。不为null的情况调用了getForNullKey()方法。 private V getForNullKey() { for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) { if (e.key == null) return e.value; } return null; } 参考：http://www.cnblogs.com/hzmark/archive/2012/12/24/HashMap.html containsKeycontainsKey(Object key)方法很简单，只是判断getEntry(key)的结果是否为null，是则返回false，否返回true 123public boolean containsKey(Object key) &#123; return getEntry(key) != null;&#125; getEntry(Object key)也没什么内容，只是根据key对应的hash值计算在table数组中的索引位置，然后遍历该链表判断是否存在相同的key值。 123456789101112final Entry&lt;K,V&gt; getEntry(Object key) &#123; int hash = (key == null) ? 0 : hash(key.hashCode()); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; containsValue判断一个value是否存在比判断key是否存在还要简单，就是遍历所有元素判断是否有相等的值。这里分为两种情况处理，value为null何不为null的情况，但内容差不多，只是判断相等的方式不同。 public boolean containsValue(Object value) { if (value == null) return containsNullValue(); Entry[] tab = table; for (int i = 0; i < tab.length ; i++) for (Entry e = tab[i] ; e != null ; e = e.next) if (value.equals(e.value)) return true; return false; } private boolean containsNullValue() { Entry[] tab = table; for (int i = 0; i < tab.length ; i++) for (Entry e = tab[i] ; e != null ; e = e.next) if (e.value == null) return true; return false; } remove(Object key)public V remove(Object key) { Entry&lt;K,V&gt; e = removeEntryForKey(key); return (e == null ? null : e.value); } 看这个方法，removeEntryKey(key)的返回结果应该是被移除的元素，如果不存在这个元素则返回为null。remove方法根据removeEntryKey返回的结果e是否为null返回null或e.value。 final Entry removeEntryForKey(Object key) { int hash = (key == null) ? 0 : hash(key.hashCode()); int i = indexFor(hash, table.length); Entry prev = table[i]; Entry e = prev; while (e != null) { Entry next = e.next; Object k; if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) { modCount++; size--; //临界情况，如果是第一个节点 if (prev == e) table[i] = next; else prev.next = next; e.recordRemoval(this); return e; } prev = e; e = next; } return e; } 删除节点需要两个指针pre和e，next可以不需要吧？ HashMap产生死锁的原因调用 PUT 函数时，当 HashMap 中的元素大于 Threshold 时，会调用 Resize 函数进行扩容，数组长度增大一倍，整个过程如下： 对索引数组中的元素遍历 对链表上的每一个节点遍历：用 next 取得要转移那个元素的下一个，将 e 转移到新 Hash 表的头部，因为可能有元素，所以先将 e.next 指向新 Hash 表的第一个元素（如果是第一次就是 null)，这时候新 Hash 的第一个元素是 e，但是 Hash 指向的却是 e 没转移时候的第一个，所以需要将 Hash 表的第一个元素指向 e 循环2，直到链表节点全部转移 循环1，直到所有索引数组全部转移 经过这几步，我们会发现链表转移的时候是逆序的。假如转移前链表顺序是1-&gt;2-&gt;3，那么转移后就会变成3-&gt;2-&gt;1。这时候就有点头绪了，死锁问题不就是因为1-&gt;2的同时2-&gt;1造成的吗？所以，HashMap 的死锁问题就出在这个transfer()函数上。 public V put(K key, V value) { if (table == EMPTY_TABLE) { inflateTable(threshold); } if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); //如果该 key 存在，就替换旧值 for (Entry e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash && ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; //如果没有这个 key，就插入一个新元素！跟进去看看 addEntry(hash, key, value, i); return null; } void addEntry(int hash, K key, V value, int bucketIndex) { //查看当前的size是否超过了我们设定的阈值threshold，如果超过，需要resize if ((size >= threshold) && (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); } //新建一个更大尺寸的hash表，把数据从老的Hash表中迁移到新的Hash表中。 void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } //创建一个新的 Hash 表 Entry[] newTable = new Entry[newCapacity]; //转移！！！！跟进去 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } //高能预警！！！！重点全在这个函数中 void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry e : table) { while(null != e) { Entry next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } } 下面着重分析一下transfer方法，精简后得到如下代码★★★★★： 12345678910while(null != e) &#123; //因为是单链表，如果要转移头指针，一定要保存下一个结点，不然转移后链表就丢了 Entry&lt;K,V&gt; next = e.next; //e 要插入到链表的头部，所以要先用 e.next 指向新的 Hash 表第一个元素 e.next = newTable[i]; //将新 Hash 表的头指针指向 e newTable[i] = e; //转移 e 的下一个结点 e = next;&#125; 死锁原因重现 假设这里有两个线程同时执行了 put() 操作，并进入了 transfer() 环节，现在假设线程1的工作情况如下代码所示，而线程2完成了整个 transfer() 过程，所以就完成了 rehash。 while(null != e) { Entry next = e.next; //线程1执行到这里被调度挂起了 e.next = newTable[i]; newTable[i] = e; e = next; } 那么现在的状态： 从上面的图我们可以看到，因为线程1的 e 指向了 key(3)，而 next 指向了 key(7)，在线程2 rehash 后，就指向了线程2 rehash 后的链表。 然后线程1被唤醒了，执行： 第一步 Entry&lt;K,V&gt; next = e.next; e.next = newTable[i]; newTable[i] = e; e = next; 链表状态如下图： 第二步 Entry&lt;K,V&gt; next = e.next; e.next = newTable[i]; newTable[i] = e; e = next; 链表状态如下： 第三步 Entry&lt;K,V&gt; next = e.next; e.next = newTable[i]; newTable[i] = e; e = next; 很明显，环形链表出现了！！当然，现在还没有事情，因为下一个节点是 null，所以transfer()就完成了，等put()的其余过程搞定后，HashMap 的底层实现就是线程1的新 Hash 表了。 没错，put()过程虽然造成了环形链表，但是它没有发生错误。它静静的等待着get()这个冤大头的到来。 现在程序被执行了一个hashMap.get(11)，这时候会调用getEntry()，这个函数就是去找对应索引的链表中有没有这个 key。然后。。。。悲剧了 因为 HashMap 为了性能考虑，没有使用锁机制。所以就是非线程安全的，而 ConcurrentHashMap 使用了锁机制，所以是线程安全的。要并发就使用 ConcurrentHashMap 参考：http://blog.csdn.net/luxia_24/article/details/52344367]]></content>
      <categories>
        <category>JDK源码阅读</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 添加本地 jar 包]]></title>
    <url>%2F2017%2F05%2F07%2F%5BMaven%5DMaven%20%E6%B7%BB%E5%8A%A0%E6%9C%AC%E5%9C%B0%20jar%20%E5%8C%85%2F</url>
    <content type="text"><![CDATA[方法一：将jar包安装到本地repository中1mvn install:install-file -Dfile=my-jar.jar -DgroupId=org.richard -DartifactId=my-jar -Dversion=1.0 -Dpackaging=jar 方法二：添加scope为system的依赖，解决编译、运行问题 &lt;dependency&gt; &lt;groupId&gt;com.microsoft.sqlserver&lt;/groupId&gt; &lt;artifactId&gt;sqljdbc&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/lib/sqljdbc-3.0.jar&lt;/systemPath&gt; &lt;/dependency&gt; 打包时将自定义的jar包复制到web/lib下 &lt;!--war打包--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;configuration&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;${project.basedir}/lib&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/lib&lt;/targetPath&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; 方法三：建立自己的仓库 http://blog.csdn.net/chagaostu/article/details/50056427]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RedisTemplate 使用及基本原理]]></title>
    <url>%2F2017%2F05%2F06%2F%5BRedis%5DRedisTemplate%20%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[RedisTemplate 配置在 Spring 配置文件中，配置的对象有： 连接池配置对象 Jedis连接工厂，提供 getConnection 方法从连接池中获取连接 RedisTemplate，Redis操作类 思路：1、首先必须有 Redis 操作类 2、然后为了提高性能，加入 Redis 连接池，调用连接池的 getConnection 方法获得连接 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot; default-lazy-init=&quot;true&quot;&gt; &lt;context:component-scan base-package=&quot;com.mk.util.redis&quot;/&gt; &lt;!-- 连接池配置 --&gt; &lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;!-- 连接池中最大空闲的连接数 --&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;$&#123;jedis.maxIdle&#125;&quot;&gt;&lt;/property&gt; &lt;!-- 连接空闲的最小时间，达到此值后空闲连接将可能会被移除。负值(-1)表示不移除. --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;$&#123;jedis.minEvictableIdleTimeMillis&#125;&quot;&gt;&lt;/property&gt; &lt;!-- 对于“空闲链接”检测线程而言，每次检测的链接资源的个数。默认为3 --&gt; &lt;property name=&quot;numTestsPerEvictionRun&quot; value=&quot;$&#123;jedis.numTestsPerEvictionRun&#125;&quot;&gt;&lt;/property&gt; &lt;!-- “空闲链接”检测线程，检测的周期，毫秒数。如果为负值，表示不运行“检测线程”。默认为-1. --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;$&#123;jedis.timeBetweenEvictionRunsMillis&#125;&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- Spring提供的Redis连接工厂 --&gt; &lt;bean id=&quot;jedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot; destroy-method=&quot;destroy&quot;&gt; &lt;!-- 连接池配置 --&gt; &lt;property name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot;&gt;&lt;/property&gt; &lt;!-- Redis服务主机 --&gt; &lt;property name=&quot;hostName&quot; value=&quot;$&#123;redis.hostName&#125;&quot;&gt;&lt;/property&gt; &lt;!-- Redis服务端口号 --&gt; &lt;property name=&quot;port&quot; value=&quot;$&#123;redis.port&#125;&quot;&gt;&lt;/property&gt; &lt;!-- 连超时设置 --&gt; &lt;property name=&quot;timeout&quot; value=&quot;$&#123;redis.timeout&#125;&quot;&gt;&lt;/property&gt; &lt;!-- 是否使用连接池 --&gt; &lt;property name=&quot;usePool&quot; value=&quot;$&#123;redis.usePool&#125;&quot;&gt;&lt;/property&gt; &lt;!-- Redis服务连接密码 --&gt; &lt;!--&lt;property name=&quot;password&quot; value=&quot;$&#123;redis.password&#125;&quot;&gt;&lt;/property&gt;--&gt; &lt;/bean&gt; &lt;!-- Spring提供的访问Redis类 --&gt; &lt;bean id=&quot;redisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt; &lt;!-- Redis连接工厂 --&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;&gt;&lt;/property&gt; &lt;property name=&quot;keySerializer&quot;&gt; &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot;/&gt; &lt;/property&gt; &lt;!-- JdkSerializationRedisSerializer支持对所有实现了Serializable的类进行序列化 --&gt; &lt;property name=&quot;valueSerializer&quot;&gt; &lt;bean class=&quot;org.springframework.data.redis.serializer.JdkSerializationRedisSerializer&quot;/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--下面是自己编写的监听器，用来实现发布订阅功能的，对于基础的redis使用不需要--&gt; &lt;bean id=&quot;redisMessageListener&quot; class=&quot;com.mk.util.redis.listener.RedisMessageListener&quot;/&gt; &lt;bean class=&quot;org.springframework.data.redis.listener.RedisMessageListenerContainer&quot; destroy-method=&quot;destroy&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;/&gt; &lt;property name=&quot;taskExecutor&quot;&gt; &lt;bean class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;5&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;messageListeners&quot;&gt; &lt;map&gt; &lt;entry key-ref=&quot;redisMessageListener&quot;&gt; &lt;!--这里配置频道信息--&gt; &lt;bean class=&quot;org.springframework.data.redis.listener.ChannelTopic&quot;&gt; &lt;constructor-arg value=&quot;notify&quot;/&gt; &lt;/bean&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; Redis操作工具类提供了set/get方法，删除缓存，缓存定时删除方法 12345678910111213141516171819202122232425262728293031323334public class RedisUtils &#123; @Autowired private RedisTemplate&lt;String,Object&gt; redisTemplate; public void set(String key, Object val) &#123; redisTemplate.boundValueOps(key).set(val); &#125; public Object get(String key) &#123; return redisTemplate.boundValueOps(key).get(); &#125; public void delete(String key) &#123; redisTemplate.delete(key); &#125; public void expire(String key, long timeout)&#123; //单位为秒 redisTemplate.expire(key, timeout, TimeUnit.SECONDS); &#125; /** * 发布消息 * * @param channel 发布的频道，需要在redis配置文件中进行配置 * @param message */ public void sendMessage(Serializable message) &#123; sendMessage(&quot;notify&quot;,message); &#125; public void sendMessage(String channel, Serializable message) &#123; redisTemplate.convertAndSend(channel,message); &#125;&#125; RedisTemplate源码1、获得连接2、调用action.doRedis3、连接创建动态代理4、释放连接 序列化：String channerl =&gt; byte[]Object message Redis 订阅和发布Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息Redis 客户端可以订阅任意数量的频道。 下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系： 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： redis 命令1、创建频道名 redisChat redis 127.0.0.1:6379&gt; SUBSCRIBE redisChat Reading messages... (press Ctrl-C to quit) 1) &quot;subscribe&quot; 2) &quot;redisChat&quot; 3) (integer) 1 2、发送消息 现在，我们先重新开启个 redis 客户端，然后在同一个频道 redisChat 发布两次消息，订阅者就能接收到消息。 redis 127.0.0.1:6379&gt; PUBLISH redisChat &quot;Redis is a great caching technique&quot; (integer) 1 redis 127.0.0.1:6379&gt; PUBLISH redisChat &quot;Learn redis by runoob.com&quot; (integer) 1 # 订阅者的客户端会显示如下消息 1) &quot;message&quot; 2) &quot;redisChat&quot; 3) &quot;Redis is a great caching technique&quot; 1) &quot;message&quot; 2) &quot;redisChat&quot; 3) &quot;Learn redis by runoob.com&quot; RedisTemplate 发布订阅 1、发送sub指令 Spring启动时加载配置文中配置的一个个bean，RedisMessageListenerContainer中配置事件监听器及当事件来临时做出的响应 &lt;bean id=&quot;redisMessageListener&quot; class=&quot;com.mk.util.redis.listener.RedisMessageListener&quot;/&gt; &lt;bean class=&quot;org.springframework.data.redis.listener.RedisMessageListenerContainer&quot; destroy-method=&quot;destroy&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;/&gt; &lt;property name=&quot;taskExecutor&quot;&gt; &lt;bean class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;5&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;messageListeners&quot;&gt; &lt;map&gt; &lt;!--可以配置多个订阅者(listener)，这里只配置一个--&gt; &lt;entry key-ref=&quot;redisMessageListener&quot;&gt; &lt;!--这里配置频道信息--&gt; &lt;bean class=&quot;org.springframework.data.redis.listener.ChannelTopic&quot;&gt; &lt;constructor-arg value=&quot;notify&quot;/&gt; &lt;/bean&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; 其中自定义的 RedisMessageListener 实现 MessageListener 接口，这个由程序员实现，当某个特定消息来临时，该执行哪个操作 1234567public class RedisMessageListener implements MessageListener &#123; @Override public void onMessage(Message message, byte[] bytes) &#123; logger.info(&quot;=============调用redis监听器onMessage====================&quot;); &#125;&#125; 加载 RedisMessageListenerContainer 类时，会调用setMessageListeners方法注入监听器； 除了注入监听器，这个方法还完成了： 开启一个客户端与Redis通信的线程（不然程序整个程序就阻塞了，所以要开新线程） 与Redis服务器建立长连接 向Redis服务器发送SUBSCRIBE命令 循环监听Redis服务器向客户端发送的消息，如果没有消息则阻塞线程；如果接收到一个消息，分派消息 启动一个新的线程，执行消息处理方法 整个执行过程的大致源码过程（删除无关代码）： RedisMessageListenerContainer： 1、Spring框架注入属性时，调用setMessageListeners方法 public void setMessageListeners(Map&lt;? extends MessageListener, Collection&lt;? extends Topic&gt;&gt; listeners) { initMapping(listeners); } 2、启动监听 private void initMapping(Map&lt;? extends MessageListener, Collection&lt;? extends Topic&gt;&gt; listeners) { //在发布者和订阅者中添加监听器 if (!CollectionUtils.isEmpty(listeners)) { for (Map.Entry&lt;? extends MessageListener, Collection&lt;? extends Topic&gt;&gt; entry : listeners.entrySet()) { addListener(entry.getKey(), entry.getValue()); } } //启动监听 if (initialized) { start(); } } 3、start中关键代码是lazyListen public void start() { lazyListen(); } 4、lazyListen中使用线程池开启一个线程用来客户端与redis服务器通信，并进行消息分派 private void lazyListen() { subscriptionExecutor.execute(subscriptionTask); } 5、执行SubscriptionTask的run方法 private class SubscriptionTask implements SchedulingAwareRunnable { public void run() { SubscriptionPresentCondition subscriptionPresent = eventuallyPerformSubscription(); } } 6、调用connection的subscribe方法 private SubscriptionPresentCondition eventuallyPerformSubscription() { connection.subscribe(new DispatchMessageListener(), unwrap(channelMapping.keySet())); } 执行JedisConnection类的方法： 7、调用JedisConnection的subscribe方法，将Spring中配置MessageListener参数传入 public void subscribe(MessageListener listener, byte[]... channels) { BinaryJedisPubSub jedisPubSub = new JedisMessageListener(listener); jedis.subscribe(jedisPubSub, channels); } 执行BinaryJedis类的方法： 8、上层传入的MessageListener被封装在BinaryJedisPubSub中，执行jedisPubSub的proceed方法 public void subscribe(BinaryJedisPubSub jedisPubSub, byte[]... channels) { jedisPubSub.proceed(client, channels); } 执行BinaryJedisPubSub类的方法： 9、核心代码 调用client的subscribe方法进行订阅，包括打开Socket与Redis Server建立长连接，并发送SUBSCRIBE命令 process为消息分派 public void proceed(Client client, byte[]… channels) { this.client = client; client.subscribe(channels); client.flush(); process(client); } 10、消息分派 do——while的结构 其中：List reply = client.getRawObjectMultiBulkReply();从底层读取服务器向客户端发送的消息，如果没有消息则阻塞，否则进行消息分派 1234567891011121314151617181920212223242526272829303132333435363738private void process(Client client) &#123; do &#123; List&lt;Object&gt; reply = client.getRawObjectMultiBulkReply(); final Object firstObj = reply.get(0); if (!(firstObj instanceof byte[])) &#123; throw new JedisException(&quot;Unknown message type: &quot; + firstObj); &#125; final byte[] resp = (byte[]) firstObj; if (Arrays.equals(SUBSCRIBE.raw, resp)) &#123; subscribedChannels = ((Long) reply.get(2)).intValue(); final byte[] bchannel = (byte[]) reply.get(1); onSubscribe(bchannel, subscribedChannels); &#125; else if (Arrays.equals(UNSUBSCRIBE.raw, resp)) &#123; subscribedChannels = ((Long) reply.get(2)).intValue(); final byte[] bchannel = (byte[]) reply.get(1); onUnsubscribe(bchannel, subscribedChannels); &#125; else if (Arrays.equals(MESSAGE.raw, resp)) &#123; final byte[] bchannel = (byte[]) reply.get(1); final byte[] bmesg = (byte[]) reply.get(2); onMessage(bchannel, bmesg); &#125; else if (Arrays.equals(PMESSAGE.raw, resp)) &#123; final byte[] bpattern = (byte[]) reply.get(1); final byte[] bchannel = (byte[]) reply.get(2); final byte[] bmesg = (byte[]) reply.get(3); onPMessage(bpattern, bchannel, bmesg); &#125; else if (Arrays.equals(PSUBSCRIBE.raw, resp)) &#123; subscribedChannels = ((Long) reply.get(2)).intValue(); final byte[] bpattern = (byte[]) reply.get(1); onPSubscribe(bpattern, subscribedChannels); &#125; else if (Arrays.equals(PUNSUBSCRIBE.raw, resp)) &#123; subscribedChannels = ((Long) reply.get(2)).intValue(); final byte[] bpattern = (byte[]) reply.get(1); onPUnsubscribe(bpattern, subscribedChannels); &#125; else &#123; throw new JedisException(&quot;Unknown message type: &quot; + firstObj); &#125; &#125; while (isSubscribed());&#125; 参考：jedis的publish/subscribe[转]含有redis源码解析http://www.cnblogs.com/wxh04/p/4301291.html 菜鸟教程 Redis 发布订阅http://www.runoob.com/redis/redis-pub-sub.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 定时器的使用]]></title>
    <url>%2F2017%2F05%2F05%2F%5BSpring%5DSpring%20%E5%AE%9A%E6%97%B6%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[配置文件xmlns 多加下面的内容、 xmlns:task=&quot;http://www.springframework.org/schema/task&quot; 然后xsi:schemaLocation多加下面的内容 http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.1.xsd 最后是我们的task任务扫描注解 &lt;task:annotation-driven/&gt; 我的配置扫描位置是： &lt;context:component-scan base-package=&quot;com.test&quot;/&gt; 基于注解方式定时器@Component public class MyTest{ @Scheduled(cron=&quot;0/5 * * * * ? &quot;) //每5秒执行一次 @Override public void myTest(){ System.out.println(&quot;进入测试&quot;); } } 常用CRON表达式一个cron表达式有至少6个（也可能7个）有空格分隔的时间元素。按顺序依次为秒（0~59）分钟（0~59）小时（0~23）天（月）（0~31，但是你需要考虑你月的天数）月（0~11）天（星期）（1~7 1=SUN 或 SUN，MON，TUE，WED，THU，FRI，SAT）7.年份（1970－2099） 其中每个元素可以是一个值(如6),一个连续区间(9-12),一个间隔时间(8-18/4)(/表示每隔4小时),一个列表(1,3,5),通配符。由于”月份中的日期”和”星期中的日期”这两个元素互斥的,必须要对其中一个设置?.0 0 10,14,16 ? 每天上午10点，下午2点，4点0 0/30 9-17 ? 朝九晚五工作时间内每半小时0 0 12 ? WED 表示每个星期三中午12点“0 0 12 ?” 每天中午12点触发“0 15 10 ? “ 每天上午10:15触发“0 15 10 ?” 每天上午10:15触发“0 15 10 ? “ 每天上午10:15触发“0 15 10 ? 2005” 2005年的每天上午10:15触发“0 14 ?” 在每天下午2点到下午2:59期间的每1分钟触发“0 0/5 14 ?” 在每天下午2点到下午2:55期间的每5分钟触发“0 0/5 14,18 ?” 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发“0 0-5 14 ?” 在每天下午2点到下午2:05期间的每1分钟触发“0 10,44 14 ? 3 WED” 每年三月的星期三的下午2:10和2:44触发“0 15 10 ? MON-FRI” 周一至周五的上午10:15触发“0 15 10 15 ?” 每月15日上午10:15触发“0 15 10 L ?” 每月最后一日的上午10:15触发“0 15 10 ? 6L” 每月的最后一个星期五上午10:15触发“0 15 10 ? 6L 2002-2005” 2002年至2005年的每月的最后一个星期五上午10:15触发“0 15 10 ? 6#3” 每月的第三个星期五上午10:15触发有些子表达式能包含一些范围或列表例如：子表达式（天（星期））可以为 “MON-FRI”，“MON，WED，FRI”，“MON-WED,SAT”“”字符代表所有可能的值因此，“”在子表达式（月）里表示每个月的含义，“”在子表达式（天（星期））表示星期的每一天 “/”字符用来指定数值的增量例如：在子表达式（分钟）里的“0/15”表示从第0分钟开始，每15分钟 在子表达式（分钟）里的“3/20”表示从第3分钟开始，每20分钟（它和“3，23，43”）的含义一样 “？”字符仅被用于天（月）和天（星期）两个子表达式，表示不指定值当2个子表达式其中之一被指定了值以后，为了避免冲突，需要将另一个子表达式的值设为“？” “L” 字符仅被用于天（月）和天（星期）两个子表达式，它是单词“last”的缩写但是它在两个子表达式里的含义是不同的。在天（月）子表达式中，“L”表示一个月的最后一天在天（星期）自表达式中，“L”表示一个星期的最后一天，也就是SAT如果在“L”前有具体的内容，它就具有其他的含义了例如：“6L”表示这个月的倒数第６天，“ＦＲＩＬ”表示这个月的最一个星期五注意：在使用“L”参数时，不要指定列表或范围，因为这会导致问题 字段 允许值 允许的特殊字符秒 0-59 , - /分 0-59 , - /小时 0-23 , - /日期 1-31 , - ? / L W C月份 1-12 或者 JAN-DEC , - /星期 1-7 或者 SUN-SAT , - ? / L C #年（可选） 留空, 1970-2099 , - * / 参考：http://luanxiyuan.iteye.com/blog/2297329]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>定时器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Maven下载Jar包]]></title>
    <url>%2F2017%2F05%2F05%2F%5BMaven%5D%E5%88%A9%E7%94%A8Maven%E4%B8%8B%E8%BD%BDJar%E5%8C%85%2F</url>
    <content type="text"><![CDATA[在任意目录下新建一个批处理文件 exec.bat call mvn -f pom.xml dependency:copy-dependencies @pause 然后再同目录下新建一个pom.xml文件 &lt;?xml version=&quot;1.0&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;temp.download&lt;/groupId&gt; &lt;artifactId&gt;temp-download&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.7&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 每次只要修改&lt;dependencies&gt;&lt;/dependencies&gt;中的内容就行了 点击运行后，会自动下载到Maven仓库中，而且在同级目录下的target文件也会有下载完成的Jar包 完整目录结构如下：]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java进行数据库备份、回复、删除]]></title>
    <url>%2F2017%2F05%2F05%2F%5B%E6%95%B0%E6%8D%AE%E5%BA%93%5DJava%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E3%80%81%E5%9B%9E%E5%A4%8D%E3%80%81%E5%88%A0%E9%99%A4%2F</url>
    <content type="text"><![CDATA[备份和删除使用Java的 Runtime 类的 exec 方法来执行命令行 Process process = Runtime.getRuntime().exec(command); 但是命令行中无法识别管道符号 &lt;，所以必须获得子进程的输入流和输出流写文件 清空数据库通过 show tables 获得数据库中所有表，然后通过 truncate tableName 命令来清空数据库，由于项目中使用 Hibernate 框架，所以利用 Hibernate 执行原生sql语句 DatabaseBackupUtilsDatabaseBackupUtils 是数据库备份和还原的工具类，可以通用 public class DatabaseBackupUtils { /** MySQL安装目录的Bin目录的绝对路径 */ private String mysqlBinPath; /** 访问MySQL数据库的用户名 */ private String username; /** 访问MySQL数据库的密码 */ private String password; public String getMysqlBinPath() { return mysqlBinPath; } public void setMysqlBinPath(String mysqlBinPath) { this.mysqlBinPath = mysqlBinPath; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public DatabaseBackupUtils(String mysqlBinPath, String username, String password) { if (!mysqlBinPath.endsWith(File.separator)) { mysqlBinPath = mysqlBinPath + File.separator; } this.mysqlBinPath = mysqlBinPath; this.username = username; this.password = password; } /** * 备份数据库 * * @param output * 输出流 * @param dbname * 要备份的数据库名 */ public void backup(OutputStream output, String dbname) { /** * 相当于在运行中输入： * cmd /c D:/MySQL/bin\mysqldump -uroot -proot --set-charset=utf8 audit * 注意：/c表示运行完命令后关闭进程，可以测试cmd /c ping localhost与cmd ping localhost的区别 */ String command = &quot;cmd /c &quot; + mysqlBinPath + &quot;mysqldump -u&quot; + username + &quot; -p&quot; + password + &quot; --all-tablespaces --add-drop-database --set-charset=utf8 &quot; + dbname; System.out.println(command); PrintWriter writer = null; BufferedReader reader = null; try { writer = new PrintWriter(new OutputStreamWriter(output, &quot;utf8&quot;)); /** * 执行mysqldump命令后会向子进程的缓存区写数据，以前在Dos命令行中通过重定向的方式将数据写入到文件中， * 在这里必须从进程的读取数据，并写入sql文件，即生成备份文件 注：如果不对控制台信息进行读出，则会导致进程堵塞无法运行 * 把进程执行中的控制台输出信息写入.sql文件，即生成了备份文件。 */ Process process = Runtime.getRuntime().exec(command); //从缓存区中读数据 reader = new BufferedReader(new InputStreamReader(process.getInputStream(), &quot;utf8&quot;)); String line = null; //边读边写 while ((line = reader.readLine()) != null) { writer.println(line); } writer.flush(); } catch (UnsupportedEncodingException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } finally { try { if (reader != null) { reader.close(); } if (writer != null) { writer.close(); } } catch (IOException e) { e.printStackTrace(); } } } /** * 备份数据库，如果指定路径的文件不存在会自动生成 * * @param dest * 备份文件的路径 * @param dbname * 要备份的数据库 */ public void backup(String dest, String dbname) { try { OutputStream out = new FileOutputStream(dest); backup(out, dbname); System.out.println(&quot;备份成功&quot;); } catch (FileNotFoundException e) { e.printStackTrace(); } } /** * 恢复数据库 * * @param input * 输入流 * @param dbname * 数据库名 */ public void restore(InputStream input, String dbname) { /** * 在命令行中使用如下命令来实现恢复 cmd /c D:/MySQL/bin\mysql -uroot -proot test &lt; test.sql * 但是在Java中无法识别管道符号，于是向缓存区中写test.sql数据，来实现管道的效果 */ String command = &quot;cmd /c &quot; + mysqlBinPath + &quot;mysql -u&quot; + username + &quot; -p&quot; + password + &quot; &quot; + dbname; System.out.println(command); try { Process process = Runtime.getRuntime().exec(command); OutputStream out = process.getOutputStream(); String line = null; String outStr = null; StringBuffer sb = new StringBuffer(&quot;&quot;); BufferedReader br = new BufferedReader(new InputStreamReader(input, &quot;utf8&quot;)); while ((line = br.readLine()) != null) { sb.append(line + &quot;\r\n&quot;); } outStr = sb.toString(); //System.out.println(outStr); OutputStreamWriter writer = new OutputStreamWriter(out, &quot;utf8&quot;); writer.write(outStr); writer.flush(); out.close(); br.close(); writer.close(); } catch (UnsupportedEncodingException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } /** * 恢复数据库 * * @param dest * 备份文件的路径 * @param dbname * 数据库名 * @throws FileNotFoundException */ public void restore(String dest, String dbname) throws FileNotFoundException { InputStream input = new FileInputStream(dest); restore(input, dbname); System.out.println(&quot;恢复成功&quot;); } public static void main(String[] args) throws SQLException { String binPath = &quot;D:/MySQL/bin&quot;; String userName = &quot;root&quot;; String pwd = &quot;root&quot;; DatabaseBackupUtils bak = new DatabaseBackupUtils(binPath, userName, pwd); //bak.backup(&quot;c:/users/asus/desktop/test.sql&quot;, &quot;test&quot;); //bak.restore(&quot;c:/users/asus/desktop/test.sql&quot;, &quot;test&quot;); } } IDatabaseBackupDao、DatabaseBackupDaoImplDatabaseBackupDaoImpl 利用Hibernate执行sql语句清空数据库，分为两个步骤： 1、获得表名2、清空数据库 IDatabaseBackupDao public interface IDatabaseBackupDao extends ICommonDao&lt;AuditAlert&gt;{ List&lt;String&gt; getTables(); void clear(List&lt;String&gt; tables); } DatabaseBackupDaoImpl @Component public class DatabaseBackupDaoImpl extends CommonDaoImpl&lt;AuditAlert&gt; implements IDatabaseBackupDao { @Override public List&lt;String&gt; getTables() { List&lt;String&gt; list = (List&lt;String&gt;) this.getHibernateTemplate().execute( new HibernateCallback() { @Override public Object doInHibernate(Session session) throws HibernateException, SQLException { List list = session .createSQLQuery( &quot;select table_name from information_schema.TABLES where TABLE_SCHEMA = &apos;audit&apos;;&quot;) .list(); return list; } }); return list; } @Override public void clear(List&lt;String&gt; tables) { final List&lt;String&gt; f = tables; this.getHibernateTemplate().execute(new HibernateCallback() { Set&lt;String&gt; ignore = new HashSet&lt;String&gt;(Arrays.asList(&quot;remote_ip&quot;, &quot;audit_user&quot;,&quot;audit_user_role&quot;,&quot;audit_role&quot;,&quot;audit_role_popedom&quot;, &quot;audit_popedom&quot;)); @Override public Object doInHibernate(Session session) throws HibernateException, SQLException { for (String tableName : f) { if(ignore.contains(tableName)){ continue; } session.createSQLQuery(&quot;truncate &quot; + tableName).executeUpdate(); } return null; } }); } } IDataBackupService、DataBackupServiceImplIDataBackupService 定义了三个方法 1、备份数据库2、恢复数据库3、清空数据库 其中备份数据库通过 DatabaseBackupUtils 工具类实现，恢复数据库由于需要连接数据库，采用 IDatabaseBackupDao 类来实现 IDataBackupService public interface IDataBackupService { /** * 备份数据库 * @throws IOException */ void doBackup() throws IOException; /** * 恢复数据库 * @throws FileNotFoundException */ void doRestore() throws FileNotFoundException; /** * 清空数据库 */ void doClear(); } DataBackupServiceImpl @Service public class DataBackupServiceImpl implements IDataBackupService { private static final String DB_USER = &quot;root&quot;; private static final String DB_PWD = &quot;root&quot;; private static final String DB_NAME = &quot;audit&quot;; private static String MYSQL_BIN_PATH; static{ BufferedReader br; try { br = new BufferedReader(new InputStreamReader(new FileInputStream(&quot;c:/AuditMysqlBinPath.txt&quot;))); MYSQL_BIN_PATH = br.readLine(); if(br != null){ br.close(); } } catch (Exception e) { // TODO Auto-generated catch block e.printStackTrace(); } } @Autowired IDatabaseBackupDao iDatabaseBackupDao; private static final DatabaseBackupUtils databaseBackupUtils = new DatabaseBackupUtils(MYSQL_BIN_PATH,DB_USER,DB_PWD); /** * 备份数据库 */ @Override public void doBackup() throws IOException { //如果audit.sql文件存在，可能是刚点击备份，所以不允许备份 File file = new File(&quot;c:/audit.sql&quot;); if(file.exists()){ throw new IllegalStateException(); } databaseBackupUtils.backup(&quot;c:/audit.sql&quot;, &quot;audit&quot;); } @Override public void doClear() { List&lt;String&gt; tables = iDatabaseBackupDao.getTables(); System.out.println(tables); iDatabaseBackupDao.clear(tables); } @Override public void doRestore() throws FileNotFoundException { databaseBackupUtils.restore(&quot;c:/audit.sql&quot;, &quot;audit&quot;); } }]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3、C3P0连接池的使用]]></title>
    <url>%2F2017%2F05%2F01%2F%5B%E6%95%B0%E6%8D%AE%E5%BA%93%5D3%E3%80%81C3P0%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[利用C3PO进行配置实现数据库连接池的使用第一步： 导入jar包 c3p0-0.9.2.1.jar 和 mchange-commons-java-0.2.3.4.jar第二步： 书写配置文件 c3p0-config.xml; 里面有一个参数是需要注意的，可以详细看看下面的配置文件注意的是：1、文件名必须为c3p0-config.xml， 这是因为C3P0会默认读取文件名为c3p0-config.xml的配置文件进而对数据库连接池进行配置。2、c3p0-config.xml 必须和你写的java代码在同一个目录下，一般就是放在项目的 src 目录下 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;c3p0-config&gt; &lt;!-- c3p0也可以指定配置文件，而且配置文件可以是properties，也可骒xml的。 当然xml的高级一些了。但是c3p0的配置文件名必须为c3p0-config.xml， 并且必须放在类路径下 --&gt; &lt;!-- 默认的配置这里我们默认使用mysql数据库 --&gt; &lt;default-config&gt; &lt;!-- 设置数据库的驱动，url， 用户名， 密码 --&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt; jdbc:mysql://127.0.0.1:3306/audit &lt;/property&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;root&lt;/property&gt; &lt;!-- 建立连接池时初始分配的连接池数 = 3--&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;3&lt;/property&gt; &lt;!-- 连接池中的最少连接数 = 2 --&gt; &lt;property name=&quot;minPoolSize&quot;&gt;2&lt;/property&gt; &lt;!-- 连接池中的最大连接数 = 50--&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;50&lt;/property&gt; &lt;!-- 当连接池中连接耗尽时再一次新生成多少个连接 Default: 3 --&gt; &lt;property name=&quot;acquireIncrement&quot;&gt;3&lt;/property&gt; &lt;!--最大空闲时间,60秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 --&gt; &lt;property name=&quot;maxIdleTime&quot;&gt;60&lt;/property&gt; &lt;!--每60秒检查所有连接池中的空闲连接。Default: 0 --&gt; &lt;property name=&quot;idleConnectionTestPeriod&quot;&gt;60&lt;/property&gt; &lt;!--当连接池用完时客户端调用getConnection()后等待获取新连接的时间，超时后将抛出SQLException,如设为0则无限期等待。单位毫秒。Default: 0 --&gt; &lt;property name=&quot;checkoutTimeout&quot;&gt;0&lt;/property&gt; &lt;/default-config&gt;&lt;/c3p0-config&gt; 第三步:创建一个连接池，连接池为单例模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class C3P0ConnectionPool&#123; /** * C3P0连接池工具类 */ private ComboPooledDataSource ds; /** * 连接池单例模式 */ private static final C3P0ConnectionPool instance = new C3P0ConnectionPool(); public static C3P0ConnectionPool getInstance()&#123; return instance; &#125; private C3P0ConnectionPool()&#123; System.setProperty(&quot;com.mchange.v2.c3p0.cfg.xml&quot;,&quot;config/c3p0-config.xml&quot;); /** * 多种读取C3P0连接池参数的方法 */ //第一种： 使用配置文件中的默认配置&lt;default-config&gt; ds = new ComboPooledDataSource(); // 第二种： 使用配置文件中设置的其他配置名字的配置 name-config // ds = new ComboPooledDataSource(&quot;Oracle-config&quot;); // 第三种： 我们可以显式的在程序中进行设置数据库连接池的信息 /*// 连接数据库驱动类 ds.setDriverClass(&quot;com.mysql.jdbc.Driver&quot;); // 数据库访问地址 ds.setJdbcUrl(&quot;jdbc:mysql:///audit&quot;); // 数据库用户名 ds.setUser(&quot;root&quot;); // 数据库密码 ds.setPassword(&quot;root&quot;); // 初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 // initialPoolSize ds.setInitialPoolSize(50); // 连接池中保留的最大连接数。Default: 15 maxPoolSize ds.setMaxPoolSize(100); // 连接池中保留的最小连接数。 ds.setMinPoolSize(2); // 获得连接的最大等待毫秒数。Default: 1000 ds.setAcquireRetryDelay(1000); // 最大空闲时间,60秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 ds.setMaxIdleTime(600);*/ &#125; /** * 连接池的主要方法：获取连接 * @throws SQLException */ public Connection getConnection() throws SQLException &#123; Connection conn = null; try &#123; conn = ds.getConnection(); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; //System.out.println(&quot;正在使用：&quot; + ds.getThreadPoolNumActiveThreads()); return conn; &#125; /** * 测试 */ public static void main(String[] args) throws PropertyVetoException, SQLException &#123; final C3P0ConnectionPool pool = C3P0ConnectionPool.getInstance(); //检测是否是单例模式 System.out.println(C3P0ConnectionPool.getInstance()); System.out.println(C3P0ConnectionPool.getInstance()); System.out.println(C3P0ConnectionPool.getInstance()); System.out.println(C3P0ConnectionPool.getInstance()); System.out.println(C3P0ConnectionPool.getInstance()); System.out.println(C3P0ConnectionPool.getInstance()); for (int i = 0; i &lt; 10000; i++) &#123; new Thread(new Runnable()&#123; @Override public void run() &#123; try &#123; Connection connection = pool.getConnection(); System.out.println(connection);//返回的是代理类，每次对象都不一样 PreparedStatement pstmt = connection.prepareStatement(&quot;SELECT * FROM logs&quot;); ResultSet rs = pstmt.executeQuery(); while (rs.next()) &#123; &#125; rs.close(); pstmt.close(); // 注意的是，即使使用了数据库连接池之后，这里也必须显式的调用close语句， // 此时的close语句并不会关闭与数据库的TCP连接，而是将连接归还回到池中去，变为空闲状态 // 如果不close掉的话，这个连接将会一直被占用 connection.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125;&#125; C3P0自定义配置文件目录将配置文件c3p0-config.xml放在自己定义的目录下 12/加载c3p0连接池配置 System.setProperty(&quot;com.mchange.v2.c3p0.cfg.xml&quot;,&quot;configs/c3p0-config.xml&quot;); C3P0的源代码的一些关键解析：几个关键的类：C3P0PooledConnectionPoolManager是连接池的管理类，C3P0PooledConnectionPool是连接池类，BasicResourcePool是真正管理数据库连接池的类 获取一个连接的代码： 1234public Connection getConnection() throws SQLException&#123; PooledConnection pc = getPoolManager().getPool().checkoutPooledConnection(); return pc.getConnection();&#125; 1) 关键步骤代码：Object resc = prelimCheckoutResource(timeout);查看池中是否有未使用的connection,有就返回（还要判断是否空闲、是否过期）；没有，如果没有达到最大数，就生成一个，或者就等待。2) 关键步骤代码：boolean refurb = attemptRefurbishResourceOnCheckout (resc);得到连接后，检测连接的可用性。3) 连接可用，接着判断连接是否处于管理中，不在就再调用本方法获取一个，在就返回本连接。 C3P0从连接池拿到的连接都是代理的连接，一个对PooledConnection类型对象的代理对象，所以可以放心调用close方法，只是连接进行了归还，不会关闭物理连接 而且C3p0中实际创建的对象是实现了PooledConnection（接口，位于javax.sql）， 它本身包含Connection,和这个connection相关的所有Statement,Result，可以实现对连接的一些管理，添加监听器等， 所做的所有数据库操作，都被PooledConnection所管理。c3p0默认的实现是NewPooledConnection C3P0使用了LinkedList来存放空闲池中的连接，每次取连接的时候是get(0), 然后remove(0) 应该是使用的队列来实现的空闲池C3P0 使用的HashMap 来存放的正在使用的连接，这样方便进行查找，连接返回的时候，根据连接可以快速的定位到要remove的那个连接C3P0 使用HashSet来存储一些失效的，但是仍旧被使用或者检查的资源。这些数据结构可以在 BasicResourcePool 类中查看到]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>连接池</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2、动态代理的连接池]]></title>
    <url>%2F2017%2F05%2F01%2F%5B%E6%95%B0%E6%8D%AE%E5%BA%93%5D2%E3%80%81%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E7%9A%84%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[设计的时候需要考虑的几点 首先是数据库连接的存储，要能很容易的管理和获取数据库连接，将数据库连接分为两部分，一部分是空闲池，一部分是正在使用的数据库连接，使用 LinkedList 实现栈来存储空闲的数据库连接，（优势在于每一次获取到的连接都是新的连接，这样的连接基本上都是可用的，基本上不会发生连接不可用导致重新再去获取连接的操作），使用 LinkedList 实现队列来存储正在使用中数据库连接（优势在于，队列的头部就是目前使用时间最长的连接，方便进行检查，回收这个使用时间超过限制的数据库连接） 如何回收分配出去的连接，即当外部的连接调用了 close 方法之后，如何让它返回到数据库连接池中，而不是销毁？答：使用动态代理，当请求一个 Connection 时，返回用户一个代理的 Connection 对象，这样就可以对 close 方法进行拦截，调用了 close 方法，会自动执行代理类中的 invoke 方法， 在 invoke 方法里面就可以实现对实际连接的一些操作了，具体实现请查看 getConnection() 方法。 其实获取连接的时候应当首先检查空闲池是否有空闲连接，再检查空闲连接是否可用，当数据库连接池没有连接的时候，要进行一次性创建新的连接，同时要进行检查看是否能进行连接的创建，是否达到了最大值等， 所以数据库的一些配置属性需要在静态代码块中通过 Properties 类读取出来。 /** * 连接池 * 空闲队列：获取连接时从空闲队列中获取 * 已使用队列：监控正在使用的连接 * 连接对象代理：调用Connention对象时并不是真正关闭连接，而是将连接对象 * 放入空闲队列。使用了内部列可以直接访问外部列的空闲队列 */ public class ProxyConnectionPool { private LinkedList idlelist; // 使用LinkedList实现栈存储数据库连接,存放的空闲连接 private LinkedList usinglist; // 使用LinkedList实现队列存储数据库连接,存放的正在使用的连接 private static Properties props; // 读取配置文件信息 private static int initialPoolSize; // 初始连接池大小 private static int maxPoolSize; // 连接池最大连接数 private static int acquireIncrement; // 无连接时，一次性创建连接数 static { props = new Properties(); try { props.load(new FileInputStream("jdbc.properties")); initialPoolSize = Integer.parseInt(props .getProperty("initialPoolSize")); maxPoolSize = Integer.parseInt(props.getProperty("maxPoolSize")); acquireIncrement = Integer.parseInt(props .getProperty("acquireIncrement")); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } } // 构造函数，在数据库连接池里先创建几个连接 // 我看了一下c3p0的源码，里面是用的代理连接 new ，而不是真实的物理连接 public ProxyConnectionPool() throws ClassNotFoundException, SQLException { idlelist = new LinkedList(); usinglist = new LinkedList(); Class.forName(props.getProperty("MySQLdriverClass")); for (int i = 0; i < initialPoolSize; i++) { Connection conn = DriverManager.getConnection(props .getProperty("MySQLurl"), props .getProperty("MySQLusername"), props .getProperty("MySQLpassword")); idlelist.addLast(conn); } } // 获取数据库连接 public Connection getConnection() throws SQLException { if (idlelist.size() > 0) { usinglist.addFirst(idlelist.getLast()); // 只是获取第一个连接并没有删除 Connection conn = idlelist.removeLast(); // 获取第一个连接并删除 // return conn; //返回真实的物理连接 // 返回一个真实物理连接的动态代理连接对象 return (Connection) Proxy.newProxyInstance(ProxyConnection.class .getClassLoader(), new Class[] { Connection.class }, new ProxyConnection(conn)); } else { // 创建新的数据库连接 boolean flag = dynamicIncrement(); if (flag) { usinglist.add(idlelist.getLast()); // 只是获取第一个连接并没有删除 Connection conn = idlelist.removeLast(); // 获取第一个连接并删除 // return conn; //返回真实的物理连接 // 返回一个真实物理连接的动态代理连接对象 return (Connection) Proxy.newProxyInstance( ProxyConnection.class.getClassLoader(), new Class[] { Connection.class }, new ProxyConnection( conn)); } else { throw new SQLException("没连接了"); } } } // 连接池里无连接，动态增长 private boolean dynamicIncrement() throws SQLException { int num = idlelist.size() + usinglist.size(); int num2 = maxPoolSize - num; // 如果可以创建连接，而且创建的连接数就是acquireIncrement if (num2 >= acquireIncrement) { for (int i = 0; i < acquireIncrement; i++) { Connection conn = DriverManager.getConnection(props .getProperty("MySQLurl"), props .getProperty("MySQLusername"), props .getProperty("MySQLpassword")); idlelist.addLast(conn); } return true; } // 如果可以创建连接,但是创建的连接数只能是num2个 if (num2 > 0) { for (int i = 0; i < num2; i++) { Connection conn = DriverManager.getConnection(props .getProperty("MySQLurl"), props .getProperty("MySQLusername"), props .getProperty("MySQLpassword")); idlelist.addLast(conn); } return true; } return false; } // Connection的动态代理类 class ProxyConnection implements InvocationHandler { private Connection conn; public ProxyConnection(Connection conn) { this.conn = conn; } // 关闭数据库连接，放回到空闲池中 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // TODO Auto-generated method stub // 分配出去的代理连接调用了close方法，进行拦截，实现我们自己想要的操作 if (method.getName().equals("close")) { // conn.close(); // 这一句的话就直接关闭连接了，所以不写 // 应该事先的操作是将 conn 放到空闲池中去，从使用池中移除 System.out.println(idlelist.size()); System.out.println(usinglist.size()); idlelist.addLast(conn); usinglist.remove(conn); System.out.println(idlelist.size()); System.out.println(usinglist.size()); return null; } // 其他方法仍然调用真实对象的方法 return method.invoke(conn, args); } } } 配置文件 jdbc.properties # mysql database driver MySQLdriverClass=com.mysql.jdbc.Driver MySQLurl=jdbc:mysql://127.0.0.1/test?useSSL=false MySQLusername=root MySQLpassword=root initialPoolSize=3 minPoolSize=2 maxPoolSize=50 acquireIncrement=3]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>连接池</tag>
        <tag>动态代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2、平衡二叉树最小节点个数]]></title>
    <url>%2F2017%2F04%2F27%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D2%E3%80%81%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9C%80%E5%B0%8F%E8%8A%82%E7%82%B9%E4%B8%AA%E6%95%B0%2F</url>
    <content type="text"><![CDATA[构建高度为n的二叉平衡树，设f（n）为高度为n时最小需要的节点数，那么： f（n） = f（n-1） + f（n-2） + 1，其中 f（1）=1，f（2） = 2 则 f（3）=4，f（4）=7，f（5）=12，f（6）=20 公式解析： 当计算高度为n的二叉平衡树节点时，那么其左右子树的高度不相差1，并且左、右子树都是二叉平衡树。因为要求节点最少，我们可以规定左子树的高度比右子树的高度大1，则 深度n的二叉平衡树的最小节点数 = 左平衡树的最小节点数 + 右平衡树的最小节点数 + 当前树的根节点树（也就是1） 但是右子树的高度比左子树的高度少1 用f（n）表示深度n的二叉平衡树的最小节点数 f（n-1）表示左平衡树的最小节点数（左子树高度当然比当前树的深度小1） f（n-2）表示右平衡树的最小节点数，比左子树高度少1的平衡树 后面的+1表示当前根节点 得到公式： f（n） = f（n-1） + f（n-2） + 1 图文解析： 上图表示构建高度6的平衡树，从左向右逐层构建，注意到高度为5的时候，左子树为高度为4的平衡树，右子树的高度比左子树少1，为高度为3的平衡树。图中两个黄色圈出的是节点为3的平衡树，树的结构一致]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>平衡二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的处理异常（java）]]></title>
    <url>%2F2017%2F04%2F21%2F%5BJava%5D%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%EF%BC%88java%EF%BC%89%2F</url>
    <content type="text"><![CDATA[https://www.zhihu.com/question/28254987 Java中异常提供了一种识别及响应错误情况的一致性机制，有效地异常处理能使程序更加健壮、易于调试。异常之所以是一种强大的调试手段，在于其回答了以下三个问题： 什么出了错? 在哪出的错? 为什么出错? 在有效使用异常的情况下，异常类型回答了”什么”被抛出，异常堆栈跟踪回答了”在哪”抛出，异常信息回答了”为什么”会抛出，如果你的异常没有回答以上全部问题，那么可能你没有很好地使用它们。有三个原则可以帮助你在调试过程中最大限度地使用好异常，这三个原则是： 具体明确 提早抛出 延迟捕获 为了阐述有效异常处理的这三个原则，本文通过杜撰个人财务管理器类JCheckbook进行讨论，JCheckbook用于记录及追踪诸如存取款,票据开具之类的银行账户活动。 具体明确Java定义了一个异常类的层次结构,其以Throwable开始，扩展出Error和Exception，而Exception又扩展出RuntimeException.如图1所示. 图1.Java异常层次结构 这四个类是泛化的，并不提供多少出错信息，虽然实例化这几个类是语法上合法的(如:new Throwable())，但是最好还是把它们当虚基类看，使用它们更加特化的子类。Java已经提供了大量异常子类，如需更加具体，你也可以定义自己的异常类。 例如：http://java.io package包中定义了Exception类的子类IOException，更加特化确的是 FileNotFoundException，EOFException和ObjectStreamException这些IOException的子 类。每一种都描述了一类特定的I/O错误：分别是文件丢失,异常文件结尾和错误的序列化对象流.异常越具体，我们的程序就能更好地回答”什么出了错”这个问题。 捕获异常时尽量明确也很重要。例如：JCheckbook可以通过重新询问用户文件名来处理FileNotFoundException，对于 EOFException，它可以根据异常抛出前读取的信息继续运行。如果抛出的是ObjectStreamException，则程序应该提示用户文件已损坏，应当使用备份文件或者其他文件。 Java让明确捕获异常变得容易,因为我们可以对同一try块定义多个catch块，从而对每种异常分别进行恰当的处理。 1234567891011121314151617181920File prefsFile = new File(prefsFilename); try&#123; readPreferences(prefsFile);&#125;catch (FileNotFoundException e)&#123; // alert the user that the specified file // does not exist&#125;catch (EOFException e)&#123; // alert the user that the end of the file // was reached&#125;catch (ObjectStreamException e)&#123; // alert the user that the file is corrupted&#125;catch (IOException e)&#123; // alert the user that some other I/O // error occurred&#125; JCheckbook 通过使用多个catch块来给用户提供捕获到异常的明确信息。举例来说：如果捕获了FileNotFoundException，它可以提示用户指定另一 个文件，某些情况下多个catch块带来的额外编码工作量可能是非必要的负担，但在这个例子中，额外的代码的确帮助程序提供了对用户更友好的响应。 除前三个catch块处理的异常之外，最后一个catch块在IOException抛出时给用户提供了更泛化的错误信息.这样一来，程序就可以尽可能提供具体的信息，但也有能力处理未预料到的其他异常。 有时开发人员会捕获范化异常，并显示异常类名称或者打印堆栈信息以求＂具体＂。千万别这么干！用户看到java.io.EOFException或者堆栈信息 只会头疼而不是获得帮助。应当捕获具体的异常并且用＂人话＂给用户提示确切的信息。不过，异常堆栈倒是可以在你的日志文件里打印。记住，异常和堆栈信息是用来帮助开发人员而不是用户的。 最后，应该注意到JCheckbook并没有在readPreferences()中捕获异常，而是将捕获和处理异常留到用户界面层来做，这样就能用对话框或其他方式来通知用户。这被称为＂延迟捕获＂，下文就会谈到。 提早抛出异常堆栈信息提供了导致异常出现的方法调用链的精确顺序，包括每个方法调用的类名，方法名，代码文件名甚至行数，以此来精确定位异常出现的现场。 1234567java.lang.NullPointerExceptionat java.io.FileInputStream.open(Native Method)at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:103)at jcheckbook.JCheckbook.readPreferences(JCheckbook.java:225)at jcheckbook.JCheckbook.startup(JCheckbook.java:116)at jcheckbook.JCheckbook.&lt;init&gt;(JCheckbook.java:27)at jcheckbook.JCheckbook.main(JCheckbook.java:318) 以上展示了FileInputStream类的open()方法抛出NullPointerException的情况。不过注意 FileInputStream.close()是标准Java类库的一部分，很可能导致这个异常的问题原因在于我们的代码本身而不是Java API。所以问题很可能出现在前面的其中一个方法，幸好它也在堆栈信息中打印出来了。 不幸的是，NullPointerException是Java中信息量最少的（却也是最常遭遇且让人崩溃的）异常。它压根不提我们最关心的事情：到底哪里是null。所以我们不得不回退几步去找哪里出了错。 通过逐步回退跟踪堆栈信息并检查代码，我们可以确定错误原因是向readPreferences()传入了一个空文件名参数。既然readPreferences()知道它不能处理空文件名，所以马上检查该条件： 123456789101112public void readPreferences(String filename)throws IllegalArgumentException&#123; if (filename == null)&#123; throw new IllegalArgumentException(&quot;filename is null&quot;); &#125; //if //...perform other operations... InputStream in = new FileInputStream(filename); //...read the preferences file...&#125; 通过提早抛出异常（又称＂迅速失败＂），异常得以清晰又准确。堆栈信息立即反映出什么出了错（提供了非法参数值），为什么出错（文件名不能为空值），以及哪里出的错（readPreferences()的前部分）。这样我们的堆栈信息就能如实提供： 12345java.lang.IllegalArgumentException: filename is nullat jcheckbook.JCheckbook.readPreferences(JCheckbook.java:207)at jcheckbook.JCheckbook.startup(JCheckbook.java:116)at jcheckbook.JCheckbook.&lt;init&gt;(JCheckbook.java:27)at jcheckbook.JCheckbook.main(JCheckbook.java:318) 另外，其中包含的异常信息（＂文件名为空＂）通过明确回答什么为空这一问题使得异常提供的信息更加丰富，而这一答案是我们之前代码中抛出的NullPointerException所无法提供的。 通过在检测到错误时立刻抛出异常来实现迅速失败，可以有效避免不必要的对象构造或资源占用，比如文件或网络连接。同样，打开这些资源所带来的清理操作也可以省却。 延迟捕获菜鸟和高手都可能犯的一个错是，在程序有能力处理异常之前就捕获它。Java编译器通过要求检查出的异常必须被捕获或抛出而间接助长了这种行为。自然而然的做法就是立即将代码用try块包装起来，并使用catch捕获异常，以免编译器报错。 问题在于，捕获之后该拿异常怎么办？最不该做的就是什么都不做。空的catch块等于把整个异常丢进黑洞，能够说明何时何处为何出错的所有信息都会永远丢失。把异常写到日志中还稍微好点，至少还有记录可查。但我们总不能指望用户去阅读或者理解日志文件和异常信息。让readPreferences()显示错误信息对话框也不合适，因为虽然JCheckbook目前是桌面应用程序，但我们还计划将它变成基于HTML的Web应用。那样的话，显示错误对话框显然不是个选择。同时，不管HTML还是C/S版本，配置信息都是在服务器上读取的，而错误信息需要显示给Web浏览器或者客户端程序。 readPreferences()应当在设计时将这些未来需求也考虑在内。适当分离用户界面代码和程序逻辑可以提高我们代码的可重用性。 在有条件处理异常之前过早捕获它，通常会导致更严重的错误和其他异常。例如，如果上文的readPreferences()方法在调用FileInputStream构造方法时立即捕获和记录可能抛出的FileNotFoundException，代码会变成下面这样： 1234567891011121314151617public void readPreferences(String filename)&#123; //... InputStream in = null; // DO NOT DO THIS!!!try&#123; in = new FileInputStream(filename);&#125;catch (FileNotFoundException e)&#123; logger.log(e);&#125; in.read(...); //...&#125; 上面的代码在完全没有能力从FileNotFoundException中恢复过来的情况下就捕获了它。如果文件无法找到，下面的方法显然无法读取它。如果 readPreferences()被要求读取不存在的文件时会发生什么情况？当然，FileNotFoundException会被记录下来，如果我们 当时去看日志文件的话，就会知道。然而当程序尝试从文件中读取数据时会发生什么？既然文件不存在，变量in就是空的，一个 NullPointerException就会被抛出。 调试程序时，本能告诉我们要看日志最后面的信息。那将会是NullPointerException，非常让人讨厌的是这个异常非常不具体。错误信息不仅误导我们什么出了错（真正的错误是FileNotFoundException而不是NullPointerException），还误导了错误的出处。真正的问题出在抛出NullPointerException处的数行之外，这之间有可能存在好几次方法的调用和类的销毁。我们的注意力被这条小鱼从真正的错误处吸引了过来，一直到我们往回看日志才能发现问题的源头。 既然readPreferences() 真正应该做的事情不是捕获这些异常，那应该是什么？看起来有点有悖常理，通常最合适的做法其实是什么都不做，不要马上捕获异常。把责任交给 readPreferences()的调用者，让它来研究处理配置文件缺失的恰当方法，它有可能会提示用户指定其他文件，或者使用默认值，实在不行的话也许警告用户并退出程序。 把异常处理的责任往调用链的上游传递的办法，就是在方法的throws子句声明异常。在声明可能抛出的异常时，注意越具体越好。这用于标识出调用你方法的程序需要知晓并且准备处理的异常类型。例如，”延迟捕获”版本的readPreferences()可能是这样的： 12345678910111213public void readPreferences(String filename)throws IllegalArgumentException,FileNotFoundException, IOException&#123; if (filename == null)&#123; throw new IllegalArgumentException(&quot;filename is null&quot;); &#125; //if //... InputStream in = new FileInputStream(filename); //...&#125; 技术上来说，我们唯一需要声明的异常是IOException，但我们明确声明了方法可能抛出FileNotFoundException。 IllegalArgumentException不是必须声明的，因为它是非检查性异常（即RuntimeException的子类）。然而声明它是为 了文档化我们的代码（这些异常也应该在方法的JavaDocs中标注出来）。 当然，最终你的程序需要捕获异常，否则会意外终止。但这里的技巧是在合适的层面捕获异常，以便你的程序要么可以从异常中有意义地恢复并继续下去，而不导致更深入的错误；要么能够为用户提供明确的信息，包括引导他们从错误中恢复过来。如果你的方法无法胜任，那么就不要处理异常，把它留到后面捕获和在恰当的层面处理。 一些例子SQLHelper没法处理的异常不要捕获，抛到上层再处理（如Action层甚至框架层） 123456789101112131415public class UserDao &#123; public void addUser(String name, String pass) throws SQLException &#123; Connection conn = DBUtils.getConnection(); try &#123; String sql = &quot;insert into user(name, pass) values(?, ?)&quot;; PreparedStatement stmt = conn.prepareStatement(sql); stmt.setString(1, name); stmt.setString(2, pass); stmt.executeUpdate(); user.setId(DBUtils.getLastInsertId()); &#125; finally &#123; DBUtils.closeConnection(); &#125; &#125;&#125; 异常控制流程在一个动作（action）中，包含了若干个业务逻辑操作，出于对用户友好的目的，假如在某操作调用失败的时候提示对应的消息并终止接下来的操作。 整体的 Try-Catch 还可以写一个拦截器，把捕捉异常的操作都放在里面，这样 action 非常干净 1234567891011121314151617181920212223242526272829303132public class MainAction &#123; @Autowired MyService myService; public void doSth1() &#123; try &#123; if (!myService.operationA()) &#123; throw new OperationFailedException(&quot;operationA failed&quot;); &#125; if (!myService.operationB()) &#123; throw new OperationFailedException(&quot;operationB failed&quot;); &#125; if (!myService.operationC()) &#123; throw new OperationFailedException(&quot;operationC failed&quot;); &#125; myService.operationD(); &#125; catch (OperationFailedException e) &#123; tip(e.getMessage()); &#125; catch(Exception e)&#123; tip(&quot;eat shit&quot;); &#125; &#125; private class OperationFailedException extends Exception &#123; public OperationFailedException(String message) &#123; super(message); &#125; &#125; public void tip(String msg) &#123; &#125;&#125; 结论经验丰富的开发人员都知道，调试程序的最大难点不在于修复缺陷，而在于从海量的代码中找出缺陷的藏身之处。只要遵循本文的三个原则，就能让你的异常协助你跟踪和消灭缺陷，使你的程序更加健壮，对用户更加友好。 英文原文：Jim Cushing，编译：ImportNew - 郑玮]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm入门]]></title>
    <url>%2F2017%2F04%2F20%2F%5BStorm%5DStorm%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[http://ifeve.com/getting-started-with-stom-index/ 专业术语spout：管理Storm集群的输入流，为bolt提供数据bolt：从spout或其它bolt接收数据，并处理数据，处理结果可作为其它bolt的数据源或最终结果nimbus：雨云，主节点的守护进程，负责为工作节点分发任务topology：拓扑结构，Storm的一个任务单元define field(s)：定义域，由spout或bolt提供，被bolt接收 Storm 概述Storm是一个分布式的，可靠的，容错的数据流处理系统。它会把工作任务委托给不同类型的组件，每个组件负责处理一项简单特定的任务。Storm集群的输入流由一个被称作spout的组件管理，spout把数据传递给bolt， bolt要么把数据保存到某种存储器，要么把数据传递给其它的bolt。你可以想象一下，一个Storm集群就是在一连串的bolt之间转换spout传过来的数据。 Storm 结构在Storm集群中，有两类节点：主节点master node和工作节点worker nodes 主节点运行着一个叫做Nimbus的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障 Supervisor守护进程作为拓扑的一部分运行在工作节点上。一个Storm拓扑结构在不同的机器上运行着众多的工作节点 Storm 操作模式 本地模式：Storm拓扑结构运行在本地计算机的单一JVM进程上 远程模式：在远程模式下，我们向Storm集群提交拓扑，它通常由许多运行在不同机器上的流程组成 Storm 快速入门教程在github中： https://github.com/runfriends/GettingStartedWithStorm-cn/blob/master/chapter2/Hello%20World%20Storm.md#bolts 创建一个简单的拓扑，数单词数量。要创建这个拓扑，我们要用一个spout读取文本，第一个bolt用来标准化单词，第二个bolt为单词计数，流程如下图所示：]]></content>
      <categories>
        <category>Storm</category>
      </categories>
      <tags>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis generator]]></title>
    <url>%2F2017%2F04%2F15%2F%5Bmybatis%5Dmybatis%20generator%2F</url>
    <content type="text"><![CDATA[详细说明http://blog.csdn.net/isea533/article/details/42102297 generatorConfig.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt; &lt;generatorConfiguration&gt; &lt;!-- 指定数据连接驱动jar地址 --&gt; &lt;classPathEntry location=&quot;D:\IDEA\workspace\mk_wechat_app\app\lib\sqljdbc-3.0.jar&quot; /&gt; &lt;!-- 一个数据库一个contex，使用flat，一个表对应一个实体类 --&gt; &lt;context id=&quot;Tables&quot; targetRuntime=&quot;MyBatis3&quot; defaultModelType=&quot;flat&quot;&gt; &lt;!-- 注释 --&gt; &lt;commentGenerator&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot; /&gt;&lt;!-- 是否取消注释 --&gt; &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot; /&gt; &lt;!-- 是否生成注释代时间戳 --&gt; &lt;/commentGenerator&gt; &lt;!--定义如何连接目标数据库--&gt; &lt;jdbcConnection driverClass=&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot; connectionURL=&quot;jdbc:sqlserver://121.12.155.196:1433;databaseName=DBERPDG&quot; userId=&quot;sa&quot; password=&quot;1qaz@WSX&quot;&gt; &lt;/jdbcConnection&gt; &lt;!-- 生成实体类地址 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.mk.domain&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;!--是否使用子包--&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;!--任何字符串属性的setter方法将调用trim方法--&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot; /&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成xml文件 --&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;/sqlMapGenerator&gt; &lt;!--DAO--&gt; &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.mk.mapper&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;/javaClientGenerator&gt; &lt;!--tableName：指定要生成的表名，可以使用SQL通配符匹配多个表。 例如要生成全部的表，可以按如下配置：&lt;table tableName=&quot;%&quot; /&gt;--&gt; &lt;table tableName=&quot;Partner_Info_Tab&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;!--Cloudscape、DB2、DB2_MF、Derby、HSQLDB、Informix、MySql、SqlServer、SYBASE--&gt; &lt;generatedKey column=&quot;Partner_No&quot; sqlStatement=&quot;SqlServer&quot;/&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; pom&lt;build&gt; &lt;plugins&gt; &lt;!--Mybatis Generator插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>generator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven插件]]></title>
    <url>%2F2017%2F04%2F13%2F%5BMaven%5DMaven%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[war打包war打包时添加第三方的jar包，如下图所示将lib目录下的jar包作为依赖 配置如下： &lt;build&gt; &lt;plugins&gt; &lt;!--war打包--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;configuration&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;${project.basedir}/lib&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/lib&lt;/targetPath&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 引入本地依赖： &lt;dependency&gt; &lt;groupId&gt;com.microsoft.sqlserver&lt;/groupId&gt; &lt;artifactId&gt;sqljdbc&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/lib/sqljdbc-3.0.jar&lt;/systemPath&gt; &lt;/dependency&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij IDEA创建 Web 项目]]></title>
    <url>%2F2017%2F04%2F13%2F%5BServlet%5DIntellij%20IDEA%E5%88%9B%E5%BB%BA%20Web%20%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[快速构建 Web 项目打开IDEA，新建Project，左边菜单栏选择 Maven，直接点 Next 选择GroupId和ArtifactId 选择项目名称，默认会填上工程位置、模块姓名等，直接点Finsh 进入到工程的主页面，注意到右上角跳出是否导入Maven，一般直接选择Auto_Import，这样在POM文件中添加依赖的时候，可以直接导入jar包 现在已经完成普通Maven项目的创建，接下来将要把他变成一个Web项目，只需要在工程名字上右键，选择Add Frame Support 选择Web Application，并勾选创建Web.xml 在工程目录上看到新添加了一个web的文件夹，而且注意到文件夹的图标和普通文件夹的图标不一样，这个文件夹是web的根目录 但是根据Maven规范，定义web根目录默认是在main文件夹下，而且以webapp命名。所以下图所示，将web文件夹重命名为webapp，而且移动到main文件夹下 打开pom.xml文件，指定工程的打包方式为war，当把该文件放到web容器下（可以是tomcat，也可以是jetty等）直接可以运行web程序 在build文件下，加入 Jetty 插件，个人觉得使用Jetty插件的好处是可以在不下载外部服务器的情况下，直接在IDEA中运行程序 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.qianmingxs&lt;/groupId&gt; &lt;artifactId&gt;Demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;maven-jetty-plugin&lt;/artifactId&gt; &lt;version&gt;6.1.21&lt;/version&gt; &lt;configuration&gt; &lt;!-- 多少秒进行一次热部署 --&gt; &lt;scanIntervalSeconds&gt;10&lt;/scanIntervalSeconds&gt; &lt;!--端口--&gt; &lt;connectors&gt; &lt;connector implementation=&quot;org.mortbay.jetty.nio.SelectChannelConnector&quot;&gt; &lt;port&gt;8080&lt;/port&gt; &lt;maxIdleTime&gt;60000&lt;/maxIdleTime&gt; &lt;/connector&gt; &lt;/connectors&gt; &lt;scanIntervalSeconds&gt;10&lt;/scanIntervalSeconds&gt; &lt;!--根目录，建议/--&gt; &lt;contextPath&gt;/&lt;/contextPath&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 打开IDEA中的Maven操作窗口，Plugins-jetty-jetty:run，直接双击就可以启动jetty容器，运行web程序，从控制台也可以看到应用程序在8080端口启动 如果想要进入调试模式，在jetty：run上右键选择 Debug 即可 在浏览器上输入localhost:8080，可以看到程序正常运行；如果在jetty文件中设置的contextPath不为path，运行的url应为localhost:8080/YourContextpath/ jetty：run-war和jetty：run功能差不多，在运行jetty：run-war的时候会先将web工程打包，然后执行war。 打包后的war在功能目录中target目录中 使用Tomcat插件在插件中加入tomcat插件即可 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.qianmingxs&lt;/groupId&gt; &lt;artifactId&gt;Demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;tomcat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/&lt;/path&gt; &lt;port&gt;8080&lt;/port&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;server&gt;tomcat6&lt;/server&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 简要说明一下： path是访问应用的路径port是 tomcat 的端口号uriEncoding URL按UTF-8进行编码，这样就解决了中文参数乱码。Server指定tomcat名称 IDEA 引入自定义jar包之后可以在 Project Structure 的 Modules - Dependencies看到添加的lib文件，或者可以在Project Structure - Libraries看到添加的lib文件 移除lib文件需要在上述两个位置中进行移除 war打包工具可以向用户自定义的文件打包到web目录下，下面给出了一个将用户自定义的lib文件打包到WEB-INF目录下 &lt;!--war打包--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;configuration&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;${project.basedir}/lib&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/lib&lt;/targetPath&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt; &lt;/plugin&gt;]]></content>
      <categories>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第20讲.Linux启动过程分析]]></title>
    <url>%2F2017%2F04%2F13%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC20%E8%AE%B2.Linux%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[BIOS就是在开机的时候，计算机系统会主动执行的第一个程序了！ 接下来 BIOS 会去分析计算机里面有哪些储存设备，我们以硬盘为例，BIOS 会依据使用者的设定去获得能够开机的硬盘，并且到该硬盘里面去读取第一个扇区的 MBR 位置。 MBR 这个仅有 446 bytes 的硬盘容量里面会放置最基本的开机管理程序，此时 BIOS就功成圆满，而接下来就是 MBR 内的开机管理程序的工作了。 这个开机管理程序的目的是在加载(load)核心档案，由于开机管理程序是操作系统在安装的时候所提供的，所以他会认识硬盘内的文件系统格式，因此就能够读取核心档案， 然后接下来就是核心档案的工作，开机管理程序也功成圆满，之后就是大家所知道的操作系统的任务啦！ 简单的说，整个开机流程到操作系统之前的动作应该是这样的： 1、BIOS：开机主动执行的程序，会认识第一个可开机的装置；2、MBR：第一个可开机装置的第一个扇区内的主要启动记录区块，内含开机管理程序；3、开机管理程序(boot loader)：一支可读取核心档案来执行的软件；4、核心档案：开始操作系统的功能… linux启动过程linux系统的启动过程如下： 12345678910a) BIOS自检 b) 启动GRUB/LILO c) 运行linux内核并检测硬件d) 运行系统的第一个进程inite) init读取系统引导配置文件/etc/inittab中的信息进行初始化 f) /etc/rc.d/rc.sysinit系统初始化脚本g) /etc/rc.d/rcX.d/[KS] * -根据运行级别X配置服务 a) 终止以&quot;K&quot;开头的服务 b) 启动以&quot;S&quot;开头的服务 h) /etc/rc.d/rc.local执行本地特殊配置 i) 其他特殊服务]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第19讲.补充Linux重要内容find alias]]></title>
    <url>%2F2017%2F04%2F13%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC19%E8%AE%B2.%E8%A1%A5%E5%85%85linux%E9%87%8D%E8%A6%81%E5%86%85%E5%AE%B9find%20alias%2F</url>
    <content type="text"><![CDATA[运行级别init [0123456]，指定系统运行级别，类似windows的正常运行模式或安全模式 12345670：关机 1：单用户2：多用户状态没有网络服务 3：多用户状态有网络服务 4：系统未使用保留给用户 5：图形界面 6：系统重启 常用运行级别是3和5，要修改默认的运行级别可改文件 1/etc/inittab的id:5:initdefault: 这一行中的数字 ##常用命令 ln 建立符号连接(和windows的快捷方式)12a) ln –s 源目标b) ln –s /etc/inittab inittab #（inittab指向实际文件/etc/inittab） 搜索文件及目录——find在Linux中，因为文件系统是以级别式的结构组成的，所以要在整个系统中找到特定的文件和目录并不是件容易的事。而“find”命令可以解决上述问题。 1、在特定的目录下搜索并显示指定名称的文件和目录 1find /root/ -name Hello.java #查找文件 2、搜索一段时间内被存取/变更的文件或目录 123456find /home –amin -10 十分钟内存取的文件和目录 find /home -amin +10 十分钟前存取的文件和目录find /home –atime -10 十小时内存取的文件和目录 find /home –cmin -10 十分钟内更改过的文件和目录 find /home –ctime -10 十小时前更改过的文件和目录 find /home –size +10k 意思是说查找/home目录下大小为10k的文件 shell使用shell脚本文件： a) 是一个文本文件 b) 命令的集合 c) 有执行的权限 d) 执行方式（./文件名） profile文件 profile文件主要是用于配置环境变量 用户登录后自动执行的shell脚本文件 配置 .bashrc 文件可以指定某些程序在用户登录的时候就自动启动。 1如：/home/tomcat/bin/startup.sh start 别名a) 命令：alias显示系统当前定义的所有aliasb)去别名 12alias llh=&apos;ls -l /home&apos;alias lm = &apos;-al | more&apos; c)去别名 1ualias lm]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第18讲.ssh安装.配置.使用]]></title>
    <url>%2F2017%2F04%2F13%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC18%E8%AE%B2.ssh%E5%AE%89%E8%A3%85.%E9%85%8D%E7%BD%AE.%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概述ssh（secure shell）是一款集远程操作linux和进行文件上传和下载的软件，在软件公司几乎所有的linux程序员都会使用ssh。安全、方便是它最大的特点 linux上默认安装ssh服务，且默认是启动的sshd，监听的端口是22。在windows系统上安装SSH客户端，集成了secureCRT与FTP的作用，确保windows linux网络畅通，就是windows能ping通]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第17讲.mysql安装.配置.使用]]></title>
    <url>%2F2017%2F04%2F13%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC17%E8%AE%B2.mysql%E5%AE%89%E8%A3%85.%E9%85%8D%E7%BD%AE.%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概述http://www.greensoftcode.net/techntxt/20112911325655007025安装教程http://m.sogou.com/web/uID=NsZTT-9VbVa3FHjJ/v=5/type=1/sp=3/ct=160216001911/keyword=linux+mysql%E5%85%8D%E5%AE%89%E8%A3%85/id=14027a77-47bf-467c-bdf4-f1f60458878f/sec=Yw8xhdD_JJCJYpZI3fALVg../tc?pg=webz&amp;clk=24&amp;url=http%3A%2F%2Fwww.faceye.net%2Fsearch%2F117071.html&amp;f=0&amp;id=14027a77-47bf-467c-bdf4-f1f60458878f&amp;pid=sogou-apps-4ff6fa96179cdc28&amp;dp=1&amp;lxg=NGRhZm9wYWtuMDxqMT86bWs7bWk4bWkla2dlJmlmbHpnYWwmanpnf3tteiU%2FJT8mMSVrfTUlbmk1&amp;key=linux+mysql%E5%85%8D%E5%AE%89%E8%A3%85&amp;pno=3&amp;g_ut=3&amp;wml=0&amp;w=1347&amp;mcv=361&amp;pcl=288,4187&amp;sed=0&amp;ml=28&amp;sct=38mysql数据库在linux下可以充分发挥威力，mysql数据库越来越受到软件公司的青睐，为什么呢？ 免费、跨平台、轻、支持多并发 在北京很多软件公司属于创业型的中、小公司，从节约成本的角度考虑，mysql特别适合中、小项目 mysql安装ps:安装之前查看是否已经安装mysql， 1rpm –qa mysql 如果有就删除之 123456rpm –e mysqlrpm –e -–nodeps mysql 强制删除yum remove mysql mysql-server mysql-libs mysql-server;find / -name mysql 将找到的相关东西delete掉；rpm -qa|grep mysql(查询出来的东东yum remove掉) 1、准备安装文件，copy到/usr/local下2、把安装文件解压 1tar -zxvf mysql-5.5.47-linux2.6-x86_64.tar.gz 3、重命名 1mv mysql-5.5.47-linux2.6-x86_64 mysql 4、创建mysql组 1useradd mysql 5、创建mysql用户，并放入到mysql组中 1useradd -g mysql mysql 6、关键步骤 123456789a) 进入mysql文件夹，执行如下命令来初始化数据库scripts/mysql_install_db --user=mysqlb) 修改文件的所有者(数据库是重要文件，不希望拥有者是普通用户)chown ‐R root .c)修改date文件夹的所有者(数据文件夹需要普通用户能够操作)chown ‐R mysql datad) 改变用户组chgrp ‐R mysql .说明：“.”点号代表当前目录及文件 7、启动mysql 12bin/mysqld_safe –-user=mysql &amp; &amp;表示以后台的方式启动 ctrl+c退出，检查一下进程，netstat ‐anp，查看监听端口是3306的是不是打开了 出现问题pid file /var/run/mysqld/mysqld.pid endedhttp://www.csdn123.com/html/exception/646/646216_646212_646218.htm 8、如何进入mysql 12cd bin./mysql ‐u root ‐p回车 9、mysql修改密码 http://www.cnblogs.com/daizhuacai/archive/2013/01/17/2865138.html 10、添加环境变量 如果希望在任何一个目录下都可以进入mysql，则需在用户变量/root/.bash_profile中添加路径 123456789a) env | more查看path中是否指定mysql 路径b) 进入/root下，查看到.bash_profile 存放用户变量 c) vi进入.bash_profile，在path后面加上 /home/mysql/bin/d) logout一下，再登录输入mysql ‐uroot ‐proot此时root用户可以在任意目录输入命令就可以进入mysql了如果需要所有用户都能在任意位置可以输入命令，则需要修改/etc/profile的PATH 11、设置mysql开机自动启动 参考http://blog.sina.com.cn/s/blog_6ccd0a11010175ri.htmlhttp://blog.163.com/longsu2010@yeah/blog/static/173612348201111710850381/ 123456cp support-files/mysql.server /etc/init.d/mysqldchkconfig --add mysqld #将mysqld加到启动服务列表里运行命令“chkconfig --list”查看系统服务chkconfig mysqld on #mysql.server开机启动chkconfig mysqld off #该命令关闭了mysql开机启动&gt; 12、多种启动方式 1234567891011一、启动1、使用 service 启动：service mysqld start2、使用 mysqld 脚本启动：/etc/inint.d/mysqld start3、使用 safe_mysqld 启动：safe_mysqld&amp;二、停止1、使用 service 启动：service mysqld stop2、使用 mysqld 脚本启动：/etc/inint.d/mysqld stop3、mysqladmin shutdown三、重启1、使用 service 启动：service mysqld restart2、使用 mysqld 脚本启动：/etc/inint.d/mysqld restart Mysql测试测试mysql数据库是否可以在linux下正确使用 a) 建立数据库和表 b) 加入部分数据 c) 编写一个ShowUser.java文件，在控制台显示用户 1234567891011121314151617import java.sql.*;public class MysqlTest&#123; public static void main(String[] args)&#123; try&#123; Class.forName(&quot;com.mysql.jdbc.Driver&quot;); Connection con = DriverManager.getConnection(&quot;jdbc:mysql://127.0.0.1:3306/Demo?user=root&amp;password=root&quot;); Statement sm = con.createStatement(); ResultSet rs = sm.executeQuery(&quot;select * from users&quot;); while(rs.next())&#123; System.out.println(rs.getString(2)); &#125; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; Note：特别注意mysql的驱动要存放的位置，放在jdk的主目录下的/jre/lib/ext/ 备份与恢复备份： 1./mysqldump ‐u root ‐p密码 数据库名 &gt; /home/data.bak 恢复： 1mysql ‐u root ‐p密码 数据库名 &lt; /home/data.bak Note：‐p和密码之间没有空格,在恢复数据库的时候，你需要建立一个空数据库！]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第16讲.监控网络状态]]></title>
    <url>%2F2017%2F04%2F13%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC16%E8%AE%B2.%E7%9B%91%E6%8E%A7%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[显示网络统计信息的命令 netstat此命令用来显示整个系统目前的网络情况。例如目前的连接、数据包传递数据、或是路由表内容，此命令直接输入即可使用 1netstat ‐anp #显示网络端口及监听该端口的进程号 检测主机连接命令ping是一种网络检测工具，它主要是用检测远程主机是否正常，或是两部主机间的介质是否为断、网线是否脱落或网卡故障 显示数据包经过历程命令traceroute（追踪路由）此命令可以直接输入使用，用来检测数据包在网络上传输的过程，从本机到远程的主机完整路径，帮助管理员解决问题 显示路由表 route路由最大的功能就是转发 所谓路由是指将数据由来源网络送往目的网络的操作。在大型网络中，路由是非常复杂的，因为数据包在抵目的地时，可能经过的节点有很多，路由表是存储在路由器或一些其他链接设置上的窗体。其中记录着了到指定目的的网络路径，以及这些路径的相关数值 此命令可以直接输入使用，来查看本机路由的情况 每个路由器都有一个路由表，显示最近的路由表 类似于古代的信使，驿站]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第15讲.进程的介绍和管理]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC15%E8%AE%B2.%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[概述 在Linux 中，每个执行的程序都称为一个进程，每一个进程都分配一个ID号 每一个进程，都会对应一个父进程，而这个父进程可以复制多个子进程，例如www服务器 每个进程都可能以两种方式存在的:前台与后台。所谓前台进程就是用户目前的屏幕上可以进行操作的，后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行 一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中，直到关机才停止进程 进程与线程进程：就是正在执行的程序线程：轻量级的进程 进程有独立的地址空间，线程没有线程不能独立存在，它是由进程创建（Linux下用fork函数，Java里用Thread或实现Runnable） 进程的管理ps命令是用来查看目前系统中，有哪些正在执行，以及它们执行的情况，可以不加任何参数，显示详细的进程信息 12345使用案例：a) ps ‐a：显示当前终端的所有进程信息 b) ps ‐u：以用户的格式显示进程信息 c) ps ‐x：显示后台进程运行的参数 d) pa –aux【看的全面，信息也全面】 #1号进程是所有进程的父进程 各列的解释： USER 进程的用户； PID 进程的ID； %CPU 进程占用的CPU百分比； %MEM 占用内存的百分比； VSZ 该进程使用的虚拟内存量（KB）； RSS 该进程占用的固定内存量（KB）； TTY 该进程在哪个终端上运行（登陆者的终端位置），若与终端无关，则显示（？）。若为pts/0等，则表示由网络连接主机进程； START 该进程被触发启动时间； TIME 该进程实际使用CPU运行的时间； COMMAND 命令的名称和参数； STAT状态位常见的状态字符 D 无法中断的休眠状态（通常 IO 的进程）； R 正在运行可中在队列中可过行的； S 处于休眠状态； T 停止或被追踪； W 进入内存交换 （从内核2.6开始无效）； X 死掉的进程 （基本很少见）； Z 僵尸进程； &lt; 优先级高的进程； N 优先级较低的进程； L 有些页被锁进内存； s 进程的领导者（在它之下有子进程）； l 多进程的（使用 CLONE_THREAD, 类似 NPTL pthreads）； + 位于后台的进程组； 终止进程若是某个进程执行一半需要停止时，或是已消了很大的系统资源时，此时可以考虑停止该进程，使用kill命令来完成此项任务 123kill 进程号 #终止某个进程kill -9 进程号 #强制关闭killall #杀死此进程和所有其子进程 ##动态监控进程 top命令与ps命令很相似。它们都用来显示正在执行的进程。top与ps最大的不同之处，在于top在执行一段时间可以更新正在运行的进程 top显示选项解释 03:32:58当前系统时间 1:52，表示系统启动了多久 1 user，当前登录到Linux上的用户数 load average：0.00 0.00 0.00，三个数分别代表不同时间段的系统平均负载（一分钟、五分钟、以及十五分钟），当前系统负载情况，一般来说，参数越小，系统运行的越轻松，当平均数>0.6时，系统就很紧张了 Task： 38 processes，进程总数； 2 running，正在运行的进程数； 79sleeping：睡眠的进程数； 0 zombie：僵尸进程数（这个进程没有用了，还占用资源，比如父进程来不及收回子进程） CPU： 2.0 us：用户空间占用CPU百分比 0.0 sy： 内核空间占用CPU百分比 0.0 ni：用户进程空间内改变过优先级的进程占用CPU百分比 97.7 id：空闲CPU百分比 0.3 wa：等待输入输出的CPU时间百分比 0.0 hi：硬件中断所占百分比 0.0 st：软件中断所占百分比 Kib Mem: 1017216 total：物理内存总量 343660 free：空闲内存总量 97692 used：使用的物理内存总量 575864 buffers：用作内核缓存的内存量 Kib Swap: 2097148k total：交换区总量 192772k free：空闲交换区总量 0 used：使用的交换区总量 PID ： 进程id PPID ： 父进程id USER ： 进程所有者的用户名 PR ： 优先级 NI ： nice值。负值表示高优先级，正值表示低优先级 RES：进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA S：进程状态 D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU：上次更新到现在的CPU时间占用百分比 %MEM：进程使用的物理内存百分比 TIME+：进程使用的CPU时间总计，单位1/100秒 COMMAND 命令名/命令行 监视特定用户12top：输入此命令，按回车键，查看执行的进程 然后输入&quot;u&quot;回车，再输入用户名，即可 终止指定的用户12top：输入此命令，按回车键，查看执行的进程k：然后输入&quot;k&quot;回车，再输入要结束的进程ID号 指定系统状态更新的时间1top ‐d 10：指定系统更新进程的时间为10秒 设置系统时间date命令：显示系统的时间，可以在直接输入”date”命令来查看系统的时间 利用date命令来更改系统的时间 1date MMDDHHMMCCYY.SS：月月日日时时分分年年.秒秒 查看月历1cal 3 2002：查看2002年3月的月历 查看年历1cal 2008：查看2008的年历]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第14讲.crontab详解]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC14%E8%AE%B2.crontab%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[概述任务调度：是指系统在某个时间执行的特定的命令或程序系统工作：有些重要的工作必须周而复始地执行，如病毒扫描等个别用户工作：个别用户可能希望执行某些程序 命令设置系统级任务调度：/etc/crontab 文件上编写调度任务设置个人任务调度，执行crontab ‐e命令，接着输入任务到调度文件 调度文件的规则 [案例] 希望每天凌晨2：00去执行 date &gt;&gt; /home/mydate2，可以在crontab ‐e中加入： 10 2 * * * date &gt;&gt; /home/mydate2 [案例]希望每分钟去执行：在crontab ‐e中加入： 1* * * * * date &gt;&gt; /home/mydate2 调度多个任务1、在crontab ‐e中直接写多个命令（不推荐） 12* * * * * date &gt;&gt; /home/mydate2 * * * * * * cp /home/mydate2 /root 缺点：所有任务按列表的方式进行写入，不能方便的管理 2、可以把所有的任务，写入到一个可执行文件（shell编程） 1234567891. vi mytask.sh，写入* * * * * date &gt;&gt; /home/mydate2 * * * * * cp /home/mydate2 /root)2. chmod 744 mytask.sh （默认不具有执行权限，只有rw-）3. crontab中写入* * * * /root/mytask.sh开始执行命令说明：.sh表示shell文件，chmod 修改权限，必须要有X的权限 ##终止任务调度12crontab ‐r：终止任务调度(删除所有) ，若只需删除一个，则进入文件删除保存crontab ‐l：列出当前有哪些任务调度]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第13讲.rpm包.samba配置]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC13%E8%AE%B2.rpm%E5%8C%85.samba%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[RPM包概述一种用于互联网下载包的打包及安装工具，它包含在某些Linux分发版中。它生成具有.RPM扩展名的文件。RPM是Redhat Package Manager（Redhat软件包管理工具）的缩写。这一文件格式虽然打上了Redhat的标志，但是其原始设计理念是开放式的，现在包括OpenLinux、S.u.S.E.以及Turbo Linux等Linux的分发版本都有采用。可以算是公认的行业标准了 RPM包的名称格式apache-1.3.23-11.i386.rpm “1.3.23-11”：软件的版本号，主版本和此版本“i386”：是软件所运行的硬件平台“rpm”：文件扩展名，代表RPM包 RPM常用命令12345678910111213rpm ‐qa #查询所安装的所有rpm软件包 rpm ‐qa | more #分页显示rpm ‐qa | grep X &quot;apache&quot; #软件名称rpm ‐q 软件包名 #查询软件包是否安装★★★rpm ‐qi 软件包名 #查询软件包信息 rpm ‐ql 软件包名 #查询软件包中的文件 rpm ‐qf 文件全路径名 #查询文件所属的软件包 [例]rpm ‐qf /etc/passwd [例]rpm ‐qf /root/install.logrpm ‐qp 包文件名 #查询包的信息对这个软件包的介绍[例]rpm ‐qp jdk-1_5_0-Linux-i586.rpm [例]rpm ‐qpi jdk-1_5_0-Linux-i586.rpm [例]rpm ‐qpl jdk-1_5_0-Linux-i586.rpm 安装RPM包1234rpm ‐ivh RPM包全路径名称 #安装包到当前系统i=install，安装v=verbose，提示，即有提示信息 h=hash，进度条 删除RPM包12rpm ‐e RPM包的名称 【案例】rpm ‐e jdk 如果其它软件包依赖于您要卸载的软件包，卸载时则会产生错误信息，如： 12【案例】rpm ‐e fooremoving these packages would break dependencies：foo is needed by bar-1.0-1 若让RPM忽略这个错误继续卸载，请使用‐‐nodeps命令行选项 12强行删除，不建议【案例】rpm ‐e ‐‐nodeps foo 升级RPM包12rpm ‐U RPM包全路径名【案例】rpm ‐U cvs-1.11.2-10.i386.rpm SPRM鸟哥p815 安装软件路径以apache为例，安装路径有 · /etc/httped · /usr/lib · /usr/bin · /usr/share/man 分别代表配置文件、函式库、执行档、联机帮助档 如果放在预设的/usr/local，那么数据就会被放在 · /usr/local/etc · /usr/local/bin · /usr/local/lib · /usr/local/man 如果每个软件都选择在这个默认的路径下安装，那么所有的软件的档案都将放置在这四个目录中，未来想要升级或移除的时候都会比较难以追查档案的来源。所以如果在安装的时候选择的是单独的目录，例如apache放在/usr/local/apache，那么档案目录就会变成： · /usr/local/apache/etc · /usr/local/apache/bin · /usr/local/apache/lib · /usr/local/apache/man 移除软件就简单的多，只要将目录移除即可 为方便Tarball的管理，建议： 1. 最好将tarball的原始数据解压到/usr/local/src中 2. 安装时最好安装到/usr/local这个默认路径下 3. 考虑未来的反安装步骤，最好可以将每个软件单独的安装在/usr/local底下 4. 为安装到单独的软件之man page加入man path搜寻：如果你安装的软件放置在/usr/local/software，那么man page搜索的设定中，可将就得在/etc/man.config的40~50加入一行MANPATH /usr/local/software/man ##函式库管理 12345678910p794静态函式库，扩展名.a动态函式库，扩展名.so绝大数的函式库都放置在：/usr/lib,/lib,Kernel的函式库在/lib/modules将动态函式库加载高速缓存当中1. 在/etc/ld.so.conf写下想要读入高速缓存当中的动态函式库所在的目录2. 接在来利用ldconfig将/etc/ld.so.conf读入快取当中，画面上不会显示任何的信息3. 同时也将数据记录一份在/etc/ld.so.cache这个档案当中 ##samba配置 ###什么是samba 这些年来，windows与Linux操作系统各自拥有自己的用户群和市场。然而在一般公司或学校里，可能同时有windows和Linux主机，windows主机彼此之间可以利用”网上邻居”来访问共享资源。NFS也能使Linux主机之间实现资源访问。而samba服务软件能够使windows与Linux之间实现资源共享. SMB通信协议采用的是C/S结构，所以SAMBA软件可分阶段客户端及服务端两部分。通过执行samba客户端程序，Linux主机使可使用网络上的windows主机所共享的资源。而在Linux主机上安装samba服务器，则可以使windows主机访问samba服务器共享的资源 ###samba安装 samba的安装步骤1、看看是否已经安装了samba1rpm ‐q samba 2、如果有的话，就先卸载1rpm ‐e ‐‐nodeps samba（强制删除） 3、把安装文件挂载到Linux下123a) samba-common-2.2.7a-7.9.0.i386.rpm b) samba-client-2.2.7a-7.9.0.i386.rpm c) samba-2.2.7a-7.9.0.i386.rpm 4、拷贝samba的rpm包到/home，准备安装1cp sam* /home 5、开始安装(顺序)123a) rpm ‐ivh samba-common-2.2.7a-7.9.0.i386.rpm b) rpm –ivh samba-client-2.2.7a-7.9.0.i386.rpm c) rpm –ivh samba-2.2.7a-7.9.0.i386.rpm 6、创建一个用户youyou12a) useradd youyou b) passwd youyou 7、给youyou设置samba密码12345将/etc/passwd中的用户都加到smbpasswd中a) cat /etc/passwd | mksmbpasswd.sh &gt; /etc/samba/smbpasswd设置密码 b) smbpasswd youyou 8、启动samba服务器，测试1234a) service smb start，启动b) service smb stop，停止 c) service smb restart,重启d) 在windows运行窗口输入Linux的IP\\192.168.222.88 输入youyou的samba用户名，密码 ###samba配置 共享资源的基本配置/etc/samba/smb.conf 1、comment：针对共享资源所做的说明文字。默认值为空字符串1【案例】comment=dir for todayhero：共享这个目录是为了todayhero这个用户 2、path：若共享的资源是目录，是指定该目录的位置1【案例】path=/tmp：共享tmp这个目录 3、guestok：是否允许用户不使用账号和密码访问此资源12【案例】guest ok=yes：允许用户不使用账号和密码访问此资源【案例】guest ok=no：不允许用户不使用账号和密码访问此资源 4、hostsallow：设置连接主机的地址12【案例】hosts allow=192.168.2.1 server.abc.com：允许来自192.168.2.1或server.abc.com 5、hostsdeny：设置禁止连接的主机地址1【案例】hosts deny=192.168.2.1：不允许192.168.2.1的主机访问samba服务器的资源 6、readonly：用于设置共享的资源是否为可读12【案例】read only=yes：允许只读【案例】read only=no：不仅仅只读，也就是说可以写入]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第12讲.网络环境配置]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC12%E8%AE%B2.%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[##第一种方法 用root身份登录，运行setup命令进入到text mode setup utility对网络进行配置-network configuration，这里可以进行IP、子网掩码、默认网关、DNS的配置 用空格键自动分配 手动IP 按TAB就可以输入 这时网卡的配置没有生效，运行/etc/rc.d/init.d/network restart命令我们刚才做的设置才生效 ##第二种方法 eth0 第一块网卡，eth1 第二块网卡….. 12ifconfig eth0 x.x.x.x对网卡进行设置 ifconfig eth0 network x.x.x.x对子网掩码设置 对广播地址和DNS使用默认的 Note：这样配置网络将会立即生效，但是是临时生效 ##第三种方法 修改/etc/sysconfig/network-scripts/ifcfg-eth0这个文件里各个属性可以修改，包括IP、子网掩码、广播地址、默认网关等。 里面的内容主要如下： onboot=yes (NO=禁用) bootproto=static(静态)/dhcp(动态) 这时网卡的配置没有生效，运行 /etc/rc.d/init.d/network restart 命令我们刚才做的设置才生效 Note： 这种方法是最底层的修改方法在linux中，所有设备都是文件]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第11讲.tcp.ip基础]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC11%E8%AE%B2.tcp.ip%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[概述TCP/IP是unix/linux世界的网络基础，在某种意义上，unix网络就是TCP/IP，而且TCP/IP就是网络互联的标准。它不是一个独立的协议，而是一组协议（TCP、IP、UDP、ARP等协议） 每个Internet上的主机和路由器都有一个IP地址，它包括网络号和主机号，现在所用的IP地址都是32位的。IP地址按照国际标准划分为A、B、C、D、E五种类型 人与人之间交流是用语言，计算机之间交流靠的是通讯协议 OSI模型:物理层，数据链路层，网络层，传输层，会话层，表示层，应用层(理论)TCP/IP模型（现实）:链路层(与硬件驱动对话)，网络层（定位IP地址和确定连路路径），传输层，应用层 好书推荐： TCP/IP详解：协议，实现，TCP事务协议美国网络作家（网络学习） QQ相互通讯的案例： 从上到下：(相当一个功能模块) qq1 qq2 发送你好！ 应用层 app+您好! 传输层 tcp+app+你好！ IP层(网络层)ip+tcp+app+你好！ 链路层帧头+ip+tcp+app+你好！+帧尾 网卡 经过路由器 TCP段，再经过IP层，会加一个ip头，是指发送到哪个地址。这样就是成了一个数据包。 经过链路层后，要会包加一个帧头和帧尾，发送给网卡。 经过路由器，最终到QQ2所在的网卡。然后逆向执行上述的一个过程，最后得到一个“你好”信息。 内部IP：外面电脑无法访问到 192.168.0.2外部IP：公网IP，电脑都可以访问到如何查看外网ip ping -t追踪路由命令；tracert 1、追踪路由 1tracert 目标IP或域名 2、ping命令测试两个IP是否畅通3、在windows下查看IP的命令 ipconfig4、在linux/unix查看ip的命令 ifconfig 局域网广播全播：对一个子网广播网络号+后面全1 netsend “不要玩CS” 192.168.255.255 子网：好管理，大划小 只要前面的网络号一样，就表示在一个子网里面，子网之间通过路由器来连接]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第10讲.shell介绍]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC10%E8%AE%B2.shell%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[概述每个人在成功登陆linux后，系统会出现不同的提示符号，例如$、~、#等，然后你就可以开始输入需要的命令，若是命令正确，系统就会依据命令的要求来执行，直到注销系统为止；在登录到注销期间，输入的每个命令都会经过解释及执行。而这个负责的机制就是shell shell编程其实作为命令语言互动式地解释和执行用户输入的命令只是shell功能的一个方面。shell还可以用来进行程序设计。它提供了定义变量和参数的手段以及丰富的程序控制结构。使用shell编程类似于DOS中批处理文件，称为shell script，又叫shell程序或shell命令文件 书籍推荐《Linux命令、编辑器和shell编程》 shell的分类 shell有很多种类，常用的有如下几种：a) /bin/ashb) /bin/bashc) /bin/tcsh—–cshd) /bin/ksh—-欧洲常用e) /bin/sh—-中国常用 查看电脑有多少个shell:ls -l /bin/*sh 查看目前使用的是哪种SHELLa) env | grep “SHELL”b) echo $SHELLc) echo $0 修改其它的SHELLchsh -s 输入新的SHELL（/bin/csh） 注销下再重新登录，使用 env 不同的SHELL 可能有不同的命令 SHELL命令补全功能（TAB）输入MK，再按两下TAB，出现两头两个字母为MK的命令。cat p再按两个TAB ，会出现开头字母为p的文件或字母 shell的使用命令历史和互动：用上下箭头键可以重复以前所输入的命令 命令完成功能：用tab键能自动完成相关命令，再次按tab可得到清单 shell命令历史记录 1history shell脚本文件是一个文本文件，为一系列命令的集合，有执行的权限，执行方式（./文件名） 用户登录后自动执行的shell脚本文件 .bashrc 位于主目录下， 系统的脚本/etc/bashrc，里面是基本配置数据 配置.bashrc文件可以指定某些程序在用户登录的时候就自动启动 .bash_profile 位于主目录下，它为系统的每个用户设置环境信息/etc/ 中 profile 主要是配置环境变量 用export可以临时加入一个系统路径，如 1export PATH=$PATH:$HOME/bin:/root/test/t1， 输出环境PATH，引用原来的值$PATH，$HOME表示工作主目录，:是路径分隔符 总结： /etc/profile，/etc/bashrc 是系统全局环境变量设定 ~/.profile，~/.bashrc用户家目录下的私有环境变量设定 已经定义好的环境变量 SHELL：默认shell PATH：路径USER：当前登录用户的用户名 显示变量内容 12echo $SHELL echo $USERecho $PATH shell通配符 【案例】export NAME=Michael - 1echo Welcome $NAME, the date is date 单引号：不处理任何变量和命令 【案例】echo ‘Welcome $NAME, the date is date ’ 双引号：处理变量但不处理命令 【案例】echo “Welcome $NAME, the date is date “ 反引号：把引号中的每个单词作为一个命令，如果是变量则先求值然后作为一个命令处理 【案例】echo “Welcome $NAME, the date is date “ 别名 命令：alias显示系统当前定义的所有alias 【案例】alias cp=’cp -i’【案例】alias li=’ls –l –color=tty’]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第9讲.Linux安装演示]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC9%E8%AE%B2.Linux%E5%AE%89%E8%A3%85%E6%BC%94%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[1、安装光盘是保持connect 2、linux安装的时候，分区是关键 说明：虚拟机安装的时候分配空间分的是5G a) /boot 分区 100M b) swap 交换分区一般是你物理内存的2倍但不要大于256M c)/ 根分区尽可能大（剩余的全部分给他）]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第8讲.Linux分区详解]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC8%E8%AE%B2.Linux%E5%88%86%E5%8C%BA%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[概述硬盘的分区主要分为d分区（Primary Portion）和扩展分区（Extension Portion）两种。只是针对一个硬盘来讲，主分区和扩展分区的数目之和不能大于4个。 基本分区可以马上被使用但不能再分区，扩展分区必须再进行分区后才能使用，也就是说它必须还要进行二次分区。那么有扩展分区再分下去的是什么呢？它就是逻辑分区（Logical Portion），而且逻辑分区没有数量上限制 对windows用户来说，有几个分区就有几个驱动器，并且每个分区都会获得一个字母标识符，然后就可以选用这个字母来指定在这个分区上的文件和目录。它们的文件结构都是独立的，非常好理解。但对这些用户初上手Redhat Linux，可就有点恼人了。 因为对Redhat Linux用户来说无论有几个分区，分给哪一个目录使用，它归根结底就只有一个根目录、一个独立且唯一的文件结构。 Redhat Linux中每个分区都是用来组成整个文件系统的一部分。因为它采用了一种叫”载入”的处理方法，它的整个文件系统中包含了一整套的文件和目录，并将一个分区和一个目录联系起来。这时要载入的那个分区将使它的存储空间在这个目录下获得 硬盘对于IDE硬盘，驱动器标识符为hdx~，其中”hd”表明分区所在设备的类型，这里是指IDE硬盘了。 “x”为盘号（a为基本盘，b为基本从属盘，c为辅助主盘，d为辅助从属盘），”~”代表分区，前四个分区用数字1到4表示，它们是主分区或扩展分区，从5开始就是逻辑分区。逻辑分割的装置文件名号码，一定由 5 号开始 例如：hda3表示为第一个IDE硬盘上的第三个主分区或扩展分区，hdb2表示为第二个IDE硬盘上的第二个主分区或扩展分区 对于SCSI硬盘则标识为”sdx~”，SCSI硬盘是用”sd”来表示分区所在设备的类型的，其余则和IDE硬盘的表示方法一样 文件系统挂载点的意义：每个filesystem都有独立的inode/block/superblock等信息，这个文件系统要能够链接到目录树才能被我们使用。将文件系统与目录树结合的动作我们成为挂载。挂载点一定是一个目录，该目录是进入该文件系统的入口。因此并不是任何文件系统都可以使用，必须要挂载到目录树的某个目录后，才能使用该文件系统 链接 Hard Link，实体链接，文件名链接到某个inode号码，两个文件名的所有相关信息都会一模一样（除了文件名），如果任意一个档名删除，其实inode与block都是存在的，仍可以通过另一个档名来读取到正确的档案数据。无论使用哪个档名来编辑，最终的结果都会写入到相同的inode与block中，均能对数据进行修改（ps:类似C++中的引用） Sysbolic Link，符号链接，即快捷方式。符号连接建立一个独立的档案，而这个档案会让数据的读取指向他link的那个档案的档名。当来源档被删除之后，符号链接的档案会开不了。 内存置换空间（swap）之建置p289 swap的功能就是在物理内存不足的情况下，内存中暂不使用的数据就会被挪到swap中，此时内存就会空出来给所需要执行的程序加载 几个重要命令挂载命令12mount [-parameters] [设备名称] [挂载点]mount /dev/sda1 /test/ #将sda1挂载到/test 特别说明：在挂载光驱时，可直接使用 mount /mnt/cdrom ###卸载命令 12umount [挂载点] umount /test/ #卸载分区 查看Linux系统分区具体情况12df -h df [目录全路径]，查看某个目录是在哪个分区 ###分区 1fdisk ‐l #查看系统有哪些分区 fdisk只有root可以执行，使用的装置名不要加上数字，因为partition是针对整个硬盘装置，而不是分区。例： 1fdisk /dev/hdc ###磁盘格式化 mkfs:make filesystem 1mkfs -t ext3 /dev/hdc6 #将/dev/hdc6格式化ext3文件系统]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第7讲.J2EE环境配置]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC7%E8%AE%B2.J2EE%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[jdk安装步骤 1、把mypackage.iso挂载到linux操作系统上2、在vm做好配置3、mount /mnt/cdrom，挂载光驱 unmount /mnt/cdrom，卸载光驱4、把安装文件拷贝到/home - 1cp 文件 /home 5、安装 1./ j2sdk-1_4_2_19-linux-i586.bin 6、查看一个文件vi /etc/profile [环境配置文件] #注释配置先前安装的jdk 7、jdk1.5.0_06配置完毕需要注销一下 eclipse安装步骤 1、挂载共享文件2、把安装文件拷贝到/home3、安装 12tar ‐zxvf eclipse-SDK-3.2.1-linux-gtk.tar.gz cp 文件 /home 4、进入图形界面，运行eclipse需要桌面支持 1startx 5、启动eclipse 1./eclipse MyEclipse安装步骤 1、挂载共享文件2、把安装文件拷贝到/home3、安装 12./ MyEclipseEnterpriseWorkbenchInstaller_5_1_0GA_E3_2_1.bin cp 文件 /home 注意点:进入图形界面安装支持，否则报错 选择已安装的eclipse的主目录 重新启动eclipse 1./eclipse &amp; #后台运行eclipse 这时会发现，菜单栏上多了一个MyEclipse选项 tomcat安装步骤 我们知道java ee的服务器有tomcat、jboss、weblogic、websphere、resin…这些都可以安装到linux下，我们给人家安装tomcat，安装步骤如下： 1、挂载共享文件2、把安装文件拷贝到/home3、安装4、测试 编写一个简单的jsp页面 配置tomcat和jdk 12tar ‐zxvf jakarta-tomcat-5.0.30.tar.gz cp 文件 /home]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第4、5、6讲.文件权限.用户组]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC4%E3%80%815%E3%80%816%E8%AE%B2.%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90.%E7%94%A8%E6%88%B7%E7%BB%84%2F</url>
    <content type="text"><![CDATA[用户组在Linux中的每个用户必须属于一个组，不能独立于组外。在Linux中每个文件有所有者、所在组、其它组的概念 所有者 一般为文件的创建者，谁创建了该文件，就天然的成为该文件的所有者用ls ‐ahl命令可以看到文件的所有者也可以使用chown 用户名文件名来修改文件的所有者 文件所在组 当某个用户创建了一个文件后，这个文件的所在组就是该用户所在的组用ls ‐ahl命令可以看到文件的所在组 也可以使用chgrp组名文件名来修改文件所在的组 其它组 除开文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组 文件权限 10个字符确定不同用户能对文件干什么 第一个字符代表文件（-）、目录（d），链接（l） [b]则表示为装置文件里面的可供储存的接口讴备(可随机存取装置) [c]则表示为装置文件里面的串行端口讴备，例如键盘、鼠标(一次性读取装置) 其余字符每3个一组（rwx），读（r）、写（w）、执行（x） 第一组rwx：文件所有者的权限是读、写和执行 第二组rw-：与文件所有者同一组的用户的权限是读、写但不能执行 第三组r--：不与文件所有者同组的其他用户的权限是读不能写和执行 也可用数字表示为：r=4，w=2，x=1 因此rwx=4+2+1=7 注意：最大权限777 注意： ● 文件夹x为进入文件下的权限 ● 开放目录给任何人浏览时，应该至少也要给予r及x的权限 ● x在目录当中是与"能否进入该目录"有关，至于那个w则具有相当重要的权限，因为他可以让使用者删除、更新、新建档案或目录 文件预设权限鸟哥Linux私房菜 p223 查询的方式有两种，一种是直接输入umask，看到数字形态的权限设置分数；另一种则是加入-S(Symbolic)选项，就会以符号类型的方式来显示出权限 文件预设没有x权限，即只有rw两个选项，最大666分，-rw-rw-rw- 目录默认所有权限均开放，即777分，drwxrwxrwx umask的分数指的是默认值减掉的权限。r=4，w=2，x=1。要拿掉写的权限，输入2，拿掉度的权限，输入4等 例，umask为022，所以user没有拿掉任何权限，group与others权限拿掉2，也就是w权限，所以，建立文件时权限为-rw-r--r--，建立文件夹时drwxr-xr-x 专题制作，要求同一组的用户能够修改，只要umask 002就行 档案特殊权限 档案的重要权限除了rwx（读、写、执行），还有其他特殊权限（s跟t）。s和t权限的意义与系统的帐号（第十四章）及系统的程序（第十七章）相关。 s这个表示根据出现位置的不同，可分为SUID和SGID： 1、s标志出现在档案拥有者的x权限上时，如passwd，称为Set UID，简称SUID的特殊权限。SUID的限制和功能： ● 仅对二进制程序有效 ● 执行者对该程序具有x的可执行权限★★★ ● 本权限仅在该程序的运行时 ★★★ ● 执行者将具有程序拥有者的权限 ★★★ （自己的话：用户对二进制程序有可执行权利，在程序运行时，暂时获得该程序拥有者的权限） 问题：所有帐号密码都记录在/etc/shadow，这个档案只有root可以修改，但个人用户的帐号显然能够修改自己的密码，问什么？ 答：passwd是一个二进制程序，个人用户对/usr/bin/passwd有x权限，用户在执行passwd的过程中，会暂时获得程序所有者[root]的权限的，对密码进行修改 2、s标志出现在文件所在组的x权限上时，成为Set GID，SGID的功能： ● SGID对二进制程序有用 ● 程序执行者对该程序有x权限 ● 执行者在执行过程中会获得该程序群组的支持 当使用个人账户去执行locate时，会取得slocate群组的支持，就能够读取mlocate.db 3、SBIT，Stick Bit仅对当前目录有效，作用： ● 当用户对于此目录具有w、x权限 ● 当用户在该目录下建立档案或目录时，仅自己与root有权利删除该档案 /tep任何人都能够在/tmp内新增、修改档案，但仅文件的建立者或root能够删除该文件 123456789101112SUID、SGID、SBIT权限设定设定的方法是在原先数字更改权限方式前再加上一个数字● SUID 4● SGID 2● SBIT 1例将一个文件权限设为[-rws r-x r-x]，这里s标志出现在文件所有者的x权限位置，所以是SUIDchmod 4755 # 加入SUIDchmod 6755 # 加入SUID和SGIDchmod 1755 # 加入SBITchmod 7666 # 出现-rwSrwSrwT，因为下达7666，user、group、other都没有x权限，那么这个S、T代表空（因为SUID是文件执行时，获得文件所有者的权限，但连文件所有者都无法执行了，哪来的权限给其他人使用） 权限与指令的关系1、进入目录： 可用命令如cd，用户对这个目录至少需要x权限，如果还要在这个目录利用ls查阅文件名，用户还需要对这个目录具有r权限 2、在目录中读取一个文件 可使用指令cat，more，less等，用户对这个目录至少需要x权限，对文件需要有r权限 3、修改一个文件 使用vim编辑器等，需要对该文件的目录有x权限，对文件有r和w权限 4、进入某个目录并执行该目录下的某个指令 用户对目录有x权限，对该文件有x权限 atime、mtime、ctime时间参数意义 ● +4代表大于等于5天前的文件 find /var -mtime +4 ● -4代表小于等于四天内的文件 find /var -mtime -4 ● 4代表4-5那一天的文件 find /var -mtime 4 差别 ● ctime是指change time ● mtime, 就是modify time mtime和ctime的区别在于，只有修改了文件的内容，才会更新文件的mtime，而对文件更名，修改文件的属主等操作，只会更新ctime。 举例说明: 对文件进行mv操作，mtime不变，ctime更新；编辑文件内容，mtime和ctime同时修改。其他操作的影响，可以自己试验。但是我发现对文件执行touch操作，会同时修改mtime和ctime，所以具体修改哪个时间，还取决于不同命令自己的实现； atime, 这个就是每次查看文件内容的时候会更新。比如cat操作，而ls操作是不会更新的。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第3讲.用户管理.目录结构]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC3%E8%AE%B2.%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86.%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[简单介绍详细介绍http://blog.sina.com.cn/s/blog_620eb3b20101hzt3.html linux的文件系统是采用层级式的树状目录结构，在此结构中的最上层是根目录”/“，然后在此目录下再创建其他的目录 深刻理解linux文件目录是非常重要的（9个） 12345678root，存放root用户的相关文件 home，存放普通用户的相关文件bin，存放常用命令的目录，如vi，susbin，要具有一定权限才可以使用命令 mnt，默认挂载光驱和软驱的目录etc，存放配置的相关文件usr，安装一个软件的默认目录，相当于windows下的program filesvar，存放经常变化的文件，如网络连接的sock文件boot，存放引导系统启动的相关文件 装置文件名 IDE 硬盘：/dev/hd[a-d] CDROM：/dev/cdrom 打印机：/dev/lp[0-2] 软盘驱劢器：/dev/fd[0-1] 网络卡：/dev/eth[0-n] Linux的用户管理 useradd 用户名 #添加用户，root权限，home会出现一个文件夹 passwd 用户名 #为新用户设密码 userdel 用户名 #删除用户a) 【案例】userdel xiaoming #删除用户但保存用户主目录b) 【案例】userdel‐r xiaoming #删除用户以及用户主目录 logout #当前用户退出 who am i #当前用户是谁 提示：”#”表示root用户，”$”表示普通用户。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第2讲. VI编辑器的使用]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC2%E8%AE%B2.%20VI%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是vi编辑器vi编辑器是linux下最有名的编辑器，也是我们学习linux必须掌握的工具，在linux下也可使用vi进行程序的开发，如java程序，c程序。 ps：VI编辑器由Bill Joy 1976年在bsd unix 开发的（世界第一骇客，成为了自由软件协会） vi分三种模式，分别是一般模式、编辑模式与指令列命令模式 一般模式：打开文档默认进入，可以移动光标，删除字符，删除整行，也可以复制粘帖。 编辑模式：按下i，I，o，O，a，A，r，R进入编辑模式，按Esc退出编辑模式。 指令命令模式：输入[:/?]三种任何一个按钮，就可以将光标移到最底下那一行，这个模式可以提供搜寻资料，读取、存盘，大量取代字符，离开vi，显示行号等动作。 如何使用vi进行开发？Java程序 在linux下使用vi开发一个简单的java程序Hello.java，并且在linux下运行成功 vi Hello.java 输入i，进入到插入模式 输入Esc键，进入命令模式 输入冒号:[wq 表示保存退出，q!表示退出不保存] 编译javac Hello.java 运行java Hello c程序 gcc Hello.cpp gcc -o Hello Hello.cpp[参数o表示可自定义生成的out文件名，否则默认为a. out，重复写会覆盖以前的值][自己命名gcc -o my1 Hello.cpp] ./Hello]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux命令缩写，方便记忆 http://blog.chinaunix.net/uid-27164517-id-3299073.html 开发者常用指令 netstat -anp | grep 8080 #查询端口 route #路由表 tracert #路由追踪 ps -aux #进程列表 kill -9 pid #杀进程 top env #查看环境变量 /etc/profile 和 ~/.bash_profile #系统整体配置文件（系统/个人用户） ehoc $PATH #PATH路径 ifconfig #在linux/unix查看ip的命令 df - h #查看Linux系统分区具体情况 df -h /etc #查看/etc底下可用的磁盘容量以易读的容量格式显示 crontab -e #任务调度 ls -a #显示隐藏文件 ls -l #列表显示 du -h --max-depth=1 #查看文件夹大小 cat Hello.txt | grep "pattern" #搜索字符串 grep -n "pattern" file1 file2 #文件中查找，显示行数，可以在多个文件 tar -zxvf libpcap-1.3.0.tar.gz #解压 zip aa.zip 文件名 #压缩 ./configure，make，make install #Linux下编译安装源代码三个步骤 rpm ‐ivh RPM包全路径名称 #安装包到当前系统 rpm -ivh url --replacepkgs #重新安装软件 rpm ‐e RPM包的名称 #删除 sudo 命令 / sudo su #管理员权限 #文件操作 mkdir folder #建立文件夹 touch filename #新建文件 rmdir folder #删除空目录 rm filename #删除文件 rm -rf 目录名字 #删除文件夹 -r下递归-f强行删除 cp file1 file2 #拷贝 cp -r dir1 dir2 #递归复制命令（复制子目录信息） find /root/ -name Hello.java #查找文件[不常用，速度慢，执行在硬盘中搜索，时间在文件权限那里] 常用123456789101112131415161718192021222324252627282930313233343536373839cd ~ #跳转到用户主目录tab #文件名自动提示pwd #查看当前目录reset #清屏clear #清屏ctrl + alt + T #终端，需在首选项-快捷键中设置env #查看环境变量/etc/profile #系统整体配置文件~/.bash_profile或~/.bash_login或~/.profile #个人设定ehoc $PATH #PATH路径ls #文件列表ls -a #显示隐藏文件ls -l #列表显示ls -al &lt;path&gt; #查看path路径下的文件列表ls -ld /tmp #查看目录的权限| #管道命令&gt; #管道定向，双箭头&gt;&gt;追加到文件结尾less #u，d，space，bmore #空格下一页，shift+PageUp上一页[more name]cat xxx | moregrep xxx #搜索字符串grep -n &quot;System&quot; file1 file2 #查找，显示行数tar -zxvf libpcap-1.3.0.tar.gz #解压zip aa.zip 文件名mount /mnt/cdrom #挂载光驱 unmount /mnt/cdrom #卸载光驱ifconfig #在linux/unix查看ip的命令df - h #查看Linux系统分区具体情况df -h /etc #查看/etc底下可用的磁盘容量以易读的容量格式显示crontab -e #任务调度 软件安装1234567891011121314151617181920212223242526272829303132333435# 安装二进制文件vim README/INSTALL #安装前参阅安装说明./configure --help #查看可用参数./configure --prefix=/usr/local/xxx#检查环境，创建makefile文件make clean #根据makefile清理一下环境make #根据makefile进行编译make insatll #根据makefile进行安装# rpmrpm ‐q 软件包名 #查询软件包是否安装rpm -qi rpm包 #列出该软件的详细信息rpm -ql rpm包 #列出该软件所有的文件与目录所在的完整文件名rpm -qc rpm包 #查询配置文件rpm -qf 配置文件 #查询配置文件是哪个软件的rpm -qa #已安装的软件名称rpm ‐ivh RPM包全路径名称 #安装包到当前系统rpm -ivh url --replacepkgs #重新安装软件rpm ‐e RPM包的名称 #删除rpm ‐e ‐‐nodeps samba #强制删除 rpm ‐Uvh RPM包全路径名 #升级，未安装的文件也会直接安装rpm - Fvh #升级，未安装的不安装rpm - V 软件 #该软件的档案被更动过，会列出来rpm -Va #列出系统上所有可能被更动的档案rpm -Vp 文件名 #列出该软件内可能被更动过的文件rpm -Vf #某个文件是否被更动过# yumyun install 软件 #安装软件yum update 软件 #升级软件yum remove 软件 #移除软件yum list 软件 #可用列表 ##文件操作12345678910111213141516171819202122232425mkdir folder #建立文件夹touch filename #新建文件rmdir folder #删除空目录rm filename #删除文件rm -rf 目录名字 #删除文件夹 -r下递归-f强行删除rm -i bashrc* #利用通配符删除bashrc开头的文件 mv test.log test1.txt #文件改名mv -i log1.txt log2.txt #将文件file1改名为file2，如果file2已经存在，则询问是否覆盖mv test1.txt test3 #移动文件mv log1.txt log2.txt log3.txt test3 #将文件log1.txt,log2.txt,log3.txt移动到目录test3中。 cp file1 file2 #拷贝cp -i file1 file2 #文件是否覆盖提醒cp -a file1 file2 #相当于-dpR,保持文件的连接(d),保持原文件的属性(p)并作递归处理(R)cp -p file1 file2 #连同文件的属性一起复制过去，而非使用默认属性cp -r dir1 dir2 #递归复制命令（复制子目录信息）cp -rf dir1 dir2 #拷贝文件夹，不提示是否覆盖whereis &lt;文件或目录&gt; #查找文件locate &lt;文件或目录&gt; #查找包含该字符的文件或目录，updatedb更新数据库find /root/ -name Hello.java #查找文件[不常用，速度慢，执行在硬盘中搜索，时间在文件权限那里]ln –s /etc/inittab inittab #（inittab指向实际文件/etc/inittab） #ln 建立符号连接(和windows的快捷方式) ##系统管理1234567891011121314151617181920212223242526272829303132333435363738shutdown -h now #立即进行关机(管理员root才可以) shutdown -r now #现在重新启动计算机 rebot #重启halt #关机logout #注销chkconfig #系统服务netstat -anp | grep 8080 #查询端口route #路由表tracert #路由追踪ps -aux #进程列表kill -9 pid #杀进程sudo 命令 / sudo su #管理员权限exit #退出当前用户su - test #切换普通用户su或su - #切换回root//pythonsudo pip install -r requirements.txt#系统服务service mysqld start #启动mysql数据库service mysqld stop #停止service mysqld status #查看状态chkconfig --list #查看系统服务chkconfig mysqld on #添加到开机启动chkconfig mydql off #关闭开机启动#防火墙service iptables status #查询防火墙状态service iptables stop #停止防火墙service iptables start #启动防火墙service iptables restart #重启防火墙chkconfig iptables off #永久关闭防火墙chkconfig iptables on #永久关闭后启用更改过滤规则 1、vim /etc/sysconfig/iptables 2、添加过滤规则 3、service iptables restart 重启 ##vim操作p336一般模式：12345678910111213141516171819202122232425262728293031- 移动光标hjkl #左下上右ctrl + f #屏幕向下一页，相当与Page Down★ctrl + b #屏幕向上一页，相当于Page Up★ctrl + d #屏幕向下半页ctrl + u #屏幕向上移动半页0或[home] #移动到这一行的最前面字符处★$或[end] #移动到这一行的最后面字符★nG #n为数字，移动到文档第n行★- 搜索/pattern #向下寻找和pattern匹配的内容★?pattern #向上寻找和pattern匹配的内容:noh #取消高亮字母n或N #向前或向后继续寻找- 替换:n1,n2s/word1/word2/g #n1与n2行之间用word2替换word1★:1,$s/word1/word2/g #从第一行到最后一行寻找word1，替换为word2★:1,$s/word1/word2/gc #第一行到最后一行寻找word1，替换为word2，替换前提示用户确认★- 删除 x,X #x向后删一个字符，X向前删★dd #删除一行★- 复制粘帖 yy #复制光标那一行★p，P #p下一行粘帖，P上一行u #复原前一个动作ctrl+r #重做上一个动作. #重复前一个动作 编辑模式：123i,I #i光标处插入，I所在行第一个非空字符插入a,A #a光标所下一个字符插入，行最后一个字符插入o,O #光标所在下一行插入新的一行，O上一行 指令列模式：1234567:w #将编辑的数据写入硬盘文件:w! #强行写入:q #离开vi:q! #强制离开，不保存:wq #储存离开:w filename #另存为！&lt;command&gt; #执行shell命令 分页器命令：1234字母u和d #分页器向上、向下翻动半页空格、b #分页器向下翻一页，向上翻一页字母j和k #向下翻一行，上翻一行左箭头、右箭头 #行截断，向左向右滚动 其他：1234:1,$d #全部删除v,V,ctrl+v #字符选择,行选择，区块选择y #反白的地方复制d #反白的地方删除 ##linux的用户、权限管理1234567891011121314151617181920212223242526# 用户useradd 用户名 #添加用户，root权限，home会出现一个文件夹passwd 用户名 #为新用户设密码userdel 用户名 #删除用户a) 【案例】userdel xiaoming #删除用户但保存用户主目录 b) 【案例】userdel ‐r xiaoming #删除用户以及用户主目录cat /etc/passwd #查看Linux下所有用户信息用户：密码：用户ID：组ID：用户主目录：shell解释器logout #当前用户退出 who am i #当前用户是谁# 用户组groupadd policeman #添加组，只能在root用户下操作cat /etc/group #查看所有组useradd –g 组名 用户名 #创建用户，并添加到指定组usermod -g 组名 用户名 #把一个用户移值到另一个组# 操作chmod 777 文件名 #用户所在组、其他组都能进行读、写、执行chown 用户名 文件名 #修改文件所有者chown ‐R root ./abc #改变abc这个目录及其下面所有的文件和目录的所有者是rootchgrp 组名 文件名 #修改文件所有组umask #文件预设权限，为文件或文件夹建立时默认的权限，umask -S以符号类型的方式显示 ##压缩1234567891011121314151617181920212223242526272829303132333435363738#gzip常用用法gzip 文件名 #压缩文件，并删除源文件，后缀gzgzip -d xxx.gz #解压#bzip2常用用法bzip2压缩比比gzip还要好，后缀bz2bzip2 文件名 #压缩bzip2 -d 压缩名 #解压bzcat 压缩名 #查看压缩包#zip常用用法zip aa.zip 文件名1 文件名2 #压缩文件zip –r aa.zip 文件夹路径 #压缩文件夹zip file.zip * -x file #将不需要压缩的文件排除在外 unzip file.zip #直接解压缩文件unzip file.zip –x file2 #除了file2文件外，其他的文件都解压缩unzip –Z file.zip #查看file.zip压缩包的内容。也可以使用“-l”、“-v”来查看压缩包的内容zip -d test1.zip test.MYI #删除压缩文件test1.zip中test.MYI文件zip -m test1.zip test. MYI #向压缩文件中test1.zip中添加test. MYI文件#打包指令tarp307-j 透过bzip2压缩，档名取为*.tar.bz2-z 透过gzip压缩，档名趣味*.tar.gztar -jcvf filename.tar.bz2 要被压缩的档案或目录 #压缩tar -jtvf filename.tar.bz2 #查询tar -jxvf filename.tar.bz2 #解压缩tar -jxvf filename.tar.bz2 -C /tmp #-C解压目录tar -jzxf filename.tar.bz2 待解开档名 #解开单一档案tar -jcvf filename.tar.bz2 --exluce=etc* #不包含默写档案tar -zpcvf /root/etc.tar.gz /etc tar -jpcvf /root/etc.tar.bz2 /etc#备份etc,p保留原本档案的权限与属性 环境变量.bash_profile 位于主目录下，它为系统的每个用户设置环境信息 **/etc/ 中 profile 主要是配置环境变量** 配置 .bashrc 文件可以指定某些程序在用户登录的时候就自动启动。 ##命令集 1234date #日期cal #日历bc #计算器ctrl + D #文字输入结束 ##命令专题命令init [0123456]12345678910111213141516171819202122指定系统运行级别，类似windows的正常运行模式或安全模式 0：关机 1：单用户2：多用户状态没有网络服务 3：多用户状态有网络服务[常用]4：系统未使用保留给用户 5：图形界面 6：系统重启常用运行级别是3和5，要修改默认的运行级别可改文件 /etc/inittab的id:5:initdefault:这一行中的数字切换用户：输入su切换用户或者logoutFAQ：不小心设置了6，导致系统启动-重启-启动循环，怎么办？ 1. 在进入grub引导界面时，在数秒的时候，请输入 e 2. 然后选中第二行(kernel)，输入e3. 在出现的界面里，输入1【1表示单用户级别】(6.5中测试是输入single，最终显示的是quiet single)，1的前面需要加一个空格，单用户模式既可以修改模式，又可以修改密码，Enter 4. 返回后，按b，重新启动注意：用运行级别1可以绕过ROOT密码，不需要密码就可以用，用passwd就OK 配置文件被更改 如：12345678910111213141516最前面的八个信息是： S ：(file Size differs) 档案的容量大小是否被改变 M ：(Mode differs) 档案的类型戒档案的属性 (rwx) 是否被改变？如是否可执行等参数已被改变 5 ：(MD5 sum differs) MD5 这一种纹码的内容已经不同 D ：(Device major/minor number mis-match) 装置的主/次代码已经改变 L ：(readLink(2) path mis-match) Link 路径已被改变 U ：(User ownership differs) 档案的所属人已被改变 G ：(Group ownership differs) 档案的所属群组已被改变 T ：(mTime differs) 档案的建立时间已被改变第二排的意思是： c ：配置文件 (config file) d ：文件数据文件 (documentation) g ：鬼档案～通常是该档案丌被某个软件所包吨，较少发生！(ghost file) l ：许可证文件 (license file) r ：自述文件 (read me) ##shell使用 shell脚本文件： a) 是一个文本文件 b) 命令的集合 c) 有执行的权限 d) 执行方式（./文件名） profile文件profile文件主要是用于配置环境变量 用户登录后自动执行的shell脚本文件配置.bashrc文件可以指定某些程序在用户登录的时候就自动启动。1如：/home/tomcat/bin/startup.sh start]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第1讲.基础介绍]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC1%E8%AE%B2.%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[linux的初步介绍吉祥物：小企鹅（想起小时侯被企鹅咬了一口），芬生学生创建，微软反LINUX广告（四个变形动物） linux的特点优点 免费的/开源 支持多线程/多用户 安全性好 对内存和文件管理优越 缺点 操作相对困难 linux的历史1960时期左右，MIT，即麻省理工学院有一台电脑，使用分时操作系统，只能同时允许30个人通过终端登录 1965年，MIT、GE、Bell实验室，决定将30 -&gt; 300个人分时系统，multis计划，即火星计划 1969年，火星计划失败。但Bell的Ken Thompson（C语言设计者）开发了一个file server system[文件系统]，在Bell实验室很受欢迎 在Dennis Ritchie的加入下，1973年，unix诞生，开源，源码内核共享 各个大公司看到了商机，认为Unix未来会有很大的前景，在源代码基础上进行开发 IBM：AIX Sun：Solaris HP： HP unix 伯克利分校：BSD minix系统出现（也是跟上述操作系统一样），麻雀虽小，五脏俱全 Linus Torvalds，芬兰读书，拥有PC 386，1991年计划把minix移植到pc上（商用的只能放在特定的机器上），1994发布linux 1.0版 [linux is not unix]，完全没有桌面 Linux内核代码也是开源的，一些公司看到些商机 redhat红帽子 s.u.s.e 红旗linux（中国） linux的第一次接触###关机命令 123shutdown-h now #立即进行关机(管理员root才可以) shutdown -r now #现在重新启动计算机 reboot #现在重新启动计算机 ###进入图形桌面 1startx ###用户登录 1234输入用户名密码登录时尽量少用root账户登录，因为它是系统管理员，最大的权限，难免操作失误。可以利用普通用户登录，登录后再用&quot;su -&quot;命令来切换成系统管理员身份 ###用户注销 1在提示符下输入logout即可，快捷键ctrl+D]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux视频教程第0讲.开山篇]]></title>
    <url>%2F2017%2F04%2F12%2F%5BLinux%5DLinux%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E7%AC%AC0%E8%AE%B2.%E5%BC%80%E5%B1%B1%E7%AF%87%2F</url>
    <content type="text"><![CDATA[笔记：http://www.mianfeiwendang.com/doc/72c0f2fc1581313161f5e306 为什么学习Linuxlinux是一个开源、免费的操作系统，其稳定性、安全性、处理多并发已经得到业界的认可，目前很多中型，大型甚至是巨型项目都在使用linux Linux发行版市面上有很多Linux发行版：redhat 、红旗linux、ubuntu、suse、fedora，它们的内核都是一样的（Note：linux其实是一个统称，就比如面条是一个统称，可以有哨子面、阳春面、打卤面等） linux for 工作 linux系统管理员 - -linux系统的维护、配置等 linux程序员 - - 需c/c++、java，php、jsp… 细分———linux软件工程师（PC） linux嵌入式开发（单片机、芯片） 如何学习linux 第一阶段：linux平台上的开发，包括vi，gcc，gdb，make，jdk，tomcat，mysql等和linux基本操作 第二阶段：加厚c语言功底《c专家编程》或是java语言 第三阶段：学习unix环境高级编程《unix环境高级编程》 第四阶段：linux应用系统开发/linux嵌入式开发 内容讲解基础部分 linux基础知识 linux常用命令80个 linux分区/vi/权限… 实用部分 Samba安装与配置 linux网络环境配置 crontab使用 jdk/apache/mysql/ssh/rpm安装与配置 linux下java网络编程 shell初步介绍 Samba安装与配置 推荐书籍 《鸟哥的Linux的私房菜基础学习篇》鸟哥、许伟、林彩娥等编著 《Linux编程从入门到精通》宫虎波编著 《Linux内核完全剖析》赵炯编著]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息转换机制]]></title>
    <url>%2F2017%2F04%2F11%2F%5BSpring%20MVC%5D%E6%B6%88%E6%81%AF%E8%BD%AC%E6%8D%A2%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[源码分析：http://www.cnblogs.com/fangjian0423/p/springMVC-xml-json-convert.html HttpMessageConverter接口就是Spring提供的http消息转换接口 1、对Http请求报文进行抽象，通过HttpInputMessage的getBody()方法获得输入流，通过HttpOutputMessag的getBody()方法获得输出流2、消息转换器的最高层次的接口抽象：HttpMessageConverter3、根据@RequestBody注解选择适当的HttpMessageConverter实现类来将请求参数解析到string变量中 开启注解驱动：&lt;mvc:annotation-driven/&gt;后实例化了RequestMappingHandlerMapping，RequestMappingHandlerAdapter等诸多类。 RequestMappingHandlerMapping处理请求映射的，处理@RequestMapping跟请求地址之间的关系。 RequestMappingHandlerAdapter是请求处理的适配器，将会处理注解和准备handler方法中的参数（RequestMappingHandlerAdapter中的HttpMessageConverter完成Http请求体中的数据到Handler参数的映射）]]></content>
      <categories>
        <category>Spring MVC</category>
      </categories>
      <tags>
        <tag>消息转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1、数据库连接池原理]]></title>
    <url>%2F2017%2F04%2F10%2F%5B%E6%95%B0%E6%8D%AE%E5%BA%93%5D1%E3%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[早期我们怎么进行数据库操作一般来说，Java应用程序访问数据库的过程是： 加载驱动 建立连接 创建Statement对象 执行sql语句 处理结果集 关闭连接 123456789101112131415161718192021public class JDBCTest &#123; public static void main(String[] args) throws ClassNotFoundException, SQLException &#123; //1、加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //2、建立连接 Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/audit&quot;, &quot;root&quot;, &quot;root&quot;); //3、创建Statement对象 PreparedStatement statement = connection.prepareStatement(&quot;select * from audit_user where userID = ?&quot;); statement.setString(1, &quot;8aec28d9515c673301515c7966700001&quot;); //4、执行sql语句 ResultSet resultSet = statement.executeQuery(); //5、处理结果集 while(resultSet.next())&#123; System.out.println(resultSet.getString(&quot;userName&quot;)); &#125; //6、关闭连接 resultSet.close(); statement.close(); connection.close(); &#125;&#125; 存在的问题： 首先，每一次web请求都要建立一次数据库连接，建立连接是一个费时的活动，每次都得花费0.05s～1s的时间，而且系统还要分配内存资源。这个时间对于一次或几次数据库操作，或许感觉不出系统有多大的开销。可是对于现在的web应用，尤其是大型电子商务网站，同时有几百人甚至几千人在线是很正常的事。在这种情况下，频繁的进行数据库连接操作势必占用很多的系统资源，网站的响应速度必定下降，严重的甚至会造成服务器的崩溃。不是危言耸听，这就是制约某些电子商务网站发展的技术瓶颈问题。 其次，对于每一次数据库连接，使用完后都得断开。否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将不得不重启数据库。还有，这种开发不能控制被创建的连接对象数，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。 上述的用户查询案例，如果同时有1000人访问，就会不断的有数据库连接、断开操作 通过上面的分析，我们可以看出来，”数据库连接”是一种稀缺的资源，为了保障网站的正常使用，应该对其进行妥善管理。其实我们查询完数据库后，如果不关闭连接，而是暂时存放起来，当别人使用时，把这个连接给他们使用。就避免了一次建立数据库连接和断开的操作时间消耗。原理如下： 技术演进出来的数据库连接池由上面的分析可以看出，问题的根源就在于对数据库连接资源的低效管理。我们知道，对于共享资源，有一个很著名的设计模式：资源池（resource pool）。该模式正是为了解决资源的频繁分配﹑释放所造成的问题。为解决上述问题，可以采用数据库连接池技术。数据库连接池的基本思想就是为数据库连接建立一个”缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从”缓冲池”中取出一个，使用完毕之后再放回去。 我们可以通过设定连接池最大连接数来防止系统无尽的与数据库连接。更为重要的是我们可以通过连接池的管理机制监视数据库的连接的数量﹑使用情况，为系统开发﹑测试及性能调整提供依据。 我们自己尝试开发一个连接池，来为上面的查询业务提供数据库连接服务： 编写 class 实现 IConnectionPool 接口，实现从 getConnection 和 release 方法 在 class 构造器一次性创建10个连接，将连接保存 LinkedList 中 实现 getConnection，从 LinkedList 中返回一个连接 提供将连接放回连接池中方法 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 自定义连接池 */public class SimpleConnectionPool implements IConnectionPool&#123; private Queue&lt;Connection&gt; connections = new LinkedList&lt;Connection&gt;(); public SimpleConnectionPool() throws ClassNotFoundException, SQLException&#123; //加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //创建连接 for(int i = 0; i &lt; 10; i++)&#123; Connection connection = DriverManager.getConnection(&quot;jdbc:mysql:///audit&quot;, &quot;root&quot;, &quot;root&quot;); connections.add(connection); &#125; &#125; //从连接池中获取连接 @Override public Connection getConnection() &#123; return connections.poll(); &#125; //释放连接 @Override public void release(Connection connection) &#123; connections.add(connection); &#125; public static void main(String[] args) throws ClassNotFoundException, SQLException &#123; IConnectionPool pool = new SimpleConnectionPool(); //测试是否是10个数据库连接对象 Set&lt;Connection&gt; sets = new HashSet&lt;Connection&gt;(); //模拟100个用户创建连接和释放连接 for(int i = 0; i &lt; 100;i++)&#123; Connection connection = pool.getConnection(); sets.add(connection); System.out.println(connection); pool.release(connection); &#125; System.out.println(sets.size());//10 &#125;&#125; 使用连接池重构我们的用户查询函数 /** * 使用连接池重构访问数据库 */ public class Test2 { public static void main(String[] args) throws ClassNotFoundException, SQLException { // 1、建立连接池 SimpleConnectionPool pool = new SimpleConnectionPool(); for (int i = 0; i < 100; i++) { // 2、建立连接 Connection connection = pool.getConnection(); System.out.println(connection); // 3、创建Statement对象 PreparedStatement statement = connection.prepareStatement("select * from audit_user where userID = ?"); statement.setString(1, "8aec28d9515c673301515c7966700001"); // 4、执行sql语句 ResultSet resultSet = statement.executeQuery(); // 5、处理结果集 while (resultSet.next()) { System.out.println(resultSet.getString("userName")); } // 6、关闭连接 resultSet.close(); statement.close(); pool.release(connection); } } } 如果不使用连接池，不断与数据库建立连接，当超出数据库的最大连接数后会报 Too Many 连接错误 这就是数据库连接池的原理，它大大提供了数据库连接的利用率，减小了内存吞吐的开销。我们在开发过程中，就不需要再关心数据库连接的问题，自然有数据库连接池帮助我们处理，这回放心了吧。但连接池需要考虑的问题不仅仅如此，下面我们就看看还有哪些问题需要考虑。 连接池还要考虑更多的问题1、并发问题 为了使连接管理服务具有最大的通用性，必须考虑多线程环境，即并发问题。这个问题相对比较好解决，因为java语言自身提供了对并发管理的支持，使用synchronized关键字即可确保线程是同步的。使用方法为直接在类方法前面加上synchronized关键字，如： public synchronized Connection getConnection（） 2、多数据库服务器和多用户 对于大型的企业级应用，常常需要同时连接不同的数据库（如连接Oracle和sybase）。如何连接不同的数据库呢？我们采用的策略是：设计一个符合单例模式的连接池管理类 在连接池管理类的唯一实例被创建时读取一个资源文件，其中资源文件中存放着多个数据库的url地址等信息 根据资源文件提供的信息，创建多个连接池类的实例，每一个实例都是一个特定数据库的连接池。连接池管理类实例为每个连接池实例取一个名字，通过不同的名字来管理不同的连接池。 对于同一个数据库有多个用户使用不同的名称和密码访问的情况，也可以通过资源文件处理，即在资源文件中设置多个具有相同url地址，但具有不同用户名和密码的数据库连接信息。 3、事务处理 我们知道，事务具有原子性，此时要求对数据库的操作符合”all-all-nothing”原则，即对于一组sql语句要么全做，要么全不做。 在 Java 语言中，Connection 类本身提供了对事务的支持，可以通过设置 Connection 的 autocommit 属性为 false，然后显式的调用commit或rollback方法来实现。但要高效的进行connection复用，就必须提供相应的事务支持机制。可采用每一个事务独占一个连接来实现，这种方法可以大大降低事务管理的复杂性（使用ThreadLocal实现线程范围内的单例，每个线程一个） /** * 事务显示提交，出现异常回滚； * 事务中的sql语句要么全部执行，要不全部不执行 */ connection.setAutoCommit(false); try { int result = statement.executeUpdate();//成功 int a = 1/0;//异常 connection.commit(); } catch (Exception e) { e.printStackTrace(); connection.rollback(); } 4、连接池的分配与释放★★★ 连接池的分配与释放，对系统的性能有很大的影响。合理的分配与释放，可以提高连接的复用度，从而降低建立新连接的开销，同时还可以加快用户的访问速度。 对于连接的管理可使用空闲池。即把已经创建但尚未分配出去的连接按创建时间存放到一个空闲池中。 每当用户请求一个连接时，系统首先检查空闲池内有没有空闲连接。如果有就把建立时间最长（通过容器的顺序存放实现）的那个连接分配给他（实际是先做连接是否有效的判断，如果可用就分配给用户，如不可用就把这个连接从空闲池删掉，重新检测空闲池是否还有连接）； 如果没有则检查当前所开连接池是否达到连接池所允许的最大连接数（maxconn），如果没有达到，就新建一个连接，如果已经达到，就等待一定的时间（timeout）。 如果在等待的时间内有连接被释放出来就可以把这个连接分配给等待的用户，如果等待时间超过预定时间timeout 则返回空值（null）。 系统对已经分配出去正在使用的连接只做计数，当使用完后再返还给空闲池。对于空闲连接的状态，可开辟专门的线程定时检测，这样会花费一定的系统开销，但可以保证较快的响应速度。也可采取不开辟专门线程，只是在分配前检测的方法。 5、连接池的配置与维护 连接池中到底应该放置多少连接，才能使系统的性能最佳？系统可采取设置最小连接数（minconn）和最大连接数（maxconn）来控制连接池中的连接。最小连接数是系统启动时连接池所创建的连接数。如果创建过多，则系统启动就慢，但创建后系统的响应速度会很快；如果创建过少，则系统启动的很快，响应起来却慢。这样，可以在开发时，设置较小的最小连接数，开发起来会快，而在系统实际使用时设置较大的，因为这样对访问客户来说速度会快些。最大连接数是连接池中允许连接的最大数目，具体设置多少，要看系统的访问量，可通过反复测试，找到最佳点。 如何确保连接池中的最小连接数呢？有动态和静态两种策略。动态即每隔一定时间就对连接池进行检测，如果发现连接数量小于最小连接数，则补充相应数量的新连接以保证连接池的正常运转。静态是发现空闲连接不够时再去检查。 实际开发中有成熟的开源连接池供我们使用理解了连接池的原理就可以了，没有必要什么都从头写一遍，那样会花费很多时间，并且性能及稳定性也不一定满足要求。事实上，已经存在很多流行的性能优良的第三方数据库连接池jar包供我们使用。如： 1.Apache commons-dbcp 连接池下载：http://commons.apache.org/proper/commons-dbcp/ 2.c3p0 数据库连接池下载：http://sourceforge.net/projects/c3p0/ 参考http://blog.csdn.net/shuaihj/article/details/14223015]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>连接池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协作开发]]></title>
    <url>%2F2017%2F04%2F09%2F%5BGit%5D%E5%8D%8F%E4%BD%9C%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[Gitlab多人协作开发 http://herry2013git.blog.163.com/blog/static/219568011201341111240751/]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>协作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM的符号引用和直接引用]]></title>
    <url>%2F2017%2F04%2F09%2F%5BJVM%5DJVM%E7%9A%84%E7%AC%A6%E5%8F%B7%E5%BC%95%E7%94%A8%E5%92%8C%E7%9B%B4%E6%8E%A5%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[http://www.cnblogs.com/shinubi/articles/6116993.html 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可。例如，在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现。符号引用与虚拟机的内存布局无关，引用的目标并不一定加载到内存中。在Java中，一个java类将会编译成一个class文件。在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。比如org.simple.People类引用了org.simple.Language类，在编译时People类并不知道Language类的实际内存地址，因此只能使用符号org.simple.Language（假设是这个，当然实际中是由类似于CONSTANT_Class_info的常量来表示的）来表示Language类的地址。各种虚拟机实现的内存布局可能有所不同，但是它们能接受的符号引用都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用：直接引用可以是（1）直接指向目标的指针（比如，指向“类型”【Class对象】、类变量、类方法的直接引用可能是指向方法区的指针）（2）相对偏移量（比如，指向实例变量、实例方法的直接引用都是偏移量）（3）一个能间接定位到目标的句柄直接引用是和虚拟机的布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经被加载入内存中了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>符号引用</tag>
        <tag>直接引用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM性能调优]]></title>
    <url>%2F2017%2F04%2F01%2F%5BJVM%5DJVM%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[jps列出正在运行的虚拟机进程 使用案例： jps -l 语法： jps [-option] [hostid] q 只输出LVMID，省略主类的名称 m 输出main method的参数 l 输出完全的包名，应用主类名，jar的完全路径名 v 输出jvm参数 jstat监视虚拟机运行状态信息 监控堆使用率，每秒显示一次 jstat -gcutil 25444 1000 监控堆容量的变化，每秒显示一次 jstat -gc 25444 1000 语法结构： Usage: jstat -help|-options jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]] 参数解释： C:capacity U：usage Options — 选项，我们一般使用** -gcutil** 查看gc 情况 vmid — VM 的进程号，即当前运行的java 进程号 interval– 间隔时间，单位为秒或者毫秒 count — 打印次数，如果缺省则打印无数次 S0 — Heap 上的 Survivor space 0 区已使用空间的百分比 S1 — Heap 上的 Survivor space 1 区已使用空间的百分比 E — Heap 上的 Eden space 区已使用空间的百分比 O — Heap 上的 Old space 区已使用空间的百分比 P — Perm space 区已使用空间的百分比 YGC — 从应用程序启动到采样时发生 Young GC 的次数 YGCT– 从应用程序启动到采样时 Young GC 所用的时间( 单位秒 ) FGC — 从应用程序启动到采样时发生 Full GC 的次数 FGCT– 从应用程序启动到采样时 Full GC 所用的时间( 单位秒 ) GCT — 从应用程序启动到采样时用于垃圾回收的总时间( 单位秒) S0C：年轻代中第一个survivor（幸存区）的容量 (字节) S1C：年轻代中第二个survivor（幸存区）的容量 (字节) S0U：年轻代中第一个survivor（幸存区）目前已使用空间 (字节) S1U：年轻代中第二个survivor（幸存区）目前已使用空间 (字节) EC：年轻代中Eden（伊甸园）的容量 (字节) EU：年轻代中Eden（伊甸园）目前已使用空间 (字节) OC：Old代的容量 (字节) OU：Old代目前已使用空间 (字节) PC：Perm(持久代)的容量 (字节) PU：Perm(持久代)目前已使用空间 (字节) jstat的option参数： -class：统计class loader行为信息 -compile：统计编译行为信息 -gc：统计jdk gc时heap信息 -gccapacity：统计不同的generations（不知道怎么翻译好，包括新生区，老年区，permanent区）相应的heap容量情况 -gccause：统计gc的情况，（同-gcutil）和引起gc的事件 -gcnew：统计gc时，新生代的情况 -gcnewcapacity：统计gc时，新生代heap容量 -gcold：统计gc时，老年区的情况 -gcoldcapacity：统计gc时，老年区heap容量 -gcpermcapacity：统计gc时，permanent区heap容量 -gcutil：统计gc时，heap情况 -printcompilation：不知道干什么的，一直没用过。 jmapjmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。如果不使用jmap命令，想要获取Java堆转储快照还有一些比较”暴力”的手段： 可以使用-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=C:\参数，可以让虚拟机在OOM异常出现之后自动生成dump文件 通过-XX:+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]键让虚拟机生成dump文件 在Linux系统下通过Kill -3命令发送进程退出信号”恐吓”一下虚拟机，也能拿到dump文件。 使用案例，详细参数见案例说明： jmap -heap pid #查看进程堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况 jmap -histo[:live] pid #查看堆内存中的对象数目、大小统计直方图，如果带上live则只统计活对象 jmap -dump:format=b,file=eclipse.bin 7240 #生成Java程序dump快照文件 语法： jmap [ -option ] &lt;pid&gt; option参数： dump 生成堆存储快照，格式为：-dump:[live, ]format=b, file=&lt;filename&gt;，live说明是否只dump出存活的对象。 heap 显示java堆详细信息，如使用那种回收器、参数配置、分代状况等。 histo 显示堆中对象统计信息，包括类、实例数量、合计容量。 案例说明： C:\Users\Asus&gt;jmap -heap 10416 | more Attaching to process ID 10416, please wait... Debugger attached successfully. Server compiler detected. JVM version is 20.45-b01 using thread-local object allocation. #使用本地线程分配缓存 Parallel GC with 4 thread(s) # 并行垃圾回收，4个线程 Heap Configuration: #堆设置 MinHeapFreeRatio = 40 #GC后，如果发现空闲堆内存占到整个预估堆内存的40%，则放大堆内存的预估最大值，但不超过固定最大值。 MaxHeapFreeRatio = 70 #GC后，如果发现空闲堆内存占到整个预估堆内存的70%，则收缩堆内存预估最大值。什么是预估堆内存？1、预估堆内存是堆大小动态调控的重要选项之一 2、堆内存预估最大值一定小于或等于固定最大值(-Xmx指定的数值) 3、前者会根据使用情况动态调大或缩小，以提高GC回收的效率。 MaxHeapSize = 2124414976 (2026.0MB) NewSize = 1310720 (1.25MB) MaxNewSize = 17592186044415 MB OldSize = 5439488 (5.1875MB) NewRatio = 2 #新生代和老年代占用比例，-XX:NewRatio=2设置 SurvivorRatio = 8 # Eden和一块Survivor的大小比例是8：1，新生代采用复制算法，垃圾回收时将Eden和一块Survivor中存活的对象复制到另一块Survivor中，并清空上一块Survivor。因此新生代可用容量为90%（80%+10%），10%的Survivor总是空的 PermSize = 21757952 (20.75MB) MaxPermSize = 85983232 (82.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 49020928 (46.75MB) used = 30167344 (28.769821166992188MB) free = 18853584 (17.980178833007812MB) 61.53972442137366% used From Space: capacity = 4325376 (4.125MB) used = 376912 (0.3594512939453125MB) free = 3948464 (3.7655487060546875MB) 8.713970762310606% used To Space: capacity = 5898240 (5.625MB) used = 0 (0.0MB) free = 5898240 (5.625MB) 0.0% used PS Old Generation capacity = 88473600 (84.375MB) used = 56496112 (53.87889099121094MB) free = 31977488 (30.496109008789062MB) 63.85646339699074% used PS Perm Generation capacity = 21757952 (20.75MB) used = 10613560 (10.121879577636719MB) free = 11144392 (10.628120422363281MB) 48.78014254282756% used jstack：Java堆栈跟踪工具垃圾收集器选择（交互优先、吞吐量优先）1、ParNew + CMS 需要与用户交互的程序，良好的响应速度能提升用户的体验 配置： java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。 -XX:+UseParNewGC: 设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。 -XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片 2、Parallel Scavenge + Paralle Old 后台任务，吞吐量优先，最高效率地利用 CPU 时间，尽快地完成程序的运算任务 典型配置： java -server -Xms3800m -Xmx3800m -Xmn2g -Xss128k -XX:+UseParallelOldGC -XX:ParallelGCThreads=4 -XX:GCTimeRatio=99 -XX:+UseAdaptiveSizePolicy -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。 垃圾收集器介绍： Parallel Scavenge 收集器的目标则是达到一个可控制的吞吐量（Throughput）。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 由于与吞吐量关系密切，Parallel Scavenge收集器也经常被称为“吞吐量优先”收集器。 该垃圾收集器，是JAVA虚拟机在 Server 模式下的默认值，使用 Server 模式后，Java虚拟机使用 Parallel Scavenge收集器（新生代）+ Serial Old收集器（老年代） 的收集器组合进行内存回收。 参数说明： 重要的参数有三个，其中两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数及直接设置吞吐量大小的 -XX:GCTimeRatio 参数。另外一个是 UseAdaptiveSizePolicy 开关参数。 MaxGCPauseMillis 参数允许的值是一个大于0的毫秒数，收集器将尽力保证内存回收花费的时间不超过设定值。不过大家不要异想天开地认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集300MB新生代肯定比收集500MB快吧，这也直接导致垃圾收集发生得更频繁一些，停顿间隔减少，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。 GCTimeRatio 参数的值应当是一个大于0小于100的整数，是用户线程时间与垃圾收集时间比率。如果把此参数设置为19，那允许的最大GC时间就占总时间的5%（即1 /（1+19）），默认值为99，就是允许最大1%（即1 /（1+99））的垃圾收集时间，经过计算GCTimeRation = 吞吐量/(1-吞吐量)，如要求吞吐量为99%，则GCTimeRatio = 0.99/（1-0.99） = 99，吞吐量95%，GCTimeRatio = 0.95/(1-0.95) = 19 -XX:+UseAdaptiveSizePolicy 是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。 如果对于收集器运作原理不太了解，手工优化存在困难的时候，使用Parallel Scavenge收集器能够配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成，也是一个不错的选择。只需要把基本的内存数据设置好（如-Xmx设置最大堆），然后使用 MaxGCPauseMillis 参数（更关注最大停顿时间）或 GCTimeRatio 参数（更关注吞吐量）给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。 GC 相关参数总结1、与串行回收器相关的参数 -XX:+UseSerialGC:虚拟机运行在 Client 模式下的默认值，打开此开关后，使用 Serial + Serial Old 的收集器组合进行内存回收 -XX:SurvivorRatio: 新生代中 Eden 区域与 Survivor 区域的容量比值，默认为 8，代表 Eden：Survivor = 8 : 1 -XX:PretenureSizeThreshold:设置大对象直接进入老年代的阈值。当对象的大小超过这个值时，将直接在老年代分配。 -XX:MaxTenuringThreshold:设置对象进入老年代的年龄的最大值。每一次 Minor GC 后，对象年龄就加 1。任何大于这个年龄的对象，一定会进入老年代。 -XX:+HandlePromotionFailure:是否允许分配担保失败。即老年代的剩余空间不足以应付新生代的整个 Eden 和 Survivor 区的所有对象都存活的极端情况，java5以前是默认关闭，java6后默认启用 2、与并行 GC 相关的参数 -XX:+UseParNewGC: 打开此开关后，使用 ParNew + Serial Old 收集器组合进行内存回收 -XX:+UserParallelGC:虚拟机运行在 Server 模式下的默认值，打开此开关后，使用 Parallel Scavenge + Serial Old （PS MarkSweep）的收集器组合进行内存回收 -XX:+UseParallelOldGC: 打开此开关后，使用 Parallel Scavenge + Parallel Old 的收集器组合进行内存回收 -XX:ParallelGCThreads：设置用于垃圾回收的线程数。通常情况下可以和 CPU 数量相等。但在 CPU 数量比较多的情况下，设置相对较小的数值也是合理的。 -XX:MaxGCPauseMills：设置最大垃圾收集停顿时间。它的值是一个大于 0 的整数。收集器在工作时，会调整 Java 堆大小或者其他一些参数，尽可能地把停顿时间控制在 MaxGCPauseMills 以内。仅在使用 Parallel Scavenge 收集器时生效 -XX:GCTimeRatio:设置吞吐量大小，它的值是一个 0-100 之间的整数。假设 GCTimeRatio 的值为 n（用户线程时间与垃圾回收时间的比值），那么系统将花费不超过 1/(1+n) 的时间用于垃圾收集。仅在使用 Parallel Scavenge 收集器时生效 -XX:+UseAdaptiveSizePolicy:打开自适应 GC 策略。在这种模式下，新生代的大小，eden 和 survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，以达到在堆大小、吞吐量和停顿时间之间的平衡点。 3、与 CMS 回收器相关的参数 -XX:+UseConcMarkSweepGC: 打开此开关后，使用 ParNew + CMS + Serial Old 的收集器组合进行内存回收。Serial Old 收集器作为 CMS 收集器出现 Concurrent Mode Failure 失败后的后备收集器使用 -XX:+ParallelCMSThreads: 设定 CMS 的线程数量。 -XX:+CMSInitiatingOccupancyFraction:设置 CMS 收集器在老年代空间被使用多少后触发，默认为 68%。仅在使用 CMS 收集器时生效 -XX:+UseFullGCsBeforeCompaction:设定进行多少次 CMS 垃圾回收后，进行一次内存压缩。仅在使用 CMS 收集器时生效 -XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收。 -XX:+CMSParallelRemarkEndable:启用并行重标记。 -XX:CMSInitatingPermOccupancyFraction:当永久区占用率达到这一百分比后，启动 CMS 回收 (前提是-XX:+CMSClassUnloadingEnabled 激活了)。 -XX:UseCMSInitatingOccupancyOnly:表示只在到达阈值的时候，才进行 CMS 回收。 -XX:+CMSIncrementalMode:使用增量模式，比较适合单 CPU。 4、与 G1 回收器相关的参数 -XX:+UseG1GC：使用 G1 回收器。 -XX:+UnlockExperimentalVMOptions:允许使用实验性参数。 -XX:+MaxGCPauseMills:设置最大垃圾收集停顿时间。 -XX:+GCPauseIntervalMills:设置停顿间隔时间。 5、其他参数 -XX:+DisableExplicitGC: 禁用显示 GC。 6、堆设置 -Xms:初始堆大小 -Xmx:最大堆大小 -XX:NewSize=n:设置年轻代大小 -XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4 -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5 -XX:MaxPermSize=n:设置持久代大小 7、垃圾回收统计信息 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:filename]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis - 动态SQL语句]]></title>
    <url>%2F2017%2F03%2F27%2F%5Bmybatis%5DMybatis%20-%20%E5%8A%A8%E6%80%81SQL%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[多条件组合查询多条件组合查询时，根据用户的输入不为空的条件，查询出符合条件的数据。比如用户可以有三个筛选条件：name，sex，password 1、如果输入了name、sex、password，则对应的sql语句是 select * from user where name = ? and sex = ? and password = ? 2、如果输入了name，sex，对应的sql语句是 select * from user where name = ? and sex = ? 3、如果输入了name，对应的sql语句是 select * from user where name = ? 这时候就需要进行动态sql语句拼装 String name = &quot;qm&quot;; String sex = &quot;男&quot;; String password = &quot;123&quot;; StringBuilder sql = new StringBuilder(&quot;select * from user where 1 == 1&quot;); if(name != null &amp;&amp; !name.trim().equals(&quot;&quot;)){ sql.append(&quot; and name = ?&quot;); } if(sex != null &amp;&amp; !sex.trim().equals(&quot;&quot;)){ sql.append(&quot; and sex = ?&quot;); } if(password != null &amp;&amp; !password.trim().equals(&quot;&quot;)){ sql.append(&quot; and password = ?&quot;); } System.out.println(sql); 输出结果： select * from user where 1 == 1 and name = ? and sex = ? and password = ? 动态SQL语句http://limingnihao.iteye.com/blog/782190 where + if 的查询语句如果name或sex为null，此语句很可能报错或查询结果为空。此时我们使用if动态sql语句先进行判断，如果值为null或等于空字符串，我们就不进行此条件的判断，增加灵活性。 where标签会知道如果它包含的标签中有返回值的话，它就插入一个where。此外，如果标签返回的内容是以AND 或 OR 开头的，则它会剔除掉 1234567891011&lt;select id=&quot;getUser&quot; resultMap=&quot;User&quot;&gt; select * from t_user &lt;where&gt; &lt;if test=&quot;name !=null &quot;&gt; name = #&#123;name&#125; &lt;/if&gt; &lt;if test=&quot;sex != null and sex != &apos;&apos; &quot;&gt; and sex = #&#123;sex&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; if + set 的更新语句当update语句中没有使用if标签时，如果有一个参数为null，都会导致错误。当在update语句中使用if标签时，如果前面的if没有执行，则或导致逗号多余错误。使用set标签可以将动态的配置 SET 关键字，和剔除追加到条件末尾的任何不相关的逗号。 使用if+set标签修改后，如果某项为null则不进行更新，而是保持数据库原值 123456789101112&lt;update id=&quot;updateUser&quot; &gt; update user &lt;set&gt; &lt;if test=&quot;name != null and name != &apos;&apos; &quot;&gt; name = #&#123;name&#125;, &lt;/if&gt; &lt;if test=&quot;sex != null and sex != &apos;&apos; &quot;&gt; sex = #&#123;sex&#125; &lt;/if&gt; &lt;/set&gt; where id = #&#123;id&#125;; &lt;/update&gt; if + trim 代替 where/set 标签trim是更灵活的去处多余关键字的标签，他可以实践where和set的效果。 choose (when, otherwise)choose标签是按顺序判断其内部when标签中的test条件出否成立，如果有一个成立，则choose结束。当choose中所有when的条件都不满则时，则执行otherwise中的sql。类似于Java 的switch 语句，choose为switch，when为case，otherwise则为default。 例如下面例子，同样把所有可以限制的条件都写上，方面使用。choose会从上到下选择一个when标签的test为true的sql执行。安全考虑，我们使用where将choose包起来，放置关键字多于错误。 12345678910111213141516&lt;select id=&quot;getUser&quot; resultType=&quot;User&quot;&gt; SELECT * from t_user &lt;where&gt; &lt;choose&gt; &lt;when test=&quot;name !=null &quot;&gt; name = #&#123;name&#125; &lt;/when &gt; &lt;when test=&quot;sex != null and sex != &apos;&apos; &quot;&gt; and sex = #&#123;sex&#125; &lt;/when &gt; &lt;otherwise&gt; and time &gt;=#&#123;data&#125; &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt; &lt;/select&gt; 获取自增的id的值&lt;!--keyColumn：主键列的名字 keyProperty:主键的实体对应的属性名--&gt; &lt;insert id = &quot;adduser&quot; useGeneratedKeys = &quot;true&quot; keyColumn = &quot;id&quot; keyProperty=&quot;id&quot;&gt;&lt;/insert&gt; 传递多个参数（JavaBean、Map）Map传递多个参数，parameterType 可以是别名或完全限定名，map或者java.util.Map，这两个都是可以的，直接在占位符中输入Map的key即可 XML文件123456&lt;select id=&quot;selectBlogByMap&quot; parameterType=&quot;map&quot; resultType=&quot;Blog&quot;&gt; select t.ID, t.title, t.content FROM blog t where t.title = #&#123;h_title&#125; and t.content =#&#123;h_content&#125; &lt;/select&gt; 测试 123456789public void testSelectByMap() &#123; SqlSession session = sqlSessionFactory.openSession(); Map&lt;String, Object&gt; param=new HashMap&lt;String, Object&gt;(); param.put(&quot;h_title&quot;, &quot;oracle&quot;); param.put(&quot;h_content&quot;, &quot;使用序列&quot;); Blog blog = (Blog)session.selectOne(&quot;cn.enjoylife.BlogMapper.selectBlogByMap&quot;,param); session.close(); System.out.println(&quot;blog title:&quot;+blog.getTitle()); &#125; 通过JavaBean传递多个参数，直接在占位符中输入实体的属性值 XML123456&lt;select id=&quot;selectBlogByBean&quot; parameterType=&quot;Blog&quot; resultType=&quot;Blog&quot;&gt; select t.ID, t.title, t.content from blog t wheret.title = #&#123;title&#125; and t.content =#&#123;content&#125; &lt;/select&gt; 测试12345678public void testSelectByBean() &#123; SqlSession session = sqlSessionFactory.openSession(); Blog blog=new Blog(); blog.setTitle(&quot;oracle&quot;); blog.setContent(&quot;使用序列！&quot;); Blog newBlog = (Blog)session.selectOne(&quot;cn.enjoylife.BlogMapper.selectBlogByBean&quot;,blog); session.close(); System.out.println(&quot;new Blog ID:&quot;+newBlog.getId()); #{}的用法及传入多个参数 #{} 存在mapper.xml中的sql语句部分，标识该位置可以接受参数信息，相当于?占位符 传入的参数和参数名无关，问题：如果有多个参数该怎么办？ 方法一：使用0，1……自然数取出对应的数据，0表示第一个参数 select * from tb_user where user_name = #{0} and password = #{1} 方法二：使用param1，param2……param1表示第一个参数 select * from tb_user where user_name = #{param1} and password = #{param2} 方法三（常用）：在方法的定义上使用@param为传入的参数定义一个名字 在UserMapper接口中声明函数login，使用@param为每个参数定义一个名字 public User login(@Param(&quot;username&quot;) String username, @Param(&quot;password&quot;) String password); sql语句在#{}中填入定义的名字 select * from tb_user where user_name = #{username} and password = #{password} 测试 @Test public void testLogin(){ User user = userMapper.login(&quot;zhangsan&quot;,&quot;123456&quot;); System.out.println(user); }]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>动态sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对map集合进行排序]]></title>
    <url>%2F2017%2F03%2F26%2F%5BJava%5DJava%E9%9B%86%E5%90%88%20-%20%E5%AF%B9map%E9%9B%86%E5%90%88%E8%BF%9B%E8%A1%8C%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[转载：http://www.cnblogs.com/chenssy/p/3264214.html 对map集合进行排序 今天做统计时需要对X轴的地区按照地区代码（areaCode）进行排序，由于在构建XMLData使用的map来进行数据统计的，所以在统计过程中就需要对map进行排序。 简单介绍Map在讲解Map排序之前，我们先来稍微了解下map。map是键值对的集合接口，它的实现类主要包括：HashMap,TreeMap,Hashtable以及LinkedHashMap等。其中这四者的区别如下（简单介绍）： HashMap：我们最常用的Map，它根据key的HashCode 值来存储数据,根据key可以直接获取它的Value，同时它具有很快的访问速度。HashMap最多只允许一条记录的key值为Null(多条会覆盖);允许多条记录的Value为 Null。非同步的。 TreeMap: 能够把它保存的记录根据key排序,默认是按升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。TreeMap 不允许key的值为null。非同步的。 Hashtable: 与 HashMap类似，不同的是:key和value的值均不允许为null;继承Dictionary类，它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了Hashtale在写入时会比较慢。 LinkedHashMap: 保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.在遍历的时候会比HashMap慢。key和value均允许为空，非同步的。 Map排序TreeMapTreeMap默认是升序的，如果我们需要改变排序方式，则需要使用比较器：Comparator。 Comparator可以对集合对象或者数组进行排序的比较器接口，实现该接口的public compare(T o1,To2)方法即可实现排序，该方法主要是根据第一个参数o1,小于、等于或者大于o2分别返回负整数、0或者正整数。如下： 12345678910111213141516171819202122public class TreeMapTest &#123; public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new TreeMap&lt;String, String&gt;( new Comparator&lt;String&gt;() &#123; public int compare(String obj1, String obj2) &#123; // 降序排序 return obj2.compareTo(obj1); &#125; &#125;); map.put(&quot;c&quot;, &quot;ccccc&quot;); map.put(&quot;a&quot;, &quot;aaaaa&quot;); map.put(&quot;b&quot;, &quot;bbbbb&quot;); map.put(&quot;d&quot;, &quot;ddddd&quot;); Set&lt;String&gt; keySet = map.keySet(); Iterator&lt;String&gt; iter = keySet.iterator(); while (iter.hasNext()) &#123; String key = iter.next(); System.out.println(key + &quot;:&quot; + map.get(key)); &#125; &#125;&#125; 运行结果如下： d:ddddd c:ccccc b:bbbbb a:aaaaa 上面例子是对根据TreeMap的key值来进行排序的，但是有时我们需要根据TreeMap的value来进行排序。对value排序我们就需要借助于Collections的sort(List list, Comparator&lt;? super T&gt; c)方法，该方法根据指定比较器产生的顺序对指定列表进行排序。但是有一个前提条件，那就是所有的元素都必须能够根据所提供的比较器来进行比较。如下： 12345678910111213141516171819202122232425public class TreeMapTest &#123; public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new TreeMap&lt;String, String&gt;(); map.put(&quot;d&quot;, &quot;ddddd&quot;); map.put(&quot;b&quot;, &quot;bbbbb&quot;); map.put(&quot;a&quot;, &quot;aaaaa&quot;); map.put(&quot;c&quot;, &quot;ccccc&quot;); //这里将map.entrySet()转换成list List&lt;Map.Entry&lt;String,String&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;String,String&gt;&gt;(map.entrySet()); //然后通过比较器来实现排序 Collections.sort(list,new Comparator&lt;Map.Entry&lt;String,String&gt;&gt;() &#123; //升序排序 public int compare(Entry&lt;String, String&gt; o1, Entry&lt;String, String&gt; o2) &#123; return o1.getValue().compareTo(o2.getValue()); &#125; &#125;); for(Map.Entry&lt;String,String&gt; mapping:list)&#123; System.out.println(mapping.getKey()+&quot;:&quot;+mapping.getValue()); &#125; &#125;&#125; 运行结果 a:aaaaa b:bbbbb c:ccccc d:ddddd HashMap我们都是HashMap的值是没有顺序的，他是按照key的HashCode来实现的。对于这个无序的HashMap我们要怎么来实现排序呢？参照TreeMap的value排序，我们一样的也可以实现HashMap的排序。 1234567891011121314151617181920212223public class HashMapTest &#123; public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(&quot;c&quot;, &quot;ccccc&quot;); map.put(&quot;a&quot;, &quot;aaaaa&quot;); map.put(&quot;b&quot;, &quot;bbbbb&quot;); map.put(&quot;d&quot;, &quot;ddddd&quot;); List&lt;Map.Entry&lt;String,String&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;String,String&gt;&gt;(map.entrySet()); Collections.sort(list,new Comparator&lt;Map.Entry&lt;String,String&gt;&gt;() &#123; //升序排序 public int compare(Entry&lt;String, String&gt; o1, Entry&lt;String, String&gt; o2) &#123; return o1.getValue().compareTo(o2.getValue()); &#125; &#125;); for(Map.Entry&lt;String,String&gt; mapping:list)&#123; System.out.println(mapping.getKey()+&quot;:&quot;+mapping.getValue()); &#125; &#125;&#125; 运行结果 a:aaaaa b:bbbbb c:ccccc d:ddddd]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>集合排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO 系列教程]]></title>
    <url>%2F2017%2F03%2F09%2F%5BNIO%5DJava%20NIO%20%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[转自 http://ifeve.com/java-nio-all/ NIO是什么Java NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。 1、Java NIO: Channels and Buffers（通道和缓冲区） 标准的IO基于字节流和字符流进行操作的，而NIO是基于通道（Channel）和缓冲区（Buffer）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。 2、Java NIO: Non-blocking IO（非阻塞IO）Java NIO可以让你非阻塞的使用IO，例如：当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情。当数据被写入到缓冲区时，线程可以继续处理它。从缓冲区写入通道也类似。 3、Java NIO: Selectors（选择器）Java NIO引入了选择器的概念，选择器用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个的线程可以监听多个数据通道。 Java NIO 概述Java NIO 由以下几个核心部分组成： Channels Buffers Selectors Channel 和 Buffer基本上，所有的 IO 在NIO 中都从一个Channel 开始。Channel 有点象流。 数据可以从Channel读到Buffer中，也可以从Buffer 写到Channel中。这里有个图示： Channel和Buffer有好几种类型。下面是JAVA NIO中的一些主要Channel的实现： FileChannel DatagramChannel SocketChannel ServerSocketChannel 正如你所看到的，这些通道涵盖了 UDP 和 TCP 网络IO，以及文件IO。 与这些类一起的有一些有趣的接口，但为简单起见，我尽量在概述中不提到它们。本教程其它章节与它们相关的地方我会进行解释。 以下是Java NIO里关键的Buffer实现： ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 这些Buffer覆盖了你能通过IO发送的基本数据类型：byte, short, int, long, float, double 和 char。 Java NIO 还有个 MappedByteBuffer，用于表示内存映射文件，我也不打算在概述中说明。 SelectorSelector允许单线程处理多个 Channel。如果你的应用打开了多个连接（通道），但每个连接的流量都很低，使用Selector就会很方便。例如，在一个聊天服务器中。 这是在一个单线程中使用一个Selector处理3个Channel的图示： 要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新连接进来，数据接收等。 ChannelChannel与流的区别Java NIO的通道类似流，但又有些不同： 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的 通道可以异步地读写 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入 正如上面所说，从通道读取数据到缓冲区，从缓冲区写入数据到通道。如下图所示： Channel的实现这些是Java NIO中最重要的通道的实现： FileChannel DatagramChannel SocketChannel ServerSocketChannel FileChannel 从文件中读写数据。 DatagramChannel 能通过UDP读写网络中的数据。 SocketChannel 能通过TCP读写网络中的数据。 ServerSocketChannel可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 基本的 Channel 示例下面是一个使用FileChannel读取数据到Buffer中的示例： //文件通道 String path = APP.class.getClassLoader().getResource(&quot;nio-data.txt&quot;).getPath(); RandomAccessFile aFile = new RandomAccessFile(path, &quot;rw&quot;); FileChannel inChannel = aFile.getChannel(); //缓冲区 ByteBuffer buf = ByteBuffer.allocate(48); //通道向缓冲区写数据，每次循环得到ByteBuffer -&gt; byte[] -&gt; ByteArrayOutputStream把每段byte[]拼接起来 -&gt;byte[] int bytesRead = -1; ByteArrayOutputStream result = new ByteArrayOutputStream(); while ((bytesRead = inChannel.read(buf)) != -1) { //注意 buf.flip() 的调用，首先读取数据到Buffer，然后反转Buffer,接着再从Buffer中读取数据（指针移到开始位置） buf.flip(); result.write(buf.array(),0, bytesRead); //一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入 buf.clear(); } //输出结果 System.out.println(result.toString()); //关闭资源 result.close(); inChannel.close(); aFile.close(); BufferJava NIO中的Buffer用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。 Buffer的基本用法使用Buffer读写数据一般遵循以下四个步骤： 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到buffer的所有数据。(不能反过来) 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。 下面是一个使用Buffer的例子： 1234567891011121314RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel();//create buffer with capacity of 48 bytesByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf); //read into buffer.while (bytesRead != -1) &#123; buf.flip(); //make buffer ready for read while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); // read 1 byte at a time &#125; buf.clear(); //make buffer ready for writing bytesRead = inChannel.read(buf);&#125;aFile.close(); Buffer的capacity,position和limit缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。 为了理解Buffer的工作原理，需要熟悉它的三个属性： capacity position limit position和limit的含义取决于Buffer处在读模式还是写模式。不管Buffer处在什么模式，capacity的含义总是一样的。 这里有一个关于capacity，position和limit在读写模式中的说明，详细的解释在插图后面。 capacity 作为一个内存块，Buffer有一个固定的大小值，也叫”capacity”。你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。 position 当你写数据到Buffer中时，position表示当前的位置。初始的position值为0。当一个byte、long等数据写到Buffer后，position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1. 当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0。 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。 limit 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。 当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position） Buffer的类型Java NIO 有以下Buffer类型 ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 如你所见，这些Buffer类型代表了不同的数据类型。换句话说，就是可以通过char，short，int，long，float 或 double类型来操作缓冲区中的字节。 MappedByteBuffer 有些特别，在涉及它的专门章节中再讲。 Buffer的分配要想获得一个Buffer对象首先要进行分配。 每一个Buffer类都有一个allocate方法 12//分配48字节capacity的ByteBuffer的ByteBuffer buf = ByteBuffer.allocate(48); 12//分配一个可存储1024个字符的CharBufferCharBuffer buf = CharBuffer.allocate(1024); 向Buffer中写数据写数据到Buffer有两种方式： 从Channel写到Buffer。 通过Buffer的put()方法写到Buffer里。 从Channel写到Buffer的例子 12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf); //read into buffer. 通过put方法写Buffer的例子： 1buf.put(127); put方法有很多版本，允许你以不同的方式把数据写入到Buffer中。例如，写到一个指定的位置，或者把一个字节数组写入到Buffer。 更多Buffer实现的细节参考JavaDoc。 flip()方法flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。 换句话说，position现在用于标记读的位置，limit表示之前写进了多少个byte、char等 —— 现在能读取多少个byte、char等。 从Buffer中读取数据从Buffer中读取数据有两种方式： 从Buffer读取数据到Channel。 使用get()方法从Buffer中读取数据。 从Buffer读取数据到Channel的例子： 12//read from buffer into channel.int bytesWritten = inChannel.write(buf); 使用get()方法从Buffer中读取数据的例子 1byte aByte = buf.get(); get方法有很多版本，允许你以不同的方式从Buffer中读取数据。例如，从指定position读取，或者从Buffer中读取数据到字节数组。更多Buffer实现的细节参考JavaDoc。 rewind()方法Buffer.rewind()将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等）。 clear()与compact()方法一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。 如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer 被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。 如果Buffer中有一些未读的数据，调用clear()方法，数据将”被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。 如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。 compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。 mark()与reset()方法通过调用Buffer.mark()方法，可以标记Buffer中的一个特定position。之后可以通过调用Buffer.reset()方法恢复到这个position。(注意，使用flip方法会重置mark为-1)例如： 123buffer.mark();//call buffer.get() a couple of times, e.g. during parsing.buffer.reset(); //set position back to mark. equals()与compareTo()方法可以使用equals()和compareTo()方法两个Buffer。 equals() 当满足下列条件时，表示两个Buffer相等： 有相同的类型（byte、char、int等）。 Buffer中剩余的byte、char等的个数相等。 Buffer中所有剩余的byte、char等都相同。 如你所见，equals只是比较Buffer的一部分，不是每一个在它里面的元素都比较。实际上，它只比较Buffer中的剩余元素。 compareTo()方法 compareTo()方法比较两个Buffer的剩余元素(byte、char等)， 如果满足下列条件，则认为一个Buffer”小于”另一个Buffer： 第一个不相等的元素小于另一个Buffer中对应的元素 。 所有元素都相等，但第一个Buffer比另一个先耗尽(第一个Buffer的元素个数比另一个少)。（译注：剩余元素是从 position到limit之间的元素） Scatter/GatherJava NIO开始支持scatter/gather，scatter/gather用于描述从Channel（译者注：Channel在中文经常翻译为通道）中读取或者写入到Buffer中的操作。 分散（scatter）从Channel中读取是指在读操作时将读取的数据写入多个buffer中。因此，Channel将从Channel中读取的数据“分散（scatter）”到多个Buffer中。 聚集（gather）写入Channel是指在写操作时将多个buffer的数据写入同一个Channel，因此，Channel 将多个Buffer中的数据“聚集（gather）”后发送到Channel。 scatter / gather经常用于需要将传输的数据分开处理的场合，例如传输一个由消息头和消息体组成的消息，你可能会将消息体和消息头分散到不同的buffer中，这样你可以方便的处理消息头和消息体。 Scattering ReadsScattering Reads是指数据从一个channel读取到多个buffer中。如下图描述： 1234ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.read(bufferArray); 注意buffer首先被插入到数组，然后再将数组作为channel.read() 的输入参数。read()方法按照buffer在数组中的顺序将从channel中读取的数据写入到buffer，当一个buffer被写满后，channel紧接着向另一个buffer中写。 Scattering Reads在移动下一个buffer前，必须填满当前的buffer，这也意味着它不适用于动态消息(译者注：消息大小不固定)。换句话说，如果存在消息头和消息体，消息头必须完成填充（例如 128byte），Scattering Reads才能正常工作。 Gathering WritesGathering Writes是指数据从多个buffer写入到同一个channel。如下图描述： 12345ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);//write data into buffersByteBuffer[] bufferArray = &#123; header, body &#125;;channel.write(bufferArray); buffers数组是write()方法的入参，write()方法会按照buffer在数组中的顺序，将数据写入到channel，注意只有position和limit之间的数据才会被写入。因此，如果一个buffer的容量为128byte，但是仅仅包含58byte的数据，那么这58byte的数据将被写入到channel中。因此与Scattering Reads相反，Gathering Writes能较好的处理动态消息。 通道之间的数据传输在Java NIO中，如果两个通道中有一个是FileChannel，那你可以直接将数据从一个channel（译者注：channel中文常译作通道）传输到另外一个channel。 transferFrom()FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中（译者注：这个方法在JDK文档中的解释为将字节从给定的可读取字节通道传输到此通道的文件中）。下面是一个简单的例子： String fromFilePath = TransferToDemo.class.getClassLoader().getResource(&quot;fromFile.txt&quot;).getPath(); String toFilePath = TransferToDemo.class.getClassLoader().getResource(&quot;toFile.txt&quot;).getPath(); RandomAccessFile fromFile = new RandomAccessFile(fromFilePath, &quot;rw&quot;); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(toFilePath, &quot;rw&quot;); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); toChannel.transferFrom(fromChannel, position, count); 方法的输入参数position表示从position处开始向目标文件写入数据，count表示最多传输的字节数。如果源通道的剩余空间小于 count 个字节，则所传输的字节数要小于请求的字节数。此外要注意，在SoketChannel的实现中，SocketChannel只会传输此刻准备好的数据（可能不足count字节）。因此，SocketChannel可能不会将请求的所有数据(count个字节)全部传输到FileChannel中。 transferTo()transferTo()方法将数据从FileChannel传输到其他的channel中。下面是一个简单的例子： String fromFilePath = TransferToDemo.class.getClassLoader().getResource(&quot;fromFile.txt&quot;).getPath(); String toFilePath = TransferToDemo.class.getClassLoader().getResource(&quot;toFile.txt&quot;).getPath(); //打开通道 RandomAccessFile fromFile = new RandomAccessFile(fromFilePath, &quot;rw&quot;); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(toFilePath, &quot;rw&quot;); FileChannel toChannel = toFile.getChannel(); //传输数据 long position = 0; long count = fromChannel.size(); fromChannel.transferTo(position, count, toChannel); 是不是发现这个例子和前面那个例子特别相似？除了调用方法的FileChannel对象不一样外，其他的都一样。上面所说的关于SocketChannel的问题在transferTo()方法中同样存在。SocketChannel会一直传输数据直到目标buffer被填满。 SelectorSelector（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 为什么使用Selector?仅用单个线程来处理多个Channels的好处是，只需要更少的线程来处理通道。事实上，可以只用一个线程处理所有的通道。对于操作系统来说，线程之间上下文切换的开销很大，而且每个线程都要占用系统的一些资源（如内存）。因此，使用的线程越少越好。 但是，需要记住，现代的操作系统和CPU在多任务方面表现的越来越好，所以多线程的开销随着时间的推移，变得越来越小了。实际上，如果一个CPU有多个内核，不使用多任务可能是在浪费CPU能力。不管怎么说，关于那种设计的讨论应该放在另一篇不同的文章中。在这里，只要知道使用Selector能够处理多个通道就足够了。 下面是单线程使用一个Selector处理3个channel的示例图： Selector的创建]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同步异步、阻塞非阻塞]]></title>
    <url>%2F2017%2F03%2F06%2F%5BNIO%5D%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5%E3%80%81%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E%2F</url>
    <content type="text"><![CDATA[同步、异步区别/阻塞、非阻塞区别老张爱喝茶，废话不说，煮开水。 出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。 1、老张把水壶放到火上，立等水开。（同步阻塞） 老张觉得自己有点傻 2、老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞） 老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。 3、老张把响水壶放到火上，立等水开。（异步阻塞） 老张觉得这样傻等意义不大 4、老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞） 老张觉得自己聪明了。 所谓同步异步，只是对于水壶而言。普通水壶，同步；响水壶，异步。虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。 所谓阻塞非阻塞，仅仅对于老张而言。立等的老张，阻塞；看电视的老张，非阻塞。情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。 Java中的NIO是同步非阻塞，即程序可以做别的事情，但时不时去看是否有IO操作]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM重点知识总结]]></title>
    <url>%2F2017%2F03%2F03%2F%5BJVM%5DJVM%E9%87%8D%E7%82%B9%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[思维导图 Java代码的执行讨论三个问题，JDK如何将代码编译为class文件、如何装载class文件、如何执行class 编译编译器将源码编译成class文件，使用 javac 工具进行编译 编译过程：1、分析和输入到符号表。Parse过程将代码字符串转变成token序列，再由token序列生成抽象语法树；Enter过程将符号输入到符号表2、注解处理3、语法分析和生成class文件 12javac -g Foo.java 生成所有调试信息javap -c -s -l -verbose Foo来查看编译后的class文件 装载class文件由类加载器（ClassLoader）加载进内存，并形成Class对象，之后就可以对Class对象进行实例化并调用 Java类加载机制的特点：1、类加载机制可在运行时动态加载外部的类、远程网络下载过来的class文件2、可以通过JVM的类加载机制来实现类隔离的效果 类加载过程步骤：装载、链接、初始化 JVM通过类的全限定名和类加载器实例来标识一个被加载的类，类的命名方式如下： 对于接口或非数组型的类，其名称即为类名，由类所在的 ClassLoader 负责加载 数组型的类，其名称为[ + 基本类型或 L+引用类型; 123456789//接口或非数组性的类String a = &quot;123&quot;;System.out.println(a.getClass().getName());//java.lang.String//数组型的类int[] a = new int[10];System.out.println(a.getClass().getName());//[IObject[] a = new Object[10];System.out.println(a.getClass().getName());//[Ljava.lang.Object; JVM中类加载器的树状层次结构： 引导类加载器（bootstrap class loader）：它用来加载 Java 的核心库(jre/lib/rt.jar)，是用原生C++代码来实现的，并不继承自java.lang.ClassLoader。加载扩展类和应用程序类加载器，并指定他们的父类加载器，在java中获取不到。 扩展类加载器（extensions class loader）：它用来加载 Java 的扩展库(jre/ext/*.jar)。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。 对应Sun JDK中的ExtClassLoader 系统类加载器（system class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。对应Sun JDK中的AppClassLoader 自定义类加载器（custom class loader）：除了系统提供的类加载器以外，开发人员可以通过继承 java.lang.ClassLoader类的方式实现自己的类加载器。自定义的ClassLoader可用于加载非Classpath中的jar（如网络上加载的jar或二进制），还可以在加载之前对class文件做一些动作，比如解密等 类加载的双亲委派机制： 某个特定的类加载器在接到加载类的请求时，首先将加载任务委托交给父类加载器，父类加载器又将加载任务向上委托，直到最父类加载器，如果最父类加载器可以完成类加载任务，就成功返回，如果不行就向下传递委托任务，由其子类加载器进行加载。如果该类加载器的父类不能完成加载，则由该类进行加载 双亲委派机制的好处： 保证Java核心库的安全性。例如：如果用户自己写了一个java.lang.String类就会因为双亲委派机制交由Bootstrap ClassLoader加载，但Bootstrap已经加载过 java.lang.String 类，导致加载不能被加载，不会破坏原生的String类的加载） 代理模式： 与双亲委派机制相反，代理模式是先自己尝试加载，如果无法加载则向上传递，这样会造成多个不同的Classloader都加载了某Class，并且这些Class的实例对象都不相同。 由于JVM采用类名+ClassLoader实例作为Class加载的判断，JVM会保证同一个ClassLoader实例对象只能加载一次同样名称的Class，因此可以借此实现类隔离的需求。Tomcat就是代理模式 执行class的执行有解释执行和编译为机器码执行两种方式，其中编译为机器码又分为client和server两种模式 字节码解释执行：字节码是一种中间代码的方式，要由JVM在运行时对其进行解释并执行，这种方式称为字节码解释执行方式 JVM 是基于栈的体系结构来执行 class 字节码的。线程创建后，都会产生程序计数器（PC）和栈（Stack），程序计数器存放下一条要执行的指令在方法内的偏移量，栈中存放一个个栈帧，每个栈帧对应着每个方法的每次调用，而栈帧又是有局部变量区和操作数栈两部分组成，局部变量区用于存放方法中的局部变量和参数，操作数栈中用于存放方法执行过程中产生的中间结果。栈的结构如下图所示： 对于方法的指令解释执行，执行方式为冯诺依曼体系中的FDX循环方式，即获取下一条指令，解码并分派，然后执行 编译执行：解释执行的效率较低，为提升代码的执行性能，Sun JDK提供了将字节码编译为机器码的支持，编译在运行时进行，通常称为JIT编译器。 Sun JDK在执行过程中，对执行频率高的代码进行编译，对执行不频繁额代码则继续采用解释的方式 编译分为Client compiler和Server compiler。C1较轻量级，只做少量性能开销高的优化，占用内存少，适合桌面交互式应用；C2较为重量级，采用大量的传统编译优化技巧，占用内存相对多一点，适合服务端的应用 反射执行： 反射可以动态调用某对象实例中对应的方法、访问对象的属性，可以灵活得实现对象的调用 要实现动态的调用，最直接的方式就是动态得生成字节码，并加载到JVM中执行，Sun采用的即为这种方式 采用反射的方式，提升了代码编写的灵活性，但比直接编译成字节码方式，调用复杂的多，因此性能比直接执行的慢一点 内存管理主要内容是JVM如何进行内存的分配和回收 JVM自动管理内存的分配与回收，大大降低了开发人员编程序的难度，但副作用是可能在不知不觉中浪费了很多内存，导致JVM花费很多时间进行内存的回收；另外还可能由于不清楚内存的分配和回收机制，造成内存泄漏 JVM内存空间 JVM的内存结构分为以下部分： 程序计数器：每个线程拥有一个PC寄存器，记录了下一条指令在方法中的偏移 虚拟机栈：每个线程私有，栈中存放了栈帧，每次方法调用都会产生栈帧，栈帧主要分为局部变量区和操作数栈两部分；通过-Xss指定其大小 本地方法栈：用于支持native方法的执行，存储了每个native方法调用的状态，在Sun JDK的实现中本地方法栈和JVM方法栈是同一个 堆：用于存储对象实例及数组值，所有new创建出来的对象的内存都在此分配；通过-Xms和-Xmx来设定最小值和最大值，为避免频繁调整Heap的大小，通常将两个值设置成一样 方法区：存放了要加载类的信息（类的版本，属性、方法，接口信息）、即时编译器编译后的代码、静态变量、常量。运行时常量位于方法区，用于存放编译时的字面值和符号引用；在Sun JDK中这块区域对应Permanet Generation，又称为持久代，可通过-XX:PermSize及-XX:MaxPermSize来指定最小值和最大值 其中，程序计数器、虚拟机栈和本地方法栈是线程隔离的；方法区、堆是所有线程共享的 内存的各个区域详细解释———————————————————————————————————————— 堆的分代： 为了让内存回收更加高效，对堆采用了分代管理的方式 新生代：大多数情况下Java程序中新建的对象都从新生代分配，新生代由Eden Space和两块相同大小的Survivor Space（又称S0和S1或From和To）构成 老年代：1、用于存放新生代中经过多次垃圾回收仍然存活的对象；2、大对象在老年代直接分配内存；3、动态对象年龄判断，如果Survivor相同年龄所有对象大小大于Survivor空间大小的一半，年龄大于等于该年龄的对象直接进入老年代；老年代占用的内存大小为-Xmx减去-Xmn的值 虚拟机栈： 栈中存放了栈帧，每个方法调用都会产生栈帧。栈帧主要分为局部变量区和操作数栈两部分 局部变量存放方法中的局部变量和参数 操作数栈用于存放方法执行过程中产生的中间结果，计算完成后将数据放入局部变量区 内存分配策略★★★★★ 对象优先在Eden分配 大对象直接进入老年代（需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串及数组） 长期存活的对象将进入老年代 动态年龄判断：如果在Survivor区中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代 空间分配担保:在发生Minor GC前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象的总和，若大于这Minor GC是可以确保安全的。若不大于，则虚拟机检查HandlePromotionFailure的值，若允许担保失败继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小(经验值)，若大于，则尝试进行一次Minor GC，虽然是有风险的；若小于或HandlePromotionFailure不允许担保失败则进行一次Full GC 新生代内存分配： 1、Java对象所占用的内存主要从堆上进行分配，堆是所有线程共享的，因此在堆上分配内存时需要加锁，这导致了创建对象开销比较大； 2、Sun JDK为了提升内存分配的效率，会为每个新创建的线程在新生代的Eden Space分配一块独立的空间，这块空间称为TLAB（ThreadLocal Allocation Buffer，线程局部分配缓存） 在TLAB上分配内存时不需要加锁，因此JVM在给线程中的对象分配内存时会尽量在TLAB上分配，如果对象过大或TLAB空间已用完，则仍然在堆上进行分配，通常多个小的对象比大的对象更加高效 3、除了从堆上分配及从TLAB上分配外，还要一种是基于逃逸分析直接在栈上进行分配的方式 逃逸分析优化JVM原理 我们知道Java对象是在堆里分配的，在调用栈中，只保存了对象的指针。 当对象不再使用后，需要依靠GC来遍历引用树并回收内存，如果对象数量较多，将给GC带来较大压力，也间接影响了应用的性能。减少临时对象在堆内分配的数量，无疑是最有效的优化方法。 怎么减少临时对象在堆内的分配数量呢？不可能不实例化对象吧！ 场景介绍 其实，在Java应用里普遍存在一种场景。一般是在方法体内，声明了一个局部变量，且该变量在方法执行生命周期内未发生逃逸（在方法体内，未将引用暴露给外面）。 按照JVM内存分配机制，首先会在堆里创建变量类的实例，然后将返回的对象指针压入调用栈，继续执行。 这是优化前，JVM的处理方式。 逃逸分析优化 - 栈上分配 优化原理：分析找到未逃逸的变量，将变量类的实例化内存直接在栈里分配(无需进入堆)，分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。 这是优化后的处理方式，对比可以看出，主要区别在栈空间直接作为临时对象的存储介质。从而减少了临时对象在堆内的分配数量。 逃逸分析的原理很简单，但JVM在应用过程中，还是有诸多考虑。 比如，逃逸分析不能在静态编译时进行，必须在JIT里完成。原因是，与Java的动态性有冲突。因为你可以在运行时，通过动态代理改变一个类的行为，此时，逃逸分析是无法得知类已经变化了。 逃逸分析—-在计算机语言编译器语言优化管理中，分析指针动态范围的方法称之为逃逸分析（通俗点讲，当一个对象的指针被多个方法或线程引用时），我们称这个指针发生了逃逸 在这个例子中，一共举了3种常见的指针逃逸场景。分别是 全局变量赋值，方法返回值，实例引用传递。对于每一个方法中都创建了new了一个局部变量，但都将该变量暴露给外部引用 1234567891011121314151617181920212223public class G &#123; public static B b; public void globalVariablePointerEscape()&#123;//给全局变量赋值，发生逃逸 b=new B(); &#125; public B methodPointerEscape()&#123;//方法返回值，发生逃逸 return new B(); &#125; public void instancePassPointerEscape()&#123; methodPointerEscape().printClassName(this);//实例引用发生逃逸 &#125; &#125;class B&#123; public void printClassName(G g)&#123; System.out.println(g.getClass().getName()); &#125;&#125; 内存回收如何判断对象是否该回收： 引用计数算法：采用分散式的管理方式，每个对象都有一个计数器，当计数器为零时，说明此对象已经不再被使用，可被回收；每次对象赋值进行引用计数器的增减。但对循环引用的场景没办法实现回收，例如下图对象A释放了B、C的引用，但B和C互相引用，也无法回收BC，对于Java这种有复杂引用关系的语言而言，引用计数器不是非常合适 可达性分析算法★★★ 采用集中式的管理方式，全局记录数据的引用状态。基于一定条件的触发（定时、空间不足），执行时需要从根集合扫描对象的引用关系 在主流的商用程序语言（Java、C#，甚至包括前面提到的古老的Lisp）的主流实现中，都是称通过可达性分析（Reachability Analysis）来判定对象是否存活的。这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。如图3-1所示，对象object 5、object 6、object 7虽然互相有关联，但是它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象。 在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈中JNI（即一般说的Native方法）引用的对象 方法区中类静态属性引用的对象、常量引用的对象 垃圾收集算法： 复制：从根集合中扫描出存活的对象，并将存活的对象复制到一块新的完全未使用的空间中。回收的空间中存活对象较少时复制算法会比较高效，但需要增加一块新的空间及进行对象的移动 标记-清除算法：从根集合中开始扫描，对存活的对象进行标记，标记完毕后对未标记的对象进行回收。缺点是会造成内存碎片 标记-整理：从根集合中开始扫描，对存活的对象进行标记，在回收不存活对象后，会将所有存活的对象都往左端空闲的空间进行移动，并更新引用对象的指针 分代收集算法 把 Java 堆分为新生代和老年代 新生代对象的生命周期短，采用复制算法，垃圾收集时将Eden和Survivor中存活的对象一次性复制到另一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。只需要付出少量存活对象的复制成本就可以完成收集，当Survivor对象不够用时，需要老年代进行分配担保 老年代对象存活率高，没有额外的空间对它进行分配担保，必须使用“标记-清理”或“标记-整理”算法 对象引用关系：（记住弱引用和虚引用的区别） 强引用：new的方式，主动释放才会被GC 弱引用：JVM内存不足时会被回收，适合做缓存 虚引用：强引用释放后，GC时会被自动释放 垃圾收集器 上图中共有HotSpot 1.6中共有7种垃圾回收器，如果两个垃圾回收器之间有连线，说明二者可以搭配使用。 CMS可以搭配 Serial和 ParNew Serial Old 搭配 Serial、ParNew、Parallel Scavenge Parallel Old 搭配 Parallel Scavenge Serial收集器(新生代) / Serial Old收集器（老年代） Serial垃圾收集器是一个单线程的收集器。它在进行垃圾收集时，必须暂停其他工作线程，直到它收集结束 Serial收集器在新生代采用复制算法，暂停所有用户线程；在老年代采用标记-整理算法，暂停所有用户线程 Serial收集器简单高效，适用于客户端桌面程序，稍微有点卡顿可以接受 ParNew收集器 ParNew收集器其实就是Serial收集器的多线程版本，多个垃圾回收线程并行进行，但此时垃圾收集时必须暂停用户线程 新生代采用复制算法，暂停所有用户线程 ParNew是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中一个重要原因是，除Serial收集器外，只有它能与CMS收集器配合工作。CMS是HotSpot虚拟机中第一款真正意义上的并发收集器 Parallel Scavenge收集器(新生代) / Parallel Old收集器(老年代) Parallel Scavenge与ParNew很类似，是一个使用复制算法的新生代的并行多线程收集器，老年代采用标记-整理算法,垃圾回收时暂停用户线程 他们之间最大的区别是关注点不一样，ParNew等收集器的关注点在于尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是达到一个可控制的吞吐量（吞吐量指用于运行用户代码的CPU时间与总CPU时间的比值） 垃圾收集器中的并发与并行 并行（Parallel）：指多头垃圾收集器线程并行工作，但此时用户线程仍处于等待状态。 并发（Concurrent）：指用户线程与回收器线程同时工作。 CMS收集器 CMS（Concurrent Mark Sweep）收集器是基于”标记 - 清除“算法的并发收集器，其设计目标为获取最短回收停顿时间 整个过程分为四个步骤，包括：初始标记、并发标记、重新标记、并发清除 初始标记和重新标记仍需暂停所有用户线程，即Stop the World，但初始标记只是标记GC Roots能直接关联的对象，而重新标记则只是为了修正并发标记期间，因用户程序继续运行而产生变动那一部分对象，这个阶段的停顿时间比前面介绍的Stop the World的时间要短得多。整个收集过程中耗时最久的并发标记和并发清除则和用户线程一起工作，所以总地来讲，CMS中GC线程是和用户线程一起并发执行的。下图可以比较清楚地解释这个过程： CMS是一款突破性的收集器，它极大地缩短了用户线程停顿时间，可以认为其实现了并发垃圾回收，但金无足赤，人无完人，CMS还是具有这几个缺陷： 对CPU资源非常敏感。几乎所有的并行/并发系统都对CPU敏感。虽然它很少导致用户卡顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量变低。 无法处理浮动垃圾（Floating Garbage），可能出现”Concurrent Mode Failure”失败而导致另一次Full GC的产生。由于CMS并发清理阶段用户线程还在同时执行，因此此时这些线程产生的这部分垃圾CMS无法处理，只好留在下一次GC时再清理，这一部分垃圾就被称为”浮动垃圾”。因为在垃圾收集阶段用户线程还在运行，因此CMS需要预留足够的空间供这些线程使用，而不能向其他收集器那样hex等老年代几乎被完全充满时再进行回收。默认CMS收集器在老年代使用68%之后就被激活。 这个缺点来自于CMS所采用的”标记 - 清除”算法。这种方式容易产生大量碎片，当碎片过多时，容易出现老年代空间有很大剩余，但找不到连续空间进行分配给大对象，从而不得不提前触发一次GC。 G1 收集器 G1（Garbage First）收集器是当前收集器技术发展的最前沿成果，它与CMS相比会有两个显著改进： 采用”标记 - 整理“算法，避免产生碎片 可以精确地控制卡顿。这是通过让使用指定一个参数来控制在一个长度为M的时间片内垃圾回收的时间N。 G1之所以可以在基本不牺牲吞吐量的前提下完成垃圾回收，是因为它能够尽量避免全区域的垃圾回收。之前的收集器是进行收集的范围是整个新生代或老年代，而G1将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域，并且跟踪这些区域的堆积成都，在后台维护一个优先列表，每次根据优先级从列表中挑选区域进行收集。 常见面试题从编写源代码到程序运行的过程 第一步(编译)：创建完源文件之后，使用javac命令，程序会先被编译为.class文件 第二步（运行)：java类运行的过程大概可分为两个过程：1、类的加载 2、类的执行。 需要说明的是：JVM主要在程序第一次主动使用类的时候，才会去加载该类。也就是说，JVM并不是在一开始就把一个程序就所有的类都加载到内存中，而是到不得不用的时候才把它加载进来，而且只加载一次。 1、（java命令）在编译好java程序得到MainApp.class文件后，在命令行上敲java AppMain。系统就会启动一个jvm进程，jvm进程从classpath路径中找到一个名为AppMain.class的二进制文件，将 MainApp的类信息加载到运行时数据区的方法区内，这个过程叫做MainApp类的加载，然后JVM找到AppMain的主函数入口，开始执行main函数 2、（类加载器）执行过程中，会创建对象。JVM会首先从方法区加载类信息和相关常量，class加载完毕之后,在堆上为对象分配内存，然后调用初始化实例，当然这时候实例保持指向class类型信息，这个信息保存在方法区中。 3、（执行引擎）调用实例方法时，会根据引用找到对象信息，进而可定位对应的class类型信息，和方法表。 4、（执行引擎）执行方法时，在虚拟机栈中进行，分配栈帧，随着入栈出栈，完成方法调用操作。 执行引擎 运行Java的每一个线程都是一个独立的虚拟机执行引擎的实例。从线程生命周期的开始到结束，他要么在执行字节码，要么在执行本地方法。一个线程可能通过解释或者使用芯片级指令直接执行字节码，或者间接通过JIT执行编译过的本地代码。我们上文讲到的main函数，也就是执行引擎的操作入口。 对象的创建1、检查 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程 2、分配内存 接下来将为新生对象分配内存，为对象分配内存空间的任务等同于把一块确定的大小的内存从Java堆中划分出来。 假设Java堆中内存是绝对规整的，所有用过的内存放在一遍，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针指向空闲空间那边挪动一段与对象大小相等的距离，这个分配方式叫做”指针碰撞” 如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式成为”空闲列表” 选择那种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 3、Init 执行new指令之后会接着执行Init方法，进行初始化，这样一个对象才算产生出来 垃圾回收（GC 在什么时候，对什么东西，做了什么事情) 在什么时候，即什么时候触发垃圾回收 首先需要知道，GC又分为 minor GC 和 Full GC (也称为 Major GC )。Java 堆内存分为新生代和老年代，新生代中又分为1个 Eden 区域和两个 Survivor 区域。 那么对于 Minor GC 的触发条件：大多数情况下，直接在 Eden 区中进行分配。如果 Eden区域没有足够的空间，那么就会发起一次 Minor GC；对于 Full GC（Major GC）的触发条件：1、如果老年代没有足够空间的话（在新生代多次清理未被清理的晋升到老年代或直接在老年代分配的大对象，大数组），2、持久带被写满 3、System.gc()被显示调用 4、上一次GC之后堆分配策略动态变化，那么就会进行一次 Full GC。 Ps：上面所说的只是一般情况下，实际上，需要考虑一个空间分配担保的问题： 在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。如果大于则进行Minor GC，如果小于则看HandlePromotionFailure设置是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于则尝试Minor GC（如果尝试失败也会触发Full GC），如果小于后不允许担保失败，则进行Full GC。 但是，具体到什么时刻执行，这个是由系统来进行决定，是无法预测的。 对什么东西，什么对象判定为需要垃圾回收：主要根据可达性分析算法，如果一个对象不可达，那么就是可以回收的；如果一个对象可达，那么这个对象就不可以回收。对于可达性分析算法，它是通过一系列称为”GC Roots” 的对象作为起始点，当一个对象到 GC Roots 没有任何引用链相接的时候，那么这个对象就是不可达，就可以被回收。如下图: 根集合：虚拟机栈上引用的对象、本地方法引用的对象、静态变量及常量 做什么事情 主要做了清理对象，整理内存的工作。Java堆分为新生代和老年代，采用了不同的回收方式。例如新生代采用了复制算法，老年代采用了标记整理法。在新生代中，分为一个Eden 区域和两个Survivor区域，真正使用的是一个Eden区域和一个Survivor区域，GC的时候，会把存活的对象放入到另外一个Survivor区域中，然后再把这个Eden区域和Survivor区域清除。那么对于老年代，采用的是标记整理法，首先标记出存活的对象，然后再移动到一端。这样也有利于减少内存碎片。 接着继续问你为什么要在这种时候对象才会被GC？ 接着继续问你GC策略都有哪些分类？ 你如果说出来了，继续问你这些策略分别都有什么优劣势？都适用于什么场景？ 你继续说出来了以后，给你举个实际的场景，让你选择一个GC策略？ 你如果选出来了，继续问你，为什么要选择这个策略？下面是关于类加载机制的简单连环炮。首先肯定是先问你Java的类加载器都有哪些？ 回答了这些以后，可能会问你每个类加载器都加载哪些类？ 说完以后，可能会问你这些类加载之间的父子关系是怎样的？ 你在回答的时候可能会提到双亲委派模型，那么可以继续问你什么是双亲委派模型？ 你解释完了以后，可能会继续问你，为什么Java的类加载器要使用双亲委派模型？ 你回答完以后，可能会继续问你如何自定义自己的类加载器，自己的类加载器和Java自带的类加载器关系如何处理？再来一个关于内存的连环炮。首先肯定就是问你内存分为哪几部分，这些部分分别都存储哪些数据？ 然后继续问你一个对象从创建到销毁都是怎么在这些部分里存活和转移的？ 接着可能会问你，内存的哪些部分会参与GC的回收？ 完事以后，可能还会问你Java的内存模型是怎么设计的？ 你回答了以后，还会继续问你为什么要这么设计？ 问完以后，还可能会让你结合内存模型的设计谈谈validate关键字的作用？ 你在谈的时候，肯定会提到可见性，那么接着可见性这三个字，还可以继续问你并发的内容。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中关于父子类之间this关键字的一个问题]]></title>
    <url>%2F2017%2F03%2F02%2F%5BJava%5DJava%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%88%B6%E5%AD%90%E7%B1%BB%E4%B9%8B%E9%97%B4this%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[父类方法中使用this，那么这个this指的是谁？http://blog.csdn.net/sinat_31311947/article/details/50619467 java中关于父子类之间this关键字的一个问题https://my.oschina.net/mlongbo/blog/90047 Parent类： 12345678public class Parent &#123; public Parent()&#123; System.out.println(this.getClass()); &#125; public void info()&#123; System.out.println(this); &#125;&#125; Child类： 12public class Child extends Parent &#123;&#125; 测试类： 123456789public class Test &#123; public static void main(String[] args) &#123; Parent p = new Parent(); p.info(); System.out.println(); Child c = new Child(); c.info(); &#125;&#125; Child类继承Parent类，在Parent类的info方法中会输出对象的内存地址。 class demo.test.Parent demo.test.Parent@544a5ab2 class demo.test.Child demo.test.Child@2e6e1408 结论： this指的是当前对象 在new子类的时候，会先调用父类的构造方法。但是只会new一个子类对象，不会new父类对象，所以在继承关系中只有子类一个对象，this也就指的是子类对象 在继承关系中，this指的是子类，或者说谁调用的方法就是指谁。多重继承也是如此。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>this</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java正则表达式(未完待续)]]></title>
    <url>%2F2017%2F03%2F01%2F%5BJava%5DJava%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F(%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD)%2F</url>
    <content type="text"><![CDATA[1、”.”、”|”、”“都是转义字符，*必须得加”\\“ 如果用&quot;.&quot;作为分隔的话，必须是如下写法：String.split(&quot;\\.&quot;)，这样才能正确的分隔开，不能用String.split(&quot;.&quot;)； 如果用&quot;|&quot;作为分隔的话，必须是如下写法：String.split(&quot;\\|&quot;)，这样才能正确的分隔开，不能用String.split(&quot;|&quot;); 2、如果在一个字符串中有多个分隔符，可以用”|”作为连字符 比如：&quot;acount=? and uu =? or n=&quot;，把三个都分隔出来，可以用String.split(&quot;and|or&quot;); 3、public String[] split(String regex，int limit)根据匹配给定的正则表达式来拆分此字符串。 此方法返回的数组包含此字符串的每个子字符串，这些子字符串由另一个匹配给定的表达式的子字符串终止或由字符串结束符来终止。数组中的子字符串按它们在此字符串中的顺序排列。如果表达式不匹配输入的任何部分，则结果数组只具有一个元素，即此字符串。 4、public string[] split(string regex) 这里的参数的名称是 regex ，也就是 regular expression （正则表达式）。这个参数并不是一个简单的分割用的字符，而是一个正则表达式，他对一些特殊的字符可能会出现你预想不到的结果，比如测试下面的代码： 正则表达式案例多关键词123456String s=&quot;utf-8#&#123;gb2312&#125;utf-8#&#123;iso8859-1&#125;gbk#&#123;zzz&#125;&quot;;//[&apos;utf-8&apos;,&apos;gbk&apos;,&apos;gb2312&apos;,&apos;iso8859-1&apos;]Pattern pattern = Pattern.compile(&quot;utf-8|gbk|gb2312|iso8859-1&quot;);Matcher m = pattern.matcher(s);while(m.find())&#123; System.out.println(m.group());&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fastjson使用指南.]]></title>
    <url>%2F2017%2F03%2F01%2F%5BJava%5DFastjson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[Fastjson API入口类是com.alibaba.fastjson.JSON，常用的序列化操作都可以在JSON类上的静态方法直接完成。 12345678public static final Object parse(String text); // 把JSON文本parse为JSONObject或者JSONArray public static final JSONObject parseObject(String text)； // 把JSON文本parse成JSONObject public static final &lt;T&gt; T parseObject(String text, Class&lt;T&gt; clazz); // 把JSON文本parse为JavaBean public static final JSONArray parseArray(String text); // 把JSON文本parse成JSONArray public static final &lt;T&gt; List&lt;T&gt; parseArray(String text, Class&lt;T&gt; clazz); //把JSON文本parse成JavaBean集合 public static final String toJSONString(Object object); // 将JavaBean序列化为JSON文本 public static final String toJSONString(Object object, boolean prettyFormat); // 将JavaBean序列化为带格式的JSON文本 public static final Object toJSON(Object javaObject); 将JavaBean转换为JSONObject或者JSONArray。 Demo 1234567891011121314//1、反序列化，JSON字符串-&gt;对象String recvObject = &quot;&#123;\&quot;name\&quot;:\&quot;qm\&quot;,\&quot;password\&quot;:\&quot;123\&quot;&#125;&quot;;String recvArray = &quot;[\&quot;qm\&quot;,\&quot;tr\&quot;,\&quot;hj\&quot;]&quot;;JSONObject jsonObject = JSON.parseObject(recvObject);JSONArray jsonArray = JSON.parseArray(recvArray); //JSONObject、JSONArray操作System.out.println(jsonObject.getString(&quot;name&quot;) + &quot; &quot; + jsonObject.getString(&quot;password&quot;));System.out.println(jsonArray.getString(0) + &quot; &quot; + jsonArray.getString(1) + &quot; &quot; + jsonArray.getString(2));//2、序列化，对象(数组，List，Map，bean等)-&gt;JSON字符串String sendObject = JSON.toJSONString(jsonObject);String sendArray = JSON.toJSONString(jsonArray); 更详细的Fastjson使用方法 http://www.cnblogs.com/Jie-Jack/p/3758046.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Fastjson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo新特性]]></title>
    <url>%2F2017%2F02%2F28%2F%5BHexo%5DHexo%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[hexo引用自定义js文件和css样式http://longhaoteng.com/2016/08/01/hexo%E5%BC%95%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89js%E6%96%87%E4%BB%B6%E5%92%8Ccss%E6%A0%B7%E5%BC%8F/ 在 Hexo 博客中跳过渲染，创建自定义网页http://www.jianshu.com/p/f89428fce8d5 hexo干货系列：（六）hexo提交搜索引擎（百度+谷歌）http://www.jianshu.com/p/619dab2d3c08 Hexo搜索https://jobbym.github.io/2017/01/16/Hexo%E9%9B%86%E6%88%90Algolia%E6%90%9C%E7%B4%A2%E6%8F%92%E4%BB%B6/]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql编码分析]]></title>
    <url>%2F2017%2F02%2F27%2F%5B%E7%BC%96%E7%A0%81%5DMysql%E7%BC%96%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[http://www.jb51.net/article/30864.htm 查看Mysql的编码设置，在命令行中输入： show variables like &quot;char%&quot;; MySQL字符集设置 character_set_server：默认的内部操作字符集 character_set_database：当前选中数据库的默认字符集 character_set_client：客户端来源数据使用的字符集 character_set_connection：连接层字符集 character_set_results：查询结果字符集 character_set_system：系统元数据(字段名等)字符集 MySQL中的字符集转换过程1、MySQL Server收到请求时将请求数据从character_set_client转换为character_set_connection； （qm解析：发送端将字符用A进行编码，Mysql接收到字节用character_set_client解码）2、进行内部操作前将请求数据从character_set_connection转换为内部操作字符集，其确定方法如下：• 使用每个数据字段的CHARACTER SET设定值；• 若上述值不存在，则使用对应数据表的DEFAULT CHARACTER SET设定值(MySQL扩展，非SQL标准)；• 若上述值不存在，则使用对应数据库的DEFAULT CHARACTER SET设定值；• 若上述值不存在，则使用character_set_server设定值。 将操作结果从内部操作字符集转换为character_set_results。 Mysql的编码转换在Tomcat中接收的 使用 useUnicode=true&amp;characterEncoding=utf-8 作用useUnicode：是否使用Unicode字符集，如果参数characterEncoding设置为gb2312或gbk，本参数值必须设置为true，默认falsecharacterEncoding：当useUnicode设置为true时，指定字符编码。比如可设置为gb2312或gbk，默认false Java 连接 Mysql 数据库1、引入mysql-connector-java &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; 2、Java连接数据库代码 //1、加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //2、获得连接 Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/mybatis?useUnicode=true&amp;characterEncoding=utf-8&quot;, &quot;root&quot;, &quot;root&quot;); //3、创建Statement String sql = &quot;select * from tb_user&quot;; PreparedStatement statement = connection.prepareStatement(sql); //4、执行sql语句 ResultSet resultSet = statement.executeQuery(); //5、处理结果集 while (resultSet.next()) { System.out.println(resultSet.getString(1) + &quot; &quot; + resultSet.getString(2)); } //6、关闭资源 if (connection != null) { connection.close(); }]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[淘宝技术这十年——分布式架构电子商务操作系统.md]]></title>
    <url>%2F2017%2F02%2F27%2F%5B%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%5D%E6%B7%98%E5%AE%9D%E6%8A%80%E6%9C%AF%E8%BF%99%E5%8D%81%E5%B9%B4%E2%80%94%E2%80%94%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[服务化本质是模块划分，每一个模块有特定的职责，这样做的好处可以做到系统解耦，方便维护 当系统大到一定程度时，系统越来越臃肿，业务的耦合性越来越高，开发效率低下，你写一段代码编译一下要半天；业务耦合大，修改一些代码影响别处的正确使用 比如可以划分为核心模块、登录模块、短信模块等基本模块，系统这么拆分的好处： 每个系统可以单独部署，业务简单，方便扩容 有大量的可重用的模块可以复用，便于维护 能够做到专人专事，让技术人员更加专注于一个领域 拆分后的系统如何通信？需要两种中间件系统，一种是实时调用的中间件（淘宝的HSP，高性能服务框架），一种是异步消息通知的中间件（淘宝的Notify） 中间件淘宝HSF框架是一个分布式的标准Service方式的RPC（远程过程调用）框架，Service的定义是基于OSGI的方式，通讯层采用TCP/IP协议 消息中间件Notify：为了保证消息一定能够通知到，把要发出的通知存放到数据库中，如果实时发送失败，再用一个时间程序来周期性得发送这些通知，系统记下消息的中间状态和时间戳，这样保证消息一定能够发出，也一定能够通知到 分布式数据访问层TDDL：让上层用户操作一个数据库一样操作多个库，TDDL主要实现了三个主要特性1、数据访问路由，将数据的读写请求发送到合适的地方2、数据复制，一次写入多点读取3、数据存储的自由扩展 Session框架Http协议是无状态的，需要通过Session来解决服务器和浏览器的保持状态 要不用客户端Cookie来解决问题，要不用服务端的集中缓存区（Tair）的Session来解决登录问题]]></content>
      <categories>
        <category>分布式架构</category>
      </categories>
      <tags>
        <tag>分布式架构</tag>
        <tag>淘宝技术这十年</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[淘宝技术这十年——存储技术的发展]]></title>
    <url>%2F2017%2F02%2F27%2F%5B%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%5D%E6%B7%98%E5%AE%9D%E6%8A%80%E6%9C%AF%E8%BF%99%E5%8D%81%E5%B9%B4%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%8F%91%E5%B1%95%2F</url>
    <content type="text"><![CDATA[开发语言决不是系统的瓶颈，业务带来的压力多在于数据和存储方面，淘宝网的数据和存储发展大致如下： 集中式架构缓存：所有数据都从数据库获取一方面速度比较慢，另一方面数据库承受不了这么大的访问量。一些被经常访问的数据直接从缓存中获取可以显著提高效率，减轻数据库的压力 读写分离：从原来的对一个数据库进行所有读写操作，拆分为一个主库和两个从库，并且读写分离，因为写操作比读操作更费时。主库只进行写操作，从库只进行读操作，主库进行写操作的同时，数据向从数据库同步 分库分表：查询速度与数据库容量成反比，采用多个数据库，对同一张表复制成多张，同时数据库路由的框架DBRoute，统一处理了数据的合并、排序、分页等操作，让程序员像使用一个数据库一样操作多个数据库里的数据 Mysql换成Oracle：选择Oracle的原因除了它容量大、稳定、安全、性能高之外，Oracle的性能和并发访问能力之所以如此强大，有一个关键性的设计——连接池，任何一个请求只需要从连接池中取得一个连接即可，用完后释放，这不需要频繁地创建和断开连接，而连接的创建和断开的开销是非常大的。Oracle从一开始运行在本机上，Nas上，到后来的小型机上，这些都能短时间提高存储容量，但Oracle、EMC、小型机都是很贵的，随着淘宝网的快速发展，钱钱终将不能解决问题，需要自主开发新的技术，一步一步地把IOE（IBM小型机、Oracle、EMC存储） 分布式架构淘宝分布式数据库TDDL：对上层来说，像查询一个数据库一样来查询数据，还要像查询一个数据库一样快；从集中式的Oracle切换到分布式的Mysql集群；用PC服务器替换小型机，小型机通过提高CPU，内存，磁盘等方式提高处理能力，价格昂贵，这种集中式架构的存储方式越来越不适应海量数据计算能力 分布式文件存储：淘宝的去IOE战略（IBM小型机、Oracle、EMC），使用适合淘宝使用的图片存储系统TFS 分布式缓存Tair：把常用的信息放在内存中，每次都从内存里取，性能会好很多。现在常用memcached、redis这种Key-Value缓存，只不过当时他们还没崭露头角]]></content>
      <categories>
        <category>分布式架构</category>
      </categories>
      <tags>
        <tag>淘宝技术这十年</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编码转换]]></title>
    <url>%2F2017%2F02%2F26%2F%5B%E7%BC%96%E7%A0%81%5DJava%E7%BC%96%E7%A0%81%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[首先要注意，字符串在java内存中总是按unicode编码 getBytes(charset)Java中个 getBytes(charset) 函数的作用是将字符串所表示的是字符按照charset编码，并以字节表示 比如”中文”，在Java内存中用unicode编码，表示为0x4E2D 0x6587 如果charset为”gbk”，则被编码为0xD6D0 0xCEC4 如果charset为”utf-8”，则被编码为0xE4B8AD 0xE69687 如果是charset为”iso-8859-1”，由于无法编码(不能存储中文)，最后返回0x3F 0x3F，即？？ 如果包含英文字幕和中文字幕，如”a中国”，看一下不同编码英文、中文所占的字节数 在Java内存中用unicode编码，每个字符都编码为两个字节，占的位置一样大，长度为3用gbk编码英文占1个字节，中文占两个字节用utf8编码英文占1个字节，中文占3个字节用iso885901编码英文占1个字节，不能存储中文 new String(charset)这是java字符串处理的另一个标准函数，和上一个函数的作用相反，将字节数组按照charset编码进行组合识别，最后转换为unicode存储。参考上述getBytes的例子，”gbk” 和”utf8”都可以得出正确的结果”4e2d 6587”，但iso8859-1最后变成了”003f 003f”（两个问号）。 因为utf8可以用来表示/编码所有字符，所以new String( str.getBytes( “utf8” ), “utf8” ) === str，即完全可逆。 String a = &quot;中文&quot;; byte[] gbk = a.getBytes(&quot;gbk&quot;); byte[] utf8 = a.getBytes(&quot;utf-8&quot;); byte[] iso8859_1 = a.getBytes(&quot;iso-8859-1&quot;); System.out.println(new String(gbk,&quot;gbk&quot;)); System.out.println(new String(utf8,&quot;utf-8&quot;)); System.out.println(new String(iso8859_1,&quot;iso-8859-1&quot;)); 输出 中文 中文 ?? 使用ISO-8859-1存储中文http://blog.chinaunix.net/uid-26808060-id-5692454.html 在以上例子中，尝试将中文字符使用iso-8859-1编码，字节序都是0xFF，再用iso-8859-1解码后会得到？？，这是因为iso-8859-1是单字节编码，不能直接存储中文 在网络传输或其它应用中常常有统一的中间件，因此需要把其它类型的数据转换为中间件的类型。如在Java Web中，浏览器将编码后的字节流发送给Tomcat，在tomcat内部编码转换，并处理后，然后发送给接收端。这时候如果采用不同的编码可能会出现未成预料的问题，如乱码 案例1： 我们用socket传输String类型的数据时，全部都统一为UTF-8编码，这样比较可以避免一个”中文乱码”的问题，这也是最推荐的解决中文乱码的方式。 //发送端，socket发送 String sendString = &quot;北京&quot;; System.out.println(&quot;发送数据:&quot; + sendString); byte[] sendBytes = sendString.getBytes(&quot;UTF-8&quot;); //接受端，socket接收 String recString = new String(sendBytes, &quot;UTF-8&quot;); System.out.println(&quot;接收数据:&quot; + recString); 案例2 但是想要发送的数据本身就是byte[]类型的。如果将其通过UTF-8编码转换为中间件String类型就会出现问题，（解码）如： 需要采用单字节的编码方式进行转换： String sendString=new String( bytes ,”UTF-8”); 改为 String sendString=new String( bytes , “ISO-8859-1” ); byte[] Mybytes=isoString.getBytes(“UTF8”); 改为 byte[] Mybytes=isoString.getBytes( “ISO-8859-1” ); 这样所需要的字节就有恢复了 //发送端 byte[] bytes = new byte[]{50, 0, -1, 28, -24}; String sendString = new String(bytes, &quot;iso-8859-1&quot;); byte[] sendBytes = sendString.getBytes(&quot;UTF8&quot;); //接收端 String recString = new String(sendBytes, &quot;UTF-8&quot;); byte[] Mybytes = recString.getBytes(&quot;iso-8859-1&quot;);//发送的时候用iso-8859-1编码，解码是反过程 sendString显示的是拉丁字符，是iso-8859-1单字节解码后的结果 避免中文乱码及乱码产生的原因★★★1、最简单避免中文乱码的方式是统一编码，推荐整个系统中采用统一的utf-8编码方式2、编码、解码的字符集不一致会出现乱码，如采用utf-8编码，但是用gbk解码，则会产生乱码，如下： String str = &quot;上海&quot;; byte[] b = str.getBytes(&quot;utf-8&quot;); String s = new String(b,&quot;gbk&quot;); System.out.println(s);//输出结果：涓婃捣 而且产生乱码不能恢复到正确的字符： 如”上”先用utf-8编码，再用gbk解码，在用gbk编码，字节序列b和gbk不同，说明由于不同编码长度不同，产生的中文乱码不可恢复 3、ISO8859-1的中文乱码 1、出现？？ String send = &quot;上海&quot;; byte[] t = send.getBytes(&quot;iso-8859-1&quot;); String recv = new String(t,&quot;iso-8859-1&quot;); 原因是正确接收到中文字符，但在存储的时候编码成iso-8859-1，此时返回的字节都是0x3F，再次用iso-8859-1（不管用什么编码，如utf-8）解码出来的时候都出现？？。一般出现？？，都是因为字符是中文，调用了byte[] t = send.getBytes(“iso-8859-1”);语句，乱码无法恢复 2、出现拉丁乱码ä¸æµ·，将接收到的字符按照iso-8859-1编码得到字节序，即为原来utf-8编码后的正确字节，再进行utf-8解码即可（gbk同理）。如果出现拉丁乱码，乱码可以恢复，先用拉丁编码，在用正确的字符集解码 String str = &quot;上海&quot;; byte[] b = str.getBytes(&quot;utf-8&quot;); System.out.println(&quot;汉字：&quot; + str + &quot;utf-8编码形式：&quot; + Arrays.toString(b)); String s = new String(b, &quot;iso8859-1&quot;); System.out.println(&quot;与之对应的iso8859-1解码形式：&quot; + s); byte[] b1 = s.getBytes(&quot;iso8859-1&quot;); System.out.println(s + &quot;与之对应的iso8859-1编码形式：&quot; + Arrays.toString(b1)); String s1 = new String(b1, &quot;utf-8&quot;); System.out.println(&quot;解析后：&quot;+ s1); 结果： 汉字：上海utf-8编码形式：[-28, -72, -118, -26, -75, -73] 与之对应的iso8859-1解码形式：ä¸æµ· ä¸æµ·与之对应的iso8859-1编码形式：[-28, -72, -118, -26, -75, -73] 解析后：上海 3、出现汉字的乱码：中文经过utf-8编码后，再进行iso-8809-1编码，最后用gbk解码。产生原因是发送端、接收端编解码方式不一致，在字节流没有差错的情况下可以恢复 //发送 String str = &quot;上海&quot;; byte[] b = str.getBytes(&quot;utf-8&quot;); System.out.println(&quot;汉字：&quot; + str + &quot;utf-8编码形式：&quot; + Arrays.toString(b)); //中间件 String s = new String(b, &quot;iso8859-1&quot;); System.out.println(&quot;与之对应的iso8859-1解码形式：&quot; + s); byte[] b1 = s.getBytes(&quot;iso8859-1&quot;); System.out.println(s + &quot;与之对应的iso8859-1编码形式：&quot; + Arrays.toString(b1)); //接收 String s1 = new String(b1, &quot;gbk&quot;); System.out.println(&quot;发送接收端编码不一致，解析错误结果：&quot;+ s1); String s2 = new String(b1, &quot;utf-8&quot;); System.out.println(&quot;发送接收端编码不一致，解析错误结果：&quot;+ s2); 结果： 汉字：上海utf-8编码形式：[-28, -72, -118, -26, -75, -73] 与之对应的iso8859-1解码形式：ä¸æµ· ä¸æµ·与之对应的iso8859-1编码形式：[-28, -72, -118, -26, -75, -73] 发送接收端编码不一致，解析错误结果：涓婃捣 发送接收端编码不一致，解析错误结果：上海 4、iso-8809-1在中间件中使用，传送中文字符，或传送字节 1、传送中文 发送的中英文字符经过中文编码后变成字节流发送到网络，中间件采用ISO-8859-1编码，接收端和发送端采用统一的编码，能够正确解码 //发送 String str = &quot;上海&quot;; byte[] b = str.getBytes(&quot;utf-8&quot;); System.out.println(&quot;发送：&quot; + str + &quot;utf-8编码形式：&quot; + Arrays.toString(b)); //中间件 String s = new String(b, &quot;iso8859-1&quot;); System.out.println(&quot;与之对应的iso8859-1解码形式：&quot; + s); byte[] b1 = s.getBytes(&quot;iso8859-1&quot;); System.out.println(s + &quot;与之对应的iso8859-1编码形式：&quot; + Arrays.toString(b1)); //接收 String s1 = new String(b1, &quot;utf-8&quot;); System.out.println(&quot;接收：&quot;+ s1); 结果： 发送：上海utf-8编码形式：[-28, -72, -118, -26, -75, -73] 与之对应的iso8859-1解码形式：ä¸æµ· ä¸æµ·与之对应的iso8859-1编码形式：[-28, -72, -118, -26, -75, -73] 接收：上海 2、传送字节 如果需要传送字节，在发送端利用iso-8859-1解码，获得字符串。问题转换为如何正确传输该字符串，此时可以将字符串用utf-8编码发送字节流，接收端用utf-8解码得到字符串。字符串正确传递后，在用iso-8859-1解码即能获得正确的字节 如果只有发送端和接收端： //发送端 byte[] bytes = new byte[]{50, 0, -1, 28, -24}; String sendString = new String(bytes, &quot;iso-8859-1&quot;); byte[] sendBytes = sendString.getBytes(&quot;UTF8&quot;); //接收端 String recString = new String(sendBytes, &quot;UTF-8&quot;); byte[] Mybytes = recString.getBytes(&quot;iso-8859-1&quot;); 如果考虑了中间件，代码如下： //发送端 byte[] bytes = new byte[]{50, 0, -1, 28, -24}; System.out.println(&quot;传送的字节：&quot; + Arrays.toString(bytes)); String send = new String(bytes, &quot;iso-8859-1&quot;);//发送所需的字节流问题转化为发送该字节流使用iso-8859-1解码后的字符串 System.out.println(&quot;传送的字节经过iso-8859-1解码：&quot; + send); byte[] send_bytes = send.getBytes(&quot;utf-8&quot;); System.out.println(&quot;字符经过utf-8编码：&quot; + Arrays.toString(send_bytes)); //中间件 String t = new String(send_bytes, &quot;iso-8859-1&quot;); System.out.println(&quot;中间件用iso-8859-1解码的字符：&quot; + t); byte[] t_bytes = t.getBytes(&quot;iso-8859-1&quot;); System.out.println(&quot;中间件用iso-8859-1编码的字节&quot; + Arrays.toString(t_bytes)); //接收端 String recv = new String(t_bytes, &quot;utf-8&quot;);//正确接收字符串 System.out.println(&quot;接收端用utf-8解码的字符：&quot; + recv); byte[] recv_bytes = recv.getBytes(&quot;iso-8859-1&quot;);//获得原先所需的字节流 System.out.println(&quot;接收端恢复编码：&quot; + Arrays.toString(recv_bytes)); 输出结果： 传送的字节：[50, 0, -1, 28, -24] 传送的字节经过iso-8859-1解码：2 ÿè 字符经过utf-8编码：[50, 0, -61, -65, 28, -61, -88] 中间件用iso-8859-1解码的字符：2 Ã¿Ã¨ 中间件用iso-8859-1编码的字节[50, 0, -61, -65, 28, -61, -88] 接收端用utf-8解码的字符：2 ÿè 接收端恢复编码：[50, 0, -1, 28, -24] 4、中间件采用iso-8859-1编码不会出现乱码，这也是许多软件都默认采用latin1作为编码的原因，如Tomcat默认是iso-8859-1编码，Mysql默认也是iso-8859-1编码 Mysql 几个参数的意义]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中文乱码]]></title>
    <url>%2F2017%2F02%2F25%2F%5BMysql%5DMysql%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[JDBC?JDBC获得数据库连接时写在URL上的?useUnicode=true&amp;characterEncoding=utf-8，作用是指定字符的编码和解码格式 例如：mysql数据库用的是gbk编码，而项目数据库用的是utf-8编码。这时候如果添加了useUnicode=true&amp;characterEncoding=UTF-8 ，那么作用有如下两个方面： 1、存数据时： 数据库在存放项目数据的时候会先用UTF-8格式将数据解码成字节码，然后再将解码后的字节码重新使用GBK编码存放到数据库中。 2、取数据时： 在从数据库中取数据的时候，数据库会先将数据库中的数据按GBK格式解码成字节码，然后再将解码后的字节码重新按UTF-8格式编码数据，最后再将数据返回给客户端。 设置数据库字符集有时候程序操作Mysql数据库时会出现 “?????” 或者是其他中文乱码，在命令行中输入： show variables like &apos;character%&apos;; 可看到如下字符： character_set_client latin1 character_set_connection latin1 character_set_database utf8 character_set_results latin1 character_set_server utf8 character_set_system utf8 解决办法是，在连接数据库之后，读取数据之前，先执行一项查询”SET NAMES UTF8” 在PHP里为 mysql_query(“SET NAMES UTF8”); 在JDBC或者Mybatis中使用查询SQL语句为 “SET NAMES UTF8” 到MySQL命令行输入”SET NAMES UTF8;”，然后执行 show variables like &apos;character%&apos;; 发现原来为latin1的那些量”character_set_client”、“character_set_connection”、“character_set_results”的值全部变为utf8了，原来是这3个变量在捣蛋。 查阅手册，上面那句等于： SET character_set_client = utf8; SET character_set_connection = utf8; SET character_set_results = utf8; 看看这3个变量的作用： 信息输入路径：client→connection→server 信息输出路径：server→connection→results 换句话说，每个路径要经过3次改变字符集编码。以出现乱码的输出为例，server里utf8的数据，传入connection转为latin1，传入results转为latin1，utf-8页面又把results转过来。如果两种字符集不兼容，比如latin1和utf8，转化过程就为不可逆的，破坏性的。 但这里要声明一点，”SET NAMES UTF8”作用只是临时的，MySQL重启后就恢复默认了。 总结：为了让你的网页能在更多的服务器上正常地显示，还是加上”SET NAMES UTF8”吧，即使你现在没有加上这句也能正常访问。 从执行命令前后可知，set names gbk只可以修改character_set_client、character_set_connection、 character_set_results的编码方式，并且这种修改是窗口级别的，只针对本窗口有效，打开另外一个窗口修改无效。也可发现数据库底层的编码方式没有改变，插入数据后还是以utf8编码方式保持。 http://blog.csdn.net/zsmj_2011/article/details/7943734]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git笔记]]></title>
    <url>%2F2017%2F02%2F17%2F%5BGit%5DGit%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[git log -p FILEPATH 单文件的改动git reset –hard commit_id 撤销摸个commit git branch 查看本地分支git branch xx 创建分支git branch -d xx 删除分支git checkout xx 切换分支git branch -a 查看远程分支 git remote -v 查看远程地址信息git push origin :branch-name 删除远程分支 ##中文乱码git显示中文被转义http://mushanshitiancai.github.io/2016/03/18/linux/git%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符编码]]></title>
    <url>%2F2017%2F02%2F15%2F%5B%E7%BC%96%E7%A0%81%5D%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[各种字符集和编码详解http://blog.csdn.net/ancky/article/details/2034809Java字符编码http://blog.csdn.net/xiongchao2011/article/details/7276834★★★十分钟搞清字符集和字符编码http://cenalulu.github.io/linux/character-encoding/ 字符（英文、中文、符号、数字等）需要在计算机内存储，必须进行编码 什么是字符集我们在计算机屏幕上看到的是实体化的文字，而在计算机存储介质中存放的实际是二进制的比特流。那么在这两者之间的转换规则就需要一个统一的标准，否则把我们的U盘插到老板的电脑上，文档就乱码了 于是为了实现转换标准，各种字符集标准就出现了。简单的说字符集就规定了某个文字对应的二进制数字存放方式（编码）和某串二进制数值代表了哪个文字（解码）的转换关系 字符编码发展历史ASCII 最早的ASCII码用7个二进制表示（0x00 - 0x7F），能表示128个字符，足够表示英语及西欧语言 iso8859-1（Latin-1） 最优秀的扩展ASCII，8位长度（一个字节，范围从0x00 - 0xFF），能表示256个字符 单字节编码，和计算机最基础的表示单位一致，在很多协议上，默认使用该编码。比如，虽然”中文”两个字不存在iso8859-1编码，以gb2312编码为例，应该是”d6d0 cec4”，一个汉字编码成两个字节，使用iso8859-1编码的时候则将它拆开为4个字节来表示：”d6 d0 ce c4”（事实上，在进行存储的时候，也是以字节为单位处理的）。而如果是UTF编码，则是6个字节”e4 b8 ad e6 96 87”，一个汉字编码成三个字节。很明显，这种表示方法还需要以另一种编码为基础。 GB码字符集，GB2312，GB12345-90，GBK字符集 双字节编码 GBK编码能够用来同时表示繁体字和简体字，而GB2312只能表示简体字，GBK是兼容gb2312编码的，是GB2312的扩展，共收录汉字21003个、符号883个 BIG5字符集 是目前台湾、香港地区普遍使用的一种繁体汉字的编码标准，为统一繁体字编码，使用2个字节表示汉字，Big5字符集共收录13,053个中文字 Unicode字符集（UCS） 各国文字、符号进行统一性编码，Unicode编码后占用的空间大小是一样的，都是两个字节 定长编码便于计算机处理（注意GB2312/GBK不是定长编码），而unicode又可以用来表示所有字符，所以在很多软件内部是使用unicode编码来处理的，比如Java UNICODE字符集有多个编码方式，分别是UTF-8，UTF-16，UTF-32和UTF-7编码。 UTF-8 unicode对于英文字母也要用两个字节来表示，浪费空间，不利于传输和存储，因而产生了utf编码 UTF-8是不定长编码。一般来讲，英文字母都是用一个字节表示，而汉字使用三个字节 虽然utf编码对汉字使用3个字节，但即使对于汉字网页，utf编码也会比unicode编码节省，因为网页中包含了很多的英文字符 Base64 对内容进行简单加密，即一眼望去看不出内容即可，不需要进行复杂的加密 由于历史原因Email只被允许传送ASCII字符，即一个8位字节的低7位，这是产生Base64编码的主要原因 111111 x11 1111 x1111 11x111111]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thrift笔记]]></title>
    <url>%2F2017%2F02%2F13%2F%5BThrift%5DThrift%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Thrift 优点1、跨语言2、可扩展，简洁的四层接口抽象，每一层都可以独立的扩展增强或替换3、二进制的编解码方式和NIO的底层传输为它提供了不错的性能 四层接口抽象+——————————————-+| Server || (single-threaded, event-driven etc) |+——————————————-+| Processor || (compiler generated) |+——————————————-+| Protocol || (JSON, compact etc) |+——————————————-+| Transport || (raw TCP, HTTP etc) |+——————————————-+ Transport层提供了一个简单的网络读写抽象层，有阻塞与非阻塞的TCP实现与HTTP的实现。 Protocol层定义了IDL中的数据结构与Transport层的传输数据格式之间的编解码机制。传输格式有二进制，压缩二进制，JSON等格式，IDL中的数据结构则包括Message，Struct，List，Map，Int，String，Bytes等。 Processor层由编译器编译IDL文件生成。生成的代码会将传输层的数据解码为参数对象(比如商品对象有id与name两个属性，生成的代码会调用Protocol层的readInt与readString方法读出这两个属性值)，然后调用由用户所实现的函数，并将结果编码送回。 举个例子： 服务器端定义函数 Product get(Integer id, String name){ return new Product(id, name); } 1、客户端调用 get(id,name) 时，传递方法名get，参数id、name2、服务器Transport接收到数据get、id、name3、Processor调用Protocal的方法从Transport解码，从二进制转化为Integer和String，然后再服务器端调用get方法，得到结果Product 在服务端， Server层创建并管理上面的三层，同时提供线程的调度管理。而对于NIO的实现，Server层可谓操碎了心。 在客户端， Client层由编译器直接生成，也由上面的三层代码组成。只要语言支持，客户端有同步与异步两种模式。 四层接口的方法Transport层Transport TTransport除了open/close/flush，最重要的方法是int read(byte[] buf, int off, int len)，void write(byte[] buf, int off, int len)，读出、写入固定长度的内容。 TSocket使用经典的JDK Blocking IO的Transport实现 TNonblockingSocket，使用JDK NIO的Transport实现 相应的，TServerSocket和TNonblockingServerSocket是ServerTransport的BIO、NIO实现，主要实现侦听端口 WrapperTransport 包裹一个底层的Transport，并利用自己的Buffer进行额外的操作。 作用：在数据传输时需要判断什么时候是读取的开始、什么时候是读取的末尾，即需要用分隔符进行标识；使用Frame帧的概念就可以解决这个问题 Protocol层支持类型： 基本类型: i16，i32，i64, double, boolean，byte，byte[], String。 容器类型: List，Set，Map，TList/TSet/TMap类包含其元素的类型与元素的总个数。 Struct类型，即面向对象的Class，继承于TBase。TStruct类有Name属性，还含有一系列的Field。TField类有自己的Name，类型，顺序id属性。 Exception类型也是个Struct，继承于TException这个checked exception。 Enum类型传输时是个i32。 Message类型封装往返的RPC消息。TMessage类包含Name，类型(请求，返回，异常，ONEWAY)与seqId属性。 方法： Protocol 层对上述数据结构有read与write的方法 对基本类型是直接读写，对结构类型则是先调用readXXXBegin()，再调用其子元素的read()方法，再调用readXXXEnd()。 在所有函数中，Protocol层会直接调用Transport层读写特定长度的数据 Processor层具体流程： TProcessFunction是生成的服务方法类的基类，它的process函数会完成如下步骤： 调用生成的args对象的read方法从protocol层读出自己 调用子类生成的getResult()方法：拆分args对象得到参数，调用真正的用户实现得到结果，并组装成生成的result对象。 写消息头， 调用生成的result对象的write方法将自己写入protocol层5 调用transport层的flush()。 Server层基类TServer相当于一个容器，拥有生产TProcessor、TTransport、TProtocol的工厂对象。改变这些工厂类，可以修饰包裹Transport与Protocol类，改变TProcessor的单例模式或与Spring集成等等。 Blocking Server TSimpleServer同时只能处理一个Client连接，只是个玩具。 TThreadPoolServer才是典型的多线程处理的Blocking Server实现。 NonBlockingServer ★★★TThreadedSelectorServer有一条线程专门负责accept，若干条Selector线程处理网络IO，一个Worker线程池处理消息。 很明显TThreadedSelectorServer是被使用得最多的，因为在多核环境下多条Selector线程的表现会更好 具体流程： 1、AcceptThread线程使用TNonblockingServerTransport执行accept操作，将accept到的Transport round-robin的交给其中一条SelectorThread2、AcceptThread是先扔给SelectorThread里的Queue(默认长度只有4，满了就要阻塞等待)3、 因为SelectorThread自己也要处理IO，所以 SelectorThread每个循环各执行一次如下动作 注册Transport select()处理IO 处理FrameBuffer的状态变化 Thrift网络服务模型（即Server层，详解）1、TSimpleServer TSimpleServer实现是非常的简单，循环监听(即while(true)) 新请求的到来并完成对请求的处理，是个单线程阻塞模型。由于是一次只能接收和处理一个socket连接，效率比较低，在实际开发过程中很少用到它。 2、TThreadPoolServer ThreadPoolServer为解决了TSimpleServer不支持并发和多连接的问题, 引入了线程池。但仍然是多线程阻塞模式即实现的模型是One Thread Per Connection。 线程池采用能线程数可伸缩的模式，线程池中的队列采用同步队列(SynchronousQueue)。 ThreadPoolServer拆分了监听线程(accept)和处理客户端连接的工作线程(worker), 监听线程每接到一个客户端, 就投给线程池去处理。 TThreadPoolServer模式优点： 线程池模式中，数据读取和业务处理都交由线程池完成，主线程只负责监听新连接，因此在并发量较大时新连接也能够被及时接受。线程池模式比较适合服务器端能预知最多有多少个客户端并发的情况，这时每个请求都能被业务线程池及时处理，性能也非常高。 TThreadPoolServer模式缺点： 线程池模式的处理能力受限于线程池的工作能力，当并发请求数大于线程池中的线程数时，新请求也只能排队等待。 3、TNonblockingServer TNonblockingServer采用单线程非阻塞(NIO)的模式, 借助Channel/Selector机制, 采用IO事件模型来处理。所有的socket都被注册到selector中，在一个线程中通过seletor循环监控所有的socket，每次selector结束时，处理所有的处于就绪状态的socket，对于有数据到来的socket进行数据读取操作，对于有数据发送的socket则进行数据发送，对于监听socket则产生一个新业务socket并将其注册到selector中。 TNonblockingServer模式优点： 相比于TSimpleServer效率提升主要体现在IO多路复用上，TNonblockingServer采用非阻塞IO，同时监控多个socket的状态变化； TNonblockingServer模式缺点： TNonblockingServer模式在业务处理上还是采用单线程顺序来完成，在业务处理比较复杂、耗时的时候，例如某些接口函数需要读取数据库执行时间较长，此时该模式效率也不高，因为多个调用请求任务依然是顺序一个接一个执行。 4、THsHaServer THsHaServer类是TNonblockingServer类的子类，为解决TNonblockingServer的缺点, THsHa引入了线程池去处理, 其模型把读写任务放到线程池去处理即多线程非阻塞模式。HsHa是: Half-sync/Half-async的处理模式, Half-aysnc是在处理IO事件上(accept/read/write io), Half-sync用于handler对rpc的同步处理上。因此可以认为THsHaServer半同步半异步。 THsHaServer的优点： 与TNonblockingServer模式相比，THsHaServer在完成数据读取之后，将业务处理过程交由一个线程池来完成，主线程直接返回进行下一次循环操作，效率大大提升； THsHaServer的缺点： 主线程需要完成对所有socket的监听以及数据读写的工作，当并发请求数较大时，且发送数据量较多时，监听socket上新连接请求不能被及时接受。 5、TThreadedSelectorServer TThreadedSelectorServer是大家广泛采用的服务模型，其多线程服务器端使用非堵塞式I/O模型，是对TNonblockingServer的扩充, 其分离了Accept和Read/Write的Selector线程, 同时引入Worker工作线程池。 （1）一个AcceptThread线程对象，专门用于处理监听socket上的新连接； （2）若干个SelectorThread对象专门用于处理业务socket的网络I/O操作，所有网络数据的读写均是有这些线程来完成；每个SelectorThread维护一个Socket队列，负责监听这些通道上的I/O （3）一个负载均衡器SelectorThreadLoadBalancer对象，主要用于AcceptThread线程接收到一个新socket连接请求时，决定将这个新连接请求分配给哪个SelectorThread线程。 （4）一个ExecutorService类型的工作线程池，在SelectorThread线程中，监听到有业务socket中有调用请求过来，则将请求读取之后，交个ExecutorService线程池中的线程完成此次调用的具体执行 MainReactor就是Accept线程, 用于监听客户端连接, SubReactor采用IO事件线程(多个), 主要负责对所有客户端的IO读写事件进行处理. 而Worker工作线程主要用于处理每个rpc请求的handler回调处理(这部分是同步的)。因此其也是Half-Sync/Half-Async（半异步-半同步）的 。 TThreadedSelectorServer模式对于大部分应用场景性能都不会差，因为其有一个专门的线程AcceptThread用于处理新连接请求，因此能够及时响应大量并发连接请求；另外它将网络I/O操作分散到多个SelectorThread线程中来完成，因此能够快速对网络I/O进行读写操作，能够很好地应对网络I/O较多的情况。 QM总结 参考由浅入深了解Thrift之服务模型和序列化机制http://www.cnblogs.com/exceptioneye/p/4945073.html http://calvin1978.blogcn.com/articles/apache-thrift.html]]></content>
      <categories>
        <category>Thrift</category>
      </categories>
      <tags>
        <tag>Thrift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XML CDATA的作用]]></title>
    <url>%2F2017%2F02%2F13%2F%5BSSM%5DXML%20CDATA%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[http://www.cnblogs.com/myparamita/archive/2008/12/27/1363626.html XML文件中的一些特殊符号，例如：”&lt;”、”&gt;”、”/“、”？”等，会破坏了XML结构 有两种方式解决： 转义字符 CDATA部件 转义字符如果在XML文档中使用类似”&lt;”的字符, 那么解析器将会出现错误，因为解析器会认为这是一个新元素的开始。所以不应该象下面那样书写代码: &lt;message&gt;if salary &lt; 1000 then&lt;/message&gt; 为了避免出现这种情况，必须将字符”&lt;”转换成实体，象下面这样: &lt;message&gt;if salary &amp;lt; 1000 then&lt;/message&gt; 下面是五个在XML文档中预定义好的实体: &amp;lt; &lt; 小于号 &amp;gt; &gt; 大于号 &amp;amp; &amp; 和 &amp;apos; &apos; 单引号 &amp;quot; &quot; 双引号 实体必须以符号”&amp;”开头，以符号”;”结尾。 注意: 只有”&lt;” 字符和”&amp;”字符对于XML来说是严格禁止使用的。剩下的都是合法的，为了减少出错，使用实体是一个好习惯。 CDATA在CDATA内部的所有内容都会被解析器忽略。 如果文本包含了很多的”&lt;”字符和”&amp;”字符——就象程序代码一样，那么最好把他们都放到CDATA部件中。 一个 CDATA 部件以”&lt;![CDATA[“标记开始，以”]]&gt;”标记结束: &lt;script&gt; &lt;![CDATA[ function matchwo(a,b) { if (a &lt; b &amp;&amp; a &lt; 0) then { return 1 } else { return 0 } } ]]&gt; &lt;/script&gt; 在前面的例子中，所有在CDATA部件之间的文本都会被解析器忽略。 CDATA注意事项:CDATA部件之间不能再包含CDATA部件（不能嵌套）。如果CDATA部件包含了字符”]]&gt;” 或者”&lt;![CDATA[“ ，将很有可能出错哦。 同样要注意在字符串”]]&gt;”之间没有空格或者换行符。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>XML</tag>
        <tag>CDATA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven聚合与继承]]></title>
    <url>%2F2017%2F02%2F09%2F%5BMaven%5DMaven%E8%81%9A%E5%90%88%E4%B8%8E%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[聚合什么是聚合？聚合就是把多个模块或项目聚合到一起，简单统一的完成编译等工作 为了能够使用一条命令就能构建 account-email 和 account-persist两个模块，我们需要建立一个额外的名为 account-aggregator 的模块，然后通过该模块构建整个项目的所有模块。 account-aggregator本身也是个 Maven 项目，它的 POM如下 &lt;project> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.juvenxu.mvnbook.account&lt;/groupId> &lt;artifactId>account-aggregator&lt;/artifactId> &lt;version>1.0.0-SNAPSHOT&lt;/version> &lt;packaging> pom &lt;/packaging> &lt;name>Account Aggregator&lt;/name> &lt;modules> &lt;module>account-email&lt;/module> &lt;module>account-persist&lt;/module> &lt;/modules> &lt;/project> 注意：packaging的类型为pom ，module的值是一个以当前POM为主目录的相对路径。 继承在POM中申明一些配置供子POM继承，以实现”一处申明，多处使用的”目的 在account-aggregator下创建一个account-parent的子目录，然后在该子目录下创建除account-aggregator模块之外的模块的父模块。为此在该子目录下创建一个pom.xml文件如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;/groupId&gt; &lt;artifactId&gt;account-parent&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;springframework.version&gt;2.5.6&lt;/springframework.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework &lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${springframework.version}&lt;/version&gt; &lt;/dependency&gt; ...... &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;/project&gt; 需要注意的是它的packaging的值必须为pom，这一点与模块聚合一样，作为父模块的POM，其打包类型也必须为pom。由于父模块只是为了消除配置的重复，因此也就不需要src/main/java等目录了 有了父模块就让其他子模块来继承它，修改account-email的pom文件如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;/groupId&gt; &lt;artifactId&gt;account-parent&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../account-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;account-email&lt;/artifactId&gt; &lt;name&gt;Account Email&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/dependency&gt; ...... &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; ...... &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 只配置了groupId和artifactId,省去了version，如果父模块配置了依赖的scope也是可以省略的。这些信息可以省略是因为account-email继承了account-parent中的dependencyManagement配置，完整的依赖声明已经包含在父POM中了，子模块只需简单的配置groupId和artifactId。 使用这种以来管理机制虽然不能减少太多的配置项，但是经过别人实践后强烈推荐的方法。如果子模块不声明依赖的使用，即使该依赖已经在父POM文件dependencyManagement中声明了，也不会产生任何实际的效果。]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通用mapper]]></title>
    <url>%2F2017%2F01%2F18%2F%5Bmybatis%5D%E9%80%9A%E7%94%A8mapper%2F</url>
    <content type="text"><![CDATA[不是表中字段的属性必须加 @Transient 注解]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSTL常用语法]]></title>
    <url>%2F2017%2F01%2F17%2F%5BServlet%5DJSTL%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Maven依赖&lt;!--JSP相关--&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; JSP头&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;%@ taglib prefix=&quot;fmt&quot; uri=&quot;http://java.sun.com/jstl/fmt_rt&quot;%&gt; 常用标签PS：传入的对象除了一般的POJO对象，还可以是JSONObject和JSONArray &lt;c:if&gt; 标签 &lt;!-- 判断集合不为空 --&gt; &lt;c:if test=&quot;${!empty list}&quot;&gt; ... &lt;/c:if&gt; &lt;!-- 元素判断 --&gt; &lt;c:if test=&quot;${salary &gt; 2000}&quot;&gt; &lt;p&gt;我的工资为: &lt;c:out value=&quot;${salary}&quot;/&gt;&lt;p&gt; &lt;/c:if&gt; &lt;c:forEach&gt; 标签 &lt;c:forEach items="${list}" var="o" varStatus="status"> &lt;!-- 下标 --> 订单[${status.index + 1}] 的订单号是： ${o.orderNo} &lt;/c:forEach> forEach嵌套 &lt;% Map&lt;String, String[]&gt; bigCities = new HashMap&lt;String,String[]&gt;(); bigCities.put(&quot;Australia&quot;,new String[]{&quot;Sydney&quot;,&quot;Melbourne&quot;,&quot;Perth&quot;}); bigCities.put(&quot;New Zealand&quot;,new String[]{&quot;Auckland&quot;,&quot;Christchurch&quot;,&quot;Wellington&quot;}); bigCities.put(&quot;Indonesia&quot;,new String[]{&quot;Jakarta&quot;,&quot;Surabaya&quot;,&quot;Medan&quot;}); request.setAttribute(&quot;bigCities&quot;,bigCities); %&gt; &lt;c:forEach var=&quot;mapItem&quot; items=&quot;${bigCities}&quot;&gt; ${mapItem.key} : &lt;c:forEach var=&quot;city&quot; items=&quot;${mapItem.value}&quot;&gt; ${city} &lt;/c:forEach&gt; &lt;br/&gt; &lt;/c:forEach&gt; 遍历Map &lt;% Map&lt;String, String&gt; capitals = new HashMap&lt;String,String&gt;(); capitals.put(&quot;Indonesia&quot;,&quot;Jakarta&quot;); capitals.put(&quot;Malaysia&quot;,&quot;Kuala Lumpur&quot;); capitals.put(&quot;Thailand&quot;,&quot;Bangkok&quot;); request.setAttribute(&quot;capitals&quot;,capitals); %&gt; &lt;c:forEach var=&quot;capital&quot; items=&quot;${capitals}&quot;&gt; ${capital.key} ${capital.value} &lt;br/&gt; &lt;/c:forEach&gt; 日期 &lt;fmt:formatDate value=&quot;${o.confirmDate}&quot; type=&quot;date&quot; /&gt; &lt;fmt:parseDate value=&quot;${now}&quot; var=&quot;parsedEmpDate&quot; pattern=&quot;dd-MM-yyyy&quot; /&gt;]]></content>
      <categories>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>JSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文技术方向]]></title>
    <url>%2F2017%2F01%2F11%2F%5B%E8%AE%BA%E6%96%87%5D%E8%AE%BA%E6%96%87%E6%8A%80%E6%9C%AF%E6%96%B9%E5%90%91%2F</url>
    <content type="text"><![CDATA[背景各种各样的网络攻击对互联网的安全造成了重大影响 DDoS是一种常见、危害大的网络攻击 —— ddos介绍（DDoS攻击的根源）、危害（服务器崩溃，正常用户提供正常的服务），DDoS攻击类型：不同攻击速率，流量大小，隐藏源IP地址 DDoS攻击检测研究现状，检测方法分类：包分析和流量分析 为什么要大数据分析？进入大数据时代，越来越多的公司使用虚拟化数据中心和云服务，DDoS攻击开始移师云计算。尽管当前针对DDoS攻击的入侵检测模型的研究已经较为成熟，但由于云主机所具有的一些有别于普通主机的特性，所以不能将已有的入侵检测技术直接应用到云计算中。 传统的可行的方案在数据量变大时难以处理，需要使用大数据技术对对DDoS攻击检测 DDoS攻击原理，ddos攻击工具源码分析，DDoS数据库 研究目的：构建一个检测DDos系统模型，具有较高的准确性和实时性 研究内容：目前，对 DDoS 攻击检测技术的研究已经较为成熟，但随着云技术的发展，DDoS 攻击在云环境中又呈现出新的特性。云环境所拥有的强大计算能力和存储资源使得 DDoS 攻击在云环境中具有更强的破坏力。本文先对现有 DDoS 攻击原理、检测技术进行充分研究，又对云环境所具有的虚拟化、分布式特定进行分析。在综合以上二者的基础上，设计出基于云环境的 DDoS 攻击入侵检测模型。该模型具有传统入侵检测系统的优点，并加入了资源调度、容错等更适于云环境攻击检测的功能模块。 云计算-数据泄露等数据安全问题-入侵检测-DDoS攻击检测-传统技术无法处理大型数据-大数据平台Spark-DDos攻击工具源码分析-流量统计[趋势分析，总的应该是上升；]+包分析（负载检查，比如数据包大小，内容是否一致，及其他包特征来判定是否是DDos攻击）-用户行为分析（不同时间访问量不同，设定的阈值不同，回归模型，历史数据生成关联规则算法、序列模式算法、BP神经网络（深度学习）-训练处阈值进行检测（阈值动态变化）） - 当前与历史误差多少判断为遭遇DDos攻击]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文]]></title>
    <url>%2F2017%2F01%2F07%2F%5B%E8%AE%BA%E6%96%87%5D%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[基于数据挖掘的网络安全审计技术的研究与实现_辛义忠.caj背景网络攻击问题随着网络的普及而日益突出。 目前的解决方案1、入侵检测技术通过对网络安全审计数据进行分析和处理来发现网络中的入侵活动和入侵者,在网络安全领域起到了重要的作用。其关键和核心内容是进行网络安全审计。2、网络安全审计的目的是实时地、不间断地监视整个网络系统以及应用程序的运行状态,及时发现系统中可疑的、违规的或危险的行为,进行报警和采取阻断措施,并留下记录。 存在问题1、目前的审计系统可以高效地实现安全审计数据的输入、查询、统计等功能,但无法发现数据中存在的关联、关系和规则,无法根据现有的数据预测未来的发展趋势,缺乏挖掘数据背后隐藏的知识的手段。 2、目前入侵检测系统或安全审计系统中普遍采用的特征检测l的方法是由安全专家预先定义一系列特征模式来识别入侵。这种方法的问题是模式库得不到及时的更新,这样在安全审计的过程中系统不能自适应地识别出新型攻击,使误报警和漏报警问题不断发生。另外,一方面随着网络应用的普及,网络数据流量急剧增加,另一方面有些审计记录本身包含了大量的无关信息,于是,数据过载与检测速度过慢的问题也不无出现。可见，目前在安全审计的过程中普遍存在的问题主要有: （1）准确率低准确率低主要体现在误报警和漏报警两个方面。误报警是指将正常的用户行为及模式判断为入侵并发出警告。误报警是在安全审计过程中亟待解决的问题之一。由于事先定义的模式很难精确地划分正常行为和入侵行为之间的界限,因此虚警率一直居高不下。误报情况不仅使得安全管理员疲于人工应对出现的警报,也降低了安全管理员对真正报警的敏感度。而将入侵行为错判为正常行为的漏报情况也会严重影响入侵检测系统的可用性。 （2）检测速度过慢入侵检测系统事后反映的本质决定了将入侵检测的延迟最小化对于入侵检测系统来说是至关重要的。而入侵检测延迟又取决于处理数据的效率。随着网络应用的普及,网络数据流量急剧增加,一个网站每天可能会产生上百万条的事件记录。面对如此庞大的数据,入侵检测系统如何有效地完成数据审计以便做出及时反应成为一个难题。 （3）自适应性差网络上的数据是随着网络应用的变化而改变的,而特征检测是基于预先定义的模式,这就意味着它不可能根据网络数据的变化自适应地修改检测模式。因此,对于现有攻击手段的简单变种,特征检测是无能为力的,更不用说新型的攻击技术了。另外,有些审计记录包含了大量的无关信息,有些则显得过于精简,缺乏审计子系统的说明文档,这些都是目前的商业产品中审计子系统存在的问题。 3、目前大多数服务器操作系统都有日志，但是这些日志往往只是记录一些零碎的信息(如用户登录的时间信息),从这些日志中无法看到用户到底做了些什么操作,整个入侵的步骤是如何发生的。而且分散在各个操作系统中的日志需要用户管理员分别查看,进行人工的综合、分析、判断,实际上是很难奏效的。特别值得重视的是,这些服务器往扫一是处于无人看守状况下自动运行的,所以被攻克或者违规操作的时候管理员不在现场,日志文件很有可能被黑客删除或者修改,在这些被修改的日志卜进行侦破可能根本没有效果,甚至有一可能产生误导,起到相反的作用。目前在国际互联网上几已经有各种修改操作系统日志的工具,用这些工具就可以轻松修改操作系统的日志,所以这些功能和安全测评规范中的安全审计要求也有很大的差距。 4、有此Sniff类的工具(如Netxray、Snoop、Sniffit、Tcpdump)能够显示网络上流过的数抓包,并将包头和包的内部信息标识出来,这些工具从一定意义使得网络上传输的数抓变得可见,能够观察到一些网络用户正在进行的操作和传输的数据,所以这此工具对正在发生的违规操作能够起到一定的检测作用。但是仅仅是这些工具还不能承担日常的安全审计工作,因为这些工具只是对单个包进行解码,缺乏分析能力,无法判断是否是重要的信息和违规的信息,此外它们不具备上下文相关的网络操作行为判断的能力,也缺乏报警响应的能力。目前网络的实际流量是非常大的,如果不加分析全部记录的话,子任何磁盘也会在很短的时间内充满。所以这些只是些辅助判断网络故障的工具,目前还没有哪个系统真正将这些工具收集的数据长时间安全记录下来。 审计系统关键1、如何在大量的审计数据中提取出具有代表性的系统特征模式,并对程序或用户行为做出描述,是实现安全事件审计系统的关键。2、为了对审计数据进行全面、高速和准确地分析,需要利用数据挖掘等方法来处理安全事件数据,从包含大量冗余信息的数据中提取出尽可能多的隐藏的安全信息,抽象出有利于进行判断和比较的特征模型并用相应的算法由计算机判断出当前网络行为的性质。3、数据挖掘作为一种从大量数据中发现有用模式的一种新兴知识发现技术,在特征和规则的提取方面有非常大的优势。 研究目标、内容、重点、拟解决的问题(1)研究目标 用数据挖掘技术解决目前在安全审计过程中存在的不足,找出数据挖掘和网络安全审计在技术上的结合点,建立基于数据挖掘的网络安全审计模型。 (2)研究内容与工作重点 本文试图将数据挖掘技术应用于网络安全审计领域,利用数据挖掘中的分类技术、关联分析、序列模式分析和聚类技术等方法提取与安全有关的系统体征属性,并根据系统特征属性生成安全事件的分类模型,用于对安全事件的自动鉴别。目的是要建立一套完整的基于数据挖掘的网络安全审计模型,在这个模型中包括了针对安全事件审计数据的数据采集、数据预处理、特征变换与选取、数据挖掘、规则生成、挖掘结果处理等系列过程。 (3)拟解决的关键问题 1、安全审计的速度;2、安全审计的准确率;3、安全审计的自适应能力。 但目前在安全审计过程中普遍存在着检测准确率低、检测速度慢和自适应性差等问题。为了解决这些问题,本文提出了基于数据挖掘的网络安全审计系统的方案并加以实现。 数据挖掘数据挖掘是一种新兴的、并且在很短时间内得到了广泛应用的先进的智能化数据分析厅法。数据挖掘旨在从大量的数据中提取隐藏的预测性信息,发掘数据间潜在的模式,找出某些常常被忽略的信息,用便于理解和观察的方式反映给用户,作为决策的依据 数据挖掘的功能及内容1、数据预处理2、概念/类描述：用汇总的、简洁的、精确的方式描述每个类和概念称为概念/类描述3、分类： 分类(classification)是找出描述并区分数据类或概念的模型,以便能够使用模型预测类标记末知的对象类的过程。数据分类的目的是提取数据记录的特征属性,生成分类模型,该模型可以把数据库中的数据项映射到给定类别中的一个,导出模型是基于对训练数据集的分析。数据分类的处理步骤如下:获得训练数据集;定义类标识;分析训练数据集,生成分类描述模型;使用得到的类型描述模型对目标数据进行分类。数据分类算法如C4.5,。RIPER等。 4、关联分析5、演变分析6、聚类分析7、孤立点分析 数据挖掘的应用(l)针对生物医学和DNA数据分析的数据挖掘(2)针对金融数据分析的数据挖掘(3)零售业中的数据挖掘(4)电信业中的数据挖掘 基于数据挖掘的网络安全审计系统的方案通过以上研究,本文一认为将数据挖掘技术应用一于网络安全审计系统中可以较好地解决目前在安全审计过程中出现的问题。而且,在这一领域的研究人员的试验和测试结果表明,将数据挖掘技术应用于网络安全审计在理论上是可行的,在技术上建立这样套系统是可能的。因此,本文试图通过实践将数据挖掘技术应用于网络安全领域,利用数据挖掘中的分类、聚类、关联分析、序列模式分析等技术提取与安全相关的系统特征属性,并根据系统特征属性生成安全事件的分类模型,用于对安全事件的自动鉴别。目的是要建立一套完整的基于数据挖掘的网络安全审计模型。 本着去粗取精、去伪存真的原则,我们将网络安全审计作为一种数据分析的过程,着眼于对大量的安全审计数据应用数据挖掘算法,综合运用数据挖掘中的预处理、关联、序列、分类、聚类等技术,并通过系统运行过程中不断修改和扩充知识库,以一种自动和系统的手段建立一套自适应的、具备良好扩展性的网络安全审计系统[42,43]。基于以下思想,本文确定了如下方案: 1、系统中保存的数据分为当前审计数据和用户的历史行为数据。当前数据通过网络抓包工具和系统主机日志监视工具获取,历史数据是当前数据的历史记录。 2、当前审计信息和用户历史行为数据都需要经过数据的预处理,去除其中的不一致和冗余数据,对网络数据和主机数据进行集成,并对数据进行变换和归约将原始数据转换成易于挖掘的格式,形成具有特定格式的事件序列。 3、为了形成知识库模型需要构造训练数据。对于历史数据或训练数据,由数据挖掘引擎对事件序列进行分析学习,挖掘出审计数据中蕴藏的用户的正常行为模式和异常行为模式,并将正常或异常规则存入知识库中。 4、根据知识库中的规则,入侵检测模块对当前审计数据进行分析,当某用户的行为知识库中定义的异常规则相一致时,我们判定其为入侵。但当前一行为与知识库中的仁何规则都不匹配时,系统将判断当前用户行为与异常规则的相似性是否超过某一阈值,或不在正常行为之列,并认定该行为具有威胁。将这些数据加以存储,并利用聚类挖掘技术将这些数据抽象成为由类似的模式组成的多个类,再利用分类技术将数据转变为观则、添加到知识库中。这样可以通过不断修改知识库来发现未知攻击或已知攻击的变种。 基于流量行为特征的DoS＆DDoS攻击检测与异常流识别按照数据源的不同，现有DoS攻击和DDoS攻击的检测方法主要可以分为两类:基于包信息的检测方法和基于网络流量行为特征的检测方法 1)基于包信息的检测方法通过分析数据包中的特定信息或是用户日志等，建立判定规则，并根据实际的流量数据和这些规则的匹配关系来检测DoS攻击和DDoS攻击典型的研究有:文献［1］提出一种基于主机日志分析的统计方法，通过分析主机的日志数据，利用统计理论对正常行为建模，并比较待检测行为与正常行为的偏离来检测网络DoS攻击文献［2］提出了一种基于数据包包头信息综合分析的异常检测技术，通过分析目的IP地址或端口号在边沿路由器出口流量的关联检测异常文献［3］利用TCP协议不同的控制报文在交互时呈现出的数学约束关系，提出了一种评价TCP流宏观平衡性的系统测度，并将之应用于异常检测 2)基于网络流量行为特征的检测方法通过分析流量行为特征参数，如各种数据包包头信息(如IP地址端口号等)聚合后计算得到的统计量，来进行异常检测 典型的研究有: 使用美国Abilence网络［13］Losa汇接点上的流量数据进行仿真实验 抗Dos攻击模型研究_刘雅林.caj在本文中，作者重点将建立一个抗 DOS 攻击的模型，该模型利用数据挖掘（DM）原理，采用关联规则算法、序列模式算法和 BP 网络算法作为判断攻击的主要理论依据。该模型通过感应模块，获取网络流量信息；采用 BP 网络算法，训练出神经网络模型，建立网络流量趋势曲线，设立一个可以动态变化的阀值，和日志库中的网络流量进行对比分析，对异常流量进行判别；将感应模块抓取的网络连接信息利用关联规则算法、序列模式算法挖掘出关联模型和序列模式模型，作为判断攻击是否发生的重要方法。 Dos攻击的危害第九页 19页 入侵检测入侵检测系统的实现方法有基于概率统计模型的检测、基于神经网络的检测、基于专家系统的检测、基于模型推理的检测和基于免疫的检测等技术。 数据挖掘数据挖掘(DM:DataMining)一般指从大量的数据中自动地提取有效的未知新模式的探索、分析过程。它是一种从数据仓库中发现并提取潜在的、有用的知识的新技术，其作用是寻找数据间潜在的关联，做出归纳推理，以此为基础自动做出预测决策。 为什么在网络攻击中使用数据挖掘在入侵检测系统中，数据挖掘通常是指从大量的数据中自动提取出模型的过程。数据挖掘采取以数据为中心的观点，把攻击检测看作是一个数据分析过程，在异常检测过程中，数据挖掘主要是从审计数据中发现正常的使用模式；而在滥用检测过程中主要是实现审计数据编码并与攻击模式匹配的过程。数据挖掘技术能应用于入侵检测系统中，主要是由于它具有以下特点 1、处理的数据规模十分巨大；由于用户不能形成精确的查询要求，因此需要靠数据挖掘技术来寻找其可能感兴趣的东西；2、数据挖掘可对数据的迅速变化做出快速响应，以提供决策支持信息；3、数据挖掘能发现潜在规则，还可以管理和维护规则，随着新数据的不断加人，规则可随之更新；数据挖掘中规则的发现基于统计规律，发现的规则不必适合于所有数据，而且，当达到某一阀值时，便认为有此规则。因此，在攻击检测系统中利用数据挖掘技术可能会发现大量的规则。数据挖掘技术迅速发展，己经从统计学、模式识别、机器学习和数据库等领域中得到了多种算法，与攻击检测相关的算法主要有分类分析、聚类分析、关联分析和序列模式分析等。将数据挖掘用于网络攻击检测中的主要优点：它能从大量的审计数据中自动生成简洁而精确的检测模型，因此为大量的计算环境建立攻击检测系统。 DOS 攻击的特征与数据挖掘特征的关联DoS 攻击手法虽然简单，但现有的技术和手段对这种攻击几乎没有什么好的对应策略。DoS之所以难于防范和跟踪就在于它是一种自然、简单、通过“正常”渠道发起的攻击方法。由于DoS攻击是利用TCP/IP协议自身的缺陷，产生大量“合法”的数据包来攻击目标，因此对该攻击的防范相当困难。 如果仅仅是检测分析数据包，试图从中区分出合法与非法的数据包是非常困难的。我们认为对 DoS 防护的关键是检测分析由 DoS 攻击数据包形成的流特征。在深入分析 DoS 攻击的各种工具及其源码，并在分析收集的模拟 DoS 攻击通信数据包后，总结出其通信数据包及其流特征如下： 1、大多数攻击的 TCP 数据包利用了 TCP/IP 协议的 3 次握手机制，通过使用了“SYN”的状态标志，向被攻击者发送连接请求，但却不真正建立一个连接，即使得被攻击者维护大量所谓的半打开状态连接；2、利用 UDP Flood 或 TCP Flood 或 Smurf 攻击建立与被攻击方的大量连接，消耗服务器的带宽、CPU 或内存等资源；3、利用 TCP/IP 协议中允许某些怪异数据包的存在，发起攻击。其中包括以下的数据包：（1）在 TCP 数据包中同时加入 SYN 和 ACK 两种状态标志，这就使目标机器出现混乱，要花一些时间来处理这些异常情况。（2）特大型的 TCP 和 UDP 数据包，或数据包内容为固定的信息。（3）其它怪异的数据包，如错误的分段，混乱的 header 偏移量等。（4）DoS 支持对连接速率的限制。在某些情况下，连接可以被高速建立，目标主机上会被快速打开成千上万的端口，在连接超时之前所有的资源就被耗尽了。而在另一种情况下，连接也可以以一种较慢的速率建立，以避免触发目标主机上或(防火墙)的SYN Flood 保护机制。但总体上其发送速率是一种上升的趋势。 从 DDoS 的攻击特征中可以看出，作为 DoS 攻击的升级，此类攻击从单个数据包或通信连接上很像正常的通信，单纯检查单个数据包或通信连接往往不能发现该攻击，这使得检测和防护 DDoS 攻击至今仍缺乏有效的手段，只能是结合各方面有关证据辅助对 DDoS 的检测。作者在研究中发现DDoS 攻击的最终表现在于大量数据涌向受攻击站点，引发流量异常，因此结合流量分析来检测 DDoS 攻击是非常必要的。 在 DoS 攻击流特征分析中已经给出通过流量发现 DoS 攻击的例子，但是流量的分析远不止这样简单。因为各网络情况的不同，仅仅将网络流量数据作为 DoS 检测规则属性是不够的，而需要将网络实际流量以及它和理论中的正常(没有任何攻击行为的情况下的)流量的比较结果均作为关键属性。这样才能完整的反映出当前网络的流量真实情况。 那么理论中的正常流量是否可以获得的，这又如何得到的呢？这里举一个例子：一个专门提供邮箱服务的网站，一般情况下每天上午 8: 00-9: 30期间网络访问量达到一天的最高峰。这是因为大部分人习惯每天上班打开电脑的第一件事就是查看自己的信箱。正是因为每个人的行为都带有一种习惯性，这也使得网络的访问量产生规律性。既然有规律可寻，那么网络的流量就是可以预测的。本文利用趋势分析算法从大量正常通信的流量数据挖掘出网络流量(出、入、IP 段等)的趋势，预测正常流量曲线。因此本文研究的挖掘 DoS 攻击特征的数据挖掘算法除关联分析和序列分析外还有趋势分析，它利用历史数据找出变化规律，建立模型，并用此模型来预测未来数据的种类、特征等。回归分析是一种典型的方法，即利用大量的历史数据，以时间为变量建立线性或非线性回归方程。预测时，只要输入任意的时间值，通过回归方程就可求出该时间的状态。近年来，发展起来的神经网络方法，如 BP 模型，它实现了非线性样本的学习，能进行非线性函数的判别。 算法简介为了抗 DOS 攻击，我设计了一个模型，该模型将用到关联规则算法、序列模式算法以及神经网络算法。在本节里，将对这三种算法进行简介。 关联规则算法：关联规则挖掘是数据挖掘中最活跃的研究方法之一，最初提出的动机是针对购物篮分析问题提出的，其目的是为了发现交易数据库中不同商品之间的联系规则。这些规则刻画了顾客购买的行为模式，可以用来指导商家科学地安排进货、库存以及货架设计等。 序列算法：如果说关联规则算法试图发现审计数据内模式，那么序列算法能用来发现审计数据间模式。序列模式挖掘是指挖掘相对时间或其他模式出现频率高的模式。一个序列模式的经典例子是“9个月前以购买奔腾 PC 的客户很可能在一个月内订购新的 CPU 芯片 基于数据挖掘的抗 DoS 攻击模型将采取上一章介绍的数据挖掘算法，并结合 BP 网络算法，建立一个基于数据挖掘的抗 DoS 攻击的防范模型（Data Mining-Based Anti-Do S Attack Model），本模型可以从网络中抓取网络流量信息和数据包信息，然后根据知识库中已经建立的模型和训练好的流量趋势曲线，对网络信息进行判别，看是否有攻击产生。将感应模块抓取的网络连接信息利用关联规则算法、序列模式算法挖掘出关联模型和序列模式模型，作为判断攻击是否发生的重要方法。同时，为了保证某些模型难以正确判断的复杂情况（如重大事件发生时网络访问量剧增），增加了人工判断情况，对知识库中没有建立的新模型进行更新；针对某些特征比较明显的攻击，本模型用端口挖掘模块和 IP 挖掘模块进行直接处理，并不对其进行过深的分析，一定程序上避免了模型本身遭受 DoS 攻击。本模型由 8 个模块组成，它们分别是：感应模块、开采模块、分析模块、IP 挖掘模块、端口挖掘模块、控制模块、执行模块。我对这些模块分别进行了实验，其抗 DoS 攻击效果比较显著。 模型综述 在本模型中，首先要根据长时间的网络日志，建立 BP 网络，利用以前的数据训练 BP 网络，形成网络流量趋势曲线。这是对异常流量的判别标准。同时，还要利用数据挖掘的序列模式算法（frenquent episode arithmetic ）、关联规则算法（Association rules arithmetic）建立模型，作为比较的标准。 基于云计算的入侵检测技术研究_齐玉珠★★★背景近几年来,随着网络技术的高速发展和社交网络、在线视频、电子商务、搜索引擎等新一代大规模互联网的应用迅速发展下,云计算[1]应运而生。云计算逐渐出现在互联网应用和服务的各个方面,并且已经成为信息产业发展的新方向和促进经济增长的动力[2]。云计算是一项新兴的技术,是虚拟化技术[3]、并行计算[4]、网格计算[5]、效用计算[6]、储存技术[7]、负载均衡[8]等这些传统技术与网络融合的产物。云计算是一种依赖互联网的服务形式,它通过虚拟化技术将底层的计算、存储等基础资源整合起来,以按需的、便捷的服务形式提供给企业和用户,实现了可伸缩扩展、灵活、可靠、高效的 IT 服务交付平台。这种新平台使得企业用户能够最大最优化地将资源切换到需要的应用和系统上,根据需求访问计算机和存储系统,并且可以很好地解决大数据时代的各种问题,从而使云计算有着广阔的应用前景[9]。以 Google 的应用程序引擎10、亚马逊的 E2C[11]、IBM 的蓝云(Blue Cloud)[12]、微软的 Azure 为代表的云计算服务已经开始大规模商用化,越来越多的公司开始使用云计算,云计算已经成为信息技术领域新的发展方向[13]。 然而随着云计算技术广泛深入应用,其强大的计算和存储能力对入侵者有着巨大的诱惑力,云计算安全问题[14]越来越受到业界的关注,云计算环境相应的安全问题也呈现直线上升趋势。近几年,大型云服务提供商不断爆出云安全事故,如 2009 年 Google 云文档服务发生用户的个人文件外泄事件;2011 年,亚马逊云计算服务多次中断,导致第三方网站如回答服务 Quora、 跟踪服务 FourSquare 瘫痪;2009 年,微软的 SIDEKICK 服务宕机中断了一个星期,导致用户不可以访问自己的邮箱等个人数据;2012 年 ,微软云计算平台 Windows azure部分服务因闰年设置问题导致所有集群的服务管理功能被禁用。目前云计算安全问题已成为制约其发展的主要障碍[15],云环境中的安全防护措施将成为研究的热点。 入侵检测系统[16]迄今发展已有二十几年的历史,它通过对计算机网络系统中的许多关键点进行收集信息,如操作系统的审计数据,系统日志及网络数据包等。然后分析收集到的信息,进而发现违反安全规则和危害系统安全的行为,以此来保护系统和资源的安全性,机密性,完整性和可用性。入侵检测系统作为一种主动的、行之有效的网络安全防护措施,在网络安全防护中发挥着举足轻重的作用,是新一代网络安全防护体系的重要组成部分,也是继防火墙之后的网络安全系统的第二道闸门。 现在的入侵检测系统还存在许多需要解决的问题,如在高速千兆级网络下,网络流量极大,网络数据也呈现海量性,这些情况使目前的入侵检测系统满足不了对实时性和有效性的需求。目前针对以上的问题,一些研究人员着眼于算法的不断改进。然而云计算丰富的计算能力正好可以被利用来处理检测数据量大的问题,目前关于云计算的入侵检测研究还处于起步阶段,本文研究基于云计算的入侵检测系统将非常有意义。 本文首先设计了一个云计算环境下的入侵检测系统模型 CIDS,该模型可以实时采集和检测云环境数据,同时利用云计算技术进行检测数据的分析处理。在该检测系统中,使用改进的 K-means 聚类方法对检测数据进行分析,同时引入主成份分析 PCA 作为特征提取模块,达到不失特征精度和检测率的情况下对海量检测数据进行线性降维的效果。最后本文在 Hadoop 平台上进行整个分析模块检测算法的并行化设计,充分利用了云计算平台的计算资源进行入侵检测的分析,验证了云计算入侵检测系统利用其云资源时,有较好的检测率和实时性,也验证了本文 CIDS 的合理性。 总体来说,入侵检测技术发展到现在是比较成熟的技术,目前也已有很多检测方法,但随着网络数据量的海增和数据的复杂化,检测系统的性能处于了瓶颈状态。云计算作为一项新型的技术,一方面其强大的资源正好可以为入侵检测系统服务,另一方面入侵检测系统也可以检测出云计算遭受的入侵威胁,使云环境能及时做出响应,将损失降到最低,所以基于云计算的入侵检测技术是当前比较热门的研究方向。 主要的检测方法有：（1）基于特征选择的异常检测，从一组特征属性中选出能检测入侵行为的属性，并用它来对入侵行为进行分类（主成分特征分析、独立成分分析）（2）基于统计的异常检测：当前特征与数据库特征进行比较（平均值分析、基于贝叶斯网络推理方法、基于马尔科夫链方法、基于序列分析方法）（3）基于机器学习方法：系统可以通过监督式学习、死记硬背式学习或归纳学习等方式,获取个体、系统和网络的行为特征（4）基于神经网络学习方法：通过神经元权值状态的调整变化分布式计算检测数据,并将检测数据分到不同的类中,实现无监督检测（5）数据挖掘检测方法：从检测数据中挖掘出有用的关联知识,然后用这些知识检测入侵行为 Detection DDos Attacks Based on Neural-Network Using Apache SparkSeven feature are used to DDoS Attack Number of Packets Average of Packet Size Time Interval Variance Packet Size Variance Number of Bytes Packet Rate Bite Rate 数据库 2000 DARPA LLDOS 1.0 ： 攻击流量 Frequency based DDoS attack detection approach using naive Bayes classificationFrequency domain analysis would be a promising alternative for conventinal methods of detection. In this paper we provide a naive Bayes classifier with two frequency based methods of discrete Fourier transform and discrete wavelet transform in order to separate between attack and normal traffics. 背景Most intrusion detection systems (IDS) utilize one of two methods of detection: signature-based (misuse)[基于特征检测的入侵检测] and anomaly analysis [6]. In a signature-based method, the system is trained by a set of known malicious threats. During the analysis, IDS compare the pattern of ongoing traffic with its database and any match reports as intrusion. This method suffers from incapability of detecting new unknown intrusions [7][不能检测未知入侵] In anomaly-based approach, the normal pattern is determined and any activity out of this model is reported as anomalous. Although, this method can detect new intrusions, the detection probability rate is low [6]. [归纳正常情况下的模式，其他异常情况判定为入侵] Packet level analysis and payload examination are the dominant methods which are implemented in most traditional detection systems [8][包等级分析] DDos攻击数据库UDP-based attack dataset 大数据、云计算技术对审计的影响研究大数据或称巨量资料，指的是所涉及的数据量规模大到无法利用现行主流软件工具，在一定的时间内实现收集、分析、处理或转化成为帮助决策者决策的可用信息。互联网数据中心认为大数据(是为了更经济、更有效地从高频率、大容量、不同结构和类型的数据中获取价值而设计的新一代架构和技术，用它来描述和定义信息爆炸时代产生的海量数据，并命名与之相关的技术发展与创新。 大数据具有 4 个特点:第一，数据体量巨大，从 TB 级别跃升到 PB 级第二，处理速度快，这与传统的数据挖掘技术有着本质的不同第三，数据种类多，有图片、地理位置信息、视频、网络日志等多种形式第四，价值密度低，商业价值高，存在单一数据的价值并不大，但将相关数据聚集在一起，就会有很高的商业价值 大数据与云计算的关系从整体上看，大数据与云计算是相辅相成的。大数据主要专注实际业务，着眼于”数据”，提供数据采集、挖掘、分析的技术和方法，强调的是数据存储能力。云计算主要关注”计算”，关注 IT 架构，提供 IT 解决方案，强调的是计算能力，即数据处理能力。如果没有大数据的数据存储，那么云计算的计算能力再强大，也难以找到用武之地; 如果没有云计算的数据处理能力，则大数据的数据存储再丰富，也终究难以用于实践中去。 从技术上看，大数据依赖于云计算。海量数据存储技术、海量数据管理技术、MapReduce编程模型都是云计算的关键技术，也都是大数据的技术基础。而数据之所以会变”大”，最重要的便是云计算提供的技术平台。数据被放到”云”上之后，打破了过去那种各自分割的数据存储，更容易被收集和获得，大数据才能呈现在人们眼前”而巨量的数据也只能依靠云计算强大的数据处理能力，才能够 “淘尽黄沙始得金”。 基于大数据技术的安全审计系统_刘大地一、传统安全审计技术面临的困境随着信息化程度的不断提高，信息系统越来越庞大，越来越复杂，随之而来的是系统中需要安全审计的对象和审计内容更多更复杂，单位时间内需要审计信息增长巨大。在国家重要的行业中，大型信息系统的管理节点动辄达到几十万个，需要审计的重要节点常常会超过上千个，这其中包括服务器、网络设备、安全设备、数据库、应用系统等不同的节点类型，每天的访问、操作日志可达到数亿甚至几百亿条，数据量达到TB数量级 ，这对于传统的安全审计系统的数据采集及分析能力都构成了极大挑战。同时，由于审计的对象种类繁多，不同对象间日志格式可能会有很大差异，使用传统的关系型数据库去保存这些海量的异构数据，数据的有效管理、快速检索以及利用数据挖掘技术对数据进行分析时都会面临诸多较难克服的问题。 二、大数据技术带来的曙光 Google 的 Google File System、Google Bigtable和 Google MapReduce这三篇论文的发表，业界利用廉价的分布式系统进行大数据处理奠定了基础，各种相关的技术和实现不断被提出，形成了蓬勃发展的大数据技术生态系统，越来越多的应用构建其上。人们以比以往低得多的成本，获取了比以往强大得多的计算和存储能力，并且仍在继续快速地提升这一能力。作为一种需要对海量数据进行采集、分析和展现的应用系统，安全审计系统天然地对能够高性能地处理海量异构数据的技术有着强烈的需求。大数据相关技术的出现与不断发展成熟，为其适应网络发展的需求提供了新的技术支撑。使用大数据相关技术改造或开发新的安全审计系统，相对于传统技术的安全审计系统，可以在以下几个方面得到显著改善： （1）系统在采集、检索、分析和存储方面的性能瓶颈将被打破；（2）可以更好地同时应对结构化数据和非结构化数据；（3）可以利用大数据分析的相关算法和模型，对历史数据进行更广泛和更深入的分析，从海量数据中挖掘出更多对用户有价值的信息；（4）由于系统部署在更加便宜的硬件设备上，采购和维护的费用更加低廉，并可根据用户网络应用的发展而灵活实现水平扩展，有效降低了系统的总拥有成本，提高了灵活性，更好地保护了用户投资。 三、基于大数据技术的安全审计系统的设计 使用大数据相关技术解决审计过程中遇到的几方面问题： （一）大数据量的审计数据采集与存储 （二）数据归一化和关联分析 审计数据采集后首先需要对这些海量数据进行分类，按照一定的标准进行归一化，并且可以对数据进行一些简单的清洗和预处理工作。这些与传统的审计产品所采取的事件处理流程一致，所不同的是要处理的数据量非常大，数据量可能会达到500万EPS（Events Per Second，每秒事件数），峰值可能达到1000万EPS。这种性能要求不是传统的审计产品能够做到的，必须要依赖大数据集群并发处理的能力。传统产品在进行实时关联分析时一般使用内存数据库的方式，因单机版内存资源以及SQL语句效率的问题导致事件量大时，规则引擎的并发性以及处理能力均会有较大下降，导致规则引擎无法检测出异常。而使用基于大数据集群的分布式计算框架同时结合基于大数据集群的复杂事件处理流程作为实时规则分析引擎，能够高效并行地运行多种规则，并能够实时检测异常事件。具体实现上可采用Storm+Esper的方式，Storm非常适合对海量数据进行实时的统计计算，并能够快速地反馈统计结果。Storm框架利用严格且高效的事件处理流程保证运算时数据的准确性，并提供多种实时统计接口供使用。利用Storm的内存数据迭代计算框架进行关联分析运算，利用Esper实现的复杂事件处理功能作为实时关联分析的引擎，可提升系统关联分析的实时性及准确性。 （三）历史数据统计分析 对于存储在集群中的海量数据进行离线统计分析是审计系统要解决的另一个重要问题。基于大数据技术的审计系统的离线统计与分析功能主要利用分布式计算集群来对存储于其内的海量数据进行普通的分析和分类汇总等，可以满足大多数常见的分析需求。在Hadoop上层部署Hive+Hbase框架，Hive和Hbase有各自不同的特征，hive是高延迟、结构化和面向分析的，Hbase是低延迟、非结构化和面向编程的。Hive数据仓库在Hadoop上是高延迟的，Hive集成Hbase就是为了使用Hbase的一些特性，使用Hive提供的HiveSQL来简化对Map/Reduce任务的编写，利用Hive与Hbase互补加速对事件分析结果的运算效率，将通过核心模块将该命令解析为Map-Reduce，提交给Hadoop集群之后，生成报表供报表中心展示，从而对存储在HDFS上面的数据进行离线统计分析。 （四）数据挖掘 通过数据挖掘技术，可以发现一些较隐蔽的网络攻击、违规访问和一些系统配置的误配情况。目前，已有很多公开的数据挖掘算法，在技术实现上已无难度，但算法与信息安全行业的模型相结合，仍需要较长时间的训练及调试。 （五）高效便捷的海量事件追溯 追溯系统是审计系统中非常重要的一环，目的是为了在海量数据分析的基础上最终定位并解决用户实际问题，追溯系统可对平台分析出来的各种结果进行事件源定位。 面向云计算的DDoS攻击检测研究_许艺枢★★★★★研究内容，包括DDoS与大数据结合的原因本文的主要研究内容为 DDoS 攻击的检测技术。目前，对 DDoS 攻击检测技术的研究已经较为成熟，但随着云技术的发展，DDoS 攻击在云环境中又呈现出新的特性。云环境所拥有的强大计算能力和存储资源使得 DDoS 攻击在云环境中具有更强的破坏力。本文先对现有 DDoS 攻击原理、检测技术进行充分研究，又对云环境所具有的虚拟化、分布式特定进行分析。在综合以上二者的基础上，设计出基于云环境的 DDoS 攻击入侵检测模型。该模型具有传统入侵检测系统的优点，并加入了资源调度、容错等更适于云环境攻击检测的功能模块。另外，本文对传统 BP 神经网络算法进行改进，并将改进后的算法用于检测模型中，最后通过仿真实验证明其具有更为优越的检测性能。 DDos攻击概述1、攻击原理2、典型DDoS攻击3、DDoS攻击常用工具4、DDoS攻击防御与检测5、僵尸网络 DDoS攻击与大数据结合的原因DDoS（Distributed Denial of Service，分布式拒绝服务）攻击是通过耗尽受害者主机资源使其丧失提供正常网络服务能力的一种攻击。该攻击具有易实施、难防范、隐蔽性强等特点，是当今网络安全领域的研究热点。 随着越来越多的公司使用虚拟化数据中心和云服务，DDoS 攻击开始移师云计算，并且攻击方式由数据暴力泛滥转向为向应用基础设施发起攻击。尽管当前针对 DDoS 攻击的入侵检测系统的研究已经较为成熟，但由于云服务器所具有的一些有别于普通主机的特性，所以不能将已有的入侵检测技术直接应用到云计算中，这就需要对云计算中的分布式拒绝服务攻击入侵检测技术展开专门的研究。 DDoS攻击检测方法DDoS攻击检测时需要注意的问题有：一是这类攻击使用的数据包与合法数据包相似，因而检测过程中容易把合法数据包误报成攻击数据包；二是难以区分网络流量瞬时拥塞和 DDoS 攻击。因此对于 DDoS 攻击检测来说尽早检测到攻击和减少误报成为当前研究的重点。目前常用的入侵检测可分为基于特征的检测与基于异常的检测两类： 基于特征的检测方法是根据已知的攻击行为建立特征库，当出现这些攻击特征时，就认为是发生了攻击。但这种方法只能对已知的攻击模式具有检测力，对未知的攻击则无能为力。常用的基于特征的基于特征的检测技术有专家系统、模式匹配等。 基于异常的检测方法是通过建立主体的正常行为模型，来发现其异常行为，从而对未知攻击也具有检测能力。常用的基于异常的检测技术有量化分析、统计方法、神经网络、遗传算法等 (1) 基于流量自相似性的 DDoS 攻击检测 90 年代初，Leland 等人[13]通过对大量网络数据进行监测与分析发现正常的网络流量具有自相似性。当 DDoS 攻击发生时，会对网络流量的自相似特性产生较大影响，因而可以通过网络流量的自相似程度的变化来对 DDoS 攻击进行检测。 云计算中的 DDoS 攻击防御云计算的概念始于 2007 年，在 Amazon、Google 等 IT 巨头的推动下，在短短几年内便产生了巨大的影响力并成为了当前炙手可热的技术之一。“云”就像一个庞大的资源池，为客户提供许多功能强大、使用方便的服务，云用户可以根据自己的需要来使用这些资源并根据使用量付费。但是在云计算带来诸多好处之时，在云安全方面也面临许多挑战。由于云计算的一些技术还不完善，且在公有云中的云计算服务主要通过互联网提供，便大大增加了遭受 DDoS 攻击的可能性。但是由于云计算本身所具有的一些特点，使其在应对 DDoS 方面也显露了一些优势。如维基解密网站(WikiLeaks)在遭受 DDoS 攻击后，便通过使用亚马逊的云计算服务保护自己远离 DDoS 攻击。本章中，将首先对云计算以及云计算中主要的 DDoS 攻击防御技术做了简要介绍，并在此基础上提出一种将MPLS 技术运用到云计算中的方法，以提高云计算安全性能。 云计算概述1、云计算概念及特点2、云计算架构3、云计算模式 DDoS攻击给云计算带来的威胁随着云计算的发展及云技术的日趋成熟，云安全问题的重要性呈现逐步上升趋势并成为制约云计算发展的重要因素[30]。很多企业选择使用云服务及虚拟化数据中心，与此同时，企业基础设施及存储大量虚拟数据的数据中心成为 DDoS 攻击的重要目标，DDoS攻击成为了云计算所需面临的新威胁 DDoS工具升级具有更大的破坏性 云环境的需求分析★★★★★云计算所具有的超大规模、资源共享及海量数据存储能力，使得云成为攻击者们新的乐土。相较于普通的攻击，在云环境中实施的攻击速度更快，破坏力也更强。根据云环境的特性，所设计的入侵检测模型应满足已下几点基本要求：(1) 可靠性：为了使服务质量得到保障，云计算中的数据采用多副本容错和计算节点同构可互换的措施。因此，所设计的模型必需考虑到云环境的容错特性。(2) 动态性：“云”为用户所提供的资源是动态的，而“云”用户的规模也是动态的，因此，模型需要具有动态性。(3) 完整性：模型除了能够应对普通的 DDoS 攻击，还能检测出针对云环境的一些新的变种攻击，如 H-DoS、X-DoS 等。 除需满足以上需求外，还要考虑云资源所具有的分布式存储特点，因此云计算中的入侵检测模型需采用非集中的管理模式。“云”通过虚拟技术将分布的资源组织起来并实现资源的共享。虚拟机作为云环境中的基本管理单元来处理云用户所提交的任务。因此，入侵检测模型将这些虚拟机作为检测对象，同时作为这些虚拟机的安全管理者，入侵检测模型也通过虚拟技术来实现。 神经网络基于活跃熵的 D o S 攻击检测模型★★★★建立系统正常通信的情况时呈现的活跃熵特性，分析系统在遭受Dos攻击下所呈现的奇异性进行检测 通过数据包中的 I P 地址和端口等信息确定该动作所作用的主体 , 并且更新系统的活跃状态 SYNFlood型DDoS攻击检测与防御研究_李铮★★★基于阈值的攻击检测方法：设定一个阈值，大于这个阈值判断为遭受到Dos攻击。最大的优点是简单，不需要历史访问流量进行学习，缺点是使得部分攻击得逞（攻击流量没有超过阈值的情况下不能检测，使得服务器为正常访问流量提供的服务减少） 基于流量统计的攻击检测方法：tcp协议定义每接收一个数据包就会返回一个数据包，即通信双方传输的数据量是成比例的。如果返回的数据包少（被丢弃），则 2分钟读懂Hadoop和Spark的异同http://www.techweb.com.cn/network/system/2016-01-25/2267414.shtml 解决问题的层面不一样1、Hadoop 将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，意味着您不需要购买和维护昂贵的服务器硬件 2、Spark 是一个专门用来对那些分布式存储的大数据进行处理的工具，它并不会进行分布式数据的存储 两者可合可分1、Hadoop除了提供为大家所共识的HDFS分布式数据存储功能之外，还提供了叫做MapReduce的数据处理功能。所以这里我们完全可以抛开Spark，使用Hadoop自身的MapReduce来完成数据的处理。 2、Spark也不是非要依附在Hadoop身上才能生存，但如上所述，毕竟它没有提供文件管理系统，所以，它必须和其他的分布式文件系统进行集成才能运作。里我们可以选择Hadoop的HDFS,也可以选择其他的基于云的数据系统平台。但Spark默认来说还是被用在Hadoop上面的，毕竟，大家都认为它们的结合是最好的。 ★Detection DDoS attacks based on neural-network using Apache SparkThe key objective of this study is to construct a detection system have high accuracy and immedaite, The Artificial neural network(ANNs) is used to identify and detect abnormal traffic, and used famous DDos tools like ARPA 2000 LLDOS 1.0 and self-generated to training ANNs, make our detection system be able to identify the characteristic of abnormal traffic, the feature of ANN is their network will not expand by data volumes, so it is suitable for the huge volume analysis like DDoS detection, and we used Apache Spark an open source cluster computing framework, The feature of this framework is In-Memory computing, break through the bottleneck of hard disk,make run programs up to 100x faster than Hadoop MapReduce in memory. Artificial neural network(ANNs)神经网络介绍 Artificial neural networks are abstract mathematical models of brain structures and fucntions, ANNs could be a prediction ability AI machine, througe high performance computing, the feature of ANNs is their structure will not expand with the number of input and output does not change,so the memory used will be under control, and have high reliability that ability to predict unknow input data. 神经网络种类 Back-propagation Network, Hopfield Network, Radial Basis Function Network 相关研究 Detection of known and unknown DDoS attacks using Artificial Neural Networks使用神经网络-成功率98% An Anomaly-Based Method for DDoS Attacks Detection using RBF Neural Networks基于包特征-神经网络 MLlib： machine learning in apache sparkspark介绍 SYNFlood型DDoS攻击检测与防御研究_李铮开发的防DDoS攻击的系统特点：（1）基于信息熵值得实时攻击检测（2）黑白名单技术（3）自学习子系统：包含蜜罐系统和数据挖掘系统，蜜罐系统旁路收集异常网络流量，通过数据挖掘生成防御规则动态更新异常检测阈值、黑白名单列表和协议分析规则，及时调整系统对后续攻击的相应策略 常见的检测方法：1、基于阈值的攻击检测方法：设置一个阈值，高于阈值认定为发生了DDoS攻击。优点是简单，缺点是若低于阈值，即使存在攻击分组也让其通过，使得部分攻击得逞，消耗了带宽资源。 2、基于流量统计的攻击检测方法：TCP协议每接受一个数据包就会返回一个数据包，因此可以认为发送方和接收方传输的数据量是成比例的。如果返回的数据包数量过少，这类数据包应该是被认为是恶意的然后被丢弃， 基于滑动分组的熵检测方法]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[实习]]></title>
    <url>%2F2017%2F01%2F03%2F%5BJava%5D%E5%AE%9E%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[系统总体架构源文件：https://note.youdao.com/yws/res/8735/WEBRESOURCEb9e23c0741530726b0124ee5d3bfd729 1、一个基于Thrift的微服务需要创建三个模块（最终打包成三个Jar包），分别是Core、Server和Adapter core：定义接口。用接口描述语言定义并创建服务 server：Thrift的服务端。依赖core模块，实现core中定义的接口，主要的业务逻辑部分，分为Service层、Dao层、缓存和数据库。微服务就是进行分模块，把各模块放到不同的位置提供服务 adapter：Thrift的客户端。依赖core模块，其他模块如需调用Serve的接口，需引入此jar包 以论坛项目为例，整个论坛项目分为四个模块： bp-forum-core:数据定义和服务创建 bp-forum-server:服务实现 bp-forum-adapter:客户端，与服务器交互 bp-forum-wap:页面显示，通过调用adapter，获取服务 对于每一个微服务都有其各自的core、server、adapter模块 注意：虽然Server和Adapter在同一个工程下，但在实际运行环境中，一般Server运行在A主机，而B主机上的应用程序需要调用A主机上的Server，需要引入Adapter依赖，实现远程服务调用 2、前端数据显示：Freemarker——模板+数据=输出网页 Thrifthttp://www.ibm.com/developerworks/cn/java/j-lo-apachethrift/#ibm-pcon目前流行的服务调用方式有很多种，例如基于 SOAP 消息格式的 Web Service，基于 JSON 消息格式的 RESTful 服务等。其中所用到的数据传输方式包括 XML，JSON 等，然而 XML 相对体积太大，传输效率低，JSON 体积较小，新颖，但还不够完善。本文将介绍由 Facebook 开发的远程服务调用框架 Apache Thrift，它采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk 等创建高效的、无缝的服务，其传输数据采用二进制格式，相对 XML 和 JSON 体积更小，对于高并发、大数据量和多语言的环境更有优势 Guava Cachehttp://www.cnblogs.com/parryyang/p/5777019.html 当某些值会被多次调用时，将数据缓存在内存中提升速度 Guava Cache是一个全内存的本地缓存实现，它提供了线程安全的实现机制。整体上来说Guava cache 是本地缓存的不二之选，简单易用，性能好。 Guava Cache与ConcurrentMap区别最基本的区别是ConcurrentMap会一直保存所添加的元素，直到显式的移除；Guava Cache为了限制内存的占用，通常都是设定为自动回收元素 创建方式 CacheLoader Callable 相同点：从缓存中取key X的值，如果该值已经缓存过了，则返回缓存中的值，如果没有缓存过，可以通过某个方法来获取这个值。 不同点： cacheloader的定义比较宽泛， 是针对整个cache定义的，可以认为是统一的根据key值获取value的方法 callable的方式较为灵活，允许你在get的时候，针对特定key值指定获取方式 1、CacheLoader public class AppkeyInfoLocalCache { /*在创建cache时指定所有key获取value的方法！！！*/ static LoadingCache&lt;String, AppkeyInfoBasic&gt; cache = CacheBuilder.newBuilder().refreshAfterWrite(3, TimeUnit.HOURS)// 给定时间内没有被读/写访问，则回收。 .expireAfterAccess(APIConstants.TOKEN_VALID_TIME, TimeUnit.HOURS)// 缓存过期时间和redis缓存时长一样 .maximumSize(1000).// 设置缓存个数 build(new CacheLoader&lt;String, AppkeyInfoBasic&gt;() { @Override /** 当本地缓存命没有中时，调用load方法获取结果并将结果缓存 **/ public AppkeyInfoBasic load(String appKey) throws DaoException { return getAppkeyInfo(appKey); } /** 数据库进行查询 **/ private AppkeyInfoBasic getAppkeyInfo(String appKey) throws DaoException { //从数据库取值 return ((AppkeyInfoMapper) SpringContextHolder.getBean(&quot;appkeyInfoMapper&quot;)) .selectAppkeyInfoByAppKey(appKey); } }); } 2、Callable @Test public void testcallableCache() throws Exception{ Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000).build(); //设置键jerry取值方式 String resultVal = cache.get(&quot;jerry&quot;, new Callable&lt;String&gt;() { public String call() { String strProValue=&quot;hello &quot;+&quot;jerry&quot;+&quot;!&quot;; return strProValue; } }); System.out.println(&quot;jerry value : &quot; + resultVal); //设置键peida取值方式 resultVal = cache.get(&quot;peida&quot;, new Callable&lt;String&gt;() { public String call() { String strProValue=&quot;hello &quot;+&quot;peida&quot;+&quot;!&quot;; return strProValue; } }); System.out.println(&quot;peida value : &quot; + resultVal); } Mavan多模块http://juvenshun.iteye.com/blog/305865?page=2#comments 所有用Maven管理的真实的项目都应该是分模块的，每个模块都对应着一个pom.xml。它们之间通过继承和聚合相互关联 简单的Maven模块结构一个简单的Maven模块结构是这样的： app-parent |-- pom.xml (pom) | |-- app-util | |-- pom.xml (jar) | |-- app-dao | |-- pom.xml (jar) | |-- app-service | |-- pom.xml (jar) | |-- app-web |-- pom.xml (war) 上述简单示意图中，有一个父项目(app-parent)聚合很多子项目（app-util, app-dao, app-service, app-web）。每个项目，不管是父子，都含有一个pom.xml文件。而且要注意的是，小括号中标出了每个项目的打包类型。父项目是pom,也只能是pom。子项目有jar，或者war。 多模块的好处用项目层次的划分替代包层次的划分能给我们带来如下好处： 方便重用，如果你有一个新的swing项目需要用到app-dao和app-service，添加对它们的依赖即可，你不再需要去依赖一个WAR。而有些模块，如app-util，完全可以渐渐进化成公司的一份基础工具类库，供所有项目使用。这是模块化最重要的一个目的。 由于你现在划分了模块，每个模块的配置都在各自的pom.xml里，不用再到一个混乱的纷繁复杂的总的POM中寻找自己的配置。 如果你只是在app-dao上工作，你不再需要build整个项目，只要在app-dao目录运行mvn命令进行build即可，这样可以节省时间，尤其是当项目越来越复杂，build越来越耗时后。 某些模块，如app-util被所有人依赖，但你不想给所有人修改，现在你完全可以从这个项目结构出来，做成另外一个项目，svn只给特定的人访问，但仍提供jar给别人使用 RPCGRPCThrift Spring获取ApplicationContext需要将ApplicationContext保存至某个静态类中提供接口获取，那必须要在某一个地方将ApplicationContext设置进来。无法直接获取，因为获取ApplicationContext是需要上下文条件限制的。在Web环境下可以直接通过ServletContext获取。如果Bean对象本身被IoC容器所管理可直接通过注解获取。 方法一：非spring管理的类中要获得applicationcontext //获取ServletConetxt实例 HttpServletRequest httprequest = (HttpServletRequest)ServletActionContext.getRequest(); ServletContext sc = httprequest.getSession().getServletContext(); //使用 WebApplicationContextUtils.getWebApplicationContext(ServletContext) ApplicationContext wac = WebApplicationContextUtils.getWebApplicationContext(sc); 方法二：新建一个ApplicationContextHolder类，保存ApplicationContext实例 @Autowired private ApplicationContext applicationContext; 方法三：在自己定义的bean中获得 applicationcontext，可以让该bean实现applicationcontextaware接口，记得把这个bean 配置在spring的配置文件里 public class MyApplicationContext implements ApplicationContextAware { private ApplicationContext applicationContext; public void setApplicationContext(ApplicationContext ac) throws BeansException { this.applicationContext = ac; } public ApplicationContext getApplicationContext(){ return applicationContext; } } spring 的配置如下 &lt;bean id=&quot;myapplicationcontext&quot; class=&quot;com.my.utils.MyApplicationContext&quot;&gt; &lt;/bean&gt; 通过上面2种方式都可以获取到ApplicationContext如果楼主需要将ApplicationContext保存至某个静态类中提供接口获取，那必须要在某一个地方将ApplicationContext设置进来。无法直接获取。因为获取ApplicationContext是需要上下文条件限制的。在Web环境下可以直接通过ServletContext获取。如果Bean对象本身被IoC容器所管理可直接通过注解获取。 翻墙工具ShadowSocketlantern 全局gitignore$ git config –global core.excludesFile /c/gitignore$ git config –list 测试环境cd /opt/nuc_git/bp-salt-deploy/服务器ip：10.16.5.231账号：root密码：LXRoxqIqV4]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java反射]]></title>
    <url>%2F2016%2F12%2F30%2F%5BJava%5DJava%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[反射的基石-&gt;ClassJava类用于描述一类事物的共性，该类事物有什么属性，没有什么属性，至于这个属性的值是什么，则是由这个类的实例对象来确定，不同的实例对象有不同的属性值。Java程序中的各个Java类属于同一类事物，描述这类事物的Java类名就是Class。 例：众多的人可以用一个Person类来表示，那么众多的Java类也就可以用一个Class类来表示。 Person类代表人，它的实例对象就是张三，李四这样的一个个具体的人，Class类代表Java类，它的各个实例对象又分别对应各个类的内存中的字节码，例如，Person类的字节码，ArrayList类的字节码，等等。 ####什么是字节码 一个类被类加载器加载到内存中，占用一片内存空间，这个空间里面的内容就是类的字节码，不同的类的字节码是不同的，所以它们在内存中的内容是不同的，这个一个个的空间可以分别用一个个的对象来表示，这些对象显然具有相同的类型，这个类型是什么呢？Class类型 ####如何得到各个字节码对应的实例对象（Class类型） 类名.class,例如，System.class 对象.getClass(),例如，new Date().getClass() Class.forName(“类名”),例如，Class.forName(“java.util.Date”); 开发中使用较多的是Class.forName（”类名”）的方式，按参数中指定的字符串形式的类名去搜索并加载相应的类，如果该类字节码已经被加载过，则返回代表该字节码的Class实例对象，否则，按类加载器的委托机制去搜索和加载该类，如果所有的类加载器都无法加载到该类，则抛出ClassNotFoundException。123456String str1 = "abc";Class c1s1 = str1.getClass();Class c1s2 = String.class;Class c1s3 = Class.forName("java.lang.String");System.out.println(c1s1 == c1s2);//trueSystem.out.println(c1s2 == c1s3);//true 结果说明： 1. 一份字节码可以得到多个实例对象 2. 各个实例对象都将得到同一份字节码 ####九个预定义Class实例对象 isPrimitive() : 字节码是否是基本类型123456System.out.println(String.class.isPrimitive());//falseSystem.out.println(int.class.isPrimitive());//trueSystem.out.println(Integer.class.isPrimitive());//falseSystem.out.println(int.class == Integer.TYPE);//trueSystem.out.println(int[].class.isPrimitive());//falseSystem.out.println(int[].class.isArray());//true ####总结 Java类被类加载器加载到内存中，开辟一段内存空间，这段空间的内容就是类的字节码。不同的类生成不同的字节码，每个字节码可以用一个个对象表示，这些对象具有相同的类型，即Class类型。 ###2. 理解反射的概念 反射就是把Java类中的各种成分映射成相应的Java类。例如，一个Java类中用Class类的对象来表示，一个类中的组成部分：成员变量、方法、构造方法、包等信息也用一个个的Java类来表示。表示Java类的Class类显然要提供一系列的方法，来获取其中的变量、方法、构造方法、修饰符、包等信息，这些信息就是用相应的实例对象来表示，它们是Field、Method、Constructor、Package等等。 例如，System.exit和System.getProperties()方法，分别可以用Method类的methodObj1，methodOjb2表示。 ###3. Constructor类 Constructor类代表某个类中的一个构造方法。 ####得到某个类所有的构造方法 Constructor [] constructors = Class.forName(&quot;java.lang.String&quot;).getConstructors(); ####得到某一个构造方法（根据参数来获取） Constructor constructor = Class.forName(“java.lang.String”).getConstructor(StringBuffer.class); ####创建实例对象 通常方式：String str = new String(new StringBuffer(&quot;abc&quot;)); 反射方式：String str = (String)constructor.newInstance(new StringBuffer(&quot;abc&quot;)); ####Class.newInstance()方法 例子:String obj = (String)Class.forName(&quot;java.lang.String&quot;).newInstance(); 该方法内部先得到默认的构造方法，然后用该构造方法创建实例对象。 该方法内部的具体代码用到了缓存机制来保存默认构造方法的实例对象。 ###4.成员变量的反射(Field类) 1. Field类代表某个类中的一个成员变量 2. 问题：得到的Field对象是对应到类上面的成员变量，还是对应到对象上的成员变量？ 类只有一个，而该类的实例对象有多个，如果是与对象关联，那关联那个对象呢？所以字段Field代表的是类的成员变量，而不是具体的变量。 Field getDeclaredField(String name)返回一个 Field 对象，该对象反映此 Class 对象所表示的类或接口的指定已声明字段。 Field[] getDeclaredFields()返回 Field 对象的一个数组，这些对象反映此 Class 对象所表示的类或接口所声明的所有字段。 Field getField(String name)返回一个 Field 对象，它反映此 Class 对象所表示的类或接口的指定公共成员字段。 Field[] getFields()返回一个包含某些 Field 对象的数组，这些对象反映此 Class 对象所表示的类或接口的所有可访问公共字段。 代码：12345678910111213141516171819202122232425import java.lang.reflect.*;public class ReflectTest &#123; public static void main(String[] args) throws Exception&#123; ReflectPoint pt1 = new ReflectPoint(3,5); Field fieldY = pt1.getClass().getField("y"); //fieldY的值是多少？是5？错，fieldY不是对象身上的变量，而是类上的，要用它去取某个对象上对应的值 System.out.println(fieldY.get(pt1));//5 //fieldX为私有的，.getField("x")取不到，得用.getDeclaredField("x") Field fieldX = pt1.getClass().getDeclaredField("x"); //由于私有，不可访问，使用setAccessible(true)，可以表示可以取 fieldX.setAccessible(true); //能够取到x的值 System.out.println(fieldX.get(pt1));//3 &#125;&#125;class ReflectPoint &#123; private int x; public int y; public ReflectPoint(int x, int y) &#123; super(); this.x = x; this.y = y; &#125;&#125; ####成员变量反射的综合案例代码：12345678910111213141516171819202122232425262728293031323334import java.lang.reflect.*;public class ReflectTest &#123; public static void main(String[] args) throws Exception&#123; ReflectPoint pt1 = new ReflectPoint(3,5); changeStringValue(pt1); System.out.println(pt1); &#125; private static void changeStringValue(Object obj) throws Exception &#123; Field[] fields = obj.getClass().getFields(); for(Field field : fields)&#123; //对应同一份字节码，所以用== if(field.getType()==String.class)&#123; String oldValue = (String)field.get(obj); String newValue = oldValue.replace('b', 'a'); field.set(obj,newValue); &#125; &#125; &#125;&#125;class ReflectPoint &#123; private int x; public int y; public String str1 = "ball"; public String str2 = "basketball"; public String str3 = "itcast"; public ReflectPoint(int x, int y) &#123; super(); this.x = x; this.y = y; &#125; public String toString() &#123; return str1+":"+str2+":"+str3; &#125;&#125; ###5. 成员方法的反射 Method类代表某个类中的一个成员方法 得到类中的某一个方法： Method charAt = Class.forName(&quot;java.lang.String&quot;).getMethod(&quot;charAt&quot;, int.class); 调用方法： 通常方式：System.out.println(str.charAt(1)); 反射方式：System.out.println(charAt.invoke(str, 1)); 如果传递给Method对象的invoke()方法的第一个参数为null，这有着什么样的意义呢？说明该Method对象对应的是一个静态方法！ ####jdk1.4和jdk1.5的invoke方法的区别 Jdk1.5：public Object invoke(Object obj,Object… args) Jdk1.4：public Object invoke(Object obj,Object[] args) 即按jdk1.4的语法，需要将一个数组作为参数传递给invoke方法时，数组中的每个元素分别对应被调用方法中的一个参数，所以，调用charAt方法的代码也可以用Jdk1.4改写为 charAt.invoke(“str”, new Object[]{1})形式。代码：123456789import java.lang.reflect.*;public class ReflectTest &#123; public static void main(String[] args) throws Exception&#123; Method methodCharAt = String.class.getMethod("charAt", int.class); System.out.println(methodCharAt.invoke("abc",1 )); //System.out.println(methodCharAt.invoke(null,1 ));如果为null则为静态方法 //System.out.println(methodCharAt.invoke("abc",new Object[]&#123;2&#125; ));1.5以前，没有可变参数，这么写 &#125;&#125; ###6. 对接收数组参数的成员方法进行反射 问题：平时如何调用一个类的main方法？123456789101112public class ReflectTest &#123; public static void main(String[] args)&#123; TestArgument.main(new String[]&#123;"aa", "bb", "cc"&#125;); &#125;&#125;class TestArgument&#123; public static void main(String[] args)&#123; for(String arg : args)&#123; System.out.println(arg); &#125; &#125;&#125; 问题：当不知道类的名字时（类的名字作为参数），如何调用该类的main方法？ 用反射的方式，这就是反射的作用，可以将类的名字作为参数传入，启动main方法。 启动Java程序的main方法的参数是一个字符串数组，即public static void main(String[] args)，通过反射方式来调用这个main方法时，如何为invoke方法传递参数呢？ 按jdk1.5的语法，整个数组是一个参数，而按jdk1.4的语法，数组中的每个元素对应一个参数，当把一个字符串数组作为参数传递给invoke方法时，javac会到底按照哪种语法进行处理呢？ jdk1.5肯定要兼容jdk1.4的语法，会按jdk1.4的语法进行处理，即把数组打散成为若干个单独的参数。所以，在给main方法传递参数时，不能使用代码mainMethod.invoke(null,new String[]{“xxx”})，javac只把它当作jdk1.4的语法进行理解，而不把它当作jdk1.5的语法解释，因此会出现参数类型不对的问题。 解决办法： mainMethod.invoke(null,new Object[]{new String[]{“xxx”}}); mainMethod.invoke(null,(Object)new String[]{“xxx”}); //编译器会作特殊处理，编译时不把参数当作数组看待，也就不会数组打散成若干个参数了 代码：123456789101112131415161718192021222324252627import java.lang.reflect.*;public class ReflectTest &#123; public static void main(String[] args) throws Exception&#123; TestArguments.main(new String[]&#123;"sadfds","hjhgj"&#125;); System.out.println("-----------------------------"); String startingClassName = args[0]; Method mainMethod = Class.forName(startingClassName).getMethod("main", String[].class); mainMethod.invoke(null, (Object)new String[]&#123;"sadfds","hjhgj"&#125;); System.out.println("-----------------------------"); //不只是main方法，普通方法也一样 Method testMethod = Class.forName(startingClassName).getMethod("test", String[].class); testMethod.invoke(null, new String[]&#123;"sadfds","hjhgj"&#125;); &#125;&#125;class TestArguments&#123; public static void main(String[] args)&#123; for(String arg : args)&#123; System.out.println(arg); &#125; &#125; public static void test(String[] args)&#123; for(String arg : args)&#123; System.out.println(arg); &#125; &#125;&#125; ###7. 数组与Object的关系及其反射类型 具有相同维数和元素类型的数组属于同一个类型，即具有相同的Class实例对象。 代表数组的Class实例对象的getSuperClass()方法返回的父类为Object类对应的Class。 基本类型的一维数组可以被当作Object类型使用，不能当作Object[]类型使用。 非基本类型的一维数组，既可以当做Object类型使用，又可以当做Object[]类型使用。 代码举例：1234567891011121314151617181920212223242526import java.lang.reflect.*;public class ReflectTest &#123; public static void main(String[] args) throws Exception&#123; int[] a1 = new int[3]; int[] a2 = new int[4]; int[][] a3 = new int[2][3]; String[] a4 = new String[3]; System.out.println(a1.getClass()==a2.getClass());//true System.out.println(a1.getClass().getName());//[I(数组整形) //父类的名字 System.out.println(a1.getClass().getSuperclass().getName());//java.lang.Object System.out.println(a2.getClass().getSuperclass().getName());//java.lang.Object System.out.println(a3.getClass().getSuperclass().getName());//java.lang.Object System.out.println(a4.getClass().getSuperclass().getName());//java.lang.Object System.out.println(String.class.getSuperclass().getName());//java.lang.Object System.out.println(StringBuffer.class.getSuperclass().getName());//java.lang.Object //发现a1，a2，a3，a4的super都是objcet所以可以类型转换 //结论：int[]一维数组是Object,String是Object，int是基本类型，不是Object Object aObj1 = a1; Object aObj2 = a4; //Object[] aObj3 = a1;不对 int 不可以直接转为object Object[] aObj4 = a3; Object[] aObj5 = a4; &#125;&#125; Arrays.asList()方法处理int[]和String[]时的差异。12System.out.println(Arrays.asList(a1)); //[[I@55f33675]System.out.println(Arrays.asList(a4)); //[aa, bb, cc] ####数组的反射应用 Array工具类用于完成对数组的反射操作。1234567891011121314printObject(a4);//aa bb cc printObject("zyz");//zyz## 标题 ## private static void printObject(Object obj)&#123; Class clazz = obj.getClass(); if(clazz.isArray())&#123; int len = Array.getLength(obj); for(int i=0;i&lt;len;i++)&#123; System.out.println(Array.get(obj, i)); &#125; &#125;else&#123; System.out.println(obj); &#125; &#125; 获取类的泛型类型public static Class getActualType(Class entity){ //ParameterizedType:参数类型 ParameterizedType parameterizedType = (ParameterizedType) entity.getGenericSuperclass(); //获得真实类型参数数组 [0]表示第一个 Class entityClass = (Class) parameterizedType.getActualTypeArguments()[0]; return entityClass; }]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程与并发库高级应用]]></title>
    <url>%2F2016%2F12%2F14%2F%5BJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%5DJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%E5%BA%93%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[多线程与效率 多线程并不一定会提高程序的运行效率，反而会降低效率 多线程的应用不是为了提高运行效率，而是为了提高资源使用效率；当一个资源在等待I/O输入时，另一个线程可以使用处理器，提高了资源的利用率 为什么使用多线程下载速度会变快？多线程下载：并不是自己电脑快了，而是抢到更多服务器资源。例：服务器为一个客户分配一个20K的线程下载，你用多个线程，服务器以为是多个用户就分配了多个20K的资源给你 并行与并发 并行指多个事件在同一时刻发生，并行需要有多个CPU 并行是在同一个CPU上按照时间片的划分运行多个程序，在宏观上看两个任务同时执行，但是在同一时刻只有一个任务在执行 并发编程的挑战 并发编程的 目的 是让程序运行得更快，但是并不是启动越多的线程就能让程序跑的更快 如果希望多线程执行任务使程序运行得更快，需要面临许多挑战，比如：上下文切换、死锁、资源限制问题 上下文切换多线程 CPU为每个线程划分 时间片，每个线程在给定的时间片上交替运行。因为时间片非常短，从宏观上我们感觉多个线程同时运行 单核 处理器也支持多线程执行代码 上下文切换概念 每个线程在给定的时间片上运行，执行结束后会 切换 到下一个任务。但是在切换前会保存上一个任务的状态，以便下次切换回来后可以 继续加载 这个任务的状态，从保存到加载的过程称为一次上下文切换 多线程速度一定快？ 不一定，用得得当多线程的任务执行速度比串行快；但是线程有创建和上下文切换的开销，有时候并发执行速度比串行慢 如何减小上下文切换 无锁并发编程：多线程竞争锁时会引起上下文切换，可以用一些方法来避免使用锁，如数据分段，每个线程处理不同段的数据 CAS算法：Java的Atomic包使用CAS算法来更新数据，而不需要使用锁 使用最少线程：避免创造不需要的线程，比如任务少，线程多，造成大量线程处于等待状态 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换 死锁举个例子 Thread t1 = new Thread(new Runnable(){ @Override public void run(){ synchronized(A){ Thread.sleep(2000); synchronized(B){} } } }); Thread t2 = new Thread(new Runnable(){ @Override public void run(){ synchronized(B){ Thread.sleep(2000); synchronized(A){} } } }); 线程1：持有锁A，等待锁B线程2：持有锁B，等待锁A 线程1和线程2互相等待对方释放锁，引起死锁 避免死锁的一些方法 避免一个线程同时获取多个锁 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源 尝试使用定时锁，使用 .tryLock(timeout)来替代使用内部锁机制 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况 线程状态 线程创建完毕后进入new状态 调用了线程的start方法后，线程进入Runnable状态，放入jVM的可运行线程队列中，等待CPU的执行权 当线程执行时，线程状态变为Running 线程执行sleep、wait、join或者进入了IO阻塞、锁等待时，则进入Wait或Block状态 创建线程的两种传统方式传统是相对于 JDK 1.5 而言的 继承Thread创建Thread的子类，覆盖其中的run方法，运行这个子类的 start 方法即可开启线程 public class ThreadTest1 { public static void main(String[] args) { // TODO Auto-generated method stub Thread thread = new Thread() { @Override public void run() { while (true) { // 获取当前线程对象 获取线程名字 System.out.println(Thread.currentThread().getName()); // 让线程暂停，休眠，此方法会抛出中断异常InterruptedException try { Thread.sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } } } }; thread.start(); } } 实现Runnable接口创建Thread时传递一个实现Runnable接口的对象实例(用的比较多，因为符合面向对象编程的思路) public class ThreadTest1 { public static void main(String[] args) { // TODO Auto-generated method stub Thread thread = new Thread(new Runnable() { @Override public void run() { while (true) { System.out.println(Thread.currentThread().getName()); try { Thread.sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } } } }); thread.start(); } } 面试题★★★问题：下边的线程运行的是Thread子类中的run方法还是实现Runnable接口类的run方法 public class ThreadTest1 { public static void main(String[] args) { // TODO Auto-generated method stub new Thread(new Runnable() {////b、传递实现Runnable接口的对象 @Override public void run() { // TODO Auto-generated method stub System.out.println(&quot;2&quot;); } }){//a、覆盖Thread子类run方法 @Override public void run() { System.out.println(&quot;1&quot;); } }.start(); } } 分析：查看Thread的源代码，注意run方法，在如果传入的Runnable对象不为空，则去执行Runnable对象的run方法 public class Thread implements Runnable { private Runnable target; public Thread(Runnable target) { init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0); } public void run() { if (target != null) { target.run(); } } } 但是在这里，子类run方法实际就是覆盖父类中的run方法，如果覆盖了就用子类的run方法，不会再找Runnable中的run方法了，所以运行的是子类中的run方法 总结由Thread类中的run方法源代码中看出，两种传统创建线程的方式都是在调用Thread对象的run方法 如果子类重写父类的run方法，则调用子类的run方法 如果Thread对象的run方法没有被覆盖，并且像为Thread对象传递了一个Runnable对象，就会调用Runnable对象的run方法 定时器定时器在游戏上很常用，例如俄罗斯方块下降，贪吃蛇往前移动等 定时器的使用 一段时间后执行，第一个参数为任务，第二个参数为等待时间，单位是毫秒 new Timer().schedule(new TimerTask() { @Override public void run() { System.out.println(&quot;boom!&quot;); } }, 1000); 一段时间后执行，以后每隔多少时间再次执行，第一个参数为任务，第二个参数为等待多长时间，第三个参数为每隔多长时间执行一次 new Timer().schedule(new TimerTask() { @Override public void run() { System.out.println(&quot;boom!&quot;); } }, 0, 1000); 显示计时信息： //计时 new Timer().schedule(new TimerTask() { @Override public void run() { // TODO Auto-generated method stub while(true){ System.out.println(new Date().getSeconds()); try { Thread.sleep(1000); } catch (Exception e) { // TODO: handle exception } } } }, 0); Java内存模型 线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。 传统线程互斥技术 如果多个线程对同一个资源操作，会引起安全问题（多卖票），使出现的结果和预期的不一样 代码实现原子性：有一个线程正在使用这个方法的代码，别的线程就不能再使用。就和厕所里的坑一样，已经有人在用了，别人就不能再去用了。Java中某段代码要实现排他性，就将这段代码用synchronized关键字保护起来 synchronized（this）｛ for (int i=0; i&lt;len; i++) System.out.println(name.charAt(i));//逐个字符打印 System.out.println(); } 注意：要实现互斥，在这个位置必须使用的锁必须是同一个对象，即在同一个对象上进行同步，这样的话，有一个线程进入保护区域后，没出来的话，别的线程就不能进入保护区域 互斥方法： a、同步代码块 synchronized (lock){} b、同步方法 1、方法返回值前加synchronized，同步方法上边用的锁就是this对象 2、静态同步方法使用的锁是该方法所在的class对象 案例：output1和output2互斥，因为互斥变量都为当前对象 123456789101112131415161718class Outputer &#123; public void output1(String name) &#123; synchronized (this) &#123; int len = name.length(); for (int i = 0; i &lt; len; i++) System.out.print(name.charAt(i)); System.out.println(); &#125; &#125; public synchronized void output2(String name) &#123; int len = name.length(); for (int i = 0; i &lt; len; i++) System.out.print(name.charAt(i)); System.out.println(); &#125;&#125; 此时为静态函数，要实现互斥，使用Outputer的字节码 1234567891011121314151617static class Outputer &#123; public static void output1(String name) &#123; synchronized (Outputer.class) &#123; int len = name.length(); for (int i = 0; i &lt; len; i++) System.out.print(name.charAt(i)); System.out.println(); &#125; &#125; public static synchronized void output2(String name) &#123; int len = name.length(); for (int i = 0; i &lt; len; i++) System.out.print(name.charAt(i)); System.out.println(); &#125;&#125; 锁对象Lock-同步问题更完美的处理方式读写锁(ReadWriteLock)我们会有一种需求，在对数据进行读写的时候，为了保证数据的一致性和完整性，需要读和写是互斥的，写和写是互斥的，但是读和读是不需要互斥的，这样读和读不互斥性能更高些 class Data { private int data;// 共享数据 private ReadWriteLock rwl = new ReentrantReadWriteLock(); public void set(int data) { rwl.writeLock().lock();// 取到写锁 try { System.out.println(Thread.currentThread().getName() + &quot;准备写入数据&quot;); try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } this.data = data; System.out.println(Thread.currentThread().getName() + &quot;写入&quot; + this.data); } finally { rwl.writeLock().unlock();// 释放写锁 } } public void get() { rwl.readLock().lock();// 取到读锁 try { System.out.println(Thread.currentThread().getName() + &quot;准备读取数据&quot;); try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + &quot;读取&quot; + this.data); } finally { rwl.readLock().unlock();// 释放读锁 } } } Synchronized和Lock的区别1、用sychronized修饰的方法或者语句块在代码执行完之后锁自动释放，而用Lock需要我们手动释放锁，所以为了保证锁最终被释放(发生异常情况)，要把互斥区放在try内，释放锁放在finally内。 2、synchronized简单，简单意味着不灵活，而ReentrantLock的锁机制给用户的使用提供了极大的灵活性。这点在Hashtable和ConcurrentHashMap中体现得淋漓尽致。synchronized一锁就锁整个Hash表，而ConcurrentHashMap则利用ReentrantLock实现了锁分离，锁的知识segment而不是整个Hash表 3、synchronized是不公平锁，而ReentrantLock可以指定锁是公平的还是非公平的 4、synchronized实现等待/通知机制通知的线程是随机的，ReentrantLock实现等待/通知机制可以有选择性地通知 5、和synchronized相比，ReentrantLock提供给用户多种方法用于锁信息的获取，比如可以知道lock是否被当前线程获取、lock被同一个线程调用了几次、lock是否被任意线程获取等等 传统线程同步通信技术（wait、notify、notifyAll）双重检查调用Object的wait方法可以让当前线程进入等待状态，程序不能往下执行，只有调用了此Object的notify、或notifyAll方法，或者wait到达了指定的时间后，才会激活继续执行 notify只是随机找处于等待此Object的一个线程；notifyAll是通知wait此Object的所有线程 为了防止假唤醒，提高程序的可靠性，wait被唤醒后，需要再次判断等待的状态是否被更改了，如果未更改，则继续进入wait状态，这种做法称作双重检查。查看一下代码，即加上了while进行双重检查，而且wait操作写在最前面 1234while (current == connections.length) &#123; System.out.println(Thread.currentThread().getName() + &quot;在等待&quot;); this.wait();&#125; wait/notify机制原理当调用了对象的wait方法后，JVM程序执行引擎将此线程放入一个wait集合中，并释放此对象的锁（本来加上了synchronized只能有一个线程处于等待状态，现在可以多个线程处于等待状态） 当其他线程调用此对象的notify方法时，会从wait集合中随机找一个等待的此对象上的线程，并将其从wait集合中删除，JVM线程执行引擎就可以再次调度此线程了 当使用 notifyAll 方法时，则会删除 wait 集合中所有等待此对象的线程 面试题线程同步就是线程按照先后的次序运行，即”我执行完之后然后你执行” 面试题：子线程循环10次，接着主线程循环100，接着又回到子线程循环10次，接着再回到主线程又循环100，如此循环50次，请写出程序 /** * 面试题：子线程循环10次，接着主线程循环100， * 接着又回到子线程循环10次，接着再回到主线程又循环100， * 如此循环50次，请写出程序 */ /** 解题思路：线程交替运行，这是一个线程同步问题 * 1、首先保证子任务和主任务执行过程中不冲突：将子任务和主任务封装在business类中，使用关键词Synchronized保证代码块的原子性 * 2、子任务、主任务前后执行顺序控制：使用wait/notify机制，使用boolean类型的isSub变量控制当前应该执行哪个任务，如果不该执 * 行则休眠，否则执行；执行结束后必须反转isSub变量，然后通知阻塞进程继续执行 * 3、交替执行50次：子任务和主任务各自循环50次，在第2步时已经保证子任务和主任务的交替运行，完成要求 */ class TwoThreadSynchronized { public static void main(String[] args){ final Bussiness bussiness = new Bussiness(); new Thread(new Runnable() { @Override public void run() { for(int i = 0; i &lt; 50; i++) bussiness.main(i+1); } }).start(); new Thread(new Runnable() { @Override public void run() { for(int i = 0; i &lt; 50; i++) bussiness.sub(i+1); } }).start(); } } class Bussiness{ //共享变量，子任务先开始 boolean isSub = true; public synchronized void main(int loop){ while(isSub){ try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(&quot;第&quot; + loop + &quot;次循环：&quot;); System.out.print(&quot;main：&quot;); for(int i = 0; i &lt; 100; i++){ System.out.print(i + &quot; &quot;); } System.out.println(); isSub = true; notify(); } public synchronized void sub(int loop){ while(!isSub){ try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(&quot;第&quot; + loop + &quot;次循环：&quot;); System.out.print(&quot;sub：&quot;); for(int i = 0; i &lt; 10; i++){ System.out.print(i + &quot; &quot;); } System.out.println(); isSub = false; notify(); } } 线程间通信(Condition:await、signal)★★★★★需求：要求线程1和线程2互不干扰，并且交替执行 设计： 互不干扰干扰可以让两个线程在同一个对象上同步，通过Synchronized或者Lock对象。 方案一：两个方法都用Synchronized修饰，两个方法互斥 方案二：同一个Lock成员变量，每个方法开始的时候使用lock.lock()，try-finally格式，finally执行lock.unlock(); 交替运行可以设置一个标志位，如果为true执行A，如果为false执行B；如果条件标志位不符，线程处于阻塞状态 创建Condition，调用conditon的await、signal方法。当方法不满足条件时，await；满足条件后更改标志位，并且signal唤醒 class Business { private boolean bool = true; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public /*synchronized*/ void main(int loop) throws InterruptedException { lock.lock(); try { while(bool) { condition.await();//this.wait(); } for(int i = 0; i &lt; 100; i++) { System.out.println(&quot;main thread seq of &quot; + i + &quot;, loop of &quot; + loop); } bool = true; condition.signal();//this.notify(); } finally { lock.unlock(); } } public /*synchronized*/ void sub(int loop) throws InterruptedException { lock.lock(); try { while(!bool) { condition.await();//this.wait(); } for(int i = 0; i &lt; 10; i++) { System.out.println(&quot;sub thread seq of &quot; + i + &quot;, loop of &quot; + loop); } bool = false; condition.signal();//this.notify(); } finally { lock.unlock(); } } } 在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现，这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。 生产者消费者模式设计+互斥操作： 线程间通信： 这是一个处于多线程工作环境下的缓存区，缓存区提供了两个方法，put和take，put是存数据，take是取数据，内部有个缓存队列，这个缓存区类实现的功能：有多个线程往里面存数据和从里面取数据，其缓存队列(先进先出后进后出)能缓存的最大数值是100，多个线程间是互斥的，当缓存队列中存储的值达到100时，将写线程阻塞，并唤醒读线程，当缓存队列中存储的值为0时，将读线程阻塞，并唤醒写线程，这也是ArrayBlockingQueue的内部实现 多个Condition的好处： 假设缓存队列中已经存满，那么阻塞的肯定是写线程，唤醒的肯定是读线程，相反，阻塞的肯定是读线程，唤醒的肯定是写线程。那么假设只有一个Condition会有什么效果呢，缓存队列中已经存满，这个Lock不知道唤醒的是读线程还是写线程了，如果唤醒的是读线程，皆大欢喜，如果唤醒的是写线程，那么线程刚被唤醒，又被阻塞了，这时又去唤醒，这样就浪费了很多时间。 代码： class BoundedBuffer{ final Locklock = newReentrantLock();//锁对象 final Condition notFull = lock.newCondition();//写线程条件 final Condition notEmpty = lock.newCondition();//读线程条件 final Object[] items = new Object[100];//缓存队列 intputptr/*写索引*/,takeptr/*读索引*/,count/*队列中存在的数据个数*/; public void put(Object x) throws InterruptedException{ lock.lock(); try{ while(count == items.length)//如果队列满了 notFull.await();//阻塞写线程 items[putptr] = x;//赋值 if(++putptr == items.length) putptr = 0;//如果写索引写到队列的最后一个位置了，那么置为0 ++count;//个数++ notEmpty.signal();//唤醒读线程 }finally{ lock.unlock(); } } public Object take() throws InterruptedException{ lock.lock(); try{ while(count == 0)//如果队列为空 notEmpty.await();//阻塞读线程 Objectx = items[takeptr];//取值 if(++takeptr == items.length) takeptr = 0;//如果读索引读到队列的最后一个位置了，那么置为0 --count;//个数-- notFull.signal();//唤醒写线程 return x; }finally{ lock.unlock(); } } } ThreadLocal实现线程范围内的数据共享什么是线程范围内的数据共享？一个线程内部的各个函数都能访问该共享变量，而其他线程不能访问（区别于静态变量，静态变量能被所有线程访问，但需要解决线程间数据同步的问题） 应用： 用户访问Web服务器，服务器启动一条线程处理用户请求，不同用户之间不受干扰 用户访问数据库，每个用户使用独立的connection。不然会出现A用户开启事务，操作还没有结束，B用户使用的是相同的connection，提交事务，导致A用户还未完成操作但事务提交了 自己的实现的线程范围内的数据共享使用全局的map，键为线程，值为该线程中需要共享的变量。每次取值时，传入当前的线程，即可取到当前线程共享的变量 public class ThreadLocalTest { //键为当前线程，值为线程范围内的共享变量 static Map&lt;Thread, Integer&gt; map = new HashMap&lt;Thread, Integer&gt;(); public static void main(String[] args){ new Thread(new Runnable() { @Override public void run() { map.put(Thread.currentThread(),1); System.out.println(&quot;A:&quot; + new A().get()); } }).start(); new Thread(new Runnable() { @Override public void run() { map.put(Thread.currentThread(),2); System.out.println(&quot;B:&quot; + new A().get()); } }).start(); } static class A{ public Integer get(){ return map.get(Thread.currentThread()); } } } 使用 ThreadLocal 实现的线程间数据共享public class ThreadLocalTest { static ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;Integer&gt;(); public static void main(String[] args){ new Thread(new Runnable() { @Override public void run() { threadLocal.set(1); System.out.println(&quot;A:&quot; + new A().get()); } }).start(); new Thread(new Runnable() { @Override public void run() { threadLocal.set(2); System.out.println(&quot;B:&quot; + new A().get()); } }).start(); } static class A{ public Integer get(){ return threadLocal.get(); } } } 原理： 1、1个ThreadLocal代表一个与线程绑定的值2、线程中存储多个ThreadLocal的值，用Map存储 public class ThreadLocal&lt;T&gt; { public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; } return setInitialValue(); } ThreadLocalMap getMap(Thread t) { return t.threadLocals; } } 使用 ThreadLocal 实现线程范围内的单例 每个线程都使用一个类的实例，实现这个功能需要结合ThreadLocal，与线程绑定 单例模式无法实现，是在整个应用中保持单例 应用：对于每一个用户请求，对应一个线程，为之创建一个容器，仅供该用户使用。该容器可以使用线程范围内的单例来实现 public class ThreadLocalTest { public static void main(String[] args){ new Thread(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread() + " " + Person.getThreadLocalInstance()); System.out.println(Thread.currentThread() + " " + Person.getThreadLocalInstance()); } }).start(); new Thread(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread() + " " + Person.getThreadLocalInstance()); System.out.println(Thread.currentThread() + " " + Person.getThreadLocalInstance()); } }).start(); } } class Person{ private static ThreadLocal threadLocal = new ThreadLocal(); public static Person getThreadLocalInstance(){ Person person = threadLocal.get(); if(person == null){ person = new Person(); threadLocal.set(person); } return person; } private String name; private Integer age; public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } public String getName() { return name; } } ThreadLocal 设计 ThreadLocal原理分析http://blog.csdn.net/huachao1001/article/details/51970237 ThreadLocal里面的实现，主要涉及到以下几个重要类： Thread：大家很熟悉的线程类，一个Thread类自然代表一个线程 ThreadLocal：既然本文是要解析ThreadLocal类，自然就离不开这个类啦 ThreadLocalMap：可以看成一个HashMap，但是它本身具体的实现并没有实现继承HashMap甚至跟java.util.Map都沾不上一点关系。只是内部的实现跟HashMap类似（通过哈希表的方式存储） ThreadLocalMap.Entry：把它看成是保存键值对的对象，其本质上是一个WeakReference对象 ThreadLocal的存取机制可以用下图表示： 1、Thread中有一个ThreadLocalMap属性，存放线程局部变量，是键值对的存储方式，以ThreadLocal对象为键，要保存的变量为值（ThreadLocalMap.Entry是保存键值对的对象） 2、ThreadLocal可以看做是ThreadLocalMap的操作类，在当前线程中通过ThreadLocal的set/get操作，对当前线程中的ThreadLocalMap进行操作 set方法：首先获取当前线程的ThreadLocalMap的引用，然后以ThreadLocal实例作为key，保存的变量为value，保存到当前线程的ThreadLocalMap中 get方法：以当前ThreadLocal实例作为key，取出当前线程的ThreadLocalMap变量中该key的值 3、每个线程都拥有自己的ThreadLocalMap属性，每个线程都是从自己的ThreadLocalMap中取值，所以互不影响 4、作用：可以实现线程范围内的单例、线程范围内数据共享 private static ThreadLocal&lt;Person&gt; threadLocal = new ThreadLocal&lt;Person&gt;(); public static Person getThreadLocalInstance(){ Person person = threadLocal.get(); if(person == null){ person = new Person(); threadLocal.set(person); } return person; } 多个线程之间共享数据的方式探讨1、两个线程的操作一致，可以使用同一个Runnable对象。火车站买票适用这种情况 public class Method1 { public static void main(String[] args){ Runnable runnable = new sell(); new Thread(runnable).start(); new Thread(runnable).start(); } } class sell implements Runnable{ private int ticket = 1000000; public synchronized void sell(){ if(ticket &gt; 0){ ticket--; System.out.println(Thread.currentThread() + &quot; 剩余票&quot; + ticket); } } @Override public void run() { while (true){ sell(); } } } 2、两个线程操作不一样。此时必须设置第三方共享数据，并调用他的方法进行数据操作（推荐） public class Method1 { public static void main(String[] args){ final TrainCenter trainCenter = new TrainCenter(); new Thread(new Runnable() { @Override public void run() { while(true) trainCenter.sell(); } }).start(); new Thread(new Runnable() { @Override public void run() { while(true) trainCenter.sell(); } }).start(); } } class TrainCenter{ private int ticket = 100000; public int getTicket() { return ticket; } public void setTicket(int ticket) { this.ticket = ticket; } public synchronized void sell(){ if(ticket &gt; 0){ ticket--; System.out.println(Thread.currentThread() + &quot; 剩余 &quot; + ticket); } } } 3、共享数据传入Runnable对象中，进行操作 public class Method1 { public static void main(String[] args){ TrainCenter trainCenter = new TrainCenter(); new Thread(new Train1(trainCenter)).start(); new Thread(new Train2(trainCenter)).start(); } } class Train1 implements Runnable{ private TrainCenter trainCenter; public Train1(TrainCenter trainCenter){ this.trainCenter = trainCenter; } @Override public void run() { while(true){ trainCenter.sell(); } } } class Train2 implements Runnable{ private TrainCenter trainCenter; public Train2(TrainCenter trainCenter){ this.trainCenter = trainCenter; } @Override public void run() { while(true){ trainCenter.sell(); } } } class TrainCenter{ private int ticket = 100000; public int getTicket() { return ticket; } public void setTicket(int ticket) { this.ticket = ticket; } public synchronized void sell(){ if(ticket &gt; 0){ ticket--; System.out.println(Thread.currentThread() + &quot; 剩余 &quot; + ticket); } } } 线程池线程池的作用 根据系统自身的环境情况，有效的限制执行线程的数量，超出数量的任务排队等候，等待有任务执行完毕，再从队列最前面取出任务执行 减少创建和销毁线程的次数，每个工作线程可以多次使用 常见线程池1、newSingleThreadExecutor 单个线程的线程池，即线程池中每次只有一个线程工作，单线程串行执行任务 2、newFixedThreadExecutor(n) 固定数量的线程池，没提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队列直到前面的任务完成才继续执行 3、newCacheThreadExecutor（推荐使用） 可缓存线程池，当线程池大小超过了处理任务所需的线程，那么就会回收部分空闲（一般是60秒无执行）的线程，当有任务来时，又智能的添加新线程来执行。 4、newScheduleThreadExecutor 大小无限制的线程池，支持定时和周期性的执行线程 实例： 1、newSingleThreadExecutor public class TestSingleThreadExecutor { public static void main(String[] args){ //创建一个单个线程的线程池 ExecutorService pool = Executors.newSingleThreadExecutor(); //将任务放入池中并执行 pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); //关闭 pool.shutdown(); } } class Task implements Runnable{ @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot;执行中。。。&quot;); } } result： pool-1-thread-1执行中。。。 pool-1-thread-1执行中。。。 pool-1-thread-1执行中。。。 pool-1-thread-1执行中。。。 pool-1-thread-1执行中。。。 2、newFixedThreadExecutor(n) public class TestFixedThreadPool { public static void main(String[] args){ //创建一个固定线程数的线程池 ExecutorService pool = Executors.newFixedThreadPool(2); //将任务放入池中并执行 pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); //关闭 pool.shutdown(); } } result： pool-1-thread-1执行中。。。 pool-1-thread-2执行中。。。 pool-1-thread-1执行中。。。 pool-1-thread-2执行中。。。 pool-1-thread-1执行中。。。 3、newCacheThreadExecutor public class TestCachedThreadPool { public static void main(String[] args) { //创建一个可重用固定线程数的线程池 ExecutorService pool = Executors.newCachedThreadPool(); //将任务放入池中并执行 pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); pool.execute(new Task()); //关闭 pool.shutdown(); } } result： pool-1-thread-1执行中。。。 pool-1-thread-2执行中。。。 pool-1-thread-4执行中。。。 pool-1-thread-3执行中。。。 pool-1-thread-5执行中。。。 JAVA线程池shutdown和shutdownNow的区别shutDown() 当线程池调用该方法时，线程池的状态则立刻变成SHUTDOWN状态。此时，则不能再往线程池中添加任何任务，否则将会抛出RejectedExecutionException异常。但是，此时线程池不会立刻退出，直到添加到线程池中的任务都已经处理完成，才会退出。 shutdownNow() 根据JDK文档描述，大致意思是：执行该方法，线程池的状态立刻变成STOP状态，并试图停止所有正在执行的线程，不再处理还在池队列中等待的任务，当然，它会返回那些未执行的任务。 它试图终止线程的方法是通过调用Thread.interrupt()方法来实现的，但是大家知道，这种方法的作用有限，如果线程中没有sleep 、wait、Condition、定时锁等应用, interrupt()方法是无法中断当前的线程的。所以，ShutdownNow()并不代表线程池就一定立即就能退出，它可能必须要等待所有正在执行的任务都执行完成了才能退出。 线程池定时器这种做法从性能方面讲相对于传统的定时器要好 public static void main(String[] args){ Executors.newScheduledThreadPool(1).scheduleAtFixedRate(new Runnable() { @Override public void run() { System.out.println(&quot;测试开始&quot;); } },0,1, TimeUnit.SECONDS); } Callable和FutureCallable和Future，一个产生结果，一个拿到结果。 Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，Future可以拿到异步执行任务的返回值，下面来看一个简单的例子： public class CallableAndFuture { private FutureTask&lt;Integer&gt; future; public static void main(String[] args) { //复杂操作，需要耗费很长时间，但结果不是立刻需要 Callable&lt;Integer&gt; callable = new Callable&lt;Integer&gt;() { public Integer call() throws Exception { Thread.sleep(10000); return new Random().nextInt(100); } }; FutureTask&lt;Integer&gt; future = new FutureTask&lt;Integer&gt;(callable); new Thread(future).start(); try { Thread.sleep(5000);// 可能做一些事情 if(!future.isDone()){ System.out.println(&quot;任务还没有执行完，先返回默认值0&quot;); } //用户有足够的耐心等待任务执行结束 System.out.println(&quot;任务执行结束：&quot; + future.get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } } FutureTask实现了两个接口，Runnable和Future，所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值，那么这个组合的使用有什么好处呢？假设有一个很耗时的返回值需要计算，并且这个返回值不是立刻需要的话，那么就可以使用这个组合，用另一个线程去计算返回值，而当前线程在使用这个返回值之前可以做其它的操作，等到需要这个返回值时，再通过Future得到，岂不美哉！这里有一个Future模式的介绍：http://openhome.cc/Gossip/DesignPattern/FuturePattern.htm。 并发队列 ConcurrentLinkedQueue 和阻塞队列 LinkedBlockingQueue 用法在Java多线程应用中，队列的使用率很高，多数生产消费模型的首选数据结构就是队列(先进先出)。Java提供的线程安全的Queue可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是BlockingQueue，非阻塞队列的典型例子是ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 LinkedBlockingQueue由于LinkedBlockingQueue实现是线程安全的，实现了先进先出等特性，是作为生产者消费者的首选，LinkedBlockingQueue 可以指定容量，也可以不指定，不指定的话，默认最大是Integer.MAX_VALUE，其中主要用到put和take方法，put方法在队列满的时候会阻塞直到有队列成员被消费，take方法在队列空的时候会阻塞，直到有队列成员被放进来。 package cn.thread; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.LinkedBlockingQueue; /** * 多线程模拟实现生产者／消费者模型 */ public class BlockingQueueTest2 { /** * * 定义装苹果的篮子 * */ public class Basket { // 篮子，能够容纳3个苹果 BlockingQueue&lt;String&gt; basket = new LinkedBlockingQueue&lt;String&gt;(3); // 生产苹果，放入篮子 public void produce() throws InterruptedException { // put方法放入一个苹果，若basket满了，等到basket有位置 basket.put(&quot;An apple&quot;); } // 消费苹果，从篮子中取走 public String consume() throws InterruptedException { // take方法取出一个苹果，若basket为空，等到basket有苹果为止(获取并移除此队列的头部) return basket.take(); } } // 定义苹果生产者 class Producer implements Runnable { private String instance; private Basket basket; public Producer(String instance, Basket basket) { this.instance = instance; this.basket = basket; } public void run() { try { while (true) { // 生产苹果 System.out.println(&quot;生产者准备生产苹果：&quot; + instance); basket.produce(); System.out.println(&quot;!生产者生产苹果完毕：&quot; + instance); // 休眠300ms Thread.sleep(300); } } catch (InterruptedException ex) { System.out.println(&quot;Producer Interrupted&quot;); } } } // 定义苹果消费者 class Consumer implements Runnable { private String instance; private Basket basket; public Consumer(String instance, Basket basket) { this.instance = instance; this.basket = basket; } public void run() { try { while (true) { // 消费苹果 System.out.println(&quot;消费者准备消费苹果：&quot; + instance); System.out.println(basket.consume()); System.out.println(&quot;!消费者消费苹果完毕：&quot; + instance); // 休眠1000ms Thread.sleep(1000); } } catch (InterruptedException ex) { System.out.println(&quot;Consumer Interrupted&quot;); } } } public static void main(String[] args) { BlockingQueueTest2 test = new BlockingQueueTest2(); // 建立一个装苹果的篮子 Basket basket = test.new Basket(); ExecutorService service = Executors.newCachedThreadPool(); Producer producer = test.new Producer(&quot;生产者001&quot;, basket); Producer producer2 = test.new Producer(&quot;生产者002&quot;, basket); Consumer consumer = test.new Consumer(&quot;消费者001&quot;, basket); service.submit(producer); service.submit(producer2); service.submit(consumer); // 程序运行5s后，所有任务停止 // try { // Thread.sleep(1000 * 5); // } catch (InterruptedException e) { // e.printStackTrace(); // } // service.shutdownNow(); } } 原理：1、双向链表，队列中维持头指针和为指针，元素个数的类型是 AtomicInteger2、put的时候使用重入锁，可以被中断； ConcurrentLinkedQueueConcurrentLinkedQueue是Queue的一个安全实现．Queue中元素按FIFO原则进行排序，采用CAS操作，来保证元素的一致性。 原理：1、tail节点不一定指向最后一个元素，也有可能是倒数第二个节点。 为什么这么设计？ 在单线程中，插入节点后，将新插入的节点设置为tail。但是在多线程的情况下，假设有多个插入节点操作A，B，可能会先将B插入的节点设置为tail，然后再将A插入的节点设置为tail，导致tail不是严格的指向尾部指针(如下图)。所以设置tail指针也需要CAS操作 插入节点操作必须使用CAS操作，如果每次移动tail指针也要采用CAS，移动tail指针操作也会影响插入节点的CAS操作（因为在插入节点的CAS操作时，要保证tail为最后一个节点），那样会特别影响性能，导致操作容易失败，所以采用延时移动tail指针 如果tail指针离最后一个节点的距离很大，每次要遍历到最后一个节点，特别耗时，所以当tail指针离最后一个节点的距离超过2，让tail节点指向最后一个节点 2、如何插入节点★★★★★★ 如果tail为最后一个节点，采用CAS操作加入新节点（预期p的next节点为null，如果是则将p的next设置为新节点；否则重试） 如果tail不是最后一个节点，p后移一位指向最后一个元素，继续循环 如果tail指针与新插入的指针距离相差2（代码中由p！=t体现），则CAS更新tail指针 总结：1、插入节点必须采用CAS操作，更新tail也必须采用CAS操作，影响性能，所以延迟tail节点更新2、tail指针距离最后一个节点太远，需要遍历。所以当tail指针距离最后一个节点大于等于2时，CAS移动tail指针为最后一个节点3、插入节点时，如果tail指针指向最后一个节点，则CAS增加节点；如果不是，则移动p为下一个节点，然后循环增加节点；如果距离超过2，才CAS更新tail指针 源码： public boolean offer(E e) { checkNotNull(e); final Node newNode = new Node(e); for (Node t = tail, p = t;;) { Node q = p.next; if (q == null) {//最后一个节点 // p is last node if (p.casNext(null, newNode)) { // Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become "live". if (p != t) // hop two nodes at a time casTail(t, newNode); // Failure is OK. return true; } // Lost CAS race to another thread; re-read next } else if (p == q) // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. p = (t != (t = tail)) ? t : head; else // Check for tail updates after two hops. p = (p != t && t != (t = tail)) ? t : q;//p不是最后一个节点，后移一位 } } 出队： 从上图可知，并不是每次出队时都更新head节点，当head节点里有元素时，直接弹出head节点里的元素，而不会更新head节点。只有当head节点里没有元素时，出队操作才会更新head节点。这种做法也是通过hops变量来减少使用CAS更新head节点的消耗，从而提高出队效率。让我们再通过源码来深入分析下出队过程。 队列判空： 有些人在判断队列是否为空时喜欢用queue.size()==0，让我们来看看size方法： public int size() { int count = 0; for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) if (p.item != null) // Collection.size() spec says to max out if (++count == Integer.MAX_VALUE) break; return count; } 可以看到这样在队列在结点较多时会依次遍历所有结点，这样的性能会有较大影响，因而可以考虑empty函数，它只要判断第一个结点(注意不一定是head指向的结点)。 public boolean isEmpty() { return first() == null; } 应用： import java.util.concurrent.ConcurrentLinkedQueue; import java.util.concurrent.CountDownLatch; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ConcurrentLinkedQueueTest { private static ConcurrentLinkedQueue&lt;Integer&gt; queue = new ConcurrentLinkedQueue&lt;Integer&gt;(); private static int count = 2; // 线程个数 //CountDownLatch，一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 private static CountDownLatch latch = new CountDownLatch(count); public static void main(String[] args) throws InterruptedException { long timeStart = System.currentTimeMillis(); ExecutorService es = Executors.newFixedThreadPool(4); ConcurrentLinkedQueueTest.offer(); for (int i = 0; i &lt; count; i++) { es.submit(new Poll()); } latch.await(); //使得主线程(main)阻塞直到latch.countDown()为零才继续执行 System.out.println(&quot;cost time &quot; + (System.currentTimeMillis() - timeStart) + &quot;ms&quot;); es.shutdown(); } /** * 生产 */ public static void offer() { for (int i = 0; i &lt; 100000; i++) { queue.offer(i); } } /** * 消费 * @author 林计钦 * @version 1.0 2013-7-25 下午05:32:56 */ static class Poll implements Runnable { public void run() { // while (queue.size()&gt;0) { while (!queue.isEmpty()) { System.out.println(queue.poll()); } latch.countDown(); } } } 参考Java线程(九)：Condition-线程通信更高效的方式http://blog.csdn.net/ghsau/article/details/7481142 Java并发编程（七）ConcurrentLinkedQueue的实现原理和源码分析http://blog.csdn.net/itachi85/article/details/52205256 聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析http://www.infoq.com/cn/articles/ConcurrentLinkedQueue/ 无锁队列的实现http://coolshell.cn/articles/8239.html CAS操作1、读取当前内存值，作为预估值2、当执行CAS指令时，如果内存当前值等于预估值，则更新；否则不执行，重试 示例： 1、读取 ——&gt; 2、执行+1操作，指令1和指令2不是原子操作，所以在指令1的时候有个预估值，在执行的时候，判断当前值和预估值是否一样，如果一样说明之前没有别的线程对该变量操作，可以更改当前值 代码如下： if (this == expect) { this = update return true; } else { return false; } 参考JAVA CAS原理深度分析http://blog.csdn.net/hsuxu/article/details/9467651 线程中断、线程让步、线程睡眠、线程合并线程中断 interrupt()interrupt()方法并不是中断线程的执行，而是为调用该方法的线程对象打上一个标记，设置其中断状态为true，通过isInterrupted()方法可以得到这个线程状态 public class InterruptTest { public static void main(String[] args) throws InterruptedException { MyThread t = new MyThread("MyThread"); t.start(); Thread.sleep(100);// 睡眠100毫秒 t.interrupt();//中断t线程 } } class MyThread extends Thread { int i = 0; public MyThread(String name) { super(name); } public void run() { while(!isInterrupted()) {// 当前线程没有被中断，则执行 System.out.println(getName() + getId() + "执行了" + ++i + "次"); } } } 这样的话，线程被顺利的中断执行了。很多人实现一个线程类时，都会再加一个 flag 标记，以便控制线程停止执行，其实完全没必要，通过线程自身的中断状态，就可以完美实现该功能 Thread.interrupted()方法是一个静态方法，它是判断当前线程的中断状态，需要注意的是，线程的中断状态会由该方法清除。换句话说，如果连续两次调用该方法，则第二次调用将返回 false（在第一次调用已清除了其中断状态之后，且第二次调用检验完中断状态前，当前线程再次中断的情况除外）。 线程让步 yield()程让步用于正在执行的线程，在某些情况下让出CPU资源，让给其它线程执行注意，如果存在synchronized线程同步的话，线程让步不会释放锁(监视器对象)。 线程睡眠 sleep线程睡眠的过程中，如果是在synchronized线程同步内，是持有锁(监视器对象)的，也就是说，线程是关门睡觉的，别的线程进不来 线程合并 join线程合并是优先执行调用该方法的线程，再执行当前线程，来看一个小例子： public class JoinTest { public static void main(String[] args) throws InterruptedException { JoinThread t1 = new JoinThread(&quot;t1&quot;); JoinThread t2 = new JoinThread(&quot;t2&quot;); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(&quot;主线程开始执行！&quot;); } } class JoinThread extends Thread { public JoinThread(String name) { super(name); } public void run() { for(int i = 1; i &lt;= 10; i++) System.out.println(getName() + getId() + &quot;执行了&quot; + i + &quot;次&quot;); } } t1和t2都执行完才继续主线程的执行，所谓合并，就是等待其它线程执行完，再执行当前线程，执行起来的效果就好像把其它线程合并到当前线程执行一样。 参考http://blog.csdn.net/ghsau/article/details/17560467 并发编程的设计模式Future 模式考虑这样一个情况，使用者可能快速翻页浏览文件中，而图片档案很大，如此在浏览到有图片的页数时，就会导致图片的载入，因而造成使用者浏览文件时会有停顿的现象，所以我们希望在文件开启之后，会有一个默认背景（可以是纯色图片，也可以是正在加载的图片），与此同时，程序开始加载图片的工作，如此使用者在快速浏览页面时，所造成的停顿可以获得改善。 Future模式在请求发生时，会先产生一个Future物件给发出请求的客户，而同时间，真正的目标物件之生成，由一个新的执行持续进行（即 Worker Thread），真正的目标物件生成之后，将之设定至Future之中，而当客户端真正需要目标物件时，目标物件也已经准备好，可以让客户提取使用。 一个简单的Java程式片段示范可能像是这样： public Future request() { final Future future = new Future(); new Thread() { public void run() { // 下面這個動作可能是耗時的 RealSubject subject = new RealSubject(); future.setRealSubject(subject); } }.start(); return future; }]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
        <tag>并发库</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP]]></title>
    <url>%2F2016%2F12%2F06%2F%5B%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%5DTCP%2F</url>
    <content type="text"><![CDATA[TCP是在不可靠的端到端网络协议（IP）之上实现的可靠数据传输协议 可靠数据传输的原理完全可靠信道上的可靠数据传输：rdt1.0 rdt发送方只有一个状态，通过rdt_send(data)从较高层接收数据，产生分组，并将分组发送到信道中后，状态又跳回到等待上传调用的状态 rdt接收方只有一个状态，通过rdt_rcv（packet）从底层信道接收一个分组，提取数据，并将数据上传给高层，状态又回到等待下层调用 因为信道完全可靠，接收方不需要提供任何反馈信息给发送方 具有比特差错信道上的可靠数据传输：rdt2.0（不丢包，但包可能受损）人类处理这类情形：报文接受者在听到每句话后会说OK，如果消息接受者听到一句含糊不清的话，他可能要求你重复刚才那句话。这种口述消息协议使用了肯定确认（OK）与否定确认（请重复一遍） 在计算机网络中，基于这种重传机制的可靠数据传输协议称为自动重传请求（ARQ），需要三种协议来处理比特差错： 差错检测 接收方反馈：肯定确认（ACK），否定确认（NAK） 重传 rdt2.0发送方两个状态： 1、等待上层调用：rdt_send事件发生，产生数据包，发送该分组，状态跳到22、等待接收方的ACK或NAK 如果收到ACK分组，则发送发知道最近传输的分组已经被正确接收，因此状态返回等待上层调用 如果收到一个NAK分组，重传最后一个分组，并等待接受方的ACK或NAK rdt2.0接收方的只有一个状态：当分组到达时，接收方要么回答一个ACK，要么回答一个NAK 问题： 1、停等协议：只有当上一个分组发送成功，才能发送下一个分组，效率低2、没有考虑ACK或NAK分组受损（假设分组不丢失），发送方无法知道接收方是否正确接收了上一块发送的数据 rdt2.1：引入序列号解决冗余分组 解决ACK或NAK受损的一种方式是：当发送方收到含糊不清的ACK或NAK分组时，直接重发当前数据分组，但这引入了冗余分组，接收方不知道上次发送的ACK或NAK是否被发送方正确接收到，导致接收方无法知道接收到的分组是新的，还是一次重传（重传的数据包保证该数据包中的数据只提取一次） 解决这个问题的一个简单方法是在数据分组中 添加一个新字段，对于停等协议，1比特就够了，如果接收到的分组序号与最近收到的分组序号相同，知道是在重发，不相同则是一个新分组 发送方状态：当发送完分组0，处于等待ACK或NAK的状态，如果分组受损或收到NAK，重发分组；如果收到ACK，说明接收方正确接收到分组0，状态跳转到等待发送分组1的状态 接收方状态：如果接收到受损包，直接发送NAK；如果收到分组的序号与上一次收到的序号一致，说明是重传包，直接发送ACK；如果收到的分组序号与上一次收到的不一致，发送NAk。具体的，划分出两个状态：等待数据0和等待数据包1 rdt2.2：冗余ACK来代替NAK rdt2.1中接收到受损分组时发送一个NAK，通知发送端重发。如果不发送NAK，而是发送一个对上次正确接收的分组的ACK（即冗余ACK），发送方接收到对同一个分组的两个ACK，就知道接受方没有正确接收到跟在被确认两次的分组后面的分组 发送方状态：在等待ACK0时，若收到损坏的分组或ACK1，则重传，否则状态跳到等待上层调用1 接收方状态：如果接收到受损包，或收到分组的序号与上一次收到的序号一致，说明是重传包，直接发送以上一次的发送的ACK（冗余ACK）；如果收到的分组序号和上一次收到的不一致，则提取数据，发送ACk 具有比特差错的丢包信道上的可靠数据传输：rdt3.0需要考虑两个问题： 如何检测丢包 发生丢包后该做什么 利用校验和、序号、ACK分组和重传可以解决后一个问题，即重传，所以重点是解决如何检测丢包问题 在发送方负责检测和恢复丢包，增加一个倒计时定时器，发送一个分组后（包括重传），便启动一个定时器 发送方状态：上层调用rdt_send(data)时，发送数据包，并开启定时器，状态转移到等待ACK的状态。如果接收到破损包或者上一个分组包的ACK，先不采取任何操作，等到定时器超时后进行重传，这种方式也考虑到包丢失的情况 接收方状态：如果接收到受损包，或收到分组的序号与上一次收到的序号一致，说明是重传包，直接发送以上一次的发送的ACK（冗余ACK）；如果收到的分组序号和上一次收到的不一致，则提取数据，发送ACk（与rdt2.2一样） 流水线可靠数据传输协议停等协议的是一个功能正确的协议，但是它的性能低下，吞吐量低，是网络协议限制底层网络硬件所提供功能的形象示例 解决性能问题的一个简单方法是采用流水线技术，允许发送方发送多个分组而无须等待确认，解决流水线的差错恢复有两种基本方法： 回退N步 选择重传 回退N步（GBN）将基序号（base）定义为最早的未被确认分组的序号，将下一个序号（nextseqnum）定义为下一个待发送的分组序号 序号分为4部分： [0，base-1]内的序号对应于已经发送并确认过的序号 [base，nextseqnum-1]内的序号对应已经发送但未被确认的分组 [nextseqnum，base+N-1]内的序号可用于那些要被立刻发送的分组，其数据来自上层 大于或等于base+N的序号是不能使用的，知道当前流水线中未被确认的分组已得到确认为止 GBN发送方响应的三种类型事件： 上层的调用：如果发送窗口未满，则创建一个分组并发送，否则不传送 收到ACK：采用累积确认，表示接收方已正确接收序号n之前的所有分组 超时时间：GBN协议中，使用的一个定时器当做是最早的已发送但未被确认的分组所使用过的定时器（即base分组），如果超时将重传所有已发送但未被确认的分组（即图中灰色的分组）；如果收到一个ACK，但仍有未被确认的分组，则定时器被重新启动，如果没有已发送但未被确认的分组，则定时器终止 接收方：丢弃所有失序分组。如果期望n分组，而n+1分组却到了，不需要缓存n+1分组，因为如果n分组丢失，发送方将会重新发送n分组和n+1分组，这样设计，接收方不需要缓存任何失序分组，接收方只需要维护下一个按需接收的分组的序号。 选择重传]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DOS文献]]></title>
    <url>%2F2016%2F11%2F30%2F%5B%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%5DDOS%E6%96%87%E7%8C%AE%2F</url>
    <content type="text"><![CDATA[SYNFlood型DDos攻击检测与防御研究Linux系统增加Netfilter防火墙功能，在IP层内提供了另外5个插入点，非常容易捕获并处理网络数据包 防DDos攻击的系统特点： 1、基于信息熵值得实时攻击检测 2、黑白单过滤，减轻防御模块的工作任务 3、协议分析 4、基于SYN Cookie技术的SYN Flood攻击防御模块 5、自学习子系统，包含蜜罐系统和数据挖掘系统，蜜罐系统旁路手机网络异常流量，通过数据挖掘生成防御规则动态更新异常检测阈值、黑白名单列表和协议分析规则，调整后续攻击响应策略 Linux包捕获机制DDos防御系统最基本的功能之一就是对网络数据包进行处理，因此需要捕获数据包并分析过滤，Linux系统环境下数据获取有两种方式： 通过内核防火墙Netfilter/Iptables获取 通过包捕获机制Libpcap旁路获取 选择：正常情况下使用Netfilter/Iptables，会增加不必要的系统开销，因此在正常网络流量环境下，采用Libpcap旁路获取数据包形式 Libpcap是Unix/Linux平台下的网络数据包捕获函数宝，而在Windows系统下有相应的Winpcap库 攻击检测算法与SYN Cookie算法研究基于TCP协议的攻击占了DDos攻击的绝大多数，而SYN Flood攻击又在TCP攻击中扮演着最重要的角色，当前防御SYN Flood攻击最流行的方法是使用SYN Proxy和SYN Cookie DDos攻击防御系统检测阶段的任务就是要在攻击分组到来时及时向防御系统发出警报，从而使防御系统能在短时间做出反应，开启防御策略，实施分组过滤]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[instanceof, isinstance,isAssignableFrom的区别]]></title>
    <url>%2F2016%2F11%2F24%2F%5BJava%5Dinstanceof%2C%20isinstance%2CisAssignableFrom%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[类-实例instanceof运算符只被用于对象引用变量，检查左边的被测试对象是不是右边类或接口的实例化。如果被测对象是null值，则测试结果总是false。 形象地：自身实例或子类实例 instanceof 自身类返回true例： String s=new String(“javaisland”); System.out.println(s instanceof String); //true Class-实例Class类的isInstance(Object obj)方法，obj是被测试的对象，如果obj是调用这个方法的class或接口 的实例，则返回true。这个方法是instanceof运算符的动态等价。形象地：自身类.class.isInstance(自身实例或子类实例)返回true例：String s=new String(“javaisland”); System.out.println(String.class.isInstance(s)); //true Class-ClassClass类的isAssignableFrom(Class cls)方法，如果调用这个方法的class或接口 与 参数cls表示的类或接口相同，或者是参数cls表示的类或接口的父类，则返回true。形象地：自身类.class.isAssignableFrom(自身类或子类.class)返回true例：System.out.println(ArrayList.class.isAssignableFrom(Object.class)); //false System.out.println(Object.class.isAssignableFrom(ArrayList.class)); //true]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中你不知道的注入方式]]></title>
    <url>%2F2016%2F11%2F10%2F%5BSpring%5DSpring%E4%B8%AD%E4%BD%A0%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E6%B3%A8%E5%85%A5%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言在Spring配置文件中使用XML文件进行配置，实际上是让Spring执行了相应的代码，例如： 使用元素，实际上是让Spring执行无参或有参构造器 使用元素，实际上是让Spring执行一次setter方法 但Java程序还可能有其他类型的语句：调用getter方法、调用普通方法、访问类或对象的Field等，而Spring也为这种语句提供了对应的配置语法： 调用getter方法：使用PropertyPathFactoryBean 调用类或对象的Filed值：使用FiledRetrievingFactoryBean 调用普通方法：使用MethodInvokingFactoryBean https://my.oschina.net/itblog/blog/206481]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat操作Servlet流程]]></title>
    <url>%2F2016%2F11%2F07%2F%5BServlet%5DTomcat%E6%93%8D%E4%BD%9CServlet%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Tomcat调用Servlet的流程 Listener的初始化最早，Filter次之。他俩的初始化都是在容器启动完成之前初始化的。 Servlet没有初始化，原因是没有匹配的请求进来。 如果想要servlet自动初始化，需要在指定的servlet中配置参数，没有此标签，默认启动时servlet不进行初始化。 初始化的顺序跟Listener、Filter、Servlet在web.xml中的顺序无关。而多个Filter或多个Servlet的时候，谁的mapping在前面，谁先初始化。 如果web.xml中配置了，它用于向 ServletContext 提供键值对，即应用程序上下文信息。我们的 listener, filter 等在初始化时会用到这些上下文中的信息，context-param 配置节可写在任意位置，初始化顺序： context-param &gt; Listener &gt; Filter &gt; Servlet 过滤器 Filter的初始化方法在服务器启动时执行,过滤方法在请求发出后立即调用，可以过滤特定的URL 过滤器的URL匹配遵从最大长度匹配原则 一个URL匹配多个过滤器，按照filter-mapping配置节点的出现顺序 依次调用doFilter() 过滤器链： 参考：http://blog.sina.com.cn/s/blog_667ab8240101gfd6.html 有多个过滤器 filter1 filter2 filter3，组成一个过滤器链 FilterChain[filter1,filter2,filter3] 如何做到过滤器的依次执行？调用过滤器链的doFilter参数，获取下一个过滤器链，然后执行下一个Filter的方法 前置方法和后置方法的执行顺序？ 1、前置方法按照过滤器的调用顺序因此按顺序执行2、后置方法的顺序与前置方法相反，即后调用的过滤器的后置方法先执行3、Chain.doFilter前的代码为访问Servlet前执行，Chain.doFilter后的代码访问Servlet后执行（分析源代码） 1、下面是一个简单的时序图 2、对上面时序图中用到的主要类进行分析 1) ApplicationFilterChain类,有两个主要函数，下面是省略过的代码 public voiddoFilter(request, response) {//暴露在外面的调用接口 if( Globals.IS_SECURITY_ENABLED ) { finalServletRequest req = request; finalServletResponse res = response; internalDoFilter(req,res); return null; } else { internalDoFilter(request,response); } } private voidinternalDoFilter(request, response) { if (pos &lt; n) {//判断是否还有filter需要执行 ApplicationFilterConfig filterConfig = filters[pos++]; Filter filter = null; filter = filterConfig.getFilter(); filter.doFilter(request, response, this); return ; //执行过滤器方法时，不执行以下代码，当pos=n，即执行完所有filter后执行servlet } //filter执行完后，执行servlet if ((request instanceofHttpServletRequest) &amp;&amp;(response instanceof HttpServletResponse)) { servlet.service((HttpServletRequest) request,(HttpServletResponse)response); } void addFilter(ApplicationFilterConfig filterConfig) { if (n == filters.length) { ApplicationFilterConfig[] newFilters = new ApplicationFilterConfig[n + INCREMENT]; System.arraycopy(filters, 0, newFilters, 0, n); filters = newFilters; } filters[n++] = filterConfig; } 2) Servlet类的主要方法，以HttpServlet类为例，其主要方法是service(Request,Response) public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException { HttpServletRequest request; HttpServletResponse response; try { request = (HttpServletRequest) req; response = (HttpServletResponse) res; } catch (ClassCastException e) { throw new ServletException(&quot;non-HTTP request or response&quot;); } service(request, response);//内部的方法 } protected void service(HttpServletRequest , HttpServletResponse) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { long lastModified = getLastModified(req); if (lastModified == -1) { doGet(req, resp); //常用的方法 } else { long ifModifiedSince; try { ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); } catch (IllegalArgumentException iae) { ifModifiedSince = -1; } if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) { maybeSetLastModified(resp, lastModified); doGet(req, resp); } else { resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); } } } else if (method.equals(METHOD_HEAD)) { long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp);//常用的方法 } else if (method.equals(METHOD_PUT)) { doPut(req, resp); } else if (method.equals(METHOD_DELETE)) { doDelete(req, resp); } else if (method.equals(METHOD_OPTIONS)) { doOptions(req,resp); } else if (method.equals(METHOD_TRACE)) { doTrace(req,resp); } else { String errMsg =lStrings.getString(&quot;http.method_not_implemented&quot;); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); } }]]></content>
      <categories>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>标签2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 接口和抽象类区别]]></title>
    <url>%2F2016%2F11%2F01%2F%5BJava%5DJava%20%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[参考http://blog.csdn.net/xw13106209/article/details/6923556 面向接口编程OOP面向对象的编程，如果要提高程序的复用率，增加程序的可维护性，可扩展性，就必须是面向接口的编程，面向抽象的编程，正确地使用接口、抽象类这些有用的抽象类型作为你结构层次上的顶层。 Java接口和抽象类1、[最大区别] Java接口和Java抽象类最大的一个区别，就在于Java抽象类既可以有没有具体实现的抽象方法，也可以提供某些方法的部分实现；而Java接口只能定义方法，不能有方法的实现 2、[抽象类优势] Java的抽象类非常有用，如果向一个抽象类里加入一个新的具体方法时，那么它所有的子类都一下子都得到了这个新方法，而如果向Java接口中加入一个新方法，所有实现这个接口的类都无法成功通过编译了，因为你必须让每一个类都再实现这个方法才行，这显然是Java接口的缺点 3、[接口优势] 一个抽象类的实现只能由具体子类给出，但是由于Java的单继承特性，一个具体子类继承了抽象类，这个子类的类型就比较单一；在这一点，Java接口的优势就出来了，任何一个实现了Java接口的的类都可以具有这个接口的类型，而且一个类可以实现多个Java接口，类型就比较多；Java接口是定义混合类型的理想工具，混合类表示一个类不仅仅具有某个主类型的行为，而且具有其他次要行为 4、★★★[总结] 抽象类的优势是抽象类中既可以有具体的实现方法，也可以有没有具体实现的抽象方法，继承的子类都可以拥有抽象类实现的方法，缺点是由于Java的单继承性，实现抽象类的子类类型比较单一；一个类可以实现多个接口，因此一个类就可以拥有多个类型，缺点是接口中只能定义方法的类型，实现接口必须实现接口的全部方法 5、[缺省适配模式] 声明类型的工作仍然由Java接口承担，但是同时给出一个Java抽象类，且实现了这个Java接口；而其他同属于这个抽象类型的具体类可以选择实现这个Java接口，也可以选择继承这个抽象类；在层次结构中，Java接口在最上面，然后紧跟着抽象类，这下两个优点都能发挥到极致]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>接口</tag>
        <tag>抽象类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro笔记]]></title>
    <url>%2F2016%2F10%2F17%2F%5BSSM%5DShiro%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[术语（Terminology）Authentication（鉴权，身份验证）：校验Subject（主体）的身份是否合法Authorization（授权）：根据主体的角色和权限来决定允许或拒绝访问请求Cipher：执行加密或解密的算法Principal：一个主体的标识属性，独一无二的标识，可以是昵称、用户ID、安全码……Credential（证书）：验证主体身份的信息Cryptography（密码学）：密码学保护信息不被不比希望让他看的人的看到Hash：数据经过hash方法得到的结果不可逆Permission：描述原始的功能，定义应用程序能够做的一些操作Realm（领域）：可以访问应用程序的安全数据，例如用户、角色和权限的组件。可以当做安全的DAO，将应用程序数据翻译成Shiro能够理解的格式，这样Shiro可以提供简洁的API，不管有多少数据源或者应用程序Role：权限的集合，并取一个独一无二的名字Session：主体与软件交互过程中的有状态数据环境，当用户使用应用程序时可以在Session中增加/读取/删除数据，当用户退出应用程序，Session终止Subject：应用程序用户，但他不一定但指一个人，它也可以代表调用你应用程序的外部进程，或者一个间断执行操作的守护系统账户，它可以抽象表示为操作应用程序的主体 简介Apache Shiro是一个强大易用的Java安全框架，提供鉴权、授权、加密、会话管理的综合解决方法。在实践中达到管理应用程序安全的作用，而减少与应用程序的耦合 Shiro可以在任何环境中运行，从最简单的命令行应用程序到企业级web程序和集群应用程序 Shiro快速入门（j2se）官方地址：http://shiro.apache.org/10-minute-tutorial.html Shiro APIimport org.apache.shiro.SecurityUtils; import org.apache.shiro.authc.*; import org.apache.shiro.config.IniSecurityManagerFactory; import org.apache.shiro.mgt.SecurityManager; import org.apache.shiro.session.Session; import org.apache.shiro.subject.Subject; import org.apache.shiro.util.Factory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class Quickstart { private static final transient Logger log = LoggerFactory.getLogger(Quickstart.class); public static void main(String[] args) { /* * 创建Shiro SecurityManager，同时设置realms、users、roles、permissions， * 最简单的方式是创建一个.ini，通过它返回一个SecurityManager实例。ini文件见下一节 */ Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory(&quot;classpath:shiro.ini&quot;); SecurityManager securityManager = factory.getInstance(); // 设置 SecurityManager 为一个静态实例，可以被 JVM 访问到 SecurityUtils.setSecurityManager(securityManager); // 设置Shiro环境完毕，看下它的操作★★★★★ // 获得当前操作的用户，此时currentUser为空，用户还未登录 Subject currentUser = SecurityUtils.getSubject(); // 用Session存储数据（web或EJB容器不需要！！！） Session session = currentUser.getSession(); session.setAttribute(&quot;someKey&quot;, &quot;aValue&quot;); String value = (String) session.getAttribute(&quot;someKey&quot;); if (value.equals(&quot;aValue&quot;)) { log.info(&quot;Retrieved the correct value! [&quot; + value + &quot;]&quot;); } // 用户登录，校验角色和权限 if (!currentUser.isAuthenticated()) { //获得用户名和密码 UsernamePasswordToken token = new UsernamePasswordToken(&quot;lonestarr&quot;, &quot;vespa&quot;); token.setRememberMe(true); try { currentUser.login(token); } catch (UnknownAccountException uae) { log.info(&quot;There is no user with username of &quot; + token.getPrincipal()); } catch (IncorrectCredentialsException ice) { log.info(&quot;Password for account &quot; + token.getPrincipal() + &quot; was incorrect!&quot;); } catch (LockedAccountException lae) { log.info(&quot;The account for username &quot; + token.getPrincipal() + &quot; is locked. &quot; + &quot;Please contact your administrator to unlock it.&quot;); } // 捕捉更多的异常，可以是用户自定义 catch (AuthenticationException ae) { //unexpected condition? error? } } // 查看用户标识 log.info(&quot;User [&quot; + currentUser.getPrincipal() + &quot;] logged in successfully.&quot;); // 测试用户是否具备角色 if (currentUser.hasRole(&quot;schwartz&quot;)) { log.info(&quot;May the Schwartz be with you!&quot;); } else { log.info(&quot;Hello, mere mortal.&quot;); } // 测试用户是否具备某个权限 if (currentUser.isPermitted(&quot;lightsaber:weild&quot;)) { log.info(&quot;You may use a lightsaber ring. Use it wisely.&quot;); } else { log.info(&quot;Sorry, lightsaber rings are for schwartz masters only.&quot;); } // 测试用户是否具备某个权限 if (currentUser.isPermitted(&quot;winnebago:drive:eagle5&quot;)) { log.info(&quot;You are permitted to &apos;drive&apos; the winnebago with license plate (id) &apos;eagle5&apos;. &quot; + &quot;Here are the keys - have fun!&quot;); } else { log.info(&quot;Sorry, you aren&apos;t allowed to drive the &apos;eagle5&apos; winnebago!&quot;); } // 注销用户 currentUser.logout(); System.exit(0); } } shiro.ini # 用户和他们分配的角色 [users] # 用户'root'的密码是'secret'，包含'admin'的角色 root = secret, admin # 用户'guest'的密码是'guest'，包含'guest'的角色 guest = guest, guest # 用户'presidentskroob'的密码是'12345'，包含'president'的角色 presidentskroob = 12345, president # 用户'darkhelmet'的密码是'ludicrousspeed'，包含角色'darklord'和schwartz' darkhelmet = ludicrousspeed, darklord, schwartz # 用户'lonestarr'的密码是'vespa'，包含角色'goodguy'和'schwartz' lonestarr = vespa, goodguy, schwartz # 角色和他们分配的权限 [roles] # 'admin'的角色拥有所有权限，用通配符'*'表示 admin = * # 角色'schwartz'拥有lightsaber下的任意权限 schwartz = lightsaber:* # 角色'goodguy'允许'drive' (action) the winnebago (type) with # license plate 'eagle5' (instance specific id) goodguy = winnebago:drive:eagle5 Web应用程序整合官方文档：http://shiro.apache.org/webapp-tutorial.html 开启Shiro环境Shiro可以用多重方式配置，取决于你使用的web应用程序框架，如Spring，Guice等，这里采用Shiro默认，最简单的方式：基于INI文件的配置 添加 shiro.ini 文件位置：src/main/webapp/WEB-INF/shiro.ini [main] cacheManager = org.apache.shiro.cache.MemoryConstrainedCacheManager securityManager.cacheManager = $cacheManager 这个INI文件只简单包含main部分，和一些最小配置 定义 cacheManager 的实例 在 Shiro securityManager 上配置新的cacheManager的实例 在web.xml文件中支持Shiro加载shiro.ini文件启动新的Shiro环境，使Web应用程序支持Shiro环境 &lt;listener&gt; &lt;listener-class&gt;org.apache.shiro.web.env.EnvironmentLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;filter&gt; &lt;filter-name&gt;ShiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.shiro.web.servlet.ShiroFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;ShiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt; &lt;dispatcher&gt;INCLUDE&lt;/dispatcher&gt; &lt;dispatcher&gt;ERROR&lt;/dispatcher&gt; &lt;/filter-mapping&gt; 定义一个 ServletContextListener，应用程序启动时启动Shiro环境（包括Shiro SecurityManager）。监听器默认寻找 WEB-INF/shiro.ini 文件 作为 Shiro 的配置文件 过滤器拦截所有请求，所以Shiro在请求达到应用程序之前，能够执行必要的身份验证和访问控制操作 &lt;filter-mapping&gt;声明确保所有请求类型都能被ShiroFilter拦截，一般filter-mapping声明不需要指定dispatcher元素，但是Shiro需要定义它们，这样可以过滤所有不同的请求类型 运行webappmvn tomcat:run 这些输出指明Shiro确定在你的webapp中运行 15:41:22.296 [main] INFO o.a.shiro.web.env.EnvironmentLoader - Starting Shiro environment initialization. 15:41:22.733 [main] INFO o.a.shiro.web.env.EnvironmentLoader - Shiro environment initialized in 435 ms. 连接到用户仓库Realm 在我们登录、退出、执行访问控制等其他安全相关的操作之前，我们需要用户！所有我们会设置Shiro去访问用户仓库 用户仓库会有多种形式：MySQL数据库、MongoDB、LDAP、活动目录、简单文件、其他私有数据仓库，Shiro通过 Realm 来操作这些 Realm扮演Shiro与安全数据之间的桥梁，也可以说是连接器。当用户执行鉴权（登录）或授权（访问控制），Shiro从应用程序配置的所有Realm中寻找数据 Realm 是一个安全DAO，封装了连接细节，Shiro需要数据时通过Realm可以直接获取。Realm可以配置多个，但至少要有一个 默认为iniRealm ini简单配置了两个用户，用户名密码分别为admin：admin，guest：guest [users] admin=admin guest=guest Shiro登录/退出与访问控制ini文件，添加访问控制[main] # 对于Shiro任何默认过滤器都有一个loginUrl属性，authc过滤器会跳转到登录页面 shiro.loginUrl = /login.jsp # 用户 [users] admin = admin guest = guest # 过滤请求，路径相对于应用程序路径[HttpServletRequest.getContextPath()] [urls] # 匹配到请求/login.jsp，开启authc过滤器，跳转到loginUrl页面 /login.jsp = authc # 匹配到请求/logout，开启logout过滤器，跳转到首页 /logout = logout # 匹配到请求/admin/**，开启authc过滤器，跳转到loginUrl页面 /admin/** = authc 登录页面Shiro会默认读取username、password、rememberMe &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Apache Shiro Tutorial Webapp : Login&lt;/title&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;!-- Add some nice styling and functionality. We&apos;ll just use Twitter Bootstrap --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;//netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap.min.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;//netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap-theme.min.css&quot;&gt; &lt;style&gt; body{padding-top:20px;} &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-4 col-md-offset-4&quot;&gt; &lt;div class=&quot;panel panel-default&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h3 class=&quot;panel-title&quot;&gt;Please sign in&lt;/h3&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;form name=&quot;loginform&quot; action=&quot;&quot; method=&quot;POST&quot; accept-charset=&quot;UTF-8&quot; role=&quot;form&quot;&gt; &lt;fieldset&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input class=&quot;form-control&quot; placeholder=&quot;Username or Email&quot; name=&quot;username&quot; type=&quot;text&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input class=&quot;form-control&quot; placeholder=&quot;Password&quot; name=&quot;password&quot; type=&quot;password&quot; value=&quot;&quot;&gt; &lt;/div&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input name=&quot;rememberMe&quot; type=&quot;checkbox&quot; value=&quot;true&quot;&gt; Remember Me &lt;/label&gt; &lt;/div&gt; &lt;input class=&quot;btn btn-lg btn-success btn-block&quot; type=&quot;submit&quot; value=&quot;Login&quot;&gt; &lt;/fieldset&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- jQuery (necessary for Bootstrap&apos;s JavaScript plugins) --&gt; &lt;script src=&quot;https://code.jquery.com/jquery.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;//netdna.bootstrapcdn.com/bootstrap/3.0.2/js/bootstrap.min.js&quot;&gt;&lt;/script&gt; &lt;!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn&apos;t work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src=&quot;https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js&quot;&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;/body&gt; &lt;/html&gt; 登录验证页面如果用户/密码正确，跳转到主页面，否则继续跳转到登录页 public class LoginServlet extends HttpServlet { @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { String username = request.getParameter(&quot;username&quot;); String password = request.getParameter(&quot;password&quot;); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(username, password); try{ subject.login(token); }catch (Exception e){ request.getRequestDispatcher(&quot;/login.jsp&quot;).forward(request,response); return; } request.getRequestDispatcher(&quot;/WEB-INF/main.jsp&quot;).forward(request,response); } } 基于角色的权限控制★★★★★[main] # 认证页面 shiro.loginUrl = /login.jsp # 用户没有权限时跳转页面 perms.unauthorizedUrl = /unauthorizedUrl.jsp roles.unauthorizedUrl = /unauthorizedUrl.jspgi [users] # admin的密码是admin，拥有admin角色，包含admin下的所有权限 admin = admin,admin # guest的密码是guest，拥有user角色，包含user下的所有权限 guest = guest,user # qm的密码是qm，不拥有任何角色，即没有任何权限 qm = qm [roles] # admin拥有的权限 admin = admin:*,user:* # user拥有的权限 user = user:* [urls] /login.jsp = annon /logout = logout # /admin/**路径只有拥有admin角色的用户才能访问 /admin/** = authc,roles[admin] # 访问/user/list.jsp必须拥有user:list权限，所以拥有admin或者user的角色都可以访问 /user/list.jsp = authc,perms[user:list] # 访问/user/** 只要认证用户都可以访问 /user/** = authc 当用户访问一个url时，Shiro从上到下扫描权限，如果有一个匹配则不继续往下进行扫描，所以优先级很重要。对于特殊的访问权限，放在上面 Shiro细节认证认证身份流程 流程如下：1、首先调用 Subject.login(token)进行登录，其会自动委托给 Security Manager，调用之前必须通过 SecurityUtils. setSecurityManager()设置；2、SecurityManager 负责真正的身份验证逻辑；它会委托给 Authenticator 进行身份验证；3、 Authenticator 才是真正的身份验证者， Shiro API 中核心的身份认证入口点， 此处可以自定义插入自己的实现；4、Authenticator 可能会委托给相应的 AuthenticationStrategy 进行多 Realm 身份验证，默认ModularRealmAuthenticator 会调用 AuthenticationStrategy 进行多 Realm 身份验证；5、Authenticator 会把相应的 token 传入 Realm，从 Realm 获取身份验证信息，如果没有返回/抛出异常表示身份验证失败了。此处可以配置多个 Realm，将按照相应的顺序及策略进行访问。 自定义realm登录操作 public class realm_test { public static void main(String[] args){ // 设置SecurityManager SecurityManager securityManager = new IniSecurityManagerFactory(&quot;classpath:shiro.ini&quot;).getInstance(); SecurityUtils.setSecurityManager(securityManager); //获取主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(&quot;admin&quot;,&quot;admin&quot;); try{ //登录操作，登录不成功会抛出异常 subject.login(token); //输出认证的用户名 System.out.println(subject.getPrincipal()); }catch (UnknownAccountException e){ System.out.println(&quot;用户名不存在&quot;); }catch (IncorrectCredentialsException e){ System.out.println(&quot;用户名密码错误&quot;); } } } 自定义realm public class MyRealm implements Realm{ //模拟数据库，放入一些用户名和密码 private static Map&lt;String,String&gt; DB = new HashMap&lt;String,String&gt;(); static { DB.put(&quot;admin&quot;,&quot;admin&quot;); DB.put(&quot;qm&quot;,&quot;qm&quot;); } @Override //Realm的名称 public String getName() { return &quot;MyRealm&quot;; } @Override //该realm支持哪些token public boolean supports(AuthenticationToken authenticationToken) { return authenticationToken instanceof UsernamePasswordToken; } @Override //执行subject.login操作调用的方法 public AuthenticationInfo getAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException { //获取token中的用户和密码 String username = authenticationToken.getPrincipal().toString(); String password = new String((char[])authenticationToken.getCredentials()); //验证失败 if(!DB.containsKey(username)) throw new UnknownAccountException(&quot;用户名不存在&quot;); if(!password.equals(DB.get(username))) throw new IncorrectCredentialsException(&quot;用户名密码错误&quot;); //System.out.println(username + &quot; &quot; + password); //验证成功返回一个AuthenticationInfo return new SimpleAuthenticationInfo(username, password,getName()); } } 配置使用自定义realm [main] #创建一个MyRealm实例，这句话等同于&lt;bean id = &quot;myRealm&quot; class = &quot;MyRealm&quot;/&gt; myRealm = MyRealm #依赖注入，在securityManager中传入自定义realm的实例 securityManager.realms = $myRealm 多 Realm 配置#声明一个 realm myRealm1=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm1 myRealm2=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm2 #指定 securityManager 的 realms 实现 securityManager.realms=$myRealm1,$myRealm2 securityManager 会按照 realms 指定的顺序进行身份认证。此处我们使用 显示指定顺序的方式 指定了 Realm 的顺序，如果删除”securityManager.realms=$myRealm1,$myRealm2”，那么 securityManager 会按照 realm 声明的顺序进行使用（即无需设置 realms 属性，其会自动发 现），当我们显示指定 realm 后 ， 他没有指定 realm 将被忽 略， 如”securityManager.realms=$myRealm1”，那么 myRealm2 不会被自动设置进去。 Shiro 默认提供的 Realm及开发建议★★★★★ 以后一般继承 AuthorizingRealm （授权）即可； 其继承了 AuthenticatingRealm （即身份验证） ，而且也间接继承了 CachingRealm（带有缓存实现）。其中主要默认实现如下： org.apache.shiro.realm.text.IniRealm： [users]部分指定用户名/密码及其角色； [roles]部分指定角色即权限信息； org.apache.shiro.realm.text.PropertiesRealm：user.username=password,role1,role2 指定用户名/密码及其角色；role.role1=permission1,permission2 指定角色及权限信息； org.apache.shiro.realm.jdbc.JdbcRealm：通过 sql 查询相应的信息，如 “select password from users where username =?”获取用户密码，”select password, password_salt from users where username =?”获取用户密码及盐；”select role_name from user_roles where username =?”获取用户角色；”selectpermission from roles_permissions where role_name =?”获取角色对应的权限信息；也可以调用相应的 api 进行自定义 sql； jdbcRealm使用 1、依赖 &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;0.2.23&lt;/version&gt; &lt;/dependency&gt; 2、配置数据库 查看jdbcReaml源代码，发现其中固定了一个sql语句，要求数据库中有一个users表，并且有username、password两个字段 3、配置 [main] # 数据源 dataSource = com.alibaba.druid.pool.DruidDataSource dataSource.driverClassName = com.mysql.jdbc.Driver dataSource.url = jdbc:mysql://localhost:3306/jdbcRealm dataSource.username = root dataSource.password = root #创建一个jdbcRealm实例，并且注入数据源 jdbcRealm = org.apache.shiro.realm.jdbc.JdbcRealm jdbcRealm.dataSource = $dataSource securityManager.realms = $jdbcRealm 4、验证 public class realm_test { public static void main(String[] args){ // 设置SecurityManager SecurityManager securityManager = new IniSecurityManagerFactory(&quot;classpath:shiro.ini&quot;).getInstance(); SecurityUtils.setSecurityManager(securityManager); //获取主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(&quot;admin&quot;,&quot;admin&quot;); try{ //登录操作，登录不成功会抛出异常 subject.login(token); //输出认证的用户名 System.out.println(subject.getPrincipal()); }catch (UnknownAccountException e){ System.out.println(&quot;用户名不存在&quot;); }catch (IncorrectCredentialsException e){ System.out.println(&quot;用户名密码错误&quot;); } } } Authenticator接口及其子类源码分析★★★★★★1、定义接口Authenticator，定义了一个authenticate认证方法 public interface Authenticator { public AuthenticationInfo authenticate(AuthenticationToken authenticationToken) throws AuthenticationException; } 2、抽象类AbstractAuthenticator实现Authenticator接口，类的作用是通过doAuthenticate方法来获取AuthenticationInfo并返回；doAuthenticate方法为抽象方法，由子类重写 public abstract class AbstractAuthenticator implements Authenticator, LogoutAware { public final AuthenticationInfo authenticate(AuthenticationToken token) throws AuthenticationException { AuthenticationInfo info; info = doAuthenticate(token); } protected abstract AuthenticationInfo doAuthenticate(AuthenticationToken token) throws AuthenticationException; } } 3、ModularRealmAuthenticator继承了AbstractAuthenticator，通过调用realm的getAuthenticationInfo方法获得AuthenticationInfo public class ModularRealmAuthenticator extends AbstractAuthenticator { //保存realm的实例 private Collection&lt;Realm> realms; private AuthenticationStrategy authenticationStrategy; protected AuthenticationInfo doAuthenticate(AuthenticationToken authenticationToken) throws AuthenticationException { assertRealmsConfigured(); Collection realms = getRealms(); if (realms.size() == 1) { return doSingleRealmAuthentication(realms.iterator().next(), authenticationToken); } else { return doMultiRealmAuthentication(realms, authenticationToken); } } protected AuthenticationInfo doSingleRealmAuthentication(Realm realm, AuthenticationToken token) { AuthenticationInfo info = realm.getAuthenticationInfo(token); return info; } protected AuthenticationInfo doMultiRealmAuthentication(Collection realms, AuthenticationToken token) { //若有多个realm，遍历所有realm，根据AuthenticationStrategy 接口指定的策略，返回AuthenticationInfo；默认使用AtLeastOneSuccessfulStrategy策略 AuthenticationStrategy strategy = getAuthenticationStrategy(); AuthenticationInfo aggregate = strategy.beforeAllAttempts(realms, token); for (Realm realm : realms) { aggregate = strategy.beforeAttempt(realm, token, aggregate); AuthenticationInfo info = null; info = realm.getAuthenticationInfo(token); aggregate = strategy.afterAttempt(realm, token, info, aggregate, t); } aggregate = strategy.afterAllAttempts(token, aggregate); return aggregate; } } 授权角色角色代表了权限的集合，赋予用户角色，这样用户就可以拥有一组权限，赋予权限比较方便 隐式角色：通过 判断用户是否有某个角色 来判断用户有没有操作权限，颗粒度是以角色为单位进行访问控制的，颗粒度较粗，如果应用中允许CTO、技术总监、开发工程师使用打印机，假设某天不允许开发工程师使用打印机了，就需要在相关代码的判断逻辑中移除技术总监角色，造成多处代码的修改 显示角色：程序中 通过权限 控制谁能访问某个资源。假设哪个角色不能访问某个资源，只需要从角色的权限集合中移除即可，颗粒度是以资源/实例为单位的，颗粒度较细 基于角色的访问控制（隐式角色）判断用户是否有某个角色来进行权限控制，颗粒度较大，很多地方对角色进行判断，如果有一天不需要了就要修改代码，在判断这个角色的地方把它删除 ini配置文件： [users] admin = admin,r1,r2 Shiro 提供了 hasRole/hasRole 用于判断用户是否拥有某个角色/某些权限 //判断是否拥有角色 r1 System.out.println(subject.hasRole(&quot;r1&quot;)); //必须同时拥有r1和r2才会true，否则返回false System.out.println(subject.hasAllRoles(Arrays.asList(&quot;r1&quot;,&quot;r2&quot;))); //返回boolean[]数组，相当于判断是否拥有每个角色 System.out.println(Arrays.toString(subject.hasRoles(Arrays.asList(&quot;r1&quot;,&quot;r3&quot;)))); Shiro 提供的 checkRole/checkRoles 和 hasRole/hasAllRoles 不同的地方是它在判断为假的情况下会抛出 UnauthorizedException 异常 subject().checkRole(&quot;role1&quot;); 基于资源的访问控制（显示角色）ini配置文件 [users] admin = admin,r1 [roles] r1=user:create,user:update r2:user:create,user:delete 测试 System.out.println(subject.isPermitted(&quot;user:create&quot;)); System.out.println(subject.isPermittedAll(&quot;user:create&quot;,&quot;user:update&quot;)); checkPermission/checkPermissions会在失败的情况下抛出 UnauthorizedException 异常 规则 基于资源的访问控制（显示角色），也可以叫基于权限的访问控制，这种方式的一般规则是”资源标识符：操作”，即是资源级别的粒度；这种方式的好处就是如果要修改基本都是一个资源级别的修改，不会对其他模块代码产生影响，粒度小。但是实现起来可能稍微复杂点，需要维护”用户——角色，角色——权限（资源：操作）”之间的关系 权限规则：”资源标识符：操作：对象实例ID”，即对哪个资源的哪个实例可以进行什么操作。其默认支持通配符权限字符串，”:”表示资源/操作/实例的分割；”,”表示操作的分割；”*”表示任意资源/操作/实例。 1、单个资源单个权限 #ini文件 role1 = system:user:update #测试 subject().checkPermissions(&quot;system:user:update&quot;); 2、单个资源多个权限 #ini文件 role41=system:user:update,system:user:delete #测试 subject().checkPermissions(&quot;system:user:update&quot;, &quot;system:user:delete&quot;); 3、单个资源全部权限 #ini文件 role52=system:user:* 4、所有资源全部权限 #ini文件 role61=*:view #测试 subject().checkPermissions(&quot;user:view&quot;); 5、实例级别的权限 《跟我我学Shiro》26页 授权流程 流程如下：1、首先调用 Subject.isPermitted/hasRole接口，其会委托给 SecurityManager，而SecurityManager 接着会委托给 Authorizer；2、Authorizer 是真正的授权者，如果我们调用如 isPermitted(“user:view”)，其首先会通过PermissionResolver 把字符串转换成相应的 Permission 实例；3、在进行授权之前，其会调用相应的 Realm 获取 Subject 相应的角色/权限用于匹配传入的角色/权限；4、Authorizer 会判断 Realm 的角色/权限是否和传入的匹配，如果有多个 Realm，会委托给ModularRealmAuthorizer 进行循环判断，如果匹配如 isPermitted/hasRole会返回 true，否则返回 false 表示授权失败。 授权源码分析★★★★★1、定义接口Authorizer接口，包括一些isPermitted、checkPermission、hasRole、checkRole一些方法 public interface Authorizer { boolean isPermitted(PrincipalCollection principals, String permission); boolean isPermitted(PrincipalCollection subjectPrincipal, Permission permission); boolean[] isPermitted(PrincipalCollection subjectPrincipal, String... permissions); boolean[] isPermitted(PrincipalCollection subjectPrincipal, List&lt;Permission&gt; permissions); boolean isPermittedAll(PrincipalCollection subjectPrincipal, String... permissions); boolean isPermittedAll(PrincipalCollection subjectPrincipal, Collection&lt;Permission&gt; permissions); void checkPermission(PrincipalCollection subjectPrincipal, String permission) throws AuthorizationException; void checkPermission(PrincipalCollection subjectPrincipal, Permission permission) throws AuthorizationException; void checkPermissions(PrincipalCollection subjectPrincipal, String... permissions) throws AuthorizationException; void checkPermissions(PrincipalCollection subjectPrincipal, Collection&lt;Permission&gt; permissions) throws AuthorizationException; boolean hasRole(PrincipalCollection subjectPrincipal, String roleIdentifier); boolean[] hasRoles(PrincipalCollection subjectPrincipal, List&lt;String&gt; roleIdentifiers); boolean hasAllRoles(PrincipalCollection subjectPrincipal, Collection&lt;String&gt; roleIdentifiers); void checkRole(PrincipalCollection subjectPrincipal, String roleIdentifier) throws AuthorizationException; void checkRoles(PrincipalCollection subjectPrincipal, Collection&lt;String&gt; roleIdentifiers) throws AuthorizationException; void checkRoles(PrincipalCollection subjectPrincipal, String... roleIdentifiers) throws AuthorizationException; } 2、同样，和认证一样有一个ModularRealmAuthorizer实现，委托给realm的方法去实现 public class ModularRealmAuthorizer implements Authorizer, PermissionResolverAware, RolePermissionResolverAware { &lt;font color=&apos;red&apos;&gt;//保存realm的实例&lt;/font&gt; protected Collection&lt;Realm&gt; realms; protected PermissionResolver permissionResolver; protected RolePermissionResolver rolePermissionResolver; public boolean hasRole(PrincipalCollection principals, String roleIdentifier) { assertRealmsConfigured(); for (Realm realm : getRealms()) { if (!(realm instanceof Authorizer)) continue; if (((Authorizer) realm).hasRole(principals, roleIdentifier)) { return true; } } return false; } } Realm及相关对象★★★★★用户、角色、权限的关系 用户——角色之间是多对多关系，角色——权限之间是多对多关系，用户和权限之间通过角色建立关系 在系统中验证时通过权限验证，角色只是权限集合，即显示角色 realm接口及其子类源码分析1、定义Realm接口，吃、从数据源中获得安全数据（如用户，角色，权限），判断用户身份是否合法，判断用户是否有权限 public interface Realm { //realm的名称 String getName(); //判断此 Realm 是否支持此 Token boolean supports(AuthenticationToken token); //传入用户凭证（用户名、密码），返回AuthenticationInfo AuthenticationInfo getAuthenticationInfo(AuthenticationToken token) throws AuthenticationException; } 2、CachingRealm，增加缓存的功能：维护一个CacheManager的成员变量；增加一个name成员变量，实现getName()方法 public abstract class CachingRealm implements Realm, Nameable, CacheManagerAware, LogoutAware { private CacheManager cacheManager; } 3、抽象类AuthenticatingRealm继承CachingRealm，主要功能是：1、从数据源中获取用户信息 2、利用CredentialsMatcher类，将用户传入的密码与数据库返回的密码进行比较（一般我们会自己创建service方法，判断用户名是否存在、密码是否正确，如果出现错误则抛出异常，验证通过返回AuthenticationInfo，此时Shiro会在帮你验证一次，其实没有必要，但框架这么写着你必须使用正确的CredentialsMatcher，使验证通过）；抽象方法doGetAuthenticationInfo需要由子类重写 public abstract class AuthenticatingRealm extends CachingRealm implements Initializable { //CredentialsMatcher用于密码校验 private CredentialsMatcher credentialsMatcher; public final AuthenticationInfo getAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { AuthenticationInfo info = getCachedAuthenticationInfo(token); if (info == null) { //otherwise not cached, perform the lookup: //从数据源获得用户信息 info = doGetAuthenticationInfo(token); log.debug("Looked up AuthenticationInfo [{}] from doGetAuthenticationInfo", info); if (token != null && info != null) { cacheAuthenticationInfoIfPossible(token, info); } } else { log.debug("Using cached authentication info [{}] to perform credentials matching.", info); } if (info != null) { //在Shiro中验证密码 assertCredentialsMatch(token, info); } else { log.debug("No AuthenticationInfo found for submitted AuthenticationToken [{}]. Returning null.", token); } return info; } //从数据源获得用户信息由子类改写 protected abstract AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException; //利用CredentialsMatcher验证密码是否正确，默认是SimpleCredentialsMatcher，调用其doCredentialsMatch方法，根据字节来判断密码是否一样 protected void assertCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) throws AuthenticationException { CredentialsMatcher cm = getCredentialsMatcher(); if (cm != null) { if (!cm.doCredentialsMatch(token, info)) { //not successful - throw an exception to indicate this: String msg = "Submitted credentials for token [" + token + "] did not match the expected credentials."; throw new IncorrectCredentialsException(msg); } } else { throw new AuthenticationException("A CredentialsMatcher must be configured in order to verify " + "credentials during authentication. If you do not wish for credentials to be examined, you " + "can configure an " + AllowAllCredentialsMatcher.class.getName() + " instance."); } } } 4、抽象类AuthorizingRealm，继承AuthenticatingRealm，主要功能是完成Authorizer委托的任务，完成isPermitted、hasRole等方法，所以实现了Authorizer接口；doGetAuthorizationInfo方法需要由子类改写 注意：成员变量PermissionResolver、RolePermissionResolver，由Authorizer传入 public abstract class AuthorizingRealm extends AuthenticatingRealm implements Authorizer, Initializable, PermissionResolverAware, RolePermissionResolverAware { //成员变量PermissionResolver、RolePermissionResolver，由Authorizer传入 private PermissionResolver permissionResolver; private RolePermissionResolver permissionRoleResolver; /* * 1、调用getAuthorizationInfo方法从数据库获得权限信息 * 2、查看用户是否有该操作的权限 */ public boolean hasRole(PrincipalCollection principal, String roleIdentifier) { AuthorizationInfo info = getAuthorizationInfo(principal); return hasRole(roleIdentifier, info); } protected boolean hasRole(String roleIdentifier, AuthorizationInfo info) { return info != null && info.getRoles() != null && info.getRoles().contains(roleIdentifier); } protected abstract AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals); //权限：1、调用PermissionResolver，先把权限字符串转换为Permission public boolean isPermitted(PrincipalCollection principals, String permission) { Permission p = getPermissionResolver().resolvePermission(permission); return isPermitted(principals, p); } //2、判断权限 public boolean isPermitted(PrincipalCollection principals, Permission permission) { AuthorizationInfo info = getAuthorizationInfo(principals); return isPermitted(permission, info); } //3、调用Permission的implies方法，将数据库的权限与用户传入的进行对比 protected boolean isPermitted(Permission permission, AuthorizationInfo info) { Collection perms = getPermissions(info); if (perms != null && !perms.isEmpty()) { for (Permission perm : perms) { if (perm.implies(permission)) { return true; } } } return false; } } realm相关对象实际开发过程中，自定义的realm继承AuthorizingRealm，改写doGetAuthenticationInfo和doGetAuthorizationInfo方法 doGetAuthenticationInfo 获取身份验证相关信息：1、调用Subject.login(token)触发方法，根据token获得User信息，没找到用户、密码不正确时抛出异常 2、生成AuthenticationInfo信息并返回 3、父类AuthenticatingRealm 使用 CredentialsMatcher 进行判断密码是否匹配， 如果不匹配将抛出密码错误异常，如果密码重试重试次数太多将抛出重试次数异常 doGetAuthorizationInfo 获取授权信息：根据用户名获得角色及权限信息，并组装成AuthorizationInfo返回 AuthenticationToken AuthenticationToken 用于收集用户提交的身份（如用户名）及凭据（如密码） Shiro 提供了一个直接拿来用的 UsernamePasswordToken，用于实现用户名/密码 Token 组，另外其实现了 RememberMeAuthenticationToken 和 HostAuthenticationToken， 可以实现记住我及主机验证的支持。 AuthenticationInfo AuthenticationInfo 有两个作用：1、如果 Realm 是 AuthenticatingRealm 子类，则提供给 AuthenticatingRealm 内部使用的CredentialsMatcher 进行凭据验证； （如果没有继承它需要在自己的 Realm 中自己实现验证）；2、提供给 SecurityManager 来创建 Subject（提供身份信息）； AuthorizationInfo AuthorizationInfo 用于聚合授权信息的 当我们使用 AuthorizingRealm 时 ， 如果身份验证成功 ， 在进行授权时就通过doGetAuthorizationInfo 方法获取角色/权限信息用于授权验证 Subject Subject 是 Shiro 的核心对象，基本所有身份验证、授权都是通过 Subject 完成。 SecurityManager源码分析★★★★★1、定义SecurityManager接口，同时继承Authenticator、Authorizer、SessionManager，为什么？代理模式，SecurityManager代理Authenticator、Authorize和SessionManager的操作，需要实现三者的接口 public interface SecurityManager extends Authenticator, Authorizer, SessionManager { Subject login(Subject subject, AuthenticationToken authenticationToken) throws AuthenticationException; void logout(Subject subject); Subject createSubject(SubjectContext context); } 2、CachingSecurityManager维护一个CacheManager成员变量 public abstract class CachingSecurityManager implements SecurityManager, Destroyable, CacheManagerAware, EventBusAware { private CacheManager cacheManager; } 3、RealmSecurityManager，设置realm public abstract class RealmSecurityManager extends CachingSecurityManager { private Collection&lt;Realm&gt; realms; public void setRealm(Realm realm) { if (realm == null) { throw new IllegalArgumentException(&quot;Realm argument cannot be null&quot;); } Collection&lt;Realm&gt; realms = new ArrayList&lt;Realm&gt;(1); realms.add(realm); setRealms(realms); } } 4、AuthenticatingSecurityManager保存一个Authenticator，默认是ModularRealmAuthenticator，代理认证的功能 public abstract class AuthenticatingSecurityManager extends RealmSecurityManager { private Authenticator authenticator; public AuthenticatingSecurityManager() { super(); this.authenticator = new ModularRealmAuthenticator(); } } 5、AuthorizingSecurityManager保存一个Authorizer功能，默认是ModularRealmAuthorizer，代理授权功能 public abstract class AuthorizingSecurityManager extends AuthenticatingSecurityManager { private Authorizer authorizer; public AuthorizingSecurityManager() { super(); this.authorizer = new ModularRealmAuthorizer(); } } 6、SessionsSecurityManager保存一个SessionManager，默认是DefaultSessionManager，代理会话管理 public abstract class SessionsSecurityManager extends AuthorizingSecurityManager { private SessionManager sessionManager; public SessionsSecurityManager() { super(); this.sessionManager = new DefaultSessionManager(); applyCacheManagerToSessionManager(); } } 7、DefaultSecurityManager：利用SubjectDAO、SubjectFactory创建、存储Subject public class DefaultSecurityManager extends SessionsSecurityManager { protected RememberMeManager rememberMeManager; protected SubjectDAO subjectDAO; protected SubjectFactory subjectFactory; public DefaultSecurityManager() { super(); this.subjectFactory = new DefaultSubjectFactory(); this.subjectDAO = new DefaultSubjectDAO(); } protected SubjectContext createSubjectContext() { return new DefaultSubjectContext(); } public Subject createSubject(SubjectContext subjectContext) { SubjectContext context = copy(subjectContext); context = ensureSecurityManager(context); context = resolveSession(context); context = resolvePrincipals(context); Subject subject = doCreateSubject(context); save(subject); return subject; } } 8、DefaultWebSecurityManager：增加了一些Session的维护 加密AuthenticatingRealm中的成员变量CredentialsMatcher进行密码验证服务，Shiro 提供了 redentialsMatcher 的散列实现 HashedCredentialsMatcher，它用于密码验证，且可以提供自己的盐 realm认证 //判断认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException { //返回AuthenticationInfo后在AuthenticatingRealm的assertCredentialsMatch方法中还需要进行验证 //数据库取出的用户名和密码 String username = &quot;admin&quot;; String password = &quot;b433ce675b32a824e24d762ca0fa1ba9&quot;;//数据库密码md5(&quot;admin&quot;,&quot;user&quot;) String salt = &quot;user&quot;; SimpleAuthenticationInfo simpleAuthenticationInfo = new SimpleAuthenticationInfo(username, password, getName()); simpleAuthenticationInfo.setCredentialsSalt(ByteSource.Util.bytes(salt)); return simpleAuthenticationInfo; } 设置密码匹配规则 staticRealm = StaticRealm hashedCredentialsMatcher = org.apache.shiro.authc.credential.HashedCredentialsMatcher hashedCredentialsMatcher.hashAlgorithmName = md5 staticRealm.credentialsMatcher = $hashedCredentialsMatcher securityManager.realms = $staticRealm Web集成ShiroFilter入口与 Spring 集成 &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; DelegatingFilterProxy 作用是自动到 spring 容器查找名字为 shiroFilter（filter-name）的 bean，并把所有 Filter 的操作委托给它。然后将 ShiroFilter 配置到 spring 容器即可 &lt;bean id=&quot;shiroFilter&quot;class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;propertyname=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;!—忽略其他，详见与 Spring 集成部分 --&gt; &lt;/bean&gt; 最后不要忘了使用 org.springframework.web.context.ContextLoaderListener 加载这个 spring配置文件即可 URL匹配[urls] /login=anon /unauthorized=anon /static/**=anon /authenticated=authc /role=authc,roles[admin] /permission=authc,perms[&quot;user:create&quot;] urls中配置格式是：url=拦截器[参数]，拦截器[参数]，即 如果当前请求的 url 匹配[urls]部分的某个 url 模式， 将会执行其配置的拦截器 anon 拦截器表示匿名访问（即不需要登录即可访问） authc 拦截器表示需要身份认证通过后才能访问 roles[admin] 拦截器表示需要有 admin 角色授权才能访问 perms[“user:create”] 拦截器表示需要有“user:create”权限才能访问 url 模式使用 Ant 风格模式，Ant 路径通配符支持 ? 、* 、**，注意通配符匹配不包括目录分隔符”/“： ?：匹配一个字符，如”/admin?”将匹配/admin1，但不匹配/admin 或/admin2； *：匹配零个或多个字符串，如/admin*将匹配/admin、/admin123，但不匹配/admin/1； **：匹配路径中的零个或多个路径，如/admin/**将匹配/admin/a 或/admin/a/b。 url 模式匹配顺序 url 模式匹配顺序是按照在配置中的声明顺序匹配，即从头开始使用第一个匹配的 url 模式对应的拦截器链 拦截器机制Shiro拦截器源码分析Shiro拦截器的基础类图 AbstractFilter：实现Filter接口，类的主要功能是实现Filter接口init方法，保存FilterConfig作为成员变量，在init方法中调用无参的setFilterConfig，子类的初始化方法通过改写onFilterConfigSet方法 NameableFilter：给Filter起个名字。在类中增加一个name成员变量，set/get方法 OncePerRequestFilter：一次请求中，保证过滤链中同一个过滤器只被执行一次，如内部的 forward 不会再多执行一次 doFilterInternal。重写Filter接口的doFilter方法，同时设置了enabled属性，表示是否开启该拦截器，子类需要重写doFilterInternal方法，加上具体的过滤操作 public final void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException { String alreadyFilteredAttributeName = getAlreadyFilteredAttributeName(); if (request.getAttribute(alreadyFilteredAttributeName) != null || shouldNotFilter(request)) { log.trace("Filter '{}' already executed. Proceeding without invoking this filter.", getName()); // Proceed without invoking this filter... filterChain.doFilter(request, response); } else { // Do invoke this filter... log.trace("Filter '{}' not yet executed. Executing now.", getName()); request.setAttribute(alreadyFilteredAttributeName, Boolean.TRUE); try { //抽象方法，由子类实现 doFilterInternal(request, response, filterChain); } finally { // Once the request has finished, we're done and we don't // need to mark as 'already filtered' any more. request.removeAttribute(alreadyFilteredAttributeName); } } } AbstractShiroFilter：Shiro过滤器前最后一个抽象类，有两个成员变量：WebSecurityManager（存储SecurityManager的引用，以便过滤器使用）、FilterChainResolver（首先拦截所有的url，再根据实际情况判断url是否需要拦截）；重写onFilterConfigSet方法，子类的初始化方法通过重写init方法完成初始化工作;重写doFilterInternal方法，为subject的入口，重点★★★★★ //重写onFilterConfigSet方法，子类重写init方法增加自定义初始化工作 protected final void onFilterConfigSet() throws Exception { //added in 1.2 for SHIRO-287: applyStaticSecurityManagerEnabledConfig(); init(); ensureSecurityManager(); //added in 1.2 for SHIRO-287: if (isStaticSecurityManagerEnabled()) { SecurityUtils.setSecurityManager(getSecurityManager()); } } ShiroFilter、SpringShiroFilter、SpringShiroFilter 实现 AbstractShiroFilter，主要功能是创建过滤器对象，并将SecurityManager和FilterChainResolver属性的注入 另一条过滤器主线：与SpringMVC中的拦截器类似进行设计 AdviceFilter AdviceFilter 提供了 AOP 风格的支持，类似于 SpringMVC 中的 Interceptor： 1、preHandler：类似于 AOP 中的前置增强；在拦截器链执行之前执行；如果返回 true 则继续拦截器链；否则中断后续的拦截器链的执行直接返回；进行预处理（如基于表单的身份验证、授权）2、postHandle： 类似于 AOP 中的后置返回增强； 在拦截器链执行完成后执行； 进行后处理 （如记录执行时间之类的）；3、afterCompletion：类似于 AOP 中的后置最终增强；即不管有没有异常都会执行；可以进行清理资源（如接触 Subject 与线程的绑定之类的）； //重写doFilterInternal方法 public void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws ServletException, IOException { Exception exception = null; try { //前置方法，如果前置返回false，则不执行下一个过滤器 boolean continueChain = preHandle(request, response); if (log.isTraceEnabled()) { log.trace("Invoked preHandle method. Continuing chain?: [" + continueChain + "]"); } if (continueChain) { executeChain(request, response, chain); } //后置方法，访问Servlet后执行 postHandle(request, response); if (log.isTraceEnabled()) { log.trace("Successfully invoked postHandle method"); } } catch (Exception e) { exception = e; } finally { //afterCompletion，不管有没有异常都会执行，可以进行清理资源 cleanup(request, response, exception); } } PathMatchingFilter：提供了基于 Ant 风格的请求路径匹配功能及拦截器参数解析的功能，如“roles[admin,user]”自动根据”，”分割解析到一个路径参数配置并绑定到相应的路径 1、pathsMatch该方法用于 path 与请求路径进行匹配的方法；如果匹配返回 true；2、onPreHandle：在 preHandle 中，当 pathsMatch 匹配一个路径后，会调用 opPreHandler 方法并将路径绑定参数配置传给 mappedValue；然后可以在这个方法中进行一些验证（如角色授权），如果验证失败可以返回 false 中断流程；默认返回 true；也就是说子类可以只实现onPreHandle 即可， 无须实现 preHandle。 如果没有 path 与请求路径匹配， 默认是通过的 （即preHandle 返回 true）。 protected boolean preHandle(ServletRequest request, ServletResponse response) throws Exception { if (this.appliedPaths == null || this.appliedPaths.isEmpty()) { if (log.isTraceEnabled()) { log.trace("appliedPaths property is null or empty. This Filter will passthrough immediately."); } return true; } for (String path : this.appliedPaths.keySet()) { // If the path does match, then pass on to the subclass implementation for specific checks //(first match 'wins'): if (pathsMatch(path, request)) { log.trace("Current requestURI matches pattern '{}'. Determining filter chain execution...", path); Object config = this.appliedPaths.get(path); return isFilterChainContinued(request, response, path, config); } } //no path matched, allow the request to go through: return true; } private boolean isFilterChainContinued(ServletRequest request, ServletResponse response, String path, Object pathConfig) throws Exception { if (isEnabled(request, response, path, pathConfig)) { //isEnabled check added in 1.2 if (log.isTraceEnabled()) { log.trace("Filter '{}' is enabled for the current request under path '{}' with config [{}]. " + "Delegating to subclass implementation for 'onPreHandle' check.", new Object[]{getName(), path, pathConfig}); } //The filter is enabled for this specific request, so delegate to subclass implementations //so they can decide if the request should continue through the chain or not: return onPreHandle(request, response, pathConfig); } if (log.isTraceEnabled()) { log.trace("Filter '{}' is disabled for the current request under path '{}' with config [{}]. " + "The next element in the FilterChain will be called immediately.", new Object[]{getName(), path, pathConfig}); } //This filter is disabled for this specific request, //return 'true' immediately to indicate that the filter will not process the request //and let the request/response to continue through the filter chain: return true; } AnonymousFilter：继承PathMatchingFilter，重写preHandle方法，总是返回true，则允许所有请求通过 AccessControlFilter：继承PathMatchingFilter，重写onPreHandle方法 public boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception { return isAccessAllowed(request, response, mappedValue) || onAccessDenied(request, response, mappedValue); } 1、isAccessAllowed：表示是否允许访问；mappedValue 就是[urls]配置中拦截器参数部分，如果允许访问返回 true，否则 false；2、onAccessDenied：表示当访问拒绝时是否已经处理了；如果返回 true 表示需要继续处理；如果返回 false 表示该拦截器实例已经处理了，将直接返回即可 总结： 1、如果用户有访问资源的权限，则isAccessAllowed返回true，onAccessDenied方法不会执行；2、如果没有访问权限，则isAccessAllowed返回false，而且会执行onAccessDenied方法，方法中可以进行页面跳转等操作，方法体一般返回false，表示不需要执行后面的过滤器了 两个方法为抽象方法，都需要都子类重写 另外 AccessControlFilter 还提供了如下方法用于处理如登录成功后/重定向到上一个请求： void setLoginUrl(String loginUrl) //身份验证时使用，默认/login.jsp String getLoginUrl() Subject getSubject(ServletRequest request, ServletResponse response) //获取 Subject 实例 boolean isLoginRequest(ServletRequest request, ServletResponse response)//当前请求是否是登录请求 void saveRequestAndRedirectToLogin(ServletRequest request, ServletResponse response) throws IOException //将当前请求保存起来并重定向到登录页面 void saveRequest(ServletRequest request) //将请求保存起来，如登录成功后再重定向回该请 求 void redirectToLogin(ServletRequest request, ServletResponse response) //重定向到登录页面 AuthenticationFilter继承AccessControlFilter，并重写isAccessAllowed方法，判断用户是否登录 protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) { Subject subject = getSubject(request, response); return subject.isAuthenticated(); } Shiro拦截器源码分析总结1、过滤器设计，顶层是接口，然后一个抽象类实现接口，每个抽象类中值承担一个职责！ AbstractFilter保存filterConfig，并提供一个无参的onFilterConfigSet初始化方法 NameableFilter为过滤器取一个名字 OncePerRequestFilter重写doFilter方法，保证一个过滤器在一次请求中只执行一次，过滤器中个操作转移到doFilterInternal中。 之后过滤器子类分为两个分支，一个是Shiro的主过滤器，配置在web.xml中，为Shiro的入口；另一个是AOP风格的过滤器形式，类时Spring MVC中的拦截器，进入ShiroFilter中先执行完Shiro的一些过滤器，在执行Tomcat中的其他过滤器 ★★★★★AdviceFilter重写doFilterInternal方法，将过滤操作分为preHandle、postHandle、afterCompletion操作。如果preHandle返回true，执行下一个过滤器，否则访问终止 PathMatchingFilter重写preHandle方法，进行路径匹配，路径匹配后是否执行Tomcat其他过滤器由onPreHandle的返回结果决定，供子类改写 AccessControlFilter重写onPreHandle方法，可以重写isAccessAllowed、onAccessDenied来实现访问控制 开发建议：如果我们想进行访问访问的控制就可以继承AccessControlFilter；如果我们要添加一些通用数据我们可以直接继承 PathMatchingFilter 拦截器链Shiro 对 Servlet 容器的 FilterChain 进行了代理，即 ShiroFilter 在继续 Servlet 容器的 Filter 链的执行之前，通过 ProxiedFilterChain 对 Servlet 容器的 FilterChain 进行了代理；即先走Shiro 自己的 Filter 体系，然后才会委托给 Servlet 容器的 FilterChain 进行 Servlet 容器级别的 Filter 链执行； Shiro 的 ProxiedFilterChain 执行流程：1、 执行 Shiro 自己的 Filter 链； 2、再执行 Servlet 容器的 Filter 链（即原始的 Filter） ★★★★★如何实现先执行Shiro自己的Filter链，然后执行Servlet容器的Filter链？ 1、调用Shiro的主过滤器后，执行AbstractShiroFilter类的doFilterInternal方法 protected void doFilterInternal(ServletRequest servletRequest, ServletResponse servletResponse, final FilterChain chain) throws ServletException, IOException { ... subject.execute(new Callable() { public Object call() throws Exception { updateSessionLastAccessTime(request, response); executeChain(request, response, chain); return null; } }); ... } 2、AbstractShiroFilter类的executeChain方法，会返回一个Servlet过滤链的代理类ProxiedFilterChain，当执行doFilter方法时，如果Shiro内部的过滤器没有执行完，先执行内部过滤器，等全部执行完成后，在执行Servlet的下一个过滤器。代理Chain对Servlet是透明的 protected void executeChain(ServletRequest request, ServletResponse response, FilterChain origChain) throws IOException, ServletException { FilterChain chain = getExecutionChain(request, response, origChain); chain.doFilter(request, response); } 代理过滤器链ProxiedFilterChain的代码如下，包含原来的过滤链和所需要执行的Shiro过滤器；如果Shiro过滤器没有执行完，则首先执行Shiro过滤器，之后再执行 Servlet 过滤器 public class ProxiedFilterChain implements FilterChain { //TODO - complete JavaDoc private static final Logger log = LoggerFactory.getLogger(ProxiedFilterChain.class); //原来的过滤链对象 private FilterChain orig; private List filters; private int index = 0; public ProxiedFilterChain(FilterChain orig, List filters) { if (orig == null) { throw new NullPointerException("original FilterChain cannot be null."); } this.orig = orig; this.filters = filters; this.index = 0; } public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException { //如果执行完Shiro的权限过滤器，则继续执行Servlet中的过滤器 if (this.filters == null || this.filters.size() == this.index) { //we've reached the end of the wrapped chain, so invoke the original one: if (log.isTraceEnabled()) { log.trace("Invoking original filter chain."); } this.orig.doFilter(request, response); } else { if (log.isTraceEnabled()) { log.trace("Invoking wrapped filter at index [" + this.index + "]"); } this.filters.get(this.index++).doFilter(request, response, this); } } } 代理过滤链的产生流程 1、AbstractShiroFilter中的getExecutionChain方法，通过FilterChainResolver的getChain方法，获得过滤链 protected FilterChain getExecutionChain(ServletRequest request, ServletResponse response, FilterChain origChain) { FilterChain chain = origChain; FilterChainResolver resolver = getFilterChainResolver(); if (resolver == null) { log.debug("No FilterChainResolver configured. Returning original FilterChain."); return origChain; } FilterChain resolved = resolver.getChain(request, response, origChain); if (resolved != null) { log.trace("Resolved a configured FilterChain for the current request."); chain = resolved; } else { log.trace("No FilterChain configured for the current request. Using the default."); } return chain; } 2、FilterChainResolver接口的默认实现是PathMatchingFilterChainResolver，必须实现getChain方法。DefaultFilterChainManager 实现 FilterChainManager 接口，维护着 url 模式与拦截器链的关系，遍历url模式，如果与访问的url匹配，则根据匹配的 url 模式找到相应的过滤器，用来生成过滤器链； public FilterChain getChain(ServletRequest request, ServletResponse response, FilterChain originalChain) { FilterChainManager filterChainManager = getFilterChainManager(); if (!filterChainManager.hasChains()) { return null; } String requestURI = getPathWithinApplication(request); for (String pathPattern : filterChainManager.getChainNames()) { if (pathMatches(pathPattern, requestURI)) { if (log.isTraceEnabled()) { log.trace("Matched path pattern [" + pathPattern + "] for requestURI [" + requestURI + "]. " + "Utilizing corresponding filter chain..."); } return filterChainManager.proxy(originalChain, pathPattern); } } return null; } PathMatchingFilterChainResolver维护着FilterChainManager和PatternMatcher两个成员变量，FilterChainManager维护着url 模式与拦截器链的关系，默认是DefaultFilterChainManager；PatternMatcher为请求url与url 模式的匹配方式，默认是AntPathMatcher（PathMatchingFilterChainResolver中构造器时赋值） Shiro Filter初始化时，ShiroFilterFactoryBean调用getObject时，createInstance中创建了一些重要的组件，包括SecurityManager、FilterChainResolver（FilterChainManager为其成员变量）。 protected AbstractShiroFilter createInstance() throws Exception { log.debug("Creating Shiro Filter instance."); SecurityManager securityManager = getSecurityManager(); if (securityManager == null) { String msg = "SecurityManager property must be set."; throw new BeanInitializationException(msg); } if (!(securityManager instanceof WebSecurityManager)) { String msg = "The security manager does not implement the WebSecurityManager interface."; throw new BeanInitializationException(msg); } //创建DefaultFilterChainManager FilterChainManager manager = createFilterChainManager(); //Expose the constructed FilterChainManager by first wrapping it in a // FilterChainResolver implementation. The AbstractShiroFilter implementations // do not know about FilterChainManagers - only resolvers: PathMatchingFilterChainResolver chainResolver = new PathMatchingFilterChainResolver(); chainResolver.setFilterChainManager(manager); //Now create a concrete ShiroFilter instance and apply the acquired SecurityManager and built //FilterChainResolver. It doesn't matter that the instance is an anonymous inner class //here - we're just using it because it is a concrete AbstractShiroFilter instance that accepts //injection of the SecurityManager and FilterChainResolver: return new SpringShiroFilter((WebSecurityManager) securityManager, chainResolver); } 拦截器链总结1、当用户发送请求时，被Shiro Filter拦截，利用FilterChainResolver的getChain方法，获得代理的过滤链，这样可以先执行Shiro 中的一些过滤器，再执行Servlet的其他过滤器2、获得过滤链代理的主要流程是：FilterChainResolver的实现类PathMatchingFilterChainResolver维护着FilterChainManager和PatternMatcher两个成员变量，FilterChainManager维护着url 模式与拦截器链的关系，PatternMatcher为请求url与url 模式的匹配方式，遍历url模式并与请求url进行匹配，获取配置的过滤器，组成代理的过滤器链，并返回 默认拦截器public enum DefaultFilter { anon(AnonymousFilter.class), authc(FormAuthenticationFilter.class), authcBasic(BasicHttpAuthenticationFilter.class), logout(LogoutFilter.class), noSessionCreation(NoSessionCreationFilter.class), perms(PermissionsAuthorizationFilter.class), port(PortFilter.class), rest(HttpMethodPermissionFilter.class), roles(RolesAuthorizationFilter.class), ssl(SslFilter.class), user(UserFilter.class); ... } 自己提出的问题★★★★★1、Shiro Filter中SecurityManager是否需要绑定到内存的问题 详见AbstractShiroFilter.java 如果在Shiro过滤器初始化参数中设置了staticSecurityManagerEnabled的值为true，则SecurityManager与线程绑定 默认是false，即SecurityManager不与线程绑定，设置在WebEnvironment中 2、Shiro Filter中SecurityManager变量依赖注入的方式 Shiro Filter中成员变量SecurityManager实例化的方式有两种： 第一种方式是 SecurityManager 在 Spring 中创建，可以自定义设置SecurityManager的属性，然后依赖注入到Shiro Filter中（单例） 如果没有通过依赖注入的方式得到SecurityManager的实例，Shiro将自动创建默认的SecurityManager（每次调用过滤器都会创建一个默认SecurityManager，不推荐） 详见AbstractShiroFilter.java 3、★★★★在Web.xml中配置 &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;!-- 该值缺省为false,表示生命周期由SpringApplicationContext管理,设置为true则表示由ServletContainer管理 --&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;!--使用[/*]匹配所有请求,保证所有的可控请求都经过Shiro的过滤--&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 在applicationContext-shiro.xml中配置 &lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; ... &lt;/bean&gt; 则DelegatingFilterProxy类与ShiroFilterFactoryBean的关系是什么？ 答：DelegatingFilterProxy是一个代理类，具体的操作交给内部的Filter对象delegate去处理，这个delegate通过Spring容器的中的ShiroFilterFactoryBean的工厂方法getBean获取，返回对象类型是SpringShiroFilter，即代理的Filter对象为SpringShiroFilter 处理流程：1、Tomcat扫描web.xml文件，到过滤器节点，遇到DelegatingFilterProxy的配置，生成一个DelegatingFilterProxy的实例，并调用其init方法 &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; 2、init方法在其父类GenericFilterBean中实现，init方法中调用initFilterBean方法，其在子类DelegatingFilterProxy中改写，代理对象通过语句 this.delegate = initDelegate(wac) 获得3、查看initDelegate方法，有如下语句：Filter delegate = wac.getBean(getTargetBeanName(), Filter.class)，代理对象是从Spring容器中根据id获得，id即为过滤器的名称shiroFilter，你就知道为什么web.xml中过滤器的名称和application-shiro.xml中的bean id要一致了 &lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; ... &lt;/bean&gt; 4、在Spring容器中查找id为shiroFilter，类型为Filter的对象，即为ShiroFilterFactoryBean。但ShiroFilterFactoryBean实现了工厂类，上面的delegate真正的对象是通过它的getObject()获取的 public Object getObject() throws Exception { if (instance == null) { instance = createInstance(); } return instance; } 5、真正创建对象的方法在createInstance中，可见代理的过滤器是SpringShiroFilter protected AbstractShiroFilter createInstance() throws Exception { ... return new SpringShiroFilter((WebSecurityManager) securityManager, chainResolver); } 6、SpringShiroFilter: ShiroFilterFactoryBean的内部类，继承AbstractShiroFilter private static final class SpringShiroFilter extends AbstractShiroFilter { protected SpringShiroFilter(WebSecurityManager webSecurityManager, FilterChainResolver resolver) { super(); if (webSecurityManager == null) { throw new IllegalArgumentException(&quot;WebSecurityManager property cannot be null.&quot;); } setSecurityManager(webSecurityManager); if (resolver != null) { setFilterChainResolver(resolver); } } } 7、每次URL请求，经过代理过滤器DelegatingFilterProxy时，调用SpringShiroFilter实例的doFilter方法 DelegatingFilterProxy.java public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException { // Lazily initialize the delegate if necessary. Filter delegateToUse = this.delegate; if (delegateToUse == null) { synchronized (this.delegateMonitor) { if (this.delegate == null) { WebApplicationContext wac = findWebApplicationContext(); if (wac == null) { throw new IllegalStateException("No WebApplicationContext found: no ContextLoaderListener registered?"); } this.delegate = initDelegate(wac); } delegateToUse = this.delegate; } } // Let the delegate perform the actual doFilter operation. invokeDelegate(delegateToUse, request, response, filterChain); } 总结： 1、Tomcat创建代理对象，初始化代理对象的时候，代理对象通过bean工厂获得被代理对象，并做成其成员对象；每当来一个客户端请求，代理对象的doFilter方法，代理对象调用被代理对象的doFilter方法 2、DelegatingFilterProxy的主要作用就是一个代理模式的应用,可以把 servlet 容器中的filter同spring容器中的bean关联起来[既可以代理Spring Security的过滤器，也可以代理Shiro中的过滤器] 4、 路径匹配规则 1、路径为空，不进行匹配默认全部通过2、请求url与资源权限路径列表从上到下进行匹配，如果某一个路径匹配，进行权限验证，根据返回结果通过还是拒绝 会话管理会话所谓会话，即用户访问应用时保持的连接关系，在多次交互中应用能够识别出当前访问的用户是谁，且可以在多次交互中保存一些数据。如访问一些网站时登录成功后，网站可以记住用户，且在退出之前都可以识别当前用户是谁。 public interface Session { /** * 获取当前会话的唯一标识。 */ Serializable getId(); /* 获得属性 */ Object getAttribute(Object key) throws InvalidSessionException; /* 设置属性 */ void setAttribute(Object key, Object value) throws InvalidSessionException; /* 删除属性 */ Object removeAttribute(Object key) throws InvalidSessionException; ... } 会话存储/持久化★★★★★Shiro 提供 SessionDAO 用于会话的 CRUD，即 DAO（Data Access Object）模式实现： //如 DefaultSessionManager 在创建完 session 后会调用该方法；如保存到关系数据库/文件 系统/NoSQL 数据库；即可以实现会话的持久化；返回会话 ID ；主要此处返回的 ID.equals(session.getId())； Serializable create(Session session); //根据会话 ID 获取会话 Session readSession(Serializable sessionId) throws UnknownSessionException; //更新会话；如更新会话最后访问时间/停止会话/设置超时时间/设置移除属性等会调用 void update(Session session) throws UnknownSessionException; //删除会话；当会话过期/会话停止（如用户退出时）会调用 void delete(Session session); //获取当前所有活跃用户，如果用户量多此方法影响性能 Shiro 内嵌了如下 SessionDAO 实现： AbstractSessionDAO 提供了 SessionDAO 的基础实现， 如生成会话 ID 等； CachingSessionDAO提供了对开发者透明的会话缓存的功能，只需要设置相应的 CacheManager 即可；MemorySessionDAO 直接在内存中进行会话维护； 而 EnterpriseCacheSessionDAO 提供了缓存功能的会话维护，默认情况下使用 MapCache 实现，内部使用 ConcurrentHashMap 保存缓存的会话。 可以通过如下配置设置 SessionDAO： sessionDAO=org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAO sessionManager.sessionDAO=$sessionDAO Shiro 提供了使用 Ehcache 进行会话存储，Ehcache 可以配合 TerraCotta 实现容器无关的分布式集群——98页 会话管理器 会话管理器管理着应用中所有 Subject 的会话的创建、维护、删除、失效、验证等工作。是Shiro 的核心组件 顶层组件 SecurityManager 直接继承了 SessionManager，且提供了SessionsSecurityManager 实 现直接把会话管理委托给相应的 SessionManager public abstract class SessionsSecurityManager extends AuthorizingSecurityManager { private SessionManager sessionManager; public Session start(SessionContext context) throws AuthorizationException { return this.sessionManager.start(context); } public Session getSession(SessionKey key) throws SessionException { return this.sessionManager.getSession(key); } ... } Shiro 提供了三个默认实现： DefaultSessionManager：DefaultSecurityManager 使用的默认实现，用于 JavaSE 环境； ServletContainerSessionManager： DefaultWebSecurityManager 使用的默认实现，用于 Web环境，其直接使用 Servlet 容器的会话； DefaultWebSessionManager： 用于 Web 环境的实现 ， 可以替代ServletContainerSessionManager，自己维护着会话，直接废弃了 Servlet 容器的会话管理。 替换默认的会话管理器 在 Servlet 容器中，默认使用 JSESSIONID Cookie 维护会话，且会话默认是跟容器绑定的；在某些情况下可能需要使用自己的会话机制，此时我们可以使用 DefaultWebSessionManager来维护会话： #sessionIdCookie 是 sessionManager 创建会话 Cookie 的模板 sessionIdCookie=org.apache.shiro.web.servlet.SimpleCookie sessionManager=org.apache.shiro.web.session.mgt.DefaultWebSessionManager #sessionIdCookie.name：设置 Cookie 名字，默认为 JSESSIONID sessionIdCookie.name=sid #sessionIdCookie.domain：设置 Cookie 的域名，默认空，即当前访问的域名 #sessionIdCookie.domain=sishuok.com #sessionIdCookie.path：设置 Cookie 的路径，默认空，即存储在域名根下 #sessionIdCookie.path= #sessionIdCookie.maxAge：设置 Cookie 的过期时间，秒为单位，默认-1 表示关闭浏览器时过期 Cookie sessionIdCookie.maxAge=1800 #sessionIdCookie.httpOnly如果设置为 true，则客户端不会暴露给客户端脚本代码，使用HttpOnlycookie 有助于减少某些类型的跨站点脚本攻击； 此特性需要实现了 Servlet2.5 MR6及以上版本的规范的 Servlet 容器支持 sessionIdCookie.httpOnly=true sessionManager.sessionIdCookie=$sessionIdCookie #sessionManager.sessionIdCookieEnabled：是否启用/禁用 Session Id Cookie，默认是启用的；如果禁用后将不会设置 Session Id Cookie， 即默认使用了 Servlet 容器的 JSESSIONID， 且通过 URL 重写（URL 中的“;JSESSIONID=id”部分）保存 Session Id。 sessionManager.sessionIdCookieEnabled=true securityManager.sessionManager=$sessionManager 会话监听器会话监听器用于监听会话创建、过期及停止事件 会话验证Shiro 提供了会话验证调度器，用于定期的验证会话是否已过期，如果过期将停止会话；出于性能考虑， 一般情况下都是获取会话时来验证会话是否过期并停止会话的； 但是如在 web 环境中，如果用户不主动退出是不知道会话是否过期的，因此需要定期的检测会话是否过期，Shiro 提供了会话验证调度器 SessionValidationScheduler 来做这件事情。 Session源代码 Session是个状态性的数据上下文，可以理解为每个用户都有一个特定数据库，该数据库存储着每个用户自己的数据，在shiro里，它是和Subject绑定在一起的，通常用户通过Subject.getSession来获取使用。它在系统内会存活一段时间为用户提供客户端浏览器和应用服务器通讯的一些功能。以下是一些关于Session的使用场景。 1、用户登陆成功后，应用服务器产生个Session，且返回该Session的唯一标识符ID给客户端保存（可通过cookie，或者uri参数等形式）。这样用户访问需要验证后的URL时，应用服务器就能识别。 注意：shiro在用户第一次通过浏览器第一次访问应用服务器时，就会产生Session了，且返回SessionID，后面如果用户再登陆的话，则会在Session里存储该用户已经登陆的。 2、像网上商城，用户通常都会浏览自己喜欢商品，满意后则添加到购物车，由于Session相当于个人的小数据库，此时可以利用Session存储用户添加到购物车的商品，等用户选择完去付款时，此时从Session中获取该用户购物车的商品进行计费、生成订单付费即可。 Shiro实现了自己的Session，即由shiro来管理Session的生命周期。可以为任意的应用提供Session支持。 具体：http://blog.csdn.net/wojiaolinaaa/article/details/48312299 1、Session public interface Session { //返回Session的标识符 Serializable getId(); //根据key获取Session存储的值 Object getAttribute(Object key) throws InvalidSessionException; //设置值和key到session中 void setAttribute(Object key, Object value) throws InvalidSessionException; //根据key删除值 Object removeAttribute(Object key) throws InvalidSessionException; ... } 2、SimpleSession //SimpleSession实现了ValidatingSession和Serializable接口，支持验证session操作和序列化 public class SimpleSession implements ValidatingSession, Serializable { private transient Map&lt;Object, Object&gt; attributes; //sessonID，用于保持客户端浏览器和服务端Session存储容器之间的标识 private transient Serializable id; public Serializable getId() { return this.id; } public Object getAttribute(Object key) { Map&lt;Object, Object&gt; attributes = getAttributes(); if (attributes == null) { return null; } return attributes.get(key); } public void setAttribute(Object key, Object value) { if (value == null) { removeAttribute(key); } else { getAttributesLazy().put(key, value); } } public Object removeAttribute(Object key) { Map&lt;Object, Object&gt; attributes = getAttributes(); if (attributes == null) { return null; } else { return attributes.remove(key); } } } 3、DelegatingSession 服务端的代理的Session，该DelegatingSession 只是保存了真正的底层Session（SimpleSession）的key，然后根据该key来查找到SimpleSession再代理它的操作。Subject.getSession()获取的就是该DelegatingSession，也许是为了不让用户破坏底层Session的一些特性吧 public class DelegatingSession implements Session, Serializable { private final SessionKey key; //用于根据SessionKey来操作真正的底层Session private final transient NativeSessionManager sessionManager; public Serializable getId() { return key.getSessionId(); } public Object getAttribute(Object attributeKey) throws InvalidSessionException { return sessionManager.getAttribute(this.key, attributeKey); } public void setAttribute(Object attributeKey, Object value) throws InvalidSessionException { if (value == null) { removeAttribute(attributeKey); } else { sessionManager.setAttribute(this.key, attributeKey, value); } } public Object removeAttribute(Object attributeKey) throws InvalidSessionException { return sessionManager.removeAttribute(this.key, attributeKey); } } 4、ProxiedSession 该类主要作用是代理真正的Session，为子类提供可重写方法。如：不可调用代理某个方法，如果调用则抛出异常 public class ProxiedSession implements Session { //真正的Session protected final Session delegate; public Object getAttribute(Object key) throws InvalidSessionException { return delegate.getAttribute(key); } public void setAttribute(Object key, Object value) throws InvalidSessionException { delegate.setAttribute(key, value); } public Object removeAttribute(Object key) throws InvalidSessionException { return delegate.removeAttribute(key); } } 5、ImmutableSession ImmutableProxiedSession 继承与ProxiedSession ，该类主要作用是返回一个不可修改Session的代理Session,对于修改的方法都重写抛异常 public class ImmutableProxiedSession extends ProxiedSession { } 6、StoppingAwareProxiedSession StoppingAwareProxiedSession 主要是增强代理Session的方法 private class StoppingAwareProxiedSession extends ProxiedSession { } 7、HttpServletSession 该Session仅仅只是代理了servlet的HttpSession。方便与ServletContainerSessionManager和shiro实现可易配置。把session交由servlet Container来控制生命周期。 SessionFactory源码分析SessionManager根据SessionContext来创建出一个Session，默认是实现是SimpleSessionFactory 默认的SessionFactory SimpleSessionFactory的创建过程： public Session createSession(SessionContext initData) { if (initData != null) { String host = initData.getHost(); if (host != null) { return new SimpleSession(host); } } return new SimpleSession(); } 如果SessionContext有host信息，就传递给Session，然后就是直接new一个Session接口的实现SimpleSession SessionDAOSessionDAO接口，即对Session进行增删改查 public interface SessionDAO { Serializable create(Session session); Session readSession(Serializable sessionId) throws UnknownSessionException; void update(Session session) throws UnknownSessionException; void delete(Session session); Collection&lt;Session&gt; getActiveSessions(); } create:为Session分配Session-ID，并保存Session readSession:提供Session-ID取出Session SessionDAO 接口继承关系如下： AbstractSessionDAO：有一个重要的属性SessionIdGenerator，它负责给Session创建sessionId，SessionIdGenerator接口如下： public interface SessionIdGenerator { Serializable generateId(Session session); } 很简单，参数为Session，返回sessionId。SessionIdGenerator 的实现有两个JavaUuidSessionIdGenerator、RandomSessionIdGenerator。而AbstractSessionDAO默认采用的是JavaUuidSessionIdGenerator，如下： public AbstractSessionDAO() { this.sessionIdGenerator = new JavaUuidSessionIdGenerator(); } AbstractSessionDAO实现了接口create方法，具体创建Session，存储，传回Session-ID方法由子类实现： public Serializable create(Session session) { Serializable sessionId = doCreate(session); verifySessionId(sessionId); return sessionId; } abstract Serializable doCreate(Session session)； AbstractSessionDAO实现了接口readSession方法，具体根据Session-ID从缓存中获取Session的方法由子类实现： public Session readSession(Serializable sessionId) throws UnknownSessionException { Session s = doReadSession(sessionId); if (s == null) { throw new UnknownSessionException(&quot;There is no session with id [&quot; + sessionId + &quot;]&quot;); } return s; } protected abstract Session doReadSession(Serializable sessionId); MemorySessionDAO：继承了AbstractSessionDAO，它把Session存储在一个ConcurrentMap sessions集合中，key为sessionId，value为Session //Session存储在ConcurrentMap集合中 private ConcurrentMap&lt;Serializable, Session&gt; sessions; public MemorySessionDAO() { this.sessions = new ConcurrentHashMap&lt;Serializable, Session&gt;(); } //重写父类创建Session的方法 protected Serializable doCreate(Session session) { //调用父类的获取Session-ID Serializable sessionId = generateSessionId(session); //为Session设置Session-ID assignSessionId(session, sessionId); //存储Session storeSession(sessionId, session); return sessionId; } protected Session storeSession(Serializable id, Session session) { if (id == null) { throw new NullPointerException(&quot;id argument cannot be null.&quot;); } return sessions.putIfAbsent(id, session); } //重写父类读取Session的方法，从Map中根据键值取出Session protected Session doReadSession(Serializable sessionId) { return sessions.get(sessionId); } CachingSessionDAO：主要配合在别的地方存储session，维护了一个成员变量cacheManager，默认的activeSessionsCacheName名为shiro-activeSessionCache private CacheManager cacheManager; 扩展了AbstractSessionDAO的create方法，在创建Session后，放入缓存 public Serializable create(Session session) { Serializable sessionId = super.create(session); cache(session, sessionId); return sessionId; } 扩展了AbstractSessionDAO的readSession方法，先从缓存中获取，如果不行，再去数据库获取 public Session readSession(Serializable sessionId) throws UnknownSessionException { Session s = getCachedSession(sessionId); if (s == null) { s = super.readSession(sessionId); } return s; } EnterpriseCacheSessionDAO：doCreate操作完成了为Session分配Session-ID protected Serializable doCreate(Session session) { Serializable sessionId = generateSessionId(session); assignSessionId(session, sessionId); return sessionId; } doReadSession操作不执行任何功能 protected Session doReadSession(Serializable sessionId) { return null; //should never execute because this implementation relies on parent class to access cache, which //is where all sessions reside - it is the cache implementation that determines if the //cache is memory only or disk-persistent, etc. } 如果使用默认的EnterpriseCacheSessionDAO，那么设置的缓存管理器就是内存，与MemorySessionDAO无任何差异，如果使用了外部的缓存管理器，如Ehcache，则将缓存保存到指定的缓存中 public EnterpriseCacheSessionDAO() { setCacheManager(new AbstractCacheManager() { @Override protected Cache&lt;Serializable, Session&gt; createCache(String name) throws CacheException { return new MapCache&lt;Serializable, Session&gt;(name, new ConcurrentHashMap&lt;Serializable, Session&gt;()); } }); } 注意：这些缓存不支持持久化，如果要保存缓存进入数据库，需要自定义SessionDAO的doCreate()和doReadSession()方法，见张开涛的跟我学Shiro SessionManager源代码解析http://www.cnblogs.com/Kavlez/p/4135857.html 正如其名，sessionManager用于为应用中的Subject管理session，比如创建、删除、失效或者验证等，和Shiro中的其他核心组件一样，他由SecurityManager维护。 Shiro为SessionManager提供了3个实现类(顺便也整理一下与SecurityManager实现类的关系)。 DefaultSessionManager DefaultWebSessionManager ServletContainerSessionManager 其中ServletContainerSessionManager只适用于servlet容器中，如果需要支持多种客户端访问，则应该使用DefaultWebSessionManager。 SessionManager的接口关系： ThreadContext、SubjectContext（类似）http://www.codeweblog.com/shiro%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BA%8C-subject%E5%92%8Csession/ ThreadContext（类似于数据库，共享Subject、SecurityManager）ThreadLocal模式线程内共享Subject、SecurityManager，ThreadLocal模式只能共享一个变量，由于需求要保存多个对象，保存这个变量类型为Map public abstract class ThreadContext { public static final String SECURITY_MANAGER_KEY = ThreadContext.class.getName() + &quot;_SECURITY_MANAGER_KEY&quot;; public static final String SUBJECT_KEY = ThreadContext.class.getName() + &quot;_SUBJECT_KEY&quot;; private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new InheritableThreadLocalMap&lt;Map&lt;Object, Object&gt;&gt;(); ..... } 绑定SecurityManager：如果SecurityManager不为空，向线程局部变量的map中，以键存入SECURITY_MANAGER_KEY，值securityManager存入； public static void bind(SecurityManager securityManager) { if (securityManager != null) { put(SECURITY_MANAGER_KEY, securityManager); } } public static void put(Object key, Object value) { ensureResourcesInitialized(); resources.get().put(key, value); } //如果map没有初始化，新建一个HashMap private static void ensureResourcesInitialized(){ if (resources.get() == null){ resources.set(new HashMap&lt;Object, Object&gt;()); } } 取出SecurityManager：取出线程局部变量中的map，根据资源获得SecurityManager public static SecurityManager getSecurityManager() { return (SecurityManager) get(SECURITY_MANAGER_KEY); } public static Object get(Object key) { Object value = getValue(key); return value; } private static Object getValue(Object key) { Map&lt;Object, Object&gt; perThreadResources = resources.get(); return perThreadResources != null ? perThreadResources.get(key) : null; } 设置、取出Subject同理： public static void bind(Subject subject) { if (subject != null) { put(SUBJECT_KEY, subject); } } public static Subject getSubject() { return (Subject) get(SUBJECT_KEY); } SubjectContext于ThreadContext的设计类似 Subject.getSession(boolean create)整体三大步骤，先创建一个SessionContext ，然后传递SessionContext给securityMa但我们可以看下如何创建Session的nager来创建Session，最后是装饰Session,由于创建Session过程内容比较多，先说说装饰Session。 public class DelegatingSubject implements Subject { public Session getSession(boolean create) { if (this.session == null &amp;&amp; create) { //①创建SessionContext SessionContext sessionContext = createSessionContext(); //②SecurityManager调用SessionManager创建Session Session session = this.securityManager.start(sessionContext); //③装饰Session this.session = decorate(session); } return this.session; } //创建SessionContext protected SessionContext createSessionContext() { SessionContext sessionContext = new DefaultSessionContext(); if (StringUtils.hasText(host)) { sessionContext.setHost(host); } return sessionContext; } protected Session decorate(Session session) { if (session == null) { throw new IllegalArgumentException(&quot;session cannot be null&quot;); } return new StoppingAwareProxiedSession(session, this); } } 装饰Session就是将Session和DelegatingSubject封装起来，返回的Session包含Subject和Session的实例，其中owner表示拥有该Session的Subject，delegate为代理的Session，类型为DelegatingSession private class StoppingAwareProxiedSession extends ProxiedSession { private final DelegatingSubject owner; private StoppingAwareProxiedSession(Session target, DelegatingSubject owningSubject) { super(target); owner = owningSubject; } } Subject调用SessionManager创建Session的具体过程可以参见上节：Session、SessionFactory、SessionDAO、SessionManager SecurityUtils创建SubjectSecurityUtils总体如下，SecurityUtils类中维护一个securityManager变量，它需要由用户自己创建SecurityManager，然后set进入SecurityUtils中进行存储，在应用程序中共享SecurityManager public abstract class SecurityUtils { private static SecurityManager securityManager; public static Subject getSubject() { Subject subject = ThreadContext.getSubject(); if (subject == null) { subject = (new Subject.Builder()).buildSubject(); ThreadContext.bind(subject); } return subject; } public static void setSecurityManager(SecurityManager securityManager) { SecurityUtils.securityManager = securityManager; } public static SecurityManager getSecurityManager() throws UnavailableSecurityManagerException { SecurityManager securityManager = ThreadContext.getSecurityManager(); if (securityManager == null) { securityManager = SecurityUtils.securityManager; } return securityManager; } } 第一次使用SecurityUtils.getSubject()来获取Subject： public static Subject getSubject() { Subject subject = ThreadContext.getSubject(); if (subject == null) { subject = (new Subject.Builder()).buildSubject(); ThreadContext.bind(subject); } return subject; } 首先使用ThreadLocal模式来获取，若没有则使用 Subject subject = (new Subject.Builder()).buildSubject(); 创建一个并绑定到当前线程（Subject与线程绑定） 此时创建使用的是Subject内部类Builder来创建的，Builder会创建一个SubjectContext接口的实例DefaultSubjectContext，最终会委托securityManager来根据SubjectContext信息来创建一个Subject public interface Subject { ..... public static class Builder { private final SubjectContext subjectContext; private final SecurityManager securityManager; public Builder() { this(SecurityUtils.getSecurityManager()); } //Builder会创建一个SubjectContext接口的实例DefaultSubjectContext public Builder(SecurityManager securityManager) { if (securityManager == null) { throw new NullPointerException(&quot;SecurityManager method argument cannot be null.&quot;); } this.securityManager = securityManager; this.subjectContext = newSubjectContextInstance(); if (this.subjectContext == null) { throw new IllegalStateException(&quot;Subject instance returned from &apos;newSubjectContextInstance&apos; &quot; + &quot;cannot be null.&quot;); } this.subjectContext.setSecurityManager(securityManager); } protected SubjectContext newSubjectContextInstance() { return new DefaultSubjectContext(); } //委托securityManager来根据SubjectContext信息来创建一个Subject public Subject buildSubject() { return this.securityManager.createSubject(this.subjectContext); } } } ★★★★★在DefaultSecurityManager的createSubject下面详细说下该过程，在DefaultSecurityManager的createSubject方法中： public Subject createSubject(SubjectContext subjectContext) { SubjectContext context = copy(subjectContext); context = ensureSecurityManager(context); context = resolveSession(context); context = resolvePrincipals(context); Subject subject = doCreateSubject(context); save(subject); return subject; } 首先就是复制SubjectContext，即新建一个SubjectContext实例，与原来的对象具有相同的属性值，SubjectContext的详细介绍见下一节 对于context，把能获取到的参数都凑齐，SecurityManager、Session、Principal，以Session为例，整个过程如下; public class DefaultSecurityManager extends SessionsSecurityManager { //①以获取Session为例 protected SubjectContext resolveSession(SubjectContext context) { //②尝试获取context的map中获取Session if (context.resolveSession() != null) { log.debug(&quot;Context already contains a session. Returning.&quot;); return context; } try { //Context couldn&apos;t resolve it directly, let&apos;s see if we can since we have direct access to //the session manager: //③若没有再尝试获取sessionId Session session = resolveContextSession(context); if (session != null) { context.setSession(session); } } catch (InvalidSessionException e) { log.debug(&quot;Resolved SubjectContext context session is invalid. Ignoring and creating an anonymous &quot; + &quot;(session-less) Subject instance.&quot;, e); } return context; } protected Session resolveContextSession(SubjectContext context) throws InvalidSessionException { SessionKey key = getSessionKey(context); if (key != null) { return getSession(key); } return null; } protected SessionKey getSessionKey(SubjectContext context) { Serializable sessionId = context.getSessionId(); if (sessionId != null) { return new DefaultSessionKey(sessionId); } return null; } } 首先调用SubjectContext的resolveSession方法，尝试获取context的map中获取Session： 1、首先获取与SubjectContext中Session 2、如果没找到，尝试获取SubjectContext存储的Subject，如果存在的话，调用Subject的getSession方法获取Session（不新建Session，没有返回null） 若没有再尝试获取sessionId,若果有了sessionId则构建成一个DefaultSessionKey来获取对应的Session。 注意：第一次调用SecurityUtil.getSubject()创建Subject的时候不新建Session SubjectContext的参数填充完整后，进行实际的Subject创建工作，调用DefaultSecurityManager的doCreateSubject方法：请按照1，2，3，4的顺序查看 public class DefaultSecurityManager extends SessionsSecurityManager { protected SubjectDAO subjectDAO; protected SubjectFactory subjectFactory; //④SubjectDAO、SubjectFactory默认值 public DefaultSecurityManager() { super(); this.subjectFactory = new DefaultSubjectFactory(); this.subjectDAO = new DefaultSubjectDAO(); } //①创建Subject public Subject createSubject(SubjectContext subjectContext) { //SubjectContext参数的获取 SubjectContext context = copy(subjectContext); context = ensureSecurityManager(context); context = resolveSession(context); context = resolvePrincipals(context); //②具体创建Subject Subject subject = doCreateSubject(context); save(subject); return subject; } //③ //通过SubjectFactory工厂接口来创建Subject的，而DefaultSecurityManager默认使用的SubjectFactory是DefaultSubjectFactory： protected Subject doCreateSubject(SubjectContext context) { return getSubjectFactory().createSubject(context); } } 继续看DefaultSubjectFactory是怎么创建Subject的： public Subject createSubject(SubjectContext context) { SecurityManager securityManager = context.resolveSecurityManager(); Session session = context.resolveSession(); boolean sessionCreationEnabled = context.isSessionCreationEnabled(); PrincipalCollection principals = context.resolvePrincipals(); boolean authenticated = context.resolveAuthenticated(); String host = context.resolveHost(); return new DelegatingSubject(principals, authenticated, host, session, sessionCreationEnabled, securityManager); } 仍然就是从SubjectContext获取这些属性，传递给新建的Subject实例：DelegatingSubject，也没什么好说的，到此为止创建一个Subject实例DelegatingSubject，维护了Principal、authenticated、host、session，此时除了host全为空，并返回； public class DelegatingSubject implements Subject { private static final Logger log = LoggerFactory.getLogger(DelegatingSubject.class); private static final String RUN_AS_PRINCIPALS_SESSION_KEY = DelegatingSubject.class.getName() + &quot;.RUN_AS_PRINCIPALS_SESSION_KEY&quot;; protected PrincipalCollection principals; protected boolean authenticated; protected String host; protected Session session; } 创建完成之后，就需要将刚创建的Subject保存起来 来看下save方法： protected void save(Subject subject) { this.subjectDAO.save(subject); } 可以看到又是使用另一个模块来完成的即SubjectDAO，SubjectDAO接口的默认实现为DefaultSubjectDAO()，具体的实现类DefaultSubjectDAO是如何来保存的： public Subject save(Subject subject) { if (isSessionStorageEnabled(subject)) { saveToSession(subject); } else { log.trace(&quot;Session storage of subject state for Subject [{}] has been disabled: identity and &quot; + &quot;authentication state are expected to be initialized on every request or invocation.&quot;, subject); } return subject; } 首先就是判断isSessionStorageEnabled，是否要存储该Subject的session到DefaultSubjectDAO：有一个重要属性SessionStorageEvaluator，它是用来决定一个Subject的Session来记录Subject的状态，接口如下 public interface SessionStorageEvaluator { boolean isSessionStorageEnabled(Subject subject); } 其实现为DefaultSessionStorageEvaluator： public class DefaultSessionStorageEvaluator implements SessionStorageEvaluator { private boolean sessionStorageEnabled = true; public boolean isSessionStorageEnabled(Subject subject) { return (subject != null &amp;&amp; subject.getSession(false) != null) || isSessionStorageEnabled(); } } 决定策略就是通过DefaultSessionStorageEvaluator 的sessionStorageEnabled的true或false 和subject是否有Session对象来决定的。如果允许存储Subject的Session的话，下面就说 具体的存储过程： protected void saveToSession(Subject subject) { mergePrincipals(subject); mergeAuthenticationState(subject); } protected void mergePrincipals(Subject subject) { //merge PrincipalCollection state: PrincipalCollection currentPrincipals = null; //SHIRO-380: added if/else block - need to retain original (source) principals //This technique (reflection) is only temporary - a proper long term solution needs to be found, //but this technique allowed an immediate fix that is API point-version forwards and backwards compatible // //A more comprehensive review / cleaning of runAs should be performed for Shiro 1.3 / 2.0 + if (subject.isRunAs() &amp;&amp; subject instanceof DelegatingSubject) { try { Field field = DelegatingSubject.class.getDeclaredField(&quot;principals&quot;); field.setAccessible(true); currentPrincipals = (PrincipalCollection)field.get(subject); } catch (Exception e) { throw new IllegalStateException(&quot;Unable to access DelegatingSubject principals property.&quot;, e); } } if (currentPrincipals == null || currentPrincipals.isEmpty()) { currentPrincipals = subject.getPrincipals(); } Session session = subject.getSession(false); if (session == null) { //只有当Session为空，并且currentPrincipals不为空的时候才会去创建Session //Subject subject = SecurityUtils.getSubject()此时两者都是为空的， //不会去创建Session if (!CollectionUtils.isEmpty(currentPrincipals)) { session = subject.getSession(); session.setAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY, currentPrincipals); } //otherwise no session and no principals - nothing to save } else { PrincipalCollection existingPrincipals = (PrincipalCollection) session.getAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY); if (CollectionUtils.isEmpty(currentPrincipals)) { if (!CollectionUtils.isEmpty(existingPrincipals)) { session.removeAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY); } //otherwise both are null or empty - no need to update the session } else { if (!currentPrincipals.equals(existingPrincipals)) { session.setAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY, currentPrincipals); } //otherwise they&apos;re the same - no need to update the session } } } 上面有我们关心的重点，当subject.getSession(false)获取的Session为空时（它不会去创建Session），此时就需要去创建Session，subject.getSession()则默认调用的是subject.getSession(true),则会进行Session的创建，创建过程上文已详细说明了。 在第一次创建Subject的时候 Subject subject = SecurityUtils.getSubject(); 虽然Session为空，但此时还没有用户身份信息，也不会去创建Session 所以创建的DelegatingSubject实例，成员变量Principal、Session全是空 Subject.login(token)案例中的subject.login(token)该过程则会去创建Session，具体看下过程： 首先DelegatingSubject调用login方法会委托给SecurityManager的securityManager.login(this, token)方法 public void login(AuthenticationToken token) throws AuthenticationException { clearRunAsIdentitiesInternal(); //SecurityManager完成实际的登录操作 Subject subject = securityManager.login(this, token); PrincipalCollection principals; String host = null; if (subject instanceof DelegatingSubject) { DelegatingSubject delegating = (DelegatingSubject) subject; principals = delegating.principals; host = delegating.host; } else { principals = subject.getPrincipals(); } if (principals == null || principals.isEmpty()) { String msg = &quot;Principals returned from securityManager.login( token ) returned a null or &quot; + &quot;empty value. This value must be non null and populated with one or more elements.&quot;; throw new IllegalStateException(msg); } this.principals = principals; this.authenticated = true; if (token instanceof HostAuthenticationToken) { host = ((HostAuthenticationToken) token).getHost(); } if (host != null) { this.host = host; } Session session = subject.getSession(false); if (session != null) { this.session = decorate(session); } else { this.session = null; } } SecurityManager的login方法分为两步：1、对用户名、密码验证 2、创建Subject public Subject login(Subject subject, AuthenticationToken token) throws AuthenticationException { //对用户名、密码验证 AuthenticationInfo info; try { info = authenticate(token); } catch (AuthenticationException ae) { try { onFailedLogin(token, ae, subject); } catch (Exception e) { if (log.isInfoEnabled()) { log.info(&quot;onFailedLogin method threw an &quot; + &quot;exception. Logging and propagating original AuthenticationException.&quot;, e); } } throw ae; //propagate } //在该过程会进行Session的创建 Subject loggedIn = createSubject(token, info, subject); onSuccessfulLogin(token, info, loggedIn); return loggedIn; } 对于验证过程这里不再说明，重点还是在验证通过后，会创建一个新的Subject，同时Subject中包含认证信息和Session； 新建SubjectContext，并设置了认证信息 protected Subject createSubject(AuthenticationToken token, AuthenticationInfo info, Subject existing) { SubjectContext context = createSubjectContext(); context.setAuthenticated(true); context.setAuthenticationToken(token); context.setAuthenticationInfo(info); if (existing != null) { context.setSubject(existing); } //根据SubjectContext创建Subject，之前详细讲解过 return createSubject(context); } protected SubjectContext createSubjectContext() { return new DefaultSubjectContext(); } 在系统刚启动时，创建Subject时，参数SubjectContext中的Session、Principal都为空，不创建Session；但在调用Subject.login有了认证成功的AuthenticationInfo信息，调用SubjectContext在resolvePrincipals便可以获取用户信息 再次调用createSubject(context）创建Subject，此时resolvePrincipals(context)中，可以获取到刚才认证传入的AuthenticationInfo，并取出Principal。在SubjectContext中Principal不为空，但Session为空 public Subject createSubject(SubjectContext subjectContext) { SubjectContext context = copy(subjectContext); context = ensureSecurityManager(context); context = resolveSession(context); context = resolvePrincipals(context); Subject subject = doCreateSubject(context); save(subject); return subject; } PrincipalCollection不为空了，在save(subject)的时候会得到session为空，同时PrincipalCollection不为空，则会执行Session的创建。也就是说在认证通过后，会执行Session的创建，返回的Session为Subject和Session的封装体，并在Session中存入Principal调用subject.getSession()，回返回一个Subject和Session的封装体，并且设置该Session为Subject的成员变量 protected void mergePrincipals(Subject subject) { PrincipalCollection currentPrincipals = null; if (subject.isRunAs() &amp;&amp; subject instanceof DelegatingSubject) { try { Field field = DelegatingSubject.class.getDeclaredField(&quot;principals&quot;); field.setAccessible(true); currentPrincipals = (PrincipalCollection)field.get(subject); } catch (Exception e) { throw new IllegalStateException(&quot;Unable to access DelegatingSubject principals property.&quot;, e); } } if (currentPrincipals == null || currentPrincipals.isEmpty()) { currentPrincipals = subject.getPrincipals(); } Session session = subject.getSession(false); if (session == null) { if (!CollectionUtils.isEmpty(currentPrincipals)) { //【此处会执行！！！】Principal不为空会创建一个Session //调用subject.getSession()，回返回一个Subject和Session的共同体，并且设置该Session为Subject的成员变量 session = subject.getSession(); //Session中存入Principal session.setAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY, currentPrincipals); } //otherwise no session and no principals - nothing to save } else { PrincipalCollection existingPrincipals = (PrincipalCollection) session.getAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY); if (CollectionUtils.isEmpty(currentPrincipals)) { if (!CollectionUtils.isEmpty(existingPrincipals)) { session.removeAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY); } //otherwise both are null or empty - no need to update the session } else { if (!currentPrincipals.equals(existingPrincipals)) { session.setAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY, currentPrincipals); } //otherwise they&apos;re the same - no need to update the session } } } 委托SecurityManager执行登录操作完毕，回到DelegatingSubject的login函数，返回了新建的Subject Session创建完成之后会进行一次装饰，即用新建一个StoppingAwareProxiedSession对象，其中的delegate为session（也为StoppingAwareProxiedSession类型），owner为Subject，然后又进行如下操作： public class DelegatingSubject implements Subject { public void login(AuthenticationToken token) throws AuthenticationException { clearRunAsIdentitiesInternal(); //★★★★★这里的Subject则是经过认证后创建的并且也含有刚才创建的session Subject subject = securityManager.login(this, token); PrincipalCollection principals; String host = null; if (subject instanceof DelegatingSubject) { DelegatingSubject delegating = (DelegatingSubject) subject; //we have to do this in case there are assumed identities - we don't want to lose the 'real' principals: principals = delegating.principals; host = delegating.host; } else { principals = subject.getPrincipals(); } if (principals == null || principals.isEmpty()) { String msg = "Principals returned from securityManager.login( token ) returned a null or " + "empty value. This value must be non null and populated with one or more elements."; throw new IllegalStateException(msg); } //内部Subject的principal、session、authenticated复制到外部的Subject this.principals = principals; this.authenticated = true; if (token instanceof HostAuthenticationToken) { host = ((HostAuthenticationToken) token).getHost(); } if (host != null) { this.host = host; } Session session = subject.getSession(false); if (session != null) { //在这里可以看到又进行了一次装饰 this.session = decorate(session); } else { this.session = null; } } } subject 创建出来之后，暂且叫内部subject，就是把认证通过的内部subject的信息和session复制给我们外界使用的subject.login(token)的subject中（principals、host、authenticated、Session），这个subject暂且叫外部subject，看下session的赋值，又进行了一次装饰，这次装饰则把session(类型为StoppingAwareProxiedSession，即是内部subject和session的合体)和外部subject绑定到一起 从Cookie、URL、request中根据Token获取Session1、客户端请求到来，调用AbstractShiroFilter中的doFilterInternal方法，创建Subject final Subject subject = createSubject(request, response); 2、调用WebSubject.Builder().buildWebSubject方法 protected WebSubject createSubject(ServletRequest request, ServletResponse response) { return new WebSubject.Builder(getSecurityManager(), request, response).buildWebSubject(); } 3、创建WebSubject与默认的Subject稍微有差别，但还是调用父类（即Subject接口的Builder中的BuildSubject方法） public WebSubject buildWebSubject() { Subject subject = super.buildSubject(); if (!(subject instanceof WebSubject)) { String msg = &quot;Subject implementation returned from the SecurityManager was not a &quot; + WebSubject.class.getName() + &quot; implementation. Please ensure a Web-enabled SecurityManager &quot; + &quot;has been configured and made available to this builder.&quot;; throw new IllegalStateException(msg); } return (WebSubject) subject; } 4、父类的buildSubject方法，将创建Subject的方法委托为SecurityManager public Subject buildSubject() { return this.securityManager.createSubject(this.subjectContext); } 5、DefaultSecurityManager的createSubject public Subject createSubject(SubjectContext subjectContext) { SubjectContext context = copy(subjectContext); context = ensureSecurityManager(context); context = resolveSession(context); context = resolvePrincipals(context); Subject subject = doCreateSubject(context); save(subject); return subject; } 6、resolveSession(context)解析Session，context.resolveSession()返回的是null，调用Session session = resolveContextSession(context)尝试获取Session protected SubjectContext resolveSession(SubjectContext context) { //① if (context.resolveSession() != null) { log.debug(&quot;Context already contains a session. Returning.&quot;); return context; } try { //Context couldn&apos;t resolve it directly, let&apos;s see if we can since we have direct access to //the session manager: //② Session session = resolveContextSession(context); if (session != null) { context.setSession(session); } } catch (InvalidSessionException e) { log.debug(&quot;Resolved SubjectContext context session is invalid. Ignoring and creating an anonymous &quot; + &quot;(session-less) Subject instance.&quot;, e); } return context; } 7、具体看resolveContextSession，调用getSessionKey(context) protected Session resolveContextSession(SubjectContext context) throws InvalidSessionException { SessionKey key = getSessionKey(context); if (key != null) { return getSession(key); } return null; } 8、DefaultWebSecurityManager重写getSessionKey(SubjectContext context)方法 protected SessionKey getSessionKey(SubjectContext context) { if (WebUtils.isWeb(context)) { Serializable sessionId = context.getSessionId(); ServletRequest request = WebUtils.getRequest(context); ServletResponse response = WebUtils.getResponse(context); return new WebSessionKey(sessionId, request, response); } else { return super.getSessionKey(context); } } 返回WebSessionKey实例，但WebSessionKey中的sessionId为null 9、回到第7步SessionKey key = getSessionKey(context)，此时key不为空，调用SessionSecurityManager的getSession方法（接口方法） public Session getSession(SessionKey key) throws SessionException { return this.sessionManager.getSession(key); } 10、调用AbstractNativeSessionManager中的getSession public Session getSession(SessionKey key) throws SessionException { Session session = lookupSession(key); return session != null ? createExposedSession(session, key) : null; } 11、进入到lookupSession private Session lookupSession(SessionKey key) throws SessionException { if (key == null) { throw new NullPointerException(&quot;SessionKey argument cannot be null.&quot;); } return doGetSession(key); } 12、doGetSession被子类AbstractValidatingSessionManager重写 protected final Session doGetSession(final SessionKey key) throws InvalidSessionException { enableSessionValidationIfNecessary(); log.trace(&quot;Attempting to retrieve session with key {}&quot;, key); Session s = retrieveSession(key); if (s != null) { validate(s, key); } return s; } 13、retrieveSession也是个抽象方法，被子类DefaultSessionManager重写， protected Session retrieveSession(SessionKey sessionKey) throws UnknownSessionException { Serializable sessionId = getSessionId(sessionKey); if (sessionId == null) { log.debug(&quot;Unable to resolve session ID from SessionKey [{}]. Returning null to indicate a &quot; + &quot;session could not be found.&quot;, sessionKey); return null; } Session s = retrieveSessionFromDataSource(sessionId); if (s == null) { //session ID was provided, meaning one is expected to be found, but we couldn&apos;t find one: String msg = &quot;Could not find session with ID [&quot; + sessionId + &quot;]&quot;; throw new UnknownSessionException(msg); } return s; } 14、getSessionId被子类DefaultWebSessionManager重写 public Serializable getSessionId(SessionKey key) { Serializable id = super.getSessionId(key); if (id == null &amp;&amp; WebUtils.isWeb(key)) { ServletRequest request = WebUtils.getRequest(key); ServletResponse response = WebUtils.getResponse(key); id = getSessionId(request, response); } return id; } 由于父类的getSessionId返回null，执行getSessionId(request,response) protected Serializable getSessionId(SessionKey sessionKey) { return sessionKey.getSessionId(); } 15、DefaultWebSessionManager的getSessionId protected Serializable getSessionId(ServletRequest request, ServletResponse response) { return getReferencedSessionId(request, response); } 16、★★★★★★★getReferencedSessionId先解析cookie，在解析URL，最后解析 private Serializable getReferencedSessionId(ServletRequest request, ServletResponse response) { String id = getSessionIdCookieValue(request, response); if (id != null) { request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_SOURCE, ShiroHttpServletRequest.COOKIE_SESSION_ID_SOURCE); } else { //not in a cookie, or cookie is disabled - try the request URI as a fallback (i.e. due to URL rewriting): //try the URI path segment parameters first: id = getUriPathSegmentParamValue(request, ShiroHttpSession.DEFAULT_SESSION_ID_NAME); if (id == null) { //not a URI path segment parameter, try the query parameters: String name = getSessionIdName(); id = request.getParameter(name); if (id == null) { //try lowercase: id = request.getParameter(name.toLowerCase()); } } if (id != null) { request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_SOURCE, ShiroHttpServletRequest.URL_SESSION_ID_SOURCE); } } if (id != null) { request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID, id); //automatically mark it valid here. If it is invalid, the //onUnknownSession method below will be invoked and we&apos;ll remove the attribute at that time. request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_IS_VALID, Boolean.TRUE); } // always set rewrite flag - SHIRO-361 request.setAttribute(ShiroHttpServletRequest.SESSION_ID_URL_REWRITING_ENABLED, isSessionIdUrlRewritingEnabled()); return id; } SubjectContext、MapContext、Map接口设计: MapContext：实现了Map接口，内部拥有一个类型为HashMap的backingMap属性，大部分方法都由HashMap来实现，然后仅仅更改某些行为，MapContext没有选择去继承HashMap，而是使用了组合的方式，更加容易去扩展，如backingMap的类型不一定非要选择HashMap，可以换成其他的Map实现，一旦MapContext选择继承HashMap，如果想对其他的Map类型进行同样的功能增强的话，就需要另写一个类来继承它然后改变一些方法实现，这样的话就会有很多重复代码。这也是设计模式所强调的少用继承多用组合 public class MapContext implements Map&lt;String, Object&gt;, Serializable { private static final long serialVersionUID = 5373399119017820322L; private final Map&lt;String, Object&gt; backingMap; public MapContext() { this.backingMap = new HashMap&lt;String, Object&gt;(); } public MapContext(Map&lt;String, Object&gt; map) { this(); if (!CollectionUtils.isEmpty(map)) { this.backingMap.putAll(map); } } //略 } SubjectContext接口继承了Map，然后加入了几个重要的SecurityManager、SessionId、Subject、PrincipalCollection、Session、boolean authenticated、boolean sessionCreationEnabled、Host、AuthenticationToken、AuthenticationInfo等众多信息。 MapContext中增加了getTypedValue方法，便于获得参数化的类型： protected &lt;E&gt; E getTypedValue(String key, Class&lt;E&gt; type) { E found = null; Object o = backingMap.get(key); if (o != null) { if (!type.isAssignableFrom(o.getClass())) { String msg = &quot;Invalid object found in SubjectContext Map under key [&quot; + key + &quot;]. Expected type &quot; + &quot;was [&quot; + type.getName() + &quot;], but the object under that key is of type &quot; + &quot;[&quot; + o.getClass().getName() + &quot;].&quot;; throw new IllegalArgumentException(msg); } found = (E) o; } return found; } 可以把Map当做公有基本类，然后SubjectContext在此基础上扩展，类似于公有方法和新添加的方法；Map定义了这个类的功能是存储，SubjectContext在此基础上增加了SecurityManager、Subject、Session的存储 讨论1：首先是SubjectContext为什么要去实现Map？ 实现对数据的存储有设计方式有两种方式：1、继承数据结构，如map，自然就可以调用Map的put/get方法对数据进行存储2、组合方式，即类中存放一个存储型数据结构，如map，调用成员变量的put/get方法实现存储 ThreadContext采用采用的是组合方式，SubjectContext采用的是继承方式 讨论2：SubjectContext接口的作用？ SubjectContext提供了常用的get、set方法，还提供了一个resolve方法，以SecurityManager为例： SecurityManager getSecurityManager(); void setSecurityManager(SecurityManager securityManager); SecurityManager resolveSecurityManager(); 这些get、set方法则用于常用的设置和获取，而resolve则表示先调用getSecurityManager，如果获取不到，则使用其他途径来获取，如DefaultSubjectContext的实现： public SecurityManager resolveSecurityManager() { SecurityManager securityManager = getSecurityManager(); if (securityManager == null) { if (log.isDebugEnabled()) { log.debug(&quot;No SecurityManager available in subject context map. &quot; + &quot;Falling back to SecurityUtils.getSecurityManager() lookup.&quot;); } try { securityManager = SecurityUtils.getSecurityManager(); } catch (UnavailableSecurityManagerException e) { if (log.isDebugEnabled()) { log.debug(&quot;No SecurityManager available via SecurityUtils. Heuristics exhausted.&quot;, e); } } } return securityManager; } 如果getSecurityManager获取不到，则使用SecurityUtils工具来获取。再如resolvePrincipals public PrincipalCollection resolvePrincipals() { PrincipalCollection principals = getPrincipals(); if (CollectionUtils.isEmpty(principals)) { //check to see if they were just authenticated: AuthenticationInfo info = getAuthenticationInfo(); if (info != null) { principals = info.getPrincipals(); } } if (CollectionUtils.isEmpty(principals)) { Subject subject = getSubject(); if (subject != null) { principals = subject.getPrincipals(); } } if (CollectionUtils.isEmpty(principals)) { //try the session: Session session = resolveSession(); if (session != null) { principals = (PrincipalCollection) session.getAttribute(PRINCIPALS_SESSION_KEY); } } return principals; } 普通的getPrincipals()获取不到，尝试使用其他属性来获取。 SubjectFactory DefaultSubjectFactory: 根据SubjectContext，解析出ecurityManager、Session、PrincipalCollection等信息，生成一个代理Subject：DelegatingSubject public Subject createSubject(SubjectContext context) { SecurityManager securityManager = context.resolveSecurityManager(); Session session = context.resolveSession(); boolean sessionCreationEnabled = context.isSessionCreationEnabled(); PrincipalCollection principals = context.resolvePrincipals(); boolean authenticated = context.resolveAuthenticated(); String host = context.resolveHost(); return new DelegatingSubject(principals, authenticated, host, session, sessionCreationEnabled, securityManager); } Subject ★★★会话管理总结1、服务器刚启动时，创建Subject，其Principal、Session为空2、用户登录，调用Subject.login获取用户信息，创建Session，在Session中存入Principal信息，更新Subject中的Session、Principal3、下次用户携带Token登录，恢复Session，取出Principal，建立带状态信息的Subject 缓存机制环境导入依赖 &lt;!--shiro与ehcache整合--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;${shiro.version}&lt;/version&gt; &lt;!--1.3.2--&gt; &lt;/dependency&gt; &lt;!--ehcache,纯Java开源缓存框架--&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt; &lt;version&gt;2.10.1&lt;/version&gt; &lt;/dependency&gt; ehcache.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;ehcache xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ehcache.org/ehcache.xsd&quot; updateCheck=&quot;false&quot;&gt; &lt;diskStore path=&quot;java.io.tmpdir&quot;/&gt; &lt;!-- Mandatory Default Cache configuration. These settings will be applied to caches created programmtically using CacheManager.add(String cacheName) --&gt; &lt;!-- name:缓存名称。 maxElementsInMemory：缓存最大个数。 eternal:对象是否永久有效，一但设置了，timeout将不起作用。 timeToIdleSeconds：设置对象在失效前的允许闲置时间（单位：秒）。仅当eternal=false对象不是永久有效时使用，可选属性，默认值是0，也就是可闲置时间无穷大。 timeToLiveSeconds：设置对象在失效前允许存活时间（单位：秒）。最大时间介于创建时间和失效时间之间。仅当eternal=false对象不是永久有效时使用，默认是0.，也就是对象存活时间无穷大。 overflowToDisk：当内存中对象数量达到maxElementsInMemory时，Ehcache将会对象写到磁盘中。 diskSpoolBufferSizeMB：这个参数设置DiskStore（磁盘缓存）的缓存区大小。默认是30MB。每个Cache都应该有自己的一个缓冲区。 maxElementsOnDisk：硬盘最大缓存个数。 diskPersistent：是否缓存虚拟机重启期数据 Whether the disk store persists between restarts of the Virtual Machine. The default value is false. diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是120秒。 memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。默认策略是LRU（最近最少使用）。你可以设置为FIFO（先进先出）或是LFU（较少使用）。 clearOnFlush：内存数量最大时是否清除。 --&gt; &lt;defaultCache maxElementsInMemory=&quot;10000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;120&quot; timeToLiveSeconds=&quot;120&quot; overflowToDisk=&quot;true&quot; maxElementsOnDisk=&quot;10000000&quot; diskPersistent=&quot;false&quot; diskExpiryThreadIntervalSeconds=&quot;120&quot; memoryStoreEvictionPolicy=&quot;LRU&quot; /&gt; &lt;cache name=&quot;shiro&quot; maxEntriesLocalHeap=&quot;2000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;600&quot; timeToLiveSeconds=&quot;600&quot; overflowToDisk=&quot;false&quot; statistics=&quot;true&quot;&gt; &lt;/cache&gt; &lt;/ehcache&gt; OAuth2根据应用场景的不同，目前实现开放授权的方法分为两种：一种是使用OAuth协议；另一种是使用IAM服务 OAuth协议主要适用于针对个人用户对资源的开放授权，比如Google的用户Alice允许别的应用程序（如Facebook）访问他的联系人列表 IAM它的特点是”预先授权”或”离线授权”，客户端通过REST API去访问资源，资源所有者可以预先知道第三方应用所需的资源请求，一次授权之后，很少会更改。IAM服务一般在云计算服务中使用，如阿里云计算服务 OAuth 角色资源拥有者（resource owner）：能 授权 访问受保护资源的一个实体，可以是一个人，我们称之为最终用户，如新浪微博用户、zhangsan 资源服务器（resource server）：存储受保护资源，客户端通过 access token 请求资源，资源服务器响应受保护资源给客户端，存储着用户 zhangsan 的微博等信息 授权服务器（authorization server）：成功验证资源拥有者并获取授权之后，授权服务器颁发授权令牌（Access Token）给客户端 客户端（client）：如新浪微博客户端、微格等第三方应用，也可以是它自己的官方应用，其本身不存储资源，而是资源拥有者授权通过后，使用它的授权（授权令牌）访问受保护资源，然后客户端把相应的数据展示出来/提交到服务器。”客户端”术语不代表任何特定实现（如应用运行在一台服务器、桌面、手机或其他设备） OAuth2 协议流程 1、客户端从 资源拥有者 那请求授权。授权请求可以直接发给资源拥有者，或间接的通过授权服务器这种中介，后者更可取。（我们常会看到跳出弹框，是否允许第三方授权，需要用户决定是否同意）2、客户端收到一个 授权许可，代表资源服务器提供的授权3、客户端使用它自己的私有证书及授权许可到 授权服务器 验证4、如果验证成功，则下发一个 访问令牌5、客户端使用访问令牌向 资源服务器 请求受保护资源6、资源服务器会验证访问令牌的有效性，如果成功则下发受保护资源 无状态 Web 应用集成在一些环境中，可能需要把 Web 应用做成无状态的，即服务器端无状态，就是说 服务器端不会存储像会话这种东西，而是每次请求时带上相应的用户名进行登录。如一些 REST 风格的 API，如果不使用 OAuth2 协议，就可以使用如 REST+HMAC 认证进行访问。 HMAC（Hash-based Message Authentication Code）：基于散列的消息认证码，使用一个密钥和一个消息作为输入，生成它们的消息摘要。注意该密钥只有客户端和服务端知道，其他第三方是不知道的。 访问时使用该消息摘要进行传播，服务端然后对该消息摘要进行验证。如果只传递用户名+密码的消息摘要， 一旦被别人捕获可能会重复使用该摘要进行认证。解决办法如： 1、每次客户端申请一个 Token，然后使用该 Token 进行加密，而该 Token 是一次性的，即只能用一次；有点类似于 OAuth2 的 Token 机制，但是简单些；2、客户端每次生成一个唯一的 Token，然后使用该 Token 加密，这样服务器端记录下这些Token，如果之前用过就认为是非法请求 权限实例http://www.360doc.com/content/14/0529/10/11298474_381933566.shtml# 权限概述有一个用户管理系统，注册的用户分为normal用户，manager用户，admin用户，有系统管理、用户管理、角色管理三类操作，我们规定： admin 可以访问 /admin/** manager 可以访问 /admin/user/** normal 可以访问 /admin/role/** 用户 admin 拥有 admin、manager、normal 三种角色，可以访问/admin/**，/admin/user/**,/admin/role/**的资源 用户 zhangsan 拥有 manager、normal 两种角色，可以访问 /admin/user/**，/admin/role/** 用户 lisi 拥有 normal 角色，可以访问 /admin/role/** 权限是应用程序的一些基本操作，角色是权限的集合 我们采用下面的逻辑创建权限表结构（不是绝对的，根据需要修改） 用户与角色关系：多对多一个用户可以有多种角色（normal,manager,admin等等）一个角色可以有多个用户（user1,user2,user3等等） 角色与权限关系：多对多一个角色可以有多个权限（save,update,delete,query等等）一个权限可以属于多个角色 数据库设计我们创建五张表： tb_user用户表：设置了3个用户 +----+-----------+---------------------------------- | id | user_name | password +----+-----------+---------------------------------- | 1 | admin | 086bad3456e2653dc05e32a77000ce87 | 2 | zhangsan | 39dd5dcf4b69e917f7a32233462c55d4 | 3 | lisi | a259a0625727a416130cdb03e6e9dfb6 +----+-----------+---------------------------------- tb_role角色表：设置3个角色 +----+-----------+-------------+ | id | role_name | description | +----+-----------+-------------+ | 1 | admin | 系统管理员 | | 2 | manager | 系统顾问 | | 3 | normal | 系统用户 | +----+-----------+-------------+- tb_user_role用户角色表： +----+---------+---------+ | id | user_id | role_id | +----+---------+---------+ | 1 | 1 | 1 | | 2 | 1 | 2 | | 3 | 1 | 3 | | 4 | 2 | 2 | | 5 | 2 | 3 | | 6 | 3 | 3 | +----+---------+---------+ tb_resources权限表： +----+---------------+------------+----------------+ | id | resource_name | permission | url | +----+---------------+------------+----------------+ | 1 | 系统管理 | NULL | /admin/** | | 2 | 用户管理 | NULL | /admin/user/** | | 3 | 角色管理 | NULL | /admin/role/** | +----+---------------+------------+----------------+ select * from tb_role_resource角色权限表： +----+---------+-------------+ | id | role_id | resource_id | +----+---------+-------------+ | 1 | 1 | 1 | | 2 | 2 | 2 | | 3 | 3 | 3 | +----+---------+-------------+]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码阅读]]></title>
    <url>%2F2016%2F10%2F13%2F%5BJDK%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%5DJDK%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[文件IO//类加载根目录String parent = getClass().getClassLoader().getResource(“”).getPath(); BufferedOutputStream要介绍BufferedOutputStream，我们先了解一下OutputStream类抽象类OutputStream类有三个write方法 public abstract void write(int b) public void write(byte b[]) public void write(byte b[], int off, int len) 由上面我们可以看出第一个write方法是让子类覆盖的，而第二个人write（byte b[]）方法源代码如下 public void write(byte b[]) throws IOException { write(b, 0, b.length); } 所以可见最后处理还是调用第三个方法write(byte b[],int off,int len)，该方法源码如下： public void write(byte b[], int off, int len) throws IOException { if (b == null) { throw new NullPointerException(); } else if ((off &lt; 0) || (off &gt; b.length) || (len &lt; 0) || ((off + len) &gt; b.length) || ((off + len) &lt; 0)) { throw new IndexOutOfBoundsException(); } else if (len == 0) { return; } for (int i = 0 ; i &lt; len ; i++) { //注意这儿，这儿其实调用前面的抽象方法write（int b）,同时还发生了自动转型 write(b[off + i]); } } 我们先不看抽象方法是如何实现的，也就是说OutputStream也具有缓存器功能，我们可以将要写入到流中的数据写到一个byte[] buf数组中，然后调用write(byte b[])或者write(byte b[], int off, int len)也可以，那为什么还要BufferedInputStream类干什么呢，他们有什么区别呢。同时我们知道BufferedInputStream类中还有一个flush()方法，在OutputStream流中没有flush()方法，这又是为什么呢？flush()是不是必须的呢，接下来看一下BufferedOutputStream类； 首先，BufferedOutput将OutputStream类对象作为一个构造方法的参数的。首先看一下 BufferedOutputStream 类源代码 public class BufferedOutputStream extends FilterOutputStream { //这儿定义了一个byte[]数组，用来充当缓存器 protected byte buf[]; //这个变量是重点，他就是用来记录当前缓存器中的字节数量的 protected int count; //我们初始化创建一个对象的时候给了这个buf这个数组8192个字节. public BufferedOutputStream(OutputStream out) { this(out, 8192); } public BufferedOutputStream(OutputStream out, int size) { super(out); if (size &lt;= 0) { throw new IllegalArgumentException(&quot;Buffer size &lt;= 0&quot;); } // 这儿创建一个给定大小的数组对象来充当缓存器 buf = new byte[size]; } public synchronized void write(int b) throws IOException { if (count &gt;= buf.length) { flushBuffer(); } buf[count++] = (byte)b; } //该方法是重点 public synchronized void write(byte b[], int off, int len) throws IOException { //如果传进来的数组长度大于buf 数组的长度，则直接调用OutputStream对象的write方法。 if (len &gt;= buf.length) { flushBuffer(); out.write(b, off, len); return; } //验证BufferedOutputStream 类中buf剩下的空间能否装得下传进来的数组。如果不能则先将当前buf数组中数据写入底层io流中 if (len &gt; buf.length - count) { flushBuffer(); } //该处是重点，如果在当前BufferedOutputStream 类中buf数组没有满，则将传进来的数组复制到当前类对象buf数组中，同时更新count的值。 System.arraycopy(b, off, buf, count, len); count += len; //调用flushBuffer方法也就是将不满8192个字节数组中的数据发送出去。同时将count置零。 private void flushBuffer() throws IOException { if (count &gt; 0) { out.write(buf, 0, count); count = 0; } } //强制将buf数据中未满8192个字节的数据写入底层io中。 public synchronized void flush() throws IOException { flushBuffer(); out.flush(); } } 结论： OutputStream的缓存器（数组）与BufferedOutputStream中类的缓存器（数组）本质是一样的，只是BufferedOutputStream类中将要写入到底层io流中的数据先 凑个整，然后再一起写入底层io流中，这样就大大节省了io操作，大大提高了io利用率，写一次io是很费资源的。这样也出现了一个问题，假设向硬盘中写入一个文件，文件最后数据比默认值8192个字节小，则BufferOutputStream就不会将这些数据写入底层io流中，造成文件缺失，因此就需要在close()前调用flush（）方法，强制将还没有装满buf数组的数据写入底层io中。同时也可以看出节点流是不用flush()方法的，而一般的处理流都会采用固定buf这种方式的，比如常用的PrintWriter里面其实操作的就是一个BufferedWriter对象，因此也需要调用flush（）方法来刷新，因为默认是不刷新的。 引用：http://m.blog.csdn.net/article/details?id=51355523 ArrayscopyOf //复制原来的数组，长度为newLength public static T[] copyOf(T[] original, int newLength) { return (T[]) copyOf(original, newLength, original.getClass()); } public static T[] copyOf(U[] original, int newLength, Class newType) { T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); //将original复制到copy中，从originnal的0开始，copy的0开始，长度为newLength System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; } sort //from包括，toIndex不包括 public static void sort(int[] a, int fromIndex, int toIndex) { rangeCheck(a.length, fromIndex, toIndex); sort1(a, fromIndex, toIndex-fromIndex); } equals public static boolean equals(int[] a, int[] a2) { if (a==a2) return true; if (a==null || a2==null) return false; int length = a.length; if (a2.length != length) return false; for (int i=0; i]]></content>
      <categories>
        <category>JDK源码阅读</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 Token 的身份验证]]></title>
    <url>%2F2016%2F10%2F11%2F%5BJava%5D%E5%9F%BA%E4%BA%8EToken%E7%9A%84%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[为什么要身份验证可能你会说，不是有登录接口吗，输入用户名、密码，身份验证通过就可以跳到下一个页面，很简单啊！ 但是，HTTP 是一种没有状态的协议，也就是它并不知道用户是否已经登录验证过。这里我们把用户看成是客户端（可以是浏览器、Android、IOS等），客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求访问其他服务器接口的时候，还得再验证一下，否则的话用户就可以跳过登录页面，直接访问其他服务器接口，登录就失去了意义 传统身份验证方法Cookie+Session的存在主要是为了解决HTTP这一无状态协议下服务器如何识别用户的问题。当用户请求登录的时候，如果验证通过，在服务端创建一个session，session中记录一下登录的用户信息，然后把这个session的 sessionid 号发送给客户端，客户端收到以后把这个 sessionid 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候带着这个 Cookie ，这样服务端会根据 Cookie 里的sessionid恢复session，看看session中是否存有用户信息，如果是，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端 上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端创建一个守护程序定期的去清理过期的 Session 基于 Token 的身份验证方法使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的： 1、客户端使用用户名和密码请求登录2、服务端收到请求，去验证用户名与密码3、验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端4、客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里5、客户端每次向服务端请求资源的时候需要带着服务端签发的 Token6、服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据 比起传统的身份验证方法，Token 扩展性更强，也更安全点，非常适合用在 Web 应用或者移动应用上 JWT实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分： header payload signature 中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样： eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc headerheader 部分主要是两部分内容，一个是 Token 的类型，另一个是使用的算法，比如下面类型就是 JWT，使用的算法是 HS256。 { &quot;typ&quot;: &quot;JWT&quot;, &quot;alg&quot;: &quot;HS256&quot; } 上面的内容要用 Base64 的形式编码一下，所以就变成这样： eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9 PayloadPayload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段： iss：Issuer，发行者 sub：Subject，主题 aud：Audience，观众 exp：Expiration time，过期时间 nbf：Not before iat：Issued at，发行时间 jti：JWT ID 比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。 { &quot;iss&quot;: &quot;ninghao.net&quot;, &quot;exp&quot;: &quot;1438955445&quot;, &quot;name&quot;: &quot;wanghao&quot;, &quot;admin&quot;: true } 使用 Base64 编码以后就变成了这个样子： eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ SignatureJWT 的最后一部分是 Signature ，这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。 header payload secret var encodedString = base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload); HMACSHA256(encodedString, &apos;secret&apos;); 处理完成以后看起来像这样： SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc 最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样： eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc 客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源 JWT库下载官网下载https://jwt.io/#libraries-io JJWT依赖&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.7.0&lt;/version&gt; &lt;/dependency&gt; 生成tokenimport io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import io.jsonwebtoken.impl.crypto.MacProvider; import java.security.Key; // We need a signing key, so we&apos;ll create one just for this example. Usually the key would be read from your application configuration instead. Key key = MacProvider.generateKey(); String compactJws = Jwts.builder() .setSubject(&quot;Joe&quot;) .signWith(SignatureAlgorithm.HS512, key) .compact(); 校验token1、判断JWT是否有效2、JWT中个数据是否正确，比如判断Subject是否为Joe try { Jwts.parser().setSigningKey(key).parseClaimsJws(compactJws); //OK, we can trust this JWT } catch (SignatureException e) { //don&apos;t trust the JWT! } 参考文件基于 Token 的身份验证(http://ninghao.net/blog/2834)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Token</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运输层]]></title>
    <url>%2F2016%2F10%2F11%2F%5B%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%5D%E8%BF%90%E8%BE%93%E5%B1%82%2F</url>
    <content type="text"><![CDATA[概述运输层服务计算机网络最基本的问题: ● 两个实体怎样才能在一种会丢失或损坏数据的介质上可靠得通信 ● 控制运输层实体的传输速率以避免网络中的拥塞，或从拥塞中恢复出来 运输层协议为运行在不同主机上的应用进程之间提供了逻辑通信（Logic Communication）。通过逻辑，运行不同进程的主机好像直接相连一样，实际上这些主机也许位于地球的两侧，通过很多路由器及都中不同类型的链路相连 运输层协议实在端系统中而不是在网络路由器中实现的。 1、在发送方，运输层将接收到的来自发送应用程序的报文分成较小的块，并为每块加上一个运输层首部。在发送方端系统中，运输层将这些报文段传递给网络层，网络层再将其分装成网络层分组，并向目的地发送。 2、在接收方，网络层从数据报中提取出运输层报文段，并将该报文段向上交给运输层。运输层则处理接受到的报文段，使得接受方应用程序可应用该报文段中的数据 运输层TCP和UDP的分组称为报文段，网络层分组称为数据报 网络层协议叫ip，全程是网际协议，IP为主机之间提供了逻辑通信，IP的服务模型是尽力而为交付服务。他不确保报文段的交付，不保证报文段的按序交付，更不保证报文段中的数据完整性。所以IP成为不可靠服务。 ★★★ UDP提供的服务：进程间数据交付、差错检测（运输层最低限度的两个服务，也是UDP仅有的两个服务） TCP提供附加服务：提供可靠数据传输（流量控制，序号，确认，定时器等技术）、拥塞控制 多路复用与多路分解接收主机中的运输层并没有直接将数据交付给进程，而是通过一个中间的套接字来传递。接收主机上可能有多个套接字，每个套接字都有唯一的标识符。在运输层报文段设置几个字段，接收端检查这些字段并标识出接收套接字。 1、从源主机发送报文段 ● 将运输层报文段中的数据交付到正确的套接字的工作称为多路分解 ● 从源主机的不同套接字中收集数据块，并为每个数据块分装上首部信息从而生成报文段，然后将报文段传递到网络的工作称为多路复用 2、目的主机接受报文段 ● 报文段达到目的主机，根据报文段上的端口号定位到相应进程的套接字（多路分解） ● 运输层收集套接字输出的数据形成运输层报文段（多路复用） 运输层多路复用的要求： ❶ 套接字有唯一标识符 ❷ 每个报文段有特殊字段（源端口、目的端口）来指示该报文段要交付的套接字 ● UDP套接字由一个包含目的IP地址和目的端口号的二元组来标识，如果两个UDP报文段有不同的源IP地址或源端口号，但具有相同的目的IP地址和目的端口号，那么这两个报文段将通过相同的目的套接字定向到相同的目的进程 ● TCP套接字由一个四元组（源IP地址、源端口号、目的IP地址、目的端口号）来标识，两个不同源IP地址或或源端口号的TCP报文会被定向到两个不同的套接字 UDPUDP只是做了运输协议能够做的最少工作，除了多路复用/多路分解功能及一些轻型差错检测，它几乎没有对IP增加别的东西 问题：有些应用程序更适合用UDP，而不是提供可靠数据传输服务的TCP？ 答： ● 应用层能更好地控制要发送的数据和发送时间。应用层将数据交给UDP，UDP就会在数据上附上多路复用/多路分解所需的源端口号和目的端口号，及两个其他字段，并立即将其传递给网络层。而TCP有一个拥塞控制机制，当链路非常拥塞时，遏制运输层TCP发送方，同时TCP会重新发送报文段知道目的主机收到此报文并加以确认，而不管可靠交付时间需要多长。实时应用通常要求最快的发送速率，能容忍一些数据丢失 ● 无需连接确立。TCP在数据传输之前需要经过三次握手，UDP却不需要任何准备即可进行数据传输 ● 无连接状态。TCP需要在端系统中维护连接状态，连接状态包括接受和发送缓存、拥塞控制参数、序号与确认好的参数。UDP不维护连接状态 ● 分组首部开销小。每个TCP报文段都有20字节的首部开销，而UDP仅有8个字节的开销 ★★★ UDP应用可以实现可靠数据传输，通过在应用程序自身中建立可靠性机制（例如增加确认和重传机制来实现）。这会增加开发人员的工作，但应用程序可以进行可靠通信，而无需受制于TCP拥塞控制机制引起的传输速率约束。 UDP报文结构 UDP首部只有四个字段，每个字段由两个字节组成[源端口号、目的端口号、长度、校验和]，共8个字节，应用层数据占用UDP报文段的数据字段。 ● 源端口和目的端口是执行多路复用/多路分解的必备条件 ● 接受主机使用校验和来检查报文段是否存在差错 ● 长度字段包括首部在内的UDP报文长度，字节为单位 可靠数据传输的原理构建可靠数据传输协议 1、完全可靠信道上的可靠数据传输：rdt1.0 最简单的情况，底层信道是完全可靠的。 图3.9显示了rdt1.0发送方和接收方的有限状态机。初始状态用虚线表示。 ● rdt的发送方通过rdt_send(data)从高层接收数据，产生一个包含该数据的分组（make_pkt(data)）,并且将数据发送到信道中。状态回到等待状态。 ● 接收方，rdt通过rdt_rcv(packet)事件从底层信道接收一个分组，从分组中取出数据(经extract(packet,data)动作)，并将数据上传给高层（通过deliver_data(data)动作） 2、具有比特差错信道上的可靠数据传输：rdt2.0 考虑你自己是怎样通过电话口述一条长消息：报文接受者听到、明白每句话都会说OK；如果听到依据含糊不清的话，他可能要求你重复那句话。这种口述消息协议使用了肯定确认（OK），否定确认（请重复一遍）。这些控制报文使得接收方可以让发送方知道哪些内容被正确接受，哪些内容有误需要重传。计算机网络中，基于这种重传机制的可靠数据传输协议称为自动重传请求（ARQ）协议。 ARQ协议处理比特差错： ● 差错检测 ● 接收方反馈：肯定确认（ACK），否定确认（NAK） ● 重传 当rdt_send(data)事件发生时，发送方将产生一个包含待发送数据的分组(sndpkt)，然后经由udp_send(pkt)发送该分组，状态跳转到等待接收方的ACK或NAK分组。如果收到数据包且收到一个ACK，则发送方知道最近传输的分组已被正确接收，状态跳转到等待上层数据状态。如果收到一个NAK分组，该协议重传最后一个分组并等待接收方的响应。 如果发送一个数据包出现差错，则发送方将会一直重传该数据包，直到接收到ACK。这种行为也成为停等协议 接收方当分组到达时，接收方根据分组是否受损回答ACK或NAK 缺陷：如果ACK或NAK分组受损，发送方无法知道是否正确接收了上一块发送的数据（如果发送数据包后没收到ACK或NAK，则状态一直停留在等待ACK或NAK中） 解决方法：当发送方收到含糊不清的ACK或NAK分组时，只需重新发送当前数据分组即可。但这会引入冗余分组，会造成接收方无法判断接收到的分组是新的还是一次重传。 rdt2.1解决了这个问题，在数据分组中添加一个序号字段，对于停等协议，1比特序号就足够了，前后接受的序号相同则代表是重传分组。 发送方初始状态处于等待来自上层的调用0状态。当事件rdt_send(data)发生时，生成一个序号为0的数据包，向信道发送数据，状态跳转到等待序号为0的数据的ACK或NAK。如果正确接收到一个数据包，但数据包受损或是NAK，则继续等待，直到接收到的数据包没有损坏而且是ACK，说明0号数据包已经被正常接收，状态跳转到等待发送数据包1的状态。之后同理。 在接收方，初始状态为等待数据包0的状态。如果收到的数据包破损，则向发送方发送一个NAK。或者你现在想收到序号为0的数据包，但发送过来一个序号为1的数据包，说明发送方重发了数据包1，则发送一个ACK。因为是重发，所以不需要提取数据包中的数据。如果正确接收到序号为0的分组，则提取出数据，传送给上层，并想发送方发送一个ACK，告知已经成功接收数据包0，状态跳转到等待接收序号为1的数据包。之后同理。 rdt2.2接收到受损的分组，发送一个对上次正确接受的分组的ACK。发送方接收到对同一个分组的两个ACK（冗余ACK），就知道接收方没有正确接收到跟在被确人两次的分组后面的分组。 当发送方处于等待来自上层的调用0的状态时，rdt_send(data)事件发生，生成一个序号为0的数据包，通过udt_send(sndpkt)将数据发送到信道。状态跳转到等待序号为0的数据包的ACK。如果接收到为受损的ACK数据包，状态跳转到等待发送序号为1的数据包的状态。如果收到受损的数据包，或数据包的序号不为0（确认的是之前的序号，则当前发送的数据包接收方没有正确被接收），则继续处于等待序号为0的数据包的ACK。之后同理。 在接收方，注意到初始化时oncethru = 0，如果发送方第一个数据包出现错误，则接收方一直将处于等待来自下层的0这个状态，不用发累计确认ACK。当接收到的数据包没有受损，而且刚好是等待的序号为0的分组，接收方提取出分组的数据，传递给上层，然后向发送方发送序号为0的ACK，通知发送方已经成功接受序号为0的分组，状态跳转到等待序号为1的数据包这个状态。如果之前的情况，向发送方发送序号为0的ACK出现损坏，则发送方会再次发送一个序号为0的数据包。这种情况下接收方会重新发送之前的确认包，告知发送方数据包已经接受，防止重复接受，接收方也就不需要提取数据包的消息。除了重发的情况，如果接受到破损数据，也将重新发送之前的确认包，接收方就知道确认包之后的数据没有被正确接受。之后又同理。 3.具有比特差错的丢包信道上的可靠数据传输：rdt 3.0 rdt2.2已经解决了发生丢包后该做些什么，通过检验和、序号、ACK分组和重传等方式。现在需要解决的问题是怎样检测丢包。 我们让发送方负责检测和恢复丢包。假定发送方传输一个数据分组，该分组丢失或该分组的ACK丢失，这样发送方收不到来自接收方的响应。如果发送方愿意等待足够长的时间以便确认分组已丢失，则只需重传该数据分组即可。 从发送方的观点来看，重传是一种万能灵药。发送方不知道是一个数据分组丢失、一个ACK丢失，还是该分组或ACK只是过度时延，所有的情况采取的动作都是同样的：重传。为了实现基于时间的重传机制，需要一个倒计数定时器，在一个给定的时间过期后，可中断发送方。 状态图：初始状态为等待来自上层的调用0状态，当事件rdt_send(data)发生时，生成一个序号为0的数据包，发送到信道，同时启动定时器，状态跳转到等待数据包0的ACK。如果正确无差错的ACK，则数据包0成功被接收，停止计时器，状态跳转到等待上次调用发送序号为1的数据包。若在等待ACK 0的时候，收到受损数据包，或者收到序列为1的ACK（说明当前发送的数据包没有成功接收），需要重传数据包，但先不发送，等到计数器超时后再发送（因为是基于定时器的重发机制），并且重新开启定时器，状态仍为等待ACK 0.在等待来自上层的调用1的时候，此时已经完成数据的接收，但为什么会收到回复？因为如果超时时间过短，会出现过早超时的情形，发送方间隔发送两个相同的数据包，同时连个数据包都得到了回应ACK，会选择接收第一个ACK，第二个则忽略。 流水线可靠数据传输允许发送方发送多个分组而无需等待确认，这种技术称为流水线。 ● 必须增加序号范围，每个传输的分组必须有一个唯一的序号 ● 协议的发送方和接收方必须缓存多个分组 ● 所需序号范围和对缓冲的要求取决于数据传输协议处理丢失、损坏及过度延时分组的方式，解决流水线的差错恢复有两种基本的方法：回退N步和选择重传 回退N步（GBN） [0，base-1]内的序号对应于已经发送并确认过的分组，[base，nextseqnum-1]内的序号对应于已经发送，但未被确认的分组。[nextseqnum，base+N-1]内的序号可用于那些要被立即发送的分组，其数据来自上层。 那些已经被发送但还未被确认的分组的序号范围可以看成是一个在序号范围内长度为N的窗口，并且随着协议的运行，该窗口在序好空间向前滑动，因此N常被称为窗口长度，GBN协议被称为滑动窗口协议 GBN发送方必须响应以下三种类型的事件： ● 上层的调用。当上层调用rdt_send()，发送方首先检查发送窗口是否已满。如果未满则创建一个分组将其发送，变量也响应的更新。如果窗口已满，发送方将数据返回给上层，通知上次该窗口已满，然后上层可能会过一会再试 ● ●]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法4笔记]]></title>
    <url>%2F2016%2F10%2F08%2F%5B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%5D0%E3%80%81%E7%AE%97%E6%B3%954%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[输入Scanner in = new Scanner(System.in); Scanner cin = new Scanner(new BufferedInputStream(System.in)); //加Buffer可能会快一些 Scanner类提供了非常丰富的成员函数来负责读取各种数据类型: 构造函数 BigInteger(String val) 将 BigInteger 的十进制字符串表示形式转换为 BigInteger。 返回值 成员函数 String next(String pattern) 如果下一个标记与从指定字符串构造的模式匹配，则返回下一个标记, 如果参数为空,就是读取一个字符串 BigDecimal nextBigDecimal() 将输入信息的下一个标记 +扫描为一个 BigDecimal。 BigInteger nextBigInteger() 将输入信息的下一个标记扫描为一个 BigInteger。 boolean nextBoolean() 扫描解释为一个布尔值的输入标记并返回该值。 byte nextByte() 将输入信息的下一个标记扫描为一个 byte。 double nextDouble() 将输入信息的下一个标记扫描为一个 double。 float nextFloat() 将输入信息的下一个标记扫描为一个 float。 int nextInt() 将输入信息的下一个标记扫描为一个 int。 String nextLine() 此扫描器执行当前行，并返回跳过的输入信息。 long nextLong() 将输入信息的下一个标记扫描为一个 long。 short nextShort() 输出System.out.print(); // cout &lt;&lt; …; System.out.println(); // cout &lt;&lt; … &lt;&lt; endl; System.out.printf(); // 与C中的printf用法类似. 例： System.out.printf("%d%10.5f\n", a, b); // 输入b为字宽为10，右对齐，保留小数点后5位，四舍五入. 规格化的输出： 函数： // 这里0指一位数字，#指除0以外的数字(如果是0，则不显示),四舍五入. DecimalFormat fd = new DecimalFormat(&quot;#.00#&quot;); DecimalFormat gd = new DecimalFormat(&quot;0.000&quot;); System.out.println(&quot;x =&quot; + fd.format(x)); System.out.println(&quot;x =&quot; + gd.format(x)) DecimalFormat详细： 符号含义： 0 一个数字 # 一个数字，不包括 0 . 小数的分隔符的占位符 , 分组分隔符的占位符 ; 分隔格式。 - 缺省负数前缀。 % 乘以 100 和作为百分比显示 ? 乘以 1000 和作为千进制货币符显示；用货币符号代替；如果双写，用 国际货币符号代替。如果出现在一个模式中，用货币十进制分隔符代 替十进制分隔符。 X 前缀或后缀中使用的任何其它字符，用来引用前缀或后缀中的特殊字符。 例子： public class TestNumberFormat { public static void main(String[] args) { double pi = 3.1415926; // 取一位整数:3 System.out.println(new DecimalFormat(&quot;0&quot;).format(pi)); // 取一位整数和两位小数:3.14 System.out.println(new DecimalFormat(&quot;0.00&quot;).format(pi)); // 取两位整数和三位小数，整数不足部分以0填补:03.142 System.out.println(new DecimalFormat(&quot;00.000&quot;).format(pi)); // 取所有整数部分:3 System.out.println(new DecimalFormat(&quot;#&quot;).format(pi)); // 以百分比方式计数，并取两位小数:314.16% System.out.println(new DecimalFormat(&quot;#.##%&quot;).format(pi)); long c = 299792458; //显示为科学计数法，并取五位小数:2.99792E8 System.out.println(new DecimalFormat(&quot;#.#####E0&quot;).format(c)); //显示为两位整数的科学计数法，并取四位小数:29.9792E7 System.out.println(new DecimalFormat(&quot;00.####E0&quot;).format(c)); //每三位以逗号进行分隔:299,792,458 System.out.println(new DecimalFormat(&quot;,###&quot;).format(c)); //将格式嵌入文本 System.out.println(new DecimalFormat(&quot;光速大小为每秒,###米。&quot;).format(c)); System.out.println(&quot;**************************************************&quot;); double d = 299792458.546; System.out.println(new DecimalFormat(&quot;#.00&quot;).format(d)); } } 进制转换String st = Integer.toString(num, base); // 把num当做10进制的数转成base进制的st(base &lt;= 35). Integer.toHexString(255)//ff，16进制 int num = Integer.parseInt(st, base); // 把st当做base进制，转成10进制的int(parseInt有两个参数,第一个为要转的字符串,第二个为说明是什么进制). BigInterget m = new BigInteger(st, base); // st是字符串，base是st的进制. 1、如果要将一个大数以2进制形式读入 可以使用 cin.nextBigInteger(2);当然也可以使用其他进制方式读入；2、如果要将一个大数转换成其他进制形式的字符串 使用 cin.toString(2); //将它转换成2进制表示的字符串 Arrays.sort / Collections.sortComparable在 JDK 类库中，有一部分类实现了 Comparable 接口，如 Integer、Double 和 String 等。Comparable 接口有一个 comparTo(Object o) 方法，它返回整数类型 如果返回值为0，则表示 x 和 y 相等 如果返回值大于0，则表示 x 大于 y 如果返回值小于0，则表示 x 小于 y TreeSet 集合调用对象的 compareTo() 方法比较集合中的大小，注意了不是 TreeSet 调用它自己的 comparTo() 方法而是它调用集合中对象的 comparTo() 方法。TreeSet类本身并没有实现 Comparable 接口，然后进行升序排列，这种方式称为自然排序。 JDK类库中实现了Comparable接口的一些类的排序方式 BigDecimal、BigInteger、Byte、Double、Float、Integer、Long、Short排序方式按数字大小排序 Character 按字符的 Unicode 值的数字大小排序 String 按字符中字符的 Unicode 值排序 这里一定要灰常注意:使用自然排序时只能向集合中加入同类型的对象，并且这些对象的类必须实现Comparable接口 public class Solution { public static void main(String[] args) { Set set = new TreeSet(); Customer customer1 = new Customer("Tom", 17); Customer customer2 = new Customer("Tom", 16); Customer customer3 = new Customer("Som", 16); set.add(customer1); set.add(customer2); set.add(customer3); System.out.println(set); } public static class Customer implements Comparable { private String name; private int age; public Customer(String name, int age) { this.age = age; this.name = name; } @Override public int compareTo(Object o) { if(o == null || !(o instanceof Customer)){ throw new IllegalArgumentException("对象必须是Customer"); } Customer other = (Customer) o; //先按姓名升序排序，如果姓名相等跳过 if (!this.name.equals(other.name)) { return name.compareTo(other.name); } //再按年龄升序排序，如果年龄相等跳过 if (this.age != other.age) { return age - other.age; } //相等 return 0; } @Override public String toString() { return "Customer{" + "age=" + age + ", name='" + name + '\'' + '}'; } } } ComparatorTreeSet 按照 Customer 对象的 name 属性进行降序排列，然后按照 age 降序，可以先创建一个实现Comparator接口的类 public class Solution { public static void main(String[] args) { Set set = new TreeSet(new CustomerComparator()); Customer customer1 = new Customer("Tom", 17); Customer customer2 = new Customer("Tom", 16); Customer customer3 = new Customer("Som", 16); set.add(customer1); set.add(customer2); set.add(customer3); System.out.println(set); //结果：[Customer{age=17, name='Tom'}, Customer{age=16, name='Tom'}, Customer{age=16, name='Som'}] } public static class CustomerComparator implements Comparator { @Override public int compare(Customer c1, Customer c2) { /*1、如果Customer实现了Comparable接口，直接调用compareTo方法 return c1.compareTo(c2);*/ //2、自定义比较方法，降序 if (!c1.name.equals(c2.name)) { return -c1.name.compareTo(c2.name); } if (c1.age != c2.age) { return -(c1.age - c2.age); } return 0; } } } 升序、逆序理解★★★★★如果给定两个数A、B，按照数字大小进行排序，并且以A为基准与B比较，得到以下表达式： if ( A &gt; B ) return 1 if ( A &lt; B ) return -1 if ( A = B ) return 0 三个表达式可以总结为：return A - B 12345678910111213public class Solution &#123; public static void main(String[] args) &#123; Integer[] a = &#123;1, 4, 2, 3, 5&#125;; Arrays.sort(a, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1 - o2; &#125; &#125;); System.out.println(Arrays.toString(a));//[1, 2, 3, 4, 5] &#125;&#125; 这样会按照升序排序 如果是逆序，直接在升序的基础上加上负号 12345678910111213public class Solution &#123; public static void main(String[] args) &#123; Integer[] a = &#123;1, 4, 2, 3, 5&#125;; Arrays.sort(a, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return -(o1 - o2); &#125; &#125;); System.out.println(Arrays.toString(a));//[5, 4, 3, 2, 1] &#125;&#125; 这样会按照逆序排序 进一步抽象： 如果给定两个元素A、B，按照一定规则进行排序，并且以A为基准与B比较，得到以下表达式： A在什么情况下大于B return 1 A在什么情况下小于B return -1 A在什么情况下等于B return 0 之后会按照定义A、B之间的关系，得到升序的结果 规范1、如果 Java 类重新定义了 equals 方法,那么这个类也必须重新定义 hashCode() 方法,并且保证当两个对象用 equals 方法比较结果为 true 时,这两个对象的 hashCode() 方法的返回值相等 2、如果 Java 类实现了 Comparable 接口，那么这个类应该从新定义 compareTo()、equals()和hashCode()方法，保证 compareTo() 和 equals() 方法采用相同的比较规则来比较两个对象是否相等，并且保证当两个对象用 equals() 方法比较的结果为 true 时,这两个对象的 hashCode() 方法的返回值相等. 3、HashSet 和 HashMap 具有较好的性能，是 Set 和 Map 首选实现类，只有在需要排序的场合，才考虑使用 TreeSet 和 TreeMap。LinkedList 和 ArrayList各有优缺点，如果经常对元素执行插入和删除操作，那么可以用 LinkedList，如果经常随机访问元素，那么可以用ArrayList Arrays.fill()Arrays.sort()Arrays.binarySearch() 示例先按第一列升序排序，再按第二列降序排序 123456789101112131415161718192021222324252627282930313233343536373839404142public class Solution &#123; public static void main(String[] args) &#123; int[][] a = &#123;&#123;3,3&#125;,&#123;2,2&#125;,&#123;1,1&#125;,&#123;4,1&#125;,&#123;4,2&#125;,&#123;4,3&#125;&#125;; int m = a.length; int n = a[0].length; System.out.println(&quot;排序前&quot;); print(a); Arrays.sort(a, new Comparator&lt;int[]&gt;() &#123; @Override public int compare(int[] o1, int[] o2) &#123; /** * 先按第一列升序排序，再按第二列降序排序 */ //第一列升序 if(o1[0] != o2[0])&#123; return o1[0] - o2[0]; &#125; //第二列降序 if(o1[1] != o2[1])&#123; return -(o1[1] - o2[1]); &#125; return 0; &#125; &#125;); System.out.println(&quot;排序后&quot;); print(a); &#125; private static void print(int[][] a) &#123; int m = a.length; int n = a[0].length; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; System.out.print(a[i][j] + &quot; &quot;); &#125; System.out.println(); &#125; &#125;&#125; 结果： 排序前 3 3 2 2 1 1 4 1 4 2 4 3 排序后 1 1 2 2 3 3 4 3 4 2 4 1 集合中元素实现Comparable进行升序排序，先按照姓名升序排序，再按照年龄顺序排序 public class Solution { public static void main(String[] args) { List&lt;Customer&gt; lists = new ArrayList&lt;Customer&gt;(); lists.add(new Customer(&quot;Tom&quot;, 17)); lists.add(new Customer(&quot;Tom&quot;, 16)); lists.add(new Customer(&quot;Som&quot;, 16)); lists.add(new Customer(&quot;Rom&quot;, 17)); //排序 Collections.sort(lists); //输出 System.out.println(lists);//[Customer{age=17, name=&apos;Rom&apos;}, Customer{age=16, name=&apos;Som&apos;}, Customer{age=16, name=&apos;Tom&apos;}, Customer{age=17, name=&apos;Tom&apos;}] } public static class Customer implements Comparable { private String name; private int age; public Customer(String name, int age) { this.age = age; this.name = name; } @Override public int compareTo(Object o) { if(o == null || !(o instanceof Customer)){ throw new IllegalArgumentException(&quot;对象必须是Customer&quot;); } Customer other = (Customer) o; //先按姓名升序排序，如果姓名相等跳过 if (!this.name.equals(other.name)) { return name.compareTo(other.name); } //再按年龄升序排序，如果年龄相等跳过 if (this.age != other.age) { return age - other.age; } //相等 return 0; } @Override public String toString() { return &quot;Customer{&quot; + &quot;age=&quot; + age + &quot;, name=&apos;&quot; + name + &apos;\&apos;&apos; + &apos;}&apos;; } } } 逆序排序 Collections.sort(lists,Collections.&lt;Customer&gt;reverseOrder()); 原理： public int compare(Comparable&lt;Object&gt; c1, Comparable&lt;Object&gt; c2) { return c2.compareTo(c1); } 自定义排序方法 Collections.sort(lists,new CustomerComparator()); public class CustomerComparator implements Comparator&lt;Customer&gt; { @Override public int compare(Customer c1, Customer c2) { //先按name升序，再按age降序 if (!c1.name.equals(c2.name)) { return c1.name.compareTo(c2.name); } if (c1.age != c2.age) { return -(c1.age - c2.age); } return 0; } } Map排序TreeMap传入Comparator，按键排序 1234567Map&lt;String, String&gt; map = new TreeMap&lt;String, String&gt;( new Comparator&lt;String&gt;() &#123; public int compare(String obj1, String obj2) &#123; // 降序排序 return obj2.compareTo(obj1); &#125; &#125;); 还有一种通用的排序方法，调用Map.entrySet()得到Set]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA在编辑时提示could not autowire]]></title>
    <url>%2F2016%2F10%2F08%2F%5BSSM%5DIDEA%E5%9C%A8%E7%BC%96%E8%BE%91%E6%97%B6%E6%8F%90%E7%A4%BAcould%20not%20autowire%2F</url>
    <content type="text"><![CDATA[在开发中我在applicationContext-dao.xml中加入了mapper扫描器 &lt;!--mapper扫描器--&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!--扫描包路径，如果需要扫描多个包，中间使用半角逗号隔开--&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.qianlv.ssmdemo.mapper&quot; /&gt; &lt;!--这里不用sqlSessionFactory是因为如果用会导致上面配置的dataSource失效--&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot; /&gt; &lt;/bean&gt; 但是在编辑一个Service中注入mapper会提示could not autowire，但是可以正常执行的。 public class ItemsServiceImpl implements com.qianlv.ssmdemo.service.ItemsService{ @Autowired ItemsMapperCustom itemsMapperCustom; public List&lt;ItemsCustom&gt; findItemsList(ItemsQueryVo itemsQueryVo) throws Exception { return itemsMapperCustom.findItemsList(itemsQueryVo); } } 我们需要改一下IDEA的设置 将最右边的Serverity改为Warning 参考：http://blog.csdn.net/xlxxybz1314/article/details/51404700]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC-Spring-Mybatis整合]]></title>
    <url>%2F2016%2F10%2F07%2F%5BSSM%5DSpringMVC-Spring-Mybatis%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[导入依赖&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.apeius&lt;/groupId&gt; &lt;artifactId&gt;Demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--集中管理依赖版本号--&gt; &lt;properties&gt; &lt;junit.version&gt;4.10&lt;/junit.version&gt; &lt;spring.version&gt;4.1.3.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.2.8&lt;/mybatis.version&gt; &lt;mybatis.spring.version&gt;1.2.2&lt;/mybatis.spring.version&gt; &lt;mybatis.paginator.version&gt;1.2.15&lt;/mybatis.paginator.version&gt; &lt;mysql.version&gt;5.1.32&lt;/mysql.version&gt; &lt;slf4j.version&gt;1.6.4&lt;/slf4j.version&gt; &lt;jackson.version&gt;2.4.2&lt;/jackson.version&gt; &lt;druid.version&gt;1.0.9&lt;/druid.version&gt; &lt;httpclient.version&gt;4.3.5&lt;/httpclient.version&gt; &lt;jstl.version&gt;1.2&lt;/jstl.version&gt; &lt;servlet-api.version&gt;2.5&lt;/servlet-api.version&gt; &lt;jsp-api.version&gt;2.0&lt;/jsp-api.version&gt; &lt;joda-time.version&gt;2.5&lt;/joda-time.version&gt; &lt;commons-lang3.version&gt;3.3.2&lt;/commons-lang3.version&gt; &lt;commons-io.version&gt;1.3.2&lt;/commons-io.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--单元测试--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--Spring--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--Mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;3.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.jsqlparser&lt;/groupId&gt; &lt;artifactId&gt;jsqlparser&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--连接池--&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--Jackson Json处理工具包--&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;${jackson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--连接池--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--httpclient--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;${httpclient.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--JSP相关--&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;${jstl.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;${servlet-api.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;${jsp-api.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!--时间操作组件--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;${joda-time.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--Apache工具组件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;${commons-lang3.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;${commons-io.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--文件上传--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; githubhttps://github.com/rhapsody1290/SSM 查询用户列表定义EasyUIPage封装对应的easyUi需要的数据 public class EasyUIPage { private Long total; private List&lt;?&gt; rows; public Long getTotal() { return total; } public void setTotal(Long total) { this.total = total; } public List&lt;?&gt; getRows() { return rows; } public void setRows(List&lt;?&gt; rows) { this.rows = rows; } } controller@RequestMapping(value = &quot;list&quot;) @ResponseBody public EasyUIPage queryAll( @RequestParam(value = &quot;page&quot;, defaultValue = &quot;1&quot;) Integer pageNum, @RequestParam(value = &quot;rows&quot;, defaultValue = &quot;5&quot;) Integer pageSize) { EasyUIPage esayUIPage = userService.queryAllUser(pageNum,pageSize); return esayUIPage; } 编写userservice@Override public EasyUIPage queryAllUser(Integer pageNum, Integer pageSize) { PageHelper.startPage(pageNum, pageSize); List&lt;User&gt; users = userMapper.queryAllUser(); PageInfo&lt;User&gt; pageInfo = new PageInfo&lt;User&gt;(users); EasyUIPage easyUIPage = new EasyUIPage(); //easyUIPage.setRows(users); easyUIPage.setRows(pageInfo.getList()); easyUIPage.setTotal(pageInfo.getTotal()); return easyUIPage; } 编写userMapperpublic List&lt;User&gt; queryAllUser(); userMapper对应的xml&lt;select id=&quot;queryAllUser&quot; resultType=&quot;User&quot;&gt; select * from tb_user &lt;/select&gt; 页面跳转合并★★★★★★//页面跳转合并 @RequestMapping(value = &quot;/page/{pageName}&quot;) public String toPage(@PathVariable(&quot;pageName&quot;) String pageName){ return pageName; } 添加用户日期格式转换SpringMVC默认不支持字符串转换成Date格式，可以采用SpringMVC自带的转换器，还有一种简单的方法： @DateTimeFormat(pattern = &quot;yyyy-MM-dd&quot;) private Date birthday; 需要导入依赖： &lt;!--时间操作组件--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;${joda-time.version}&lt;/version&gt; &lt;/dependency&gt; 添加失败使用try-catch @RequestMapping(value = &quot;/save&quot;) @ResponseBody public Map&lt;String, String&gt; save(User user){ Map&lt;String,String&gt; map = new HashMap&lt;String, String&gt;(); try{ Integer num = userService.addUser(user); if(num &gt; 0){ map.put(&quot;status&quot;,&quot;200&quot;); }else{ map.put(&quot;status&quot;,&quot;500&quot;); } }catch (Exception e){ map.put(&quot;status&quot;,&quot;500&quot;); } return map; } 导出excel视图除了可以是html、jsp、json等常见视图之外，还可以是excel，其他 poi依赖&lt;!--操作excel--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.10.1&lt;/version&gt; &lt;/dependency&gt; 导入编写好的Excel视图UserExcelView、Constants两个Java文件 声明excel视图&lt;bean name=&quot;userExcel&quot; class=&quot;cn.apeius.usermanage.view.UserExcelView&quot;/&gt; 控制器@RequestMapping(value = &quot;export/excel&quot;) public ModelAndView export(@RequestParam(value = &quot;page&quot;, defaultValue = &quot;1&quot;) Integer pageNow, @RequestParam(value = &quot;rows&quot;, defaultValue = &quot;5&quot;) Integer pageSize){ //1、查询需要导出的数据 EasyUIPage page = this.userService.queryAllUsers(pageNow,pageSize); //2、传递数据 ModelAndView mv = new ModelAndView(); mv.addObject(&quot;userList&quot;,page.getRows()); mv.setViewName(&quot;userExcel&quot;);//定义到自定义的excel视图 return mv; } bean视图解析器数字越小优先级越高 &lt;!--定义视图解析器--&gt; &lt;bean class = &quot;org.springframework.web.servlet.view.BeanNameViewResolver&quot;&gt; &lt;property name=&quot;order&quot; value=&quot;1&quot;/&gt; &lt;/bean&gt; 删除用户控制器@ResponseBody @RequestMapping(value = &quot;/delete&quot;) //springmvc会自动把逗号切割，变成一个数组 public Map&lt;String,String&gt; deleteById(@RequestParam(value = &quot;ids&quot;) Long[] ids){ Integer num = this.userService.deleteUserByIds(ids); Map&lt;String,String&gt; map = new HashMap&lt;String, String&gt;(); if(num &gt; 0){ map.put(&quot;status&quot;,&quot;200&quot;); }else{ map.put(&quot;status&quot;,&quot;208&quot;); } return map; } sql语句&lt;delete id=&quot;deleteUserByIds&quot;&gt; delete from tb_user where id in &lt;foreach collection=&quot;ids&quot; item=&quot;id&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #{id} &lt;/foreach&gt; &lt;/delete&gt; 通用mapper通用的增删改查操作 导入依赖&lt;dependency&gt; &lt;groupId&gt;com.github.abel533&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;2.3.4&lt;/version&gt; &lt;/dependency&gt; Mybatis配置文件方式在mybatis-config.xml中添加如下配置: &lt;plugin interceptor=&quot;com.github.abel533.mapperhelper.MapperInterceptor&quot;&gt; &lt;!--主键自增方法，默认值为MYSQL，详细说明请看文档--&gt; &lt;property name=&quot;IDENTITY&quot; value=&quot;MYSQL&quot;/&gt; &lt;!--通用mapper接口，多个通用接口用逗号隔开--&gt; &lt;property name=&quot;mappers&quot; value=&quot;com.github.abel533.mapper.Mapper&quot;/&gt; &lt;/plugin&gt; 通用mapper使用继承通用的Mapper,必须指定泛型public interface UserInfoMapper extends Mapper&lt;UserInfo&gt; { //其他必须手写的接口... } 泛型(实体类)的类型必须符合要求★★★★★ 表名默认使用类名,驼峰转下划线(只对大写字母进行处理),如UserInfo默认对应的表名为user_info。 表名可以使用@Table(name = “tableName”)进行指定,对不符合第一条默认规则的可以通过这种方式指定表名. 字段默认和@Column一样,都会作为表字段,表字段默认为Java对象的Field名字驼峰转下划线形式. 可以使用@Column(name = “fieldName”)指定不符合第3条规则的字段名 使用@Transient注解可以忽略字段,添加该注解的字段不会作为表字段使用（关联查询） 建议一定是有一个@Id注解作为主键的字段,可以有多个@Id注解的字段作为联合主键. 通用mapper使用public class UserMapperTest { private UserMapper mapper; @Before public void setUp() throws Exception { ApplicationContext ac = new ClassPathXmlApplicationContext( new String[]{&quot;applicationContext.xml&quot;,&quot;applicationContext-mybatis.xml&quot;,&quot;applicationContext-tx.xml&quot;}); mapper = ac.getBean(UserMapper.class); } @After public void tearDown() throws Exception { } @Test public void testSelectOne() throws Exception { //创建User对象，设置的属性作为查询的约束 User user = new User(); user.setId(1L); //使用selectOne必须保证结果唯一，如果结果太多则会报错 System.out.println(mapper.selectOne(user)); } @Test public void testSelect() throws Exception { User record = new User(); //可以设置属性增加约束 List&lt;User&gt; users = mapper.select(record); for(User user : users) System.out.println(user); } @Test public void testSelectCount() throws Exception { User record = new User(); int count = mapper.selectCount(record); System.out.println(count); } @Test public void testSelectByPrimaryKey() throws Exception { //参数表示主键的值 System.out.println(mapper.selectByPrimaryKey(1L)); } @Test public void testInsert() throws Exception { User record = new User(); record.setUserName(&quot;踩雷&quot;); record.setName(&quot;bajie&quot;); record.setPassword(&quot;123456&quot;); record.setBirthday(new Date()); mapper.insert(record); } @Test public void testInsertSelective() throws Exception { //与testInsert的区别：只添加设置值得字段，其余让数据库默认，推荐！！！ User record = new User(); record.setUserName(&quot;李璇&quot;); record.setName(&quot;bajie&quot;); record.setPassword(&quot;123456&quot;); record.setBirthday(new Date()); mapper.insert(record); } @Test public void testDelete() throws Exception { User record = new User(); record.setName(&quot;xxxx&quot;); mapper.delete(record); } @Test public void testDeleteByPrimaryKey() throws Exception { mapper.deleteByPrimaryKey(66L); } @Test public void testUpdateByPrimaryKey() throws Exception { User record = new User(); record.setId(66L); record.setName(&quot;踩雷&quot;); mapper.updateByPrimaryKey(record); } @Test public void testUpdateByPrimaryKeySelective() throws Exception { //只更新设置的值，推荐！！！！！！！ User record = new User(); record.setId(66L); record.setName(&quot;踩雷&quot;); mapper.updateByPrimaryKeySelective(record); } @Test public void testExampleBasic(){ //进行复杂查询 Example example = new Example(User.class); Example.Criteria criteria = example.createCriteria(); criteria.andGreaterThanOrEqualTo(&quot;age&quot;,30); //添加and条件，密码为123456 criteria.andEqualTo(&quot;password&quot;,&quot;123456&quot;); List&lt;User&gt; users = mapper.selectByExample(example); for(User u : users) System.out.println(u); } @Test //SELECT AGE,NAME,UPDATED,USER_NAME USERNAME,BIRTHDAY,ID,CREATED,SEX,PASSWORD FROM tb_user // WHERE ( AGE &gt;= ? and NAME like ? ) or ( PASSWORD = ? and ID in(?,?) ) public void testExampleOr(){ //进行复杂查询，or Example example = new Example(User.class); Example.Criteria criteria = example.createCriteria(); criteria.andGreaterThanOrEqualTo(&quot;age&quot;,30); criteria.andLike(&quot;name&quot;,&quot;%xx%&quot;); Example.Criteria criteria12 = example.createCriteria(); //添加and条件，密码为123456 criteria12.andEqualTo(&quot;password&quot;,&quot;123456&quot;); List&lt;Object&gt; ids = new ArrayList&lt;Object&gt;(); ids.add(&quot;1&quot;); ids.add(&quot;2&quot;); criteria12.andIn(&quot;id&quot;,ids); //多个criteria之间是or的关系 example.or(criteria12); List&lt;User&gt; users = mapper.selectByExample(example); for(User u : users) System.out.println(u); } @Test public void testExampleSort(){ Example example = new Example(User.class); example.setOrderByClause(&quot;age desc,id desc&quot;); List&lt;User&gt; users = mapper.selectByExample(example); } }]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>JavaEE</tag>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java泛型]]></title>
    <url>%2F2016%2F09%2F30%2F%5BJava%5DJava%E6%B3%9B%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[什么是泛型泛型本质是参数化类型，也就是说把操作的数据类型指定为一个参数。这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口、泛型方法。 Java语言引入泛型的好处是：1、安全简单，在编译的时候检查类型安全，并且所有的强制转换都是自动和隐式。比如在定义集合的时候指定具体的参数类型，这样无法加入指定类型以外的数据，避免了强制类型转换时出现对转换错误的问题2、能够复用算法，防止重复代码的编写 泛型的基本应用 Jdk1.5的集合类希望你在定义集合时，明确表示你要向集合中装哪种类型的数据，无法加入指定类型以外的数据 如下例子，如果不给定参数类型，可以在集合类中加入任意类型的数据，但在取元素时必须由程序员强行转换数据类型，编译器不会报错，出现问题由程序员负责 ArrayList collection1 = new ArrayList(); collection1.add(1); collection1.add(1L); collection1.add(&quot;abc&quot;); 在指定参数后，泛型的基本用法如下，对不是给定类型的数据，编译会报错。另一个好处是取出数据后，不用对数据进行强制转换。 ArrayList&lt;String&gt; collection2 = new ArrayList&lt;String&gt;(); //collection2.add(1); //collection2.add(1L); collection2.add(&quot;abc&quot;); String string = collection2.get(0); 泛型是提供给javac编译器使用的，可以限定集合中的输入类型，让编译器挡住源程序中的非法输入，编译器编译带类型说明的集合时会去除掉”类型”信息，使程序运行效率不受影响，对于参数化的泛型类型，getClass()方法的返回值和原始类型完全一样 ArrayList&lt;Integer&gt; collection3 = new ArrayList&lt;Integer&gt;(); System.out.println(collection1.getClass() == collection2.getClass());//True System.out.println(collection2.getClass() == collection3.getClass());//True 由于编译生成的字节码会去掉泛型的类型信息，只要能跳过编译器，就可以往某个泛型集合中加入其它类型的数据，例如，用反射得到集合，再调用其add方法即可 ArrayList&lt;Integer&gt; collection3 = new ArrayList&lt;Integer&gt;(); collection3.getClass().getMethod(&quot;add&quot;,Object.class).invoke(collection3, &quot;abc&quot;); System.out.println(collection3.get(0));//abc collection3的参数类型是Integer，但用反射的方法跳过编译器，还是能够加入String类型的数据 泛型的优点 提高了我们程序的使用性，不需要在自己去做强转 将原来在运行阶段处理的问题，放到了编译阶段 提高安全性 泛型的术语ArrayList类定义和ArrayList类引用中涉及如下术语： 整个称为 ArrayList泛型类型 ArrayList中的E称为类型变量或类型参数 整个ArrayList称为参数化的类型 ArrayList中的Integer称为类型参数的实际类型参数或实际类型参数 ArrayList中的&lt;&gt;念typeof ArrayList称为原始类型 参数化类型与原始类型的兼容性 参数化类型可以引用一个原始类型，编译报告警告，例如 Collection&lt;String&gt; c = new Vector(); 原始类型可以引用一个参数化类型的对象，编译报告警告，例如 Collection c = new Vector&lt;String&gt;(); 参数化类型不考虑类型参数的继承关系不要认为String和Object有继承关系就不会报错 Vector v = new Vector();//错误 Vector v = new Vector();//错误 思考，下面的代码会报错误吗？ Vector v1 = new Vector&lt;String&gt;(); Vector&lt;Object&gt; v = v1; 答：不会，第一个语句，原始类型可以引用一个参数化类型的对象，第二个语句，参数化类型可以引用一个原始类型的对象，所以不会报错。 泛型的声明泛型可以声明在类上，可以声明在方法上，可以声明在接口上。声明在类上的泛型，在整个类的范围内都可以使用。声明在方法上的泛型，只能在方法上使用。 什么时候在方法上声明泛型？ 类上已经声明了泛型，但是在方法上我们不使用类上的泛型，而是自定义的一个，那么就可以在方法上声明，注意：在方法上声明时，泛型要定义在方法的返回值前面。 1234567891011121314public class APP &#123; public static void main(String[] args) &#123; //sayHello的参数列表中使用了泛型，可以传入不同的数据类型 String hello = sayHello(&quot;Hello&quot;); Integer integer = sayHello(1); Float aFloat = sayHello(1F); Double aDouble = sayHello(1D); &#125; //泛型定义在返回值前面 private static &lt;T&gt; T sayHello(T parameter) &#123; System.out.println(parameter); return parameter; &#125;&#125; 泛型中使用？通配符定义一个printCollection函数，参数是一个集合，类型参数是？通配符，这样可以将任何类型参数的集合作为参数传入，如ArrayList public static void printCollection(Collection&lt;?&gt; collection){ //System.out.println(collection.add(&quot;abc&quot;));//错误，因为它不知道自己未来匹配就一定是String System.out.println(collection.size());//没错，此方法与类型参数无关 for(Object object : collection){ System.out.println(object); } } 总结：使用？通配符可以引用其它各种参数化的类型，？通配符定义的变量主要用作引用，只可以调用与参数化无关的方法，不能调用与参数化有关的方法 泛型中的 ? 通配符的扩展 &lt;? extends E&gt; 它是用来限定是E类型或是E的子类型. &lt;? super E&gt; 只能是E类型或E的父类型. 限定通配符的上边界 正确：Vector&lt;? extends Number&gt; x = new Vector(); 错误：Vector&lt;? extends Number&gt; x = new Vector(); 限定通配符的下边界 正确：Vector&lt;? super Number&gt; x = new Vector(); 错误：Vector&lt;? super Number&gt; x = new Vector(); 泛型方法（自定义泛型）泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型。 在返回值前加上&lt;T&gt;表示新定义一个类型，返回x+y有错误，因为不确定T类型是否有+这个方法，返回类型为传入类型的最大公共类型，比如传入Integer和Float，返回Numberic，传入Integer和String，返回Object 泛型的实际类型只能是引用类型，不能是基本类型。T不能被基本类型替换。在案例add(1，2)中会自动装箱，而在swap案例中，数组本身就是Object，不会装箱。 12345private &lt;T&gt; void swap(T[] a, int i, int j )&#123; T tmp = a[i]; a[i] = a[j]; a[j] = tmp;&#125; 12swap(new String[]&#123;"abc","xyz","asd"&#125;,1,2);//正确//swap(new int[]&#123;1,2,3,4,5&#125;,1,2);//报错 除了在应用泛型时可以使用extends限定符，在定义泛型时也可以使用extends限定符,可以用来指定多个边界，如 12//必须实现Serializable 和cloneable两个接口&lt;V extends Serializable &amp; cloneable &gt; void method()&#123;&#125; 普通方法、构造方法和静态方法中都可以使用泛型 也可以用类型变量表示异常，称为参数化的异常，可以用于方法的throws列表中，但是不能用于catch子句中。例：用下面的代码说明对异常如何采用泛型： 12345678910111213141516private static &lt;T extends Exception&gt; sayHello() throws T&#123; try&#123; &#125;catch(Exception e)&#123; throw (T)e; &#125;&#125;``` 在泛型中可以同时**有多个类型参数**，在定义它们的尖括号中用逗号分，例如：```Javapublic static &lt;K,V&gt; V getValue(K key) &#123; return map.get(key); &#125; 我们在开发中，如果在类上已经声明了泛型，但是我们在方法上不使用类上声明的泛型，我们可以自己在方法上声明泛型。 这个在方法上声明的泛型，只能在方法内使用。如果声明在方法上，必须声明在方法的返回值前面。 泛型声明在类上，那么这个泛型可以在整个类内使用. 123456789class Demo9 &#123; public static void main(String[] args) &#123; Student&lt;String&gt; s=new Student&lt;String&gt;(); s.a="hello"; System.out.println(s.print()); &#125;&#125; 123456789101112131415//在类上定义泛型//如果将泛型定义在类上，那么这个泛型可以在整个类内使用.class Student&lt;T&gt; &#123; T a; //泛型做为成员属性 public void show()&#123; System.out.println(a); &#125; public void show(T t)&#123; //泛型作用在方法. System.out.println(t); &#125; public T print()&#123; return a; &#125;&#125; 泛型练习题 自动将Object类型的对象转换成其他类型 123456789101112public class Generic &#123; public static void main(String[] args)&#123; Object o = &quot;123&quot;; String s = convert(o); System.out.println(s); &#125; public static &lt;T&gt; T convert(Object o)&#123; return (T) o; &#125;&#125; 注意：这里的T由返回类型决定!!! 通过反射获取泛型的实际参数类型1Vector&lt;Date&gt; v1 = new Vector&lt;Date&gt;(); 通过获取v1的字节码来获取Vector的实际参数类型是不可能，因为编译器在编译后会去掉类型信息。但在已知框架中的确有这个应用，它是怎么实现的呢？ 通过变量是无法知道它的参数类型的，但是当把这个变量交给一个方法去使用的时候，方法可以获得它的参数列表，并且是泛型的形式。 1234567891011121314public class GenericTest &#123; public static void main(String[] args) throws Exception&#123; //Vector&lt;Date&gt; v1 = new Vector&lt;Date&gt;(); Method applyMethod = GenericTest.class.getMethod("applyVector", Vector.class); Type[] types = applyMethod.getGenericParameterTypes(); ParameterizedType pType = (ParameterizedType)types[0]; System.out.println(pType.getRawType()); System.out.println(pType.getActualTypeArguments()[0]); &#125; public static void applyVector(Vector&lt;Date&gt; v1)&#123; &#125;&#125; 结果： class java.util.Vector class java.util.Date 泛型DAO1、编写BaseDAO类，类中封装常用的DAO方法，如selectById 123456789101112131415161718192021222324252627public abstract class BaseDAO&lt;T&gt; &#123; private Class&lt;T&gt; entityClass; protected BaseDAO() &#123; //得到子类的泛型父类 Type type = getClass().getGenericSuperclass(); //转化为泛型类型，返回此泛型类型的实际类型参数的Type对象的数组,数组里放的都是对应类型的Class Type[] trueType = ((ParameterizedType) type).getActualTypeArguments(); this.entityClass = (Class&lt;T&gt;) trueType[0]; System.out.println(&quot;传入泛型类型：&quot; + entityClass.getCanonicalName()); &#125; protected T findById(Serializable id)&#123; //从数据库中查询，并返回 T t = null; try &#123; t = entityClass.newInstance(); Field field_id = entityClass.getDeclaredField(&quot;id&quot;); field_id.setAccessible(true); field_id.set(t,id); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return t; &#125;&#125; 当调用getClass()方法，隐含的this指针是子类对象（因为new的是子类，this对象指的是子类对象。虽然会执行父类的构造方法，但并没有构造一个父类的对象），获得父类 2、对于每一个用户自定义的DAO类，继承BaseDAO，并且传入Domain类作为类型参数。这样可以从父类BaseDAO中获得常用的单表增、删、改、查方法。如果用户需要一些复杂查询，需要自行添加 12public class UserDAO extends BaseDAO&lt;User&gt; &#123;&#125; 3、Domain对象对应数据库中的一张表，从数据库中查出的一条记录需要转变成一个Domain对象，方便Service中使用 1234567891011121314151617181920212223242526272829303132333435363738public class User &#123; private long id; private String name; private String password; public long getId() &#123; return id; &#125; public void setId(long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, password=&apos;&quot; + password + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125;&#125; 4、测试具体DAO的使用 12345public class APP &#123; UserDAO userDAO = new UserDAO(); User user = userDAO.findById(2); System.out.println(user);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[list转string[]]]></title>
    <url>%2F2016%2F09%2F30%2F%5BJava%5Dlist%E8%BD%ACstring%5B%5D%2F</url>
    <content type="text"><![CDATA[方法一：单个元素转换//ArrayList ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;(); array.add(&quot;aaa&quot;); array.add(&quot;bbb&quot;); array.add(&quot;ccc&quot;); //转化成Object数组 Object[] objs = array.toArray(); //新建数组 String[] strings = new String[array.size()]; //每个元素类型转换 int i = 0; for(Object obj : objs){ if(obj instanceof String){ strings[i++] = (String)obj; } } for(String s : strings){ System.out.println(s); } 方法二：整个转使用List的toArray(T[])方法，传入一个与list容量相等的字符串数组 //ArrayList ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;(); array.add(&quot;aaa&quot;); array.add(&quot;bbb&quot;); array.add(&quot;ccc&quot;); String[] strings = new String[array.size()]; array.toArray(strings); for(String s : strings){ System.out.println(s); }]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jave Web模型2和MVC模式]]></title>
    <url>%2F2016%2F09%2F07%2F%5BSpring%20MVC%5DJave%20Web%E6%A8%A1%E5%9E%8B2%E5%92%8CMVC%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模型1和模型2介绍 Java Web应用开发中有两种设计模型，为了方便，分别称为模型1和模型2 模型1是通过链接方式进行JSP页面之间的跳转 方式直接，适合小型应用开发 但在中型和大型应用中，这种方式会带来维护上的问题 模型2是基于MVC模式，是Java Web应用的推荐架构 一个MVC模式的应用包括模型、视图 和控制器 3个模块 视图负责应用的展示，模型封装了应用的数据和业务逻辑，控制器负责接收用户输入，改变模型，以及调整视图的显示 Servlet 或者Filter 都可以充当控制器、Spring MVC和Struts1使用一个Servlet作为控制器，而Struts2 则使用一个Filter作为控制器 大部分采用JSP 页面作为应用的视图，当然也有别的技术 模型会采用一个JavaBean 来持有模型状态，并将业务逻辑放到一个Action类中。一个JavaBean必须拥有一个无参的构造器，通过get/set方法来访问参数，同时支持持久化 模型2应用 —— 产品信息保存 githubhttps://github.com/rhapsody1290/SpringMVC_study包名为cn.apeius.product 工程目录 其中红框内的为产品信息保存应用相关文件 ProductForm.jsp —— 填写产品信息表单 ProductForm.jsp文件放在WEB-INF下，不能通过URL直接访问 一个控制器可以对应多个action(url) 通过url：product_input.action指向控制器ControllerServlet，由控制器根据相应的action跳转到页面ProductForm.jsp 页面展示 JSP代码 &lt;!DOCTYPE HTML> &lt;html> &lt;head> &lt;title>Add Product Form&lt;/title> &lt;style type="text/css">@import url(css/main.css);&lt;/style> &lt;/head> &lt;body> &lt;div id="global"> &lt;form action="product_save.action" method="post"> &lt;fieldset> &lt;legend>Add a product&lt;/legend> &lt;p> &lt;label for="name">Product Name: &lt;/label> &lt;input type="text" id="name" name="name" tabindex="1"> &lt;/p> &lt;p> &lt;label for="description">Description: &lt;/label> &lt;input type="text" id="description" name="description" tabindex="2"> &lt;/p> &lt;p> &lt;label for="price">Price: &lt;/label> &lt;input type="text" id="price" name="price" tabindex="3"> &lt;/p> &lt;p id="buttons"> &lt;input id="reset" type="reset" tabindex="4"> &lt;input id="submit" type="submit" tabindex="5" value="Add Product"> &lt;/p> &lt;/fieldset> &lt;/form> &lt;/div> &lt;/body> &lt;/html> 表单的action为product_save.action，这个url会匹配到控制器ControllerServlet，调用相应的service方法完成产品保存工作，并完成页面的跳转，显示产品的详细信息 fieldset可将表单内的元素进行分组 推荐使用标签 &lt;label for = ‘指向的标签name’&gt;标签内容&lt;/label&gt;，点击标签焦点就定位在指向的标签 @import url(css/main.css)：css在web根目录下 main.css —— 样式文件#global { text-align: left; border: 1px solid #dedede; background: #efefef; width: 560px; padding: 20px; margin: 100px auto; } form { font:100% verdana; min-width: 500px; max-width: 600px; width: 560px; } form fieldset { border-color: #bdbebf; border-width: 3px; margin: 0; } legend { font-size: 1.3em; } form label { width: 250px; display: block; float: left; text-align: right; padding: 2px; } #buttons { text-align: right; } 灰色背景为一块 DIV，设置宽度560px，marigin：100px auto使 DIV 居中显示，页面下移100px；高度不用设置，内部标签自动会撑开；另，设置padding为20px，DIV向外扩展，此时灰色面积尺寸为602（加上边框） 字体verdana在小字上仍有结构清晰端整、阅读辨识容易等高品质的表现 怎样使得冒号对齐？关键点是使设置标签长度一致，并使标签内容右对齐；默认label是inline，长度设置无效，可采用如下两种办法： 方法一：使用inline-block来设置长度 form label { width: 250px; display: inline-block; text-align: right; } 方法二：使用block来设置长度 form label { width: 250px; display: block; float: left; /*使用block后label占用一行，使用float让输入框移上来*/ text-align: right; padding: 2px; /*不是关键*/ } 心得：DIV+CSS设计，外层DIV固定尺寸，内部元素相对外层进行设计，这个DIV为一个整体 Product类和ProductForm类Product.java —— 产品信息JavaBean Java规范中说要写入文件或是通过网络传输的对象必须是可序列化的，所以弄个标志接口Serializable 来标识一个类可以被序列化 Product类实现了java.io.Serializationi接口，其实例可以安全地将数据保存到HttpSession中 package cn.apeius.product.domain; import java.io.Serializable; public class Product implements Serializable { private static final long serialVersionUID = 748392348L; private String name; private String description; private float price; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public float getPrice() { return price; } public void setPrice(float price) { this.price = price; } } ProductForm.java 表单类与HTML表单相映射，是后者在服务器端的代表 Product和ProductForm类似，是否有必要存在？表单对象会传递ServletRequest给其他组件，类似Validator，而ServletRequest是一个Servlet层的对象，不应当暴露给应用的其它层 表单类不需要实现Serialization接口，因为表单对象很少存在HttpSession中 package cn.apeius.product.form; public class ProductForm { private String name; private String description; private String price; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public String getPrice() { return price; } public void setPrice(String price) { this.price = price; } } ControllerServlet类★★★★★控制器的操作： 1、对URI处理获得action名 2、根据action，创建表单对象，数据校验，创建领域对象，并执行领域对象的业务逻辑，例如将其持久化到数据库 3、根据处理结果，跳转页面 url思考： product_input.action、product_save.acton对应一个Servlet url的形式可以采用模块+操作的形式，举个例子： 用户模块有login和logout操作，一个模块一个控制器 可以采用/user/login.action，/user/logout.action对应匹配规则为/user/*的Servlet 代码 package cn.apeius.product.servlet; import cn.apeius.product.domain.Product; import cn.apeius.product.form.ProductForm; import java.io.IOException; import javax.servlet.RequestDispatcher; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class ControllerServlet extends HttpServlet { private static final long serialVersionUID = 1579L; @Override public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { process(request, response); } @Override public void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { process(request, response); } private void process(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { /* 1、URI的形式为：/应用名/资源名，例如/app10a/product_input 2、一个Servlet可以对应多个action，本应用中访问/product_input.action和/product_save.action会进入ControllerServlet 3、这个Servlet命名为ControllerServlet，是遵循了一个约定：所有Servlet类的名称都带有Servlet后缀 */ //1、对URI处理获得action名 String uri = request.getRequestURI(); int lastIndex = uri.lastIndexOf("/"); String action = uri.substring(lastIndex + 1); //2、根据action，创建表单对象，数据校验，创建领域对象，并并执行领域对象的业务逻辑，例如将其持久化到数据库 if (action.equals("product_input.action")) { //不需要调用service类执行业务逻辑 } else if (action.equals("product_save.action")) { //创建表单对象 ProductForm productForm = new ProductForm(); //填充对象属性 productForm.setName(request.getParameter("name")); productForm.setDescription( request.getParameter("description")); productForm.setPrice(request.getParameter("price")); //创建模型 Product product = new Product(); product.setName(productForm.getName()); product.setDescription(productForm.getDescription()); try { product.setPrice(Float.parseFloat( productForm.getPrice())); } catch (NumberFormatException e) { } //调用service层的方法，保存产品，此处略 //将产品模型保存在session，以便后续页面使用 request.setAttribute("product", product); } //3、根据处理结果，跳转页面 String dispatchUrl = null; if (action.equals("product_input.action")) { dispatchUrl = "/WEB-INF/jsp/ProductForm.jsp"; } else if (action.equals("product_save.action")) { dispatchUrl = "/WEB-INF/jsp/ProductDetails.jsp"; } if (dispatchUrl != null) { RequestDispatcher rd = request.getRequestDispatcher(dispatchUrl); rd.forward(request, response); } } } ProductDetails.jsp —— 显示产品详细信息 ProductDetails.jsp 页面通过表达式语言（EL） 访问 HttpServletRequest 所包含的对象 代码 &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Save Product&lt;/title&gt; &lt;style type=&quot;text/css&quot;&gt;@import url(css/main.css);&lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;global&quot;&gt; &lt;h4&gt;The product has been saved.&lt;/h4&gt; &lt;p&gt; &lt;h5&gt;Details:&lt;/h5&gt; Product Name: ${product.name}&lt;br/&gt; Description: ${product.description}&lt;br/&gt; Price: $${product.price} &lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 测试可以通过url： http://localhost:8080/SpringMVC_study/product_input.action 访问应用注意，可以将servlet控制器作为默认主页，使得在浏览器地址中仅输入域名+应用名，就可以访问到该Servlet控制器 &lt;jsp:forward page=&quot;/product_input.action&quot;/&gt; 缺点 业务逻辑代码 都写在了Servlet控制器中，随着应用复杂度增加而不断膨胀 哪些是业务逻辑？图中红框所示，根据不同的action，创建表单对象，数据校验，创建领域对象，并执行领域对象的业务逻辑；如果action多了，controller将会变得非常臃肿 解耦控制器代码githubhttps://github.com/rhapsody1290/SpringMVC_study包名为cn.apeius.product2 思路 将原来ControllerServlet中的业务逻辑提取出来 此时的Servlet变得更加专注，作用更像是一个dispatcher，即检查每个url，根据访问的action，调用具体的controller完成业务逻辑，并完成页面跳转，而非一个controller，因此改名为DispatcherServlet 工程目录 DispatcherServlet类一个DispatcherServlet必须能够做如下事情： 根据URI调用相应的action 实例化正确的控制器类 调用控制器对象的响应方法 转到一个视图（JSP页面） public class DispatcherServlet extends HttpServlet { private static final long serialVersionUID = 748495L; @Override public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { process(request, response); } @Override public void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { process(request, response); } private void process(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { //1、对URI处理获得action名 String uri = request.getRequestURI(); int lastIndex = uri.lastIndexOf("/"); String action = uri.substring(lastIndex + 1); //2、根据action，调用具体的controller处理，DispatcherServlet只起到分派功能 String dispatchUrl = null; if (action.equals("product_input.action")) { InputProductController controller = new InputProductController(); dispatchUrl = controller.handleRequest(request, response); } else if (action.equals("product_save.action")) { SaveProductController controller = new SaveProductController(); dispatchUrl = controller.handleRequest(request, response); } //3、根据处理结果，跳转页面 if (dispatchUrl != null) { RequestDispatcher rd = request.getRequestDispatcher(dispatchUrl); rd.forward(request, response); } } } Controller接口 面向接口编程的方式，在DispatcherServlet中使用Controller来引用具体实现类，并调用其handleRequest方法完成具体业务逻辑操作 public interface Controller { String handleRequest(HttpServletRequest request, HttpServletResponse response); } InputProductController类和SaveProductController类 两个Controller都实现了Controller接口，Controller接口只有handleRequest方法 Controller接口的实现类需要通过该方法访问到请求的HttpServletRequest和HttpServletResponse handleRequest返回结果为跳转文件路径 InputProductController类 直接返回输入产品的表单页面 public class InputProductController implements Controller { public String handleRequest(HttpServletRequest request, HttpServletResponse response) { return &quot;/WEB-INF/jsp/ProductForm.jsp&quot;; } } SaveProductController类 创建表单对象 创建模型 保存产品信息到数据库 返回跳转页面 public class SaveProductController implements Controller { public String handleRequest(HttpServletRequest request, HttpServletResponse response) { ProductForm productForm = new ProductForm(); //填充表单数据 productForm.setName( request.getParameter(&quot;name&quot;)); productForm.setDescription( request.getParameter(&quot;description&quot;)); productForm.setPrice(request.getParameter(&quot;price&quot;)); //创建模型 Product product = new Product(); product.setName(productForm.getName()); product.setDescription(productForm.getDescription()); try { product.setPrice(Float.parseFloat( productForm.getPrice())); } catch (NumberFormatException e) { } //将产品信息加入数据的代码，此处省略 request.setAttribute(&quot;product&quot;, product); return &quot;/WEB-INF/jsp/ProductDetails.jsp&quot;; } } 校验器 Web应用执行action时，很重要的步骤是进行输入校验 因为校验工作很重要，Java社区专门发布了标准对Java世界的输入检验进行标准化 githubhttps://github.com/rhapsody1290/SpringMVC_study包名为cn.apeius.product2 工程目录 红色部分有修改，增加了ProductValidator类 ProductForm.jsp展示输入校验的错误信息 ProductValidator ProductValidator类中有一个validate方法，保证产品的字符串非空，价格是一个合理的数字 validate返回一个包含错误信息的字符串列表，若返回一个空列表，则表示输入合法 在SaveProductController类中使用ProductValidator类 public class ProductValidator { public List&lt;String&gt; validate(ProductForm productForm) { List&lt;String&gt; errors = new ArrayList&lt;String&gt;(); String name = productForm.getName(); if (name == null || name.trim().isEmpty()) { errors.add(&quot;Product must have a name&quot;); } String price = productForm.getPrice(); if (price == null || price.trim().isEmpty()) { errors.add(&quot;Product must have a price&quot;); } else { try { Float.parseFloat(price); } catch (NumberFormatException e) { errors.add(&quot;Invalid price value&quot;); } } return errors; } } 新版的SaveProductController 首先对变淡类进行校验，如果校验发现有错误，则页面跳转到ProductForm.jsp；若没有错误，则创建一个Product对象 public class SaveProductController implements Controller { public String handleRequest(HttpServletRequest request, HttpServletResponse response) { ProductForm productForm = new ProductForm(); //填充表单属性 productForm.setName(request.getParameter("name")); productForm.setDescription(request.getParameter("description")); productForm.setPrice(request.getParameter("price")); //校验表单 ProductValidator productValidator = new ProductValidator(); List errors = productValidator.validate(productForm); if (errors.isEmpty()) { //创建领域对象Product Product product = new Product(); product.setName(productForm.getName()); product.setDescription(productForm.getDescription()); product.setPrice(Float.parseFloat(productForm.getPrice())); //没有校验错误，执行action方法 //保存产品信息到数据库的代码 //将product存入request域中，便于后面页面显示 request.setAttribute("product", product); return "/WEB-INF/jsp/ProductDetails.jsp"; } else { //保存错误信息，在后续页面显示 request.setAttribute("errors", errors); //保留表单信息，在后续页面显示 request.setAttribute("form", productForm); return "/WEB-INF/jsp/ProductForm.jsp"; } } } 新的ProductForm.jsp 用户提交了非法数据，页面将显示相应地错误信息 &lt;%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c" %> &lt;!DOCTYPE HTML> &lt;html> &lt;head> &lt;title>Add Product Form&lt;/title> &lt;style type="text/css">@import url(css/main.css);&lt;/style> &lt;/head> &lt;body> &lt;div id="global"> &lt;c:if test="${requestScope.errors != null}"> &lt;p id="errors"> Error(s)! &lt;ul> &lt;c:forEach var="error" items="${requestScope.errors}"> &lt;li>${error}&lt;/li> &lt;/c:forEach> &lt;/ul> &lt;/p> &lt;/c:if> &lt;form action="product_save.action" method="post"> &lt;fieldset> &lt;legend>Add a product&lt;/legend> &lt;p> &lt;label for="name">Product Name: &lt;/label> &lt;input type="text" id="name" name="name" tabindex="1"> &lt;/p> &lt;p> &lt;label for="description">Description: &lt;/label> &lt;input type="text" id="description" name="description" tabindex="2"> &lt;/p> &lt;p> &lt;label for="price">Price: &lt;/label> &lt;input type="text" id="price" name="price" tabindex="3"> &lt;/p> &lt;p id="buttons"> &lt;input id="reset" type="reset" tabindex="4"> &lt;input id="submit" type="submit" tabindex="5" value="Add Product"> &lt;/p> &lt;/fieldset> &lt;/form> &lt;/div> &lt;/body> &lt;/html>]]></content>
      <categories>
        <category>Spring MVC</category>
      </categories>
      <tags>
        <tag>Spring MVC</tag>
        <tag>MVC</tag>
        <tag>模型2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动装箱与拆箱（张孝祥补充）]]></title>
    <url>%2F2016%2F09%2F06%2F%5BJava%5D%E8%87%AA%E5%8A%A8%E8%A3%85%E7%AE%B1%E4%B8%8E%E6%8B%86%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[Integer与int比较 Integer.valueof() 返回的是Integer的对象 Integer.parseInt() 返回的是一个int的值 new Integer.valueof().intValue();返回的也是一个int的值 不同类型比较public static void main(String[] args) { String a = &quot;400&quot;; String b = &quot;400&quot;; //int和Integer比较，Integer自动拆箱，结果true System.out.println(Integer.parseInt(a) == Integer.valueOf(b)); } 相同类型比较单字节（-128-127）的Integer 比较是直接作为基本类型比较，否则是对象比较 Integer c = 100; Integer d = 100; Integer c1 = 200; Integer d1 = 200; System.out.println(c == d); //为true System.out.println(c1 == d1);//为false]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP地址与整数转换]]></title>
    <url>%2F2016%2F09%2F06%2F%5B%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%5DIP%E5%9C%B0%E5%9D%80%E4%B8%8E%E6%95%B4%E6%95%B0%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[Java中byte, int的转换int -&gt; byte 可以直接使用强制类型转换: byte b = (byte) aInt; 这个操作是直接截取int中最低一个字节，如果int大于255，则值就会变得面目全非了 byte -&gt; int 这里有两种情况，一种是要求保持值不变，例如进行数值计算，可采用强制类型转换：int i = (int) aByte; 另一种是要求保持最低字节中各个位不变，3个高字节全部用 0填充，例如进行编解码操作 ，则需要采用位操作：int i = b &amp; 0xff; 理解★★★★★ Java中使用System.out.println(int);因为println中形参为int类型，会将字符类型强行转化为整型 byte b = (byte) 127; System.out.println(b); 字符类型转化为整型时有两种方式，一种是强转，高位用符号位填充；另一种是通过’与’的方式，高位用0填充 如果采用强转的方式，即int i = (int) aByte；Java默认byte是有符号的，int也是有符号的，强转后int的3个高字节全部用 符号位 填充，直接进行强转强转后数值不变，适合用于数值计算 采用位操作int i = bByte &amp; 0xff 时，bByte和0xff先分别转换成整型，再进行 ‘与’ 操作，得到一个32位整数，此时高位用0填充，常用于编码中 11111111 11111111 11111111 11101010 (a=-22) &amp; 00000000 00000000 00000000 11111111 (0xff) --------------------------------------------------------------------- = 00000000 00000000 00000000 11101010 (234) “字节变量 &amp; 0xff” 相当于将字节转换为无符号整型 Java中byte为有符号类型，占用一个字节，大小范围为-128~127，使用System.out.println(int)，首先会将byte强转为int类型，输出值保持不变；如果超过这个范围，会出现溢出，正数变负数，负数变正数 结果不变byte b = (byte) 127;//结果127，不变 因为127（0111 1111），首位为符号位，127为单字节正数最大，（-128）10000 0000为负数最小 正数变负数byte b = (byte) 128;//结果-128 1000 0000（128），在Java中byte为有符号数，一字节，首位为1，则这个数是负数，打印结果是-128 负数变正数byte b = (byte) -129;//结果127 -129（1 0111 1111），超出范围溢出，首先进行截断，结果为0111 1111，变为正数127 int InputStream.read() 读取字节流内部实现该函数返回一个int类型，范围从0至255，如果到达流末尾，返回-1。通过ByteArrayInputStream的源码可以看到是如何从byte转到int public synchronized int read() { return (pos &lt; count) ? (buf[pos++] &amp; 0xff) : -1; } int &lt;-&gt; byte[]（一个整数4个字节）方法一：（推荐） //将整数转为一个byte数组，字节数组的低位是整型的低字节位 public static byte[] toByteArray(int iSource, int iArrayLen) { byte[] bLocalArr = new byte[iArrayLen]; for (int i = 0; (i < 4) && (i < iArrayLen); i++) { bLocalArr[i] = (byte) ((iSource >> 8 * i) & 0xFF); } return bLocalArr; } 移位 转成整型，与操作，取低字节 截断，转成byte 方法二： private static byte[] int2byte(int i) { byte[] bytes = new byte[4]; bytes[0] = (byte) (0xff &amp; i); bytes[1] = (byte) ((0xff00 &amp; i) &gt;&gt; 8); bytes[2] = (byte) ((0xff0000 &amp; i) &gt;&gt; 16); bytes[3] = (byte) ((0xff000000 &amp; i) &gt;&gt; 24); return bytes; } byte[] &lt;-&gt; int方法一：（推荐） // 将byte数组转为一个整数,字节数组的低位是整型的低字节位 public static int toInt(byte[] bRefArr) { int iOutcome = 0; byte bLoop; for (int i = 0; i < bRefArr.length; i++) { bLoop = bRefArr[i]; iOutcome += (bLoop & 0xFF) < (8 * i);//左移并加起来 } return iOutcome; }]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC学习笔记]]></title>
    <url>%2F2016%2F09%2F01%2F%5BSpring%20MVC%5DSpring%20MVC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Spring MVC简介 SpringMVC是一个基于MVC设计理念的web框架 Spring MVC通过一套MVC注解，让POJO成为处理请求的控制器，无需实现任何接口，同时SpringMVC还支持REST风格的URL请求 Spring MVC在框架设计、扩展性、灵活性等方面全面超越Struts、WebWork等MVC框架，成为MVC的领跑者 Spring MVC框架围绕DispatcherServlet这个核心展开，DispatcherServlet是Spring MVC框架的总导演、总策划，他负责截获请求并将其分派给相应地处理器处理 Spring MVC 整体架构 1、用户发起请求到控制器 DispatcherServlet (请求分派)2、DispatcherServlet 去 handlerMapping 查找 Handler 对应的 Handler（Handler可以理解成struts中的 action）3、HandlerMapper 返回 HandlerExecutorChain 执行链（包含两部分内容：Handler,拦截器集合）4、DispatcherServlet 调用 HandlerAdapter5、HandlerAdapter 调用 Handler6、Handler 处理具体的业务逻辑7、Handler 处理完业务逻辑之后，返回 ModelAndView 给 HandlerAdapter，其中的 View 是视图名称，Modal 是数据模型8、HandlerAdapter 将 ModelAndView 返回给 DispatcherServlet9、DispatcherServlet 通过 ModelAndView 中的视图名称在视图解析器中查找视图10、视图解析器返回真正的 View 视图对象11、渲染视图12、返回用户响应 Spring MVC快速入门★★★★★★githubhttps://github.com/rhapsody1290/SpringMVC_study 导入依赖&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.apeius&lt;/groupId&gt; &lt;artifactId&gt;Demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!-- 全局属性配置,定义变量 --&gt; &lt;properties&gt; &lt;!--用来定义war包名称--&gt; &lt;project.build.name&gt;tools&lt;/project.build.name&gt; &lt;!--用来定义资源文件的编码格式 --&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;!-- spring版本号 --&gt; &lt;spring.version&gt;4.0.2.RELEASE&lt;/spring.version&gt; &lt;!-- mybatis版本号 --&gt; &lt;mybatis.version&gt;3.2.8&lt;/mybatis.version&gt; &lt;!-- log4j日志文件管理包版本 --&gt; &lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.16&lt;/log4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--Spring MVC--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSTL标签类 --&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--JSP相关--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; web.xml Spring MVC自带一个Dispatcher Servlet，要是用这个servlet，需要把它配置到部署描述符（web.xml文件） load-on-startup 元素是可选的，如果它存在，则在应用程序启动时 装载该servlet，并调用它的init方法；若它不存在，则在该servlet第一次请求 时进行加载 ★ DispatcherServlet将使用Spring MVC的诸多默认组件，在初始化时它会寻找WEB-INF目录下的配置文件，其命名规则为servletName-servlet.xml url-pattern为/时，拦截所有请求，包括静态资源[不拦截JSP]，此时需要设置annotation-driven和resources &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;/web-app&gt; spring-mvc的配置添加springmvc-servlet.xml spring-mvc 会默认去WEB-INF的目录下寻找${serlvet-name}-serlvet.xml的文件 所以我们把serlvetmvc的配置文件添加到web-inf的目录下，并且名字与 web.xml 中的servlet-name 相同 webapp/WEB-INF/springmvc-servlet.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;/beans&gt; 可以把配置文件放在应用程序的任意目录，用servlet定义的init-param元素，以便DispatcherServlet加载到该文件。在web.xml文件中，定义的DispatcherServlet中加入init-param节点，在里面写上系统中spring mvc配置文件的位置。 web.xml &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/config/springmvc-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; 当然还是推荐放在WEB-INF的目录下的${serlvet-name}-serlvet.xml的文件 自定义Handler（controller）★★★★★★ 在Spring2.5版本前，开发一个控制器的唯一方法是实现org.springframework.web.servlet.mvc.Controller接口，这个接口公开了一个handleRequest方法 其实现类可以访问请求的HttpServletRequest和HttpServletResponse 还必须返回包含视图路径 或视图路径和模的ModelAndView对象 Controller接口的实现类只能处理一个单一动作（Action）（一个Action对应一个Controller的实现类。调用其handleRequest方法），而一个基于注解的控制器可以同时支持多个请求处理的动作，并且无需实现任何接口 public class Hello implements Controller{ public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception { ModelAndView mv = new ModelAndView(); //设置试图名称 mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;这是第一个springmvc程序&quot;); return mv; /*也可以直接 return new ModelAndView(&quot;hello&quot;,&quot;msg&quot;,&quot;这是第一个springmvc程序&quot;); */ } } 在springmvc-servlet.xml 中配置Handler 当DispatcherServlet收到/hello.do的请求时，自动构建控制器Hello，并调用其handleRequest方法，返回ModelAndView &lt;!--配置自定义Handler，name表示对应的访问路径--&gt; &lt;bean name=&quot;/hello.do&quot; class=&quot;cn.apeius.springmvc.controller.Hello&quot;/&gt; 配置HandlerMapping（非必须，需要注释）&lt;!--配置handlerMapping--&gt; &lt;bean class=&quot;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&quot;/&gt; 配置handlerAdapter（非必须，需要注释）&lt;!--配置handlerAdapter--&gt; &lt;bean class=&quot;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&quot;/&gt; 配置视图解析器 视图解析器可以不设置，但需填入完整路径，如 /WEB-INF/views/hello.jsp 视图解析器负责解析视图 可以通过在配置文件中定义一个ViewResolver来配置视图解析器 视图解析器配置有前缀 和后缀 两个属性，这样一来view路径将缩短，如只需填hello &lt;!--配置试图解析器 Example: prefix=&quot;/WEB-INF/jsp/&quot;, suffix=&quot;.jsp&quot;, viewname=&quot;test&quot; -&gt; &quot;/WEB-INF/jsp/test.jsp--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/views/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt; 定义视图 文件路径在/WEB-INF/views/hello.jsp hello.jsp中可以使用ModelAndView中的对象 &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;hello&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;font color=&quot;red&quot;&gt;${msg}&lt;/font&gt; &lt;/body&gt; &lt;/html&gt; 分析第一个案例的执行过程方法一：看日志导入日志 log4j.properties log4j.rootLogger=DEBUG,A1 log4j.logger.org.mybatis=DEBUG log4j.appender.A1=org.apache.log4j.ConsoleAppender log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss,SSS} [%t] [%c]-[%p] %m%n 在web.xml中配置servlet 服务器开启的时候启动 &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; 方法二：看源码在DispatcherServlet的doDispatch方法中打断点 精简之后的配置springmvc-servlet.xml &lt;!--配置自定义Handler，name表示对应的访问路径--&gt; &lt;bean name=&quot;/hello.do&quot; class=&quot;cn.apeius.springmvc.controller.Hello&quot;/&gt; &lt;!--配置试图解析器 Example: prefix=&quot;/WEB-INF/jsp/&quot;, suffix=&quot;.jsp&quot;, viewname=&quot;test&quot; -&gt; &quot;/WEB-INF/jsp/test.jsp--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/views/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt; 第一个注解程序★★★★★★基于注解的控制器有以下几个优点： 一个控制器类可以处理多个动作，而一个实现了Controller接口的控制器只能处理一个动作。这就允许将相关的操作都写在同一个控制器内，从而减少应用程序中类的数量 基于注解的控制器的请求映射不需要存储在配置文件中 ，使用RequestMapping注释类型，可以对一个方法进行请求处理 创建注解的步骤1、书写一个类，需要在类上面加上@Controller 用于指示Spring类的实例是一个控制器 Spring使用扫描机制 来找到应用程序中所有基于注解的控制器类 2、@RequestMapping映射一个请求与请求处理方法。一个采用@RequestMapping注释的方法将成为一个请求处理方法，访问相应的URL请求时调用。@RequestMapping使用后面有详解 @Controller public class AnnotationHello { @RequestMapping(value = &quot;/show1&quot;)//可以省略后缀 public ModelAndView test1(){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;这是第一个注解程序&quot;); return mv; } } 3、在springmvc的配置文件中，去配置扫描包，使@Controller生效，和spring配置扫描包的方式一样 为了保证Spring能找到你的控制器，需要在Spring MVC的配置文件中声明spring-contextxmlns:context=&quot;http://www.springframework.org/schema/context&quot; 在元素中指定控制器类的基本包&lt;context:component-scan base-package=&quot;cn.apeius.springmvc.controller&quot;/&gt; 4、测试 http://localhost:8080/SpringMVC_study/show1.do 推荐使用的HandlerMapper和HandlerAdapter（什么意思？？） 使用注解驱动替换推荐的配置（什么意思？？） url-pattern为/时，拦截所有请求，包括静态资源，此时需要在springmvc-config.xml中设置annotation-driven和resources元素 annotation-driven 相当于注册了DefaultAnnotationHandlerMapping和AnnotationMethodHandlerAdapter两个bean，配置一些messageconverter，即解决了@Controller注解的使用前提配置 resource 元素则指示Spring MVC哪些静态资源需要单独处理（不通过DispatcherServlet）；如果没有annotation-driven，resource元素会阻止任意控制器被调用；若不使用resources，则不需要annotation-driven &lt;!--配置注解驱动，会默认加载HandlerMapping，HandlerAdapter--&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 确保/css目录下所有文件可见--&gt; &lt;mvc:resources mapping=&quot;/css/**&quot; location=&quot;/css/&quot;/&gt; &lt;!--允许显示所有的.html文件--&gt; &lt;mvc:resources mapping=&quot;/*.html&quot; location=&quot;/&quot;/&gt; 或者使用mvc:default-servlet-handler，过滤掉所有的静态资源 &lt;!--过滤掉所有的静态资源，把静态资直接交给tomcat去处理--&gt; &lt;mvc:default-servlet-handler/&gt; 使用RequestMapping映射请求★★★★★★ 在SpringMVC中的众多Controller以及每个Controller的众多方法，请求是如何映射到具体的处理方法上？这个就是靠@RequestMapping完成的，他完成了一个请求与请求处理方法的映射 @RequestMapping既可以定义在类上也可以定义在方法上，请求映射的规则是：类上面的@RequestMapping.value + 方法上面的@RequestMapping.value 举个例子：—— 控制器： @Controller @RequestMapping(&quot;test&quot;) public class AnnotationHello { @RequestMapping(&quot;show1&quot;)//可以省略后缀 public ModelAndView test1(){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;这是第一个注解程序&quot;); return mv; } } —— 访问URL： http://localhost:8080/SpringMVC_study/test/show1.do 五种映射标准URL映射 标准URL映射是最简单的一种映射，例如： @RequestMapping(“hello”)或 @RequestMapping（”/hello”）或 @RequestMapping(“value=”/hello””) 请求URL： http://localhost:8080/web应用名/hello.do value是RequestMapping的注释的默认属性，因此若只有唯一的属性，则可以省略属性名字，即以下两个标注含义相同： @RequestMapping(&quot;show1&quot;) @RequestMapping(value = &quot;show1&quot;) 但如果有超过一个属性时，就必须写入value属性名称 Ant风格的URL映射（通配符） 举例1： @RequestMapping(&quot;/test/*/show2&quot;) public ModelAndView test2(){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;/test/*/show2&quot;); return mv; } 能匹配： /test/a/show2.do /test/abc/show2.do /test/show2.do 匹配不到 举例2： @RequestMapping(&quot;/test/**/show3&quot;) public ModelAndView test3(){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;/test/**/show3&quot;); return mv; } 能匹配： http://localhost:8080/web应用名/test/a/show3.do http://localhost:8080/web应用名/test/b/a/d/show3.do 占位符映射 Url中可以通过一个或多个{xxxx}占位符映射,通过@PathVariable(“xxx”)绑定到方法的入参中 占位符映射让传递参数多了一种方式 例如： @RequestMapping(&quot;/test/{itemId}/{itemName}&quot;) public ModelAndView test4(@PathVariable(&quot;itemId&quot;) String itemId, @PathVariable(&quot;itemName&quot;) String itemName){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;itemId:&quot; + itemId + &quot; &quot; + &quot;itemName:&quot; + itemName); return mv; } URL: http://localhost:8080/SpringMVC_study/test/2011/iphone6s.do 结果： itemId:2011 itemName:iphone6s 限制请求方法映射若无指定method属性，则请求处理方法可以处理任意HTTP方法 只允许get请求访问 @RequestMapping(value = &quot;test5&quot;, method = RequestMethod.GET) public ModelAndView test5(){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;限制只有get请求才能进入&quot;); return mv; } 只允post和get方法 @RequestMapping(value = &quot;test5&quot;, method = {RequestMethod.GET,RequestMethod.POST}) public ModelAndView test5(){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;限制只有get、post请求才能进入&quot;); return mv; } 限制参数映射@RequestMapping(value = &quot;/test6&quot;,params = &quot;userId&quot;) public ModelAndView test6(@RequestParam(value=&quot;userId&quot;) String userId){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;限定请求参数，必须要有Userid这个信息；userid：&quot; + userId); return mv; } 请求中必须带userId参数 参数的规则如下 params=”userId”请求参数中必须包含userId params=”!userId”请求参数中不能包含userId params=”userId!=1”请求参数必须包含userId，但其值不能为1 params=”{“userId”,”name”}”必须包含userId和name参数 请求URL http://localhost:8080/SpringMVC_study/test6.do?userId=2 请求响应处理方法的数据绑定 一个请求URL与请求响应方法一一对应 数据绑定是将用户输入 与领域模型 相互绑定 类型总为String 的HTTP请求参数，可用于填充不同类型的对象属性 数据绑定使得form bean变成多余 绑定servlet内置对象非常简单，只需在参数中加入需要使用的内置对象，常用的有HttpServletRequest、HttpServletResponse、HttpSession @RequestMapping(value = &quot;/test7&quot;) public ModelAndView test7(HttpServletRequest request, HttpServletResponse response, HttpSession session){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;Servlet中的对象&quot;); System.out.println(request); System.out.println(response); System.out.println(session); return mv; } @PathVariable获取占位符中的参数 通过@PathVariable可以绑定占位符参数到方法参数中 路径变量的类型可以不是字符串 可以使用多个路径变量 @RequestMapping(&quot;/test/{itemId}/{itemName}&quot;) public ModelAndView test4(@PathVariable(&quot;itemId&quot;) String itemId, @PathVariable(&quot;itemName&quot;) String itemName){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;itemId:&quot; + itemId + &quot; &quot; + &quot;itemName:&quot; + itemName); return mv; } 特殊说明：不要省略@PathVariable中的参数 @RequestParam ★★★★★ 将请求参数传入到方法中，如http://localhost:8080/SpringMVC_study/test8?userId=qm @RequestParam 注解的参数类型不一定是字符串，可以是整型等其他 /** * required：必须要有这个参数 * defautlValue：默认值，如果defaultValue设置了值，那么required失效 * @param userId * @return */ @RequestMapping(value = "/test8") public ModelAndView test8(@RequestParam(value = "userId",required = true,defaultValue = "10") String userId){ ModelAndView mv = new ModelAndView(); mv.setViewName("hello"); mv.addObject("msg","userId：" + userId); return mv; } @CookieValue在Spring MVC中通过@CookieValue可以轻松获取cookie的值 Servlet中如何获取指定的cookie值 Cookie[] cookies = request.getCookies(); //对数组进行遍历，根据cookie中的name 来找到对应的cookie for(Cookie cookie : cookies){ if(&quot;abc&quot;.equals(cookie.getName())) cookie.getValue();//获取cookie中的值 } 使用@CookieValue @RequestMapping(value = &quot;/test9&quot;) public ModelAndView test9(@CookieValue(&quot;JSESSIONID&quot;) String JSESSIONID){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,&quot;JESSIONID：&quot; + JSESSIONID); return mv; } POJO对象绑定参数SpringMVC会将请求过来的 参数名 和POJO实体中的 属性名 进行匹配，如果名称一致，将把值填充到对象中 @RequestMapping(value = &quot;/test10&quot;) public ModelAndView test10(User user){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello&quot;); mv.addObject(&quot;msg&quot;,user); return mv; } User.java public class User { private String userName; private String password; public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } @Override public String toString(){ return userName + &quot; &quot; + password; } } 自定义复合对象类型User对象中有ContactInfo属性，Controller中的代码和第3点说的一致，但是，在表单代码中，需要使用“属性名(对象类型的属性).属性名”来命名input的name Model代码： public class ContactInfo { private String tel; private String address; public String getTel() { return tel; } public void setTel(String tel) { this.tel = tel; } public String getAddress() { return address; } public void setAddress(String address) { this.address = address; } } public class User { private String firstName; private String lastName; private ContactInfo contactInfo; public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public ContactInfo getContactInfo() { return contactInfo; } public void setContactInfo(ContactInfo contactInfo) { this.contactInfo = contactInfo; } } Controller代码： @RequestMapping("saysth.do") public void test(User user) { System.out.println(user.getFirstName()); System.out.println(user.getLastName()); System.out.println(user.getContactInfo().getTel()); System.out.println(user.getContactInfo().getAddress()); } 表单代码： &lt;form action="saysth.do" method="post"> &lt;input name="firstName" value="张" />&lt;br> &lt;input name="lastName" value="三" />&lt;br> &lt;input name="contactInfo.tel" value="13809908909" />&lt;br> &lt;input name="contactInfo.address" value="北京海淀" />&lt;br> &lt;input type="submit" value="Save" /> &lt;/form> Java的基本数据类型绑定 表单中input的name值和Controller的参数变量名保持一致，就能完成数据绑定，如果不一致可以使用@RequestParam注解 如果Controller方法参数中定义的是基本数据类型，但是从页面提交过来的数据为null或者””的话，会出现数据转换的异常。也就是必须保证表单传递过来的数据不能为null或””，所以，在开发过程中，对可能为空的数据，最好将参数数据类型定义成包装类型 Java的基本数据类型数组可以自动转换，如String[] interests，但是用户自定义User[] users不行，需要将User[]包装到一个UserForm中，通List操作 表单代码 &lt;form action=&quot;/demos/demo1.action&quot; method=&quot;post&quot;&gt; &lt;div&gt;姓名:&lt;/div&gt; &lt;div&gt;&lt;input name=&quot;name&quot; value=&quot;张三&quot;/&gt;&lt;/div&gt; &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; &lt;div&gt;年龄:&lt;/div&gt; &lt;div&gt;&lt;input name=&quot;age&quot; value=&quot;20&quot;/&gt;&lt;/div&gt; &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; &lt;div&gt;收入:&lt;/div&gt; &lt;div&gt;&lt;input name=&quot;income&quot; value=&quot;100000&quot;/&gt;&lt;/div&gt; &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; &lt;div&gt;结婚:&lt;/div&gt; &lt;div&gt; &lt;input type=&quot;radio&quot; name=&quot;isMarried&quot; value=&quot;true&quot; checked=&quot;checked&quot;/&gt;是 &lt;input type=&quot;radio&quot; name=&quot;isMarried&quot; value=&quot;false&quot;/&gt;否&lt;/div&gt; &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; &lt;div&gt;兴趣:&lt;/div&gt; &lt;div&gt; &lt;input type=&quot;checkbox&quot; name=&quot;interests&quot; value=&quot;听歌&quot; checked=&quot;checked&quot;/&gt;听歌 &lt;input type=&quot;checkbox&quot; name=&quot;interests&quot; value=&quot;书法&quot; checked=&quot;checked&quot;/&gt;书法 &lt;input type=&quot;checkbox&quot; name=&quot;interests&quot; value=&quot;看电影&quot; checked=&quot;checked&quot;/&gt;看电影 &lt;/div&gt; &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; &lt;div&gt;&lt;input type=&quot;submit&quot; value=&quot;提交表单&quot;/&gt;&lt;/div&gt; &lt;/form&gt; 测试： 集合List绑定 如果方法需要接受的list集合，不能够直接在方法中书写List，List的绑定，需要 将List对象包装到一个类中 才能绑定（如果List中的类型是Java自带的，则可以自动转换，如List &lt;Object&gt;，List，而List &lt;User&gt;不行） 与”自定义复合对象类型”数据绑定类似，但是UserForm对象的属性被定义成List，而不是普通自定义对象，所以在表单中需要指定List的下标 Spring会创建一个以最大下标值为size的List对象，List中的对象，只有在表单中对应有下标的那些才会有值，否则会为null 表单 &lt;form action=&quot;/SpringMVC_study/test11.do&quot;&gt; 用户1：&lt;input type=&quot;text&quot; name=&quot;users[0].userName&quot;/&gt;&lt;br/&gt; 用户2：&lt;input type=&quot;text&quot; name=&quot;users[1].userName&quot;/&gt;&lt;br/&gt; 用户3：&lt;input type=&quot;text&quot; name=&quot;users[2].userName&quot;/&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot; value=&quot;测试&quot;/&gt; &lt;/form&gt; 将List对象包装到一个类中 public class UserForm { private List users; public List getUsers() { return users; } public void setUsers(List users) { this.users = users; } } Action @RequestMapping(value = "/test11") public ModelAndView test11(UserForm userForm){ ModelAndView mv = new ModelAndView(); mv.setViewName("hello"); mv.addObject("msg","List集合"); for(User user : userForm.getUsers()){ System.out.println(user); } return mv; } 集合Set绑定Set和List类似，也需要绑定在对象上，而不能直接写在Controller方法的参数中。但是，绑定Set数据时，必须先在Set对象中add相应的数量的模型对象 Model代码： public class User { private String firstName; private String lastName; public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } } public class UserSetForm { private Set users = new HashSet(); public UserSetForm() { users.add(new User()); users.add(new User()); users.add(new User()); } public Set getUsers() { return users; } public void setUsers(Set users) { this.users = users; } } Controller代码： @RequestMapping(&quot;saysth.do&quot;) public void test(UserSetForm userForm) { for (User user : userForm.getUsers()) { System.out.println(user.getFirstName() + &quot; - &quot; + user.getLastName()); } } 表单代码： &lt;form action="saysth.do" method="post"> &lt;table> &lt;thead> &lt;tr> &lt;th>First Name&lt;/th> &lt;th>Last Name&lt;/th> &lt;/tr> &lt;/thead> &lt;tfoot> &lt;tr> &lt;td colspan="2">&lt;input type="submit" value="Save" />&lt;/td> &lt;/tr> &lt;/tfoot> &lt;tbody> &lt;tr> &lt;td>&lt;input name="users[0].firstName" value="aaa" />&lt;/td> &lt;td>&lt;input name="users[0].lastName" value="bbb" />&lt;/td> &lt;/tr> &lt;tr> &lt;td>&lt;input name="users[1].firstName" value="ccc" />&lt;/td> &lt;td>&lt;input name="users[1].lastName" value="ddd" />&lt;/td> &lt;/tr> &lt;tr> &lt;td>&lt;input name="users[2].firstName" value="eee" />&lt;/td> &lt;td>&lt;input name="users[2].lastName" value="fff" />&lt;/td> &lt;/tr> &lt;/tbody> &lt;/table> &lt;/form> Map绑定Map最为灵活，它也需要绑定在对象上，而不能直接写在Controller方法的参数中 Model代码： public class User { private String firstName; private String lastName; public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } } public class UserMapForm { private Map users; public Map getUsers() { return users; } public void setUsers(Map users) { this.users = users; } } Controller代码： @RequestMapping(&quot;saysth.do&quot;) public void test(UserMapForm userForm) { for (Map.Entry&lt;String, User&gt; entry : userForm.getUsers().entrySet()) { System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue().getFirstName() + &quot; - &quot; + entry.getValue().getLastName()); } } 表单代码： &lt;form action="saysth.do" method="post"> &lt;table> &lt;thead> &lt;tr> &lt;th>First Name&lt;/th> &lt;th>Last Name&lt;/th> &lt;/tr> &lt;/thead> &lt;tfoot> &lt;tr> &lt;td colspan="2">&lt;input type="submit" value="Save" />&lt;/td> &lt;/tr> &lt;/tfoot> &lt;tbody> &lt;tr> &lt;td>&lt;input name="users['x'].firstName" value="aaa" />&lt;/td> &lt;td>&lt;input name="users['x'].lastName" value="bbb" />&lt;/td> &lt;/tr> &lt;tr> &lt;td>&lt;input name="users['y'].firstName" value="ccc" />&lt;/td> &lt;td>&lt;input name="users['y'].lastName" value="ddd" />&lt;/td> &lt;/tr> &lt;tr> &lt;td>&lt;input name="users['z'].firstName" value="eee" />&lt;/td> &lt;td>&lt;input name="users['z'].lastName" value="fff" />&lt;/td> &lt;/tr> &lt;/tbody> &lt;/table> &lt;/form> 数据绑定与表单标签库结合（表单不清空）★★★★★ 数据绑定可以将用户表单输入 绑定到一个领域模型，可以自动将HTTP请求参数默认的字符串 类型转化成不同类型 的对象属性，因此不再需要FORM类 数据绑定还有另外一个好处：当输入验证失败时，它会重新生成一个HTML表单。手工编写HTML代码时，必须记着用户之前输入的值，重新填充输入字段。有了Spring的数据绑定和表单标签后，它们会替你完成这些工作 第一步： 访问displayCustomerForm.do时创建一个领域对象并初始化属性，作为表单的默认显示，并添加到Model中，然后跳转到显示表单页面SignUpForm.jsp @RequestMapping(value = "displayCustomerForm", method = RequestMethod.GET) public String displayCustomerForm(ModelMap model) { Customer customer = new Customer(); customer.setName("qm"); customer.setAge(2333); model.addAttribute("customer", customer); return "SignUpForm"; } 第二步：使用表单标签库 commandName定义了模型的名称，其对象属性将用于填充所生成的表单 input标签中个path属性，将这个输入字段绑定到commandName指定对象的一个属性 errors标签可以显示一个特定的字段错误（path=”name”）或所有字段错误（path=”*”） &lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form"%> &lt;form:form commandName="product" action="product_save" method="post"> &lt;fieldset> &lt;legend>Add a product&lt;/legend> &lt;p class="errorLine"> &lt;form:errors path="name" cssClass="error"/> &lt;/p> &lt;p> &lt;label for="name">*Product Name: &lt;/label> &lt;form:input id="name" path="name" tabindex="1"/> &lt;/p> &lt;p> &lt;label for="description">Description: &lt;/label> &lt;form:input id="description" path="description" tabindex="2"/> &lt;/p> &lt;p class="errorLine"> &lt;form:errors path="price" cssClass="error"/> &lt;/p> &lt;p> &lt;label for="price">*Price: &lt;/label> &lt;form:input id="price" path="price" tabindex="3"/> &lt;/p> &lt;p class="errorLine"> &lt;form:errors path="productionDate" cssClass="error"/> &lt;/p> &lt;p> &lt;label for="productionDate">*Production Date: &lt;/label> &lt;form:input id="productionDate" path="productionDate" tabindex="4"/> &lt;/p> &lt;p id="buttons"> &lt;input id="reset" type="reset" tabindex="5"> &lt;input id="submit" type="submit" tabindex="6" value="Add Product"> &lt;/p> &lt;/fieldset> &lt;/form:form> 转换器和格式化（麻烦，建议使用joda-time，参考ssm整合部分）1、实现一种对象类型转换成另一种对象类型2、Converter是通用元件，可以在应用程序的任意层中使用3、Formatter则是专门为Web层设计的 Converter通过转换器，实现将输入的日期字符串转换成Date类型 实现Converter接口，源数据类型和目标数据类型可以自由指定 public class StringToDateConvert implements Converter { private String datePattern; public StringToDateConvert(String datePattern){ this.datePattern = datePattern; } public Date convert(String s) { SimpleDateFormat dateFormat = new SimpleDateFormat(datePattern); dateFormat.setLenient(false); try { return dateFormat.parse(s); } catch (ParseException e) { throw new RuntimeException("格式错误"); } } } Spring MVC配置文件中编写一个conversionService bean，Bean的类必须为org.springframework.context.support.ConversionServiceFactoryBean，同时配置converters属性，它将列出程序中所有订制的Converter &lt;bean id = &quot;conversionService&quot; class=&quot;org.springframework.context.support.ConversionServiceFactoryBean&quot;&gt; &lt;property name=&quot;converters&quot;&gt; &lt;set&gt; &lt;bean class=&quot;cn.apeius.convert.StringToDateConvert&quot;&gt; &lt;constructor-arg name=&quot;datePattern&quot; value=&quot;yyyy-MM-dd&quot;/&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 给annotation-driven元素的conversion-service赋值bean名称，本例中是conversionService &lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot;/&gt; 表单输入 &lt;form action=&quot;/SpringMVC_study/test22.do&quot;&gt; &lt;fieldset&gt; &lt;legend&gt;用户登录&lt;/legend&gt; &lt;p&gt; &lt;label&gt;出生日期：&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;birthday&quot;/&gt; &lt;/p&gt; &lt;p id = &quot;buttons&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;测试&quot;/&gt; &lt;/p&gt; &lt;/fieldset&gt; &lt;/form&gt; 字符串日期自动转换 @RequestMapping(value = &quot;/test22&quot;) public ModelAndView test22(@RequestParam(&quot;birthday&quot;) Date birthday){ return new ModelAndView(&quot;hello&quot;,&quot;msg&quot;,birthday); } Formatter1、Formatter的源类型必须是一个String，适合在Web层转换表单中用户的输入2、Converter源类型可以是任意类型，可以在任意层中使用 以下案例为将一个表单输入的String日期转换成Date： 编写一个实现org.springframework.format.Formatter接口的Java类 public class DateFormatter implements Formatter{ private String datePattern; private SimpleDateFormat simpleDateFormat; public DateFormatter(String datePattern){ this.datePattern = datePattern; simpleDateFormat = new SimpleDateFormat(datePattern); simpleDateFormat.setLenient(false); } /*利用Locale将String解析成目标类型（Date）*/ public Date parse(String text, Locale locale) throws ParseException { return simpleDateFormat.parse(text); } /*利用Locale将目标类型转换成String*/ public String print(Date date, Locale locale) { return simpleDateFormat.format(date); } } 配置conversionService bean，bean的类名必须为org.springframework.format.support.FormattingConversionServiceFactoryBean，注入属性formatters，它将列出程序中所有订制的Formatter &lt;!--配置conversionService bean--&gt; &lt;bean id = &quot;conversionService&quot; class=&quot;org.springframework.format.support.FormattingConversionServiceFactoryBean&quot;&gt; &lt;property name=&quot;formatters&quot;&gt; &lt;set&gt; &lt;bean class=&quot;cn.apeius.formatter.Date，它将列出程序中所有订制的Converter&quot;&gt; &lt;constructor-arg name=&quot;datePattern&quot; value=&quot;yyyy-MM-dd&quot;/&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 给annotation-driven元素的conversion-service赋值bean名称，本例中是conversionService &lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot;/&gt; 测试同Converter 用Registrar注册Formatter注册Formatter的另一种方法是使用Registrar： 创建一个实现org.springframework.format.FormatterRegistrar接口的Java类 public class MyFormatterRegistrar implements FormatterRegistrar{ private String datePattern; public MyFormatterRegistrar(String datePattern){ this.datePattern = datePattern; } public void registerFormatters(FormatterRegistry registry) { registry.addFormatter(new DateFormatter(datePattern)); //注册更多的Formatter } } 在配置文件中注册Registrar &lt;!--配置conversionService bean--&gt; &lt;bean id = &quot;conversionService&quot; class=&quot;org.springframework.format.support.FormattingConversionServiceFactoryBean&quot;&gt; &lt;property name=&quot;formatterRegistrars&quot;&gt; &lt;set&gt; &lt;bean class=&quot;cn.apeius.formatter.MyFormatterRegistrar&quot;&gt; &lt;constructor-arg name=&quot;datePattern&quot; value=&quot;yyyy-MM-dd&quot;/&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 给annotation-driven元素的conversion-service赋值bean名称，本例中是conversionService 选择Convert还是Formatter Converter是一般工具，可以将一种类型转换成另一种类型，Converter既可用在Web层，也可用在其他层中 Formatter只能将String转换成另一种类型，Formatter适用于web层，将表单属性进行类型转换 因此在Spring MVC程序中，选择Formatter比选择Converter更合适 使用joda-time注解对日期格式转换SpringMVC默认不支持字符串转换成Date格式，可以采用SpringMVC自带的转换器，还有一种简单的方法： 注解可以加载javaBean上: @DateTimeFormat(pattern = &quot;yyyy-MM-dd&quot;) private Date birthday; 注解接在方法参数上： public void test(@DateTimeFormat(pattern = &quot;yyyy-MM-dd&quot;) @RequestParam(&quot;date&quot;) Date date){ System.out.println(date); } 需要导入依赖： &lt;!--时间操作组件--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;${joda-time.version}&lt;/version&gt; &lt;/dependency&gt; 应用@Autowired和@Service进行依赖注入 将依赖注入到Spring MVC控制器的最简单方法是通过注解@Autowired到字段或方法 @Autowired private ProductService productService; 能被作为依赖注入的类必须声明@Service， @Service public class ProductServiceImpl implements ProductService { 在配置文件中还需添加一个元素来扫描依赖基本包 &lt;context:component-scan base-package=&quot;cn.apeius.product5.service&quot;/&gt; 验证器Validator（JSR spring5.0不通过）！！！如果一个程序中既有Formatter，又有Validator（验证器），那么在调用Controller期间，将会有一个或者多个Formatter 试图将字符串转成domain对象中个属性值，一旦转换成功，验证器 就会介入 Spring验证器验证的Product对象public class Product implements Serializable { private static final long serialVersionUID = 748392348L; private String name; private String description; private Float price; private Date productionDate; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public Float getPrice() { return price; } public void setPrice(Float price) { this.price = price; } public Date getProductionDate() { return productionDate; } public void setProductionDate(Date productionDate) { this.productionDate = productionDate; } } 实现Validator接口 /*需要实现接口中supports和validate两个方法*/ public class ProductValidator implements Validator { /*如果验证器可以处理指定的Class，supports方法将返回true*/ public boolean supports(Class klass) { return Product.class.isAssignableFrom(klass); } /*validate方法验证目标对象，并将错误填入Errors对象*/ public void validate(Object target, Errors errors) { Product product = (Product) target; /* 1、给Errors对象添加错误最容易的方法是调用Errors对象的一个reject或rejectValue方法， 大多时候只传入一个错误码，Spring会在属性文件中查找错误码，获得相应的错误信息 void reject(String errorcode) void rejectValue(String field, String errorCode) 2、使用ValidationUtils类 if(firstName == null || firstName.isEmpty()) errors.rejectValue("price","xxx") 等效于 ValidationUtils.rejectIfEmpty("price"); */ ValidationUtils.rejectIfEmpty(errors, "name", "productname.required"); ValidationUtils.rejectIfEmpty(errors, "price", "price.required"); ValidationUtils.rejectIfEmpty(errors, "productionDate", "productiondate.required"); Float price = product.getPrice(); if (price != null && price < 0) { errors.rejectValue("price", "price.negative"); } Date productionDate = product.getProductionDate(); if (productionDate != null) { // The hour,minute,second components of productionDate are 0 if (productionDate.after(new Date())) { errors.rejectValue("productionDate", "productiondate.invalid"); } } } } 错误信息属性文件若想要从某个属性文件获取错误消息，则要通过声明messageSource bean告诉spring去那里查找这个文件 messageSource bean &lt;bean id=&quot;messageSource&quot; class=&quot;org.springframework.context.support.ReloadableResourceBundleMessageSource&quot;&gt; &lt;property name=&quot;basename&quot; value=&quot;/WEB-INF/resource/messages&quot;/&gt; &lt;/bean&gt; messages.properties productname.required.product.name=Please enter a product name price.required=Please enter a price productiondate.required=Please enter a production date productiondate.invalid=Invalid production date. Please ensure the production date is not later than today. price.negative=price should be positive Controller类 @Controller public class ProductController { private static final Log logger = LogFactory .getLog(ProductController.class); @RequestMapping(value = "/product_input") public String inputProduct(Model model) { model.addAttribute("product", new Product()); return "ProductForm"; } @RequestMapping(value = "/product_save") public String saveProduct(@ModelAttribute Product product, BindingResult bindingResult, Model model) {//BindingResult继承Errors接口 logger.info("product_save"); /*实例化Vaildator类，调用其validate方法*/ ProductValidator productValidator = new ProductValidator(); productValidator.validate(product, bindingResult); /*检验该验证器是否生成错误消息，需在BindingResult中调用hasErrors方法*/ if (bindingResult.hasErrors()) { FieldError fieldError = bindingResult.getFieldError(); logger.info("Code:" + fieldError.getCode() + ", field:" + fieldError.getField()); return "ProductForm"; } // save product here model.addAttribute("product", product); return "ProductDetails"; } } JSR 303验证Hibernate Validator 是 Bean Validation 的参考实现。 Hibernate Validator 提供了 JSR 303 规范中所有内置 constraint 的实现，除此之外还有一些附加的 constraint。 依赖&lt;!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-validator --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.2.4.Final&lt;/version&gt; &lt;/dependency&gt; Product类Prodcut类中的name和productionDate字段用JSR 303标注类型进行标注 public class Product implements Serializable { private static final long serialVersionUID = 78L; @Size(min=1, max=10) private String name; private String description; private Float price; @Past private Date productionDate; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public Float getPrice() { return price; } public void setPrice(Float price) { this.price = price; } public Date getProductionDate() { return productionDate; } public void setProductionDate(Date productionDate) { this.productionDate = productionDate; } } Spring MVC 和 Struts2的区别 Struts2的入口是filter，Spring MVC的入口是Servlet，两者的实现机制不同 Struts2是基于类设计的，参数绑定到类的属性，所有的方法都可以使用；Spring MVC是基于方法设计的，参数绑定到方法的形参，并且只有一个方法可以使用 Struts2必须是多例的（Struts2传递到的参数绑定到类的属性，如果是单例会导致不同用户数据的冲突），Spring MVC默认是单例的，所以Spring MVC的性能比Struts2好 jsp 和 jstl 视图解析器userList.jsp &lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;table border=&quot;1px&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot;&gt; &lt;tr&gt; &lt;td&gt; 用户名&lt;/td&gt; &lt;td&gt; 密码&lt;/td&gt; &lt;/tr&gt; &lt;c:forEach items=&quot;${userList}&quot; var=&quot;user&quot;&gt; &lt;tr&gt; &lt;td&gt; ${user.userName} &lt;/td&gt; &lt;td&gt; ${user.password} &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; controller代码 @RequestMapping(value=&quot;/test12&quot;) public ModelAndView test12(){ ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;userList&quot;); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for(int i = 0 ; i &lt; 3 ; i ++){ User user = new User(); user.setUserName(&quot;user_name&quot;+i); user.setPassword(&quot;123456&quot;); userList.add(user); } mv.addObject(&quot;userList&quot;, userList); return mv; } 使用ResponseBody输出JSON 在实际开发过程中json是最为常用的一种方式，所以Spring MVC提供了一种更为简便的方式输出数据，即使用@ResponseBody注解 需引入Jackson:Json处理工具包 使用步骤导入依赖 &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.4.4&lt;/version&gt; &lt;/dependency&gt; 返回json数组 @RequestMapping(value=&quot;/test13&quot;) @ResponseBody public List&lt;User&gt; test13(){ List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for(int i = 0 ; i &lt; 3 ; i ++){ User user = new User(); user.setUserName(&quot;user_name&quot;+i); user.setPassword(&quot;123456&quot;); userList.add(user); } return userList; } 返回单个json对象 @RequestMapping(value=&quot;/test14&quot;) @ResponseBody public User test14(){ User user = new User(); user.setUserName(&quot;user_name&quot;); user.setPassword(&quot;123456&quot;); return user; } 原理 忽略某个JaveBean的属性// 密码 @JsonIgnore private String password; @RequestBody使用@RequestBody可以将请求的json字符串转化POJO对象 传递json对象 @RequestMapping(value=&quot;/test15&quot;) @ResponseStatus(value= HttpStatus.OK) public void test15(@RequestBody User user){ System.out.println(user); } 传递json数组 @RequestMapping(value=&quot;/test16&quot;) @ResponseStatus(value= HttpStatus.OK) public void test16(@RequestBody List&lt;User&gt; users){ for(User user : users){ System.out.println(user); } } 文件上传添加依赖&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; 定义文件上传解析器在springmvc的配置文件中，去定义文件上传的解析器 &lt;!-- 定义文件上传解析器 --&gt; &lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!-- 设定默认编码 --&gt; &lt;property name=&quot;defaultEncoding&quot; value=&quot;UTF-8&quot;&gt;&lt;/property&gt; &lt;!-- 设定文件上传的最大值5MB，5*1024*1024 --&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;5242880&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 客户端编程&lt;form method=&quot;post&quot; action=&quot;/SpringMVC_study/upload&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;p&gt;&lt;input type=&quot;file&quot; name=&quot;file&quot;/&gt;&lt;/p&gt; &lt;p&gt;&lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt;&lt;/p&gt; &lt;/form&gt; 如果想要上传多个文件，在input元素中加入multiple属性： &lt;input type=&quot;file&quot; name=&quot;file&quot; multiple/&gt; MultipartFile接口上传到Spring MVC程序的文件会被包在一个MultipartFile对象中，具有以下方法： byte[] getBytes() #以字节数组形式返回文件的内容 String getContentType() # 返回文件的内容类型 InputStream getInputStream() # 返回一个InputStream，从中读取文件的内容 String getName() # 以多部分的形式返回参数的名称 String getOriginalFilename() # 返回客户端本地驱动器中个初始文件名 String getSize() # 以字为单位，返回文件的大小 boolean isEmpty() # 表示被上传的文件是否为空 void transferTo(File destination) # 将上传的文件保存到目标目录下 利用注解上传单文件@RequestMapping(value=&quot;/upload&quot;) public String upload(@RequestParam(&quot;file&quot;) MultipartFile multipartFile) throws Exception { if (multipartFile != null) { // multipartFile.getOriginalFilename() 获取文件的原始名称 multipartFile.transferTo(new File(&quot;d:\\tmp\\&quot; + multipartFile.getOriginalFilename())); } return &quot;redirect:/success.html&quot;; } 利用注解上传多文件@RequestMapping(value=&quot;/uploadMultipartFile&quot;) public String uploadMultipartFile(@RequestParam(&quot;files&quot;) MultipartFile[] multipartFiles) throws Exception { for(MultipartFile multipartFile : multipartFiles){ if (multipartFile != null) { // multipartFile.getOriginalFilename() 获取文件的原始名称 multipartFile.transferTo(new File(&quot;d:\\tmp\\&quot; + multipartFile.getOriginalFilename())); } } return &quot;redirect:/success.html&quot;; } 利用domain类上传文件★★★★★Product类中加入了新的属性 List images： public class Product implements Serializable { private static final long serialVersionUID = 74458L; @NotNull @Size(min=1, max=10) private String name; private String description; private Float price; private List&lt;MultipartFile> images; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public Float getPrice() { return price; } public void setPrice(Float price) { this.price = price; } public List&lt;MultipartFile> getImages() { return images; } public void setImages(List&lt;MultipartFile> images) { this.images = images; } } 控制器： @RequestMapping(value = &quot;/product_save&quot;) public String saveProduct(HttpServletRequest servletRequest, @ModelAttribute Product product, BindingResult bindingResult, Model model) { List&lt;MultipartFile&gt; files = product.getImages(); List&lt;String&gt; fileNames = new ArrayList&lt;String&gt;(); if (null != files &amp;&amp; files.size() &gt; 0) { for (MultipartFile multipartFile : files) { String fileName = multipartFile.getOriginalFilename(); fileNames.add(fileName); File imageFile = new File(servletRequest.getServletContext() .getRealPath(&quot;/image&quot;), fileName); try { multipartFile.transferTo(imageFile); } catch (IOException e) { e.printStackTrace(); } } } // save product here model.addAttribute(&quot;product&quot;, product); return &quot;ProductDetails&quot;; } 进度条 HTML5 input元素的change事件，当input元素的值发生改变时，就会被触发 HTML5 在XMLHttpRequest对象中添加的progress事件，当异步使用XMLHttpRequest对象上传文件时，就会持续地触发progress对象，直到上传进度完成或取消。通过监听progress事件，可以监控文件上传操作的进度 UploadFile的domain类UploadFile类中包含一个MultipartFile属性，代表一个文件 public class UploadedFile implements Serializable { private static final long serialVersionUID = 72348L; private MultipartFile multipartFile; public MultipartFile getMultipartFile() { return multipartFile; } public void setMultipartFile(MultipartFile multipartFile) { this.multipartFile = multipartFile; } } Html5FileUploadController类 @Controller public class Html5FileUploadController { private static final Log logger = LogFactory .getLog(Html5FileUploadController.class); @RequestMapping(value = "/html5") public String inputProduct() { return "Html5"; } @RequestMapping(value = "/file_upload") public void saveFile(HttpServletRequest servletRequest, @ModelAttribute UploadedFile uploadedFile, BindingResult bindingResult, Model model) { MultipartFile multipartFile = uploadedFile.getMultipartFile(); String fileName = multipartFile.getOriginalFilename(); try { File file = new File(servletRequest.getSession().getServletContext().getRealPath("/file"), fileName); multipartFile.transferTo(file); System.out.println(file.getAbsolutePath()); } catch (IOException e) { e.printStackTrace(); } } } html5.jsphtml5.jsp的用户界面主要包含了一个名为progressBar的div元素，一个表单和另一个名为debug的div元素。progressBar用于展示上传进度，debug用于展示调试信息，表单中有一个类型为file的input元素的一个按钮，有一些注意点： 标识为files的input元素，它有一个multiple属性，用于支持多文件选择 这个按钮不是一个提交按钮，单击它不会提交表单，脚本是利用XMLHttpRequest对象来完成上传的 &lt;!DOCTYPE HTML> &lt;html> &lt;head> &lt;script> /*① * JavaScript代码执行的第一个件事是分配四个变量： * totalFileLength，totalUploaded，fileCount，filesUploaded。 * totalFileLength表示要上传的文件总长度，totalUploaded表示目前已经上传的字节数， * fileCount表示上传的文件数量，filesUploaded表示已经上传的文件数量 */ var totalFileLength, totalUploaded, fileCount, filesUploaded; function debug(s) { var debug = document.getElementById('debug'); if (debug) { debug.innerHTML = debug.innerHTML + '&lt;br/>' + s; } } /*② * 启动时将files input元素的change事件映射到onFileSelect函数， * 从本地目录选择了不同的文件，就会触发change事件； * 将按钮的click事件映射到startUpload函数，点击就执行上传操作 */ window.onload = function() { document.getElementById('files').addEventListener( 'change', onFileSelect, false); document.getElementById('uploadButton'). addEventListener('click', startUpload, false); } /*③ * 每当用户选择本地目录不同文件时就会调用该函数，计算fileCount和totalFileLength */ function onFileSelect(e) { var files = e.target.files; // FileList object var output = []; fileCount = files.length; totalFileLength = 0; for (var i=0; i&lt;fileCount; i++) { var file = files[i]; output.push(file.name, ' (', file.size, ' bytes, ', file.lastModifiedDate.toLocaleDateString(), ')' ); output.push('&lt;br/>'); debug('add ' + file.size); totalFileLength += file.size; } document.getElementById('selectedFiles').innerHTML = output.join(''); debug('totalFileLength:' + totalFileLength); } /*④ * 当用户调用Upload按钮时，就会调用startUpload函数，初始化totalUploaded和filesUploaded， * 随之调用uploadNext函数，上传下一个文件 */ function startUpload() { totalUploaded = filesUploaded = 0; uploadNext(); } /*⑤★★★★★ * 首先创建一个XMLHttpRequest和FormData对象，并将接下来要上传的文件添加到它的后面， * 随后，uploadNext函数将XMLHttpRequest对象的progress事件添加到onUploadProgress函数， * 并将load事件和error事件分别添加到onUploadComplete和onUploadFailed * 接下来打开一个服务器连接，并发出FormData * 在上传期间，会重复得调用onUploadProgress函数，让它有机会更新进度条 */ function uploadNext() { var xhr = new XMLHttpRequest(); var fd = new FormData(); var file = document.getElementById('files'). files[filesUploaded]; fd.append("multipartFile", file); xhr.upload.addEventListener( "progress", onUploadProgress, false); xhr.addEventListener("load", onUploadComplete, false); xhr.addEventListener("error", onUploadFailed, false); xhr.open("POST", "file_upload"); debug('uploading ' + file.name); xhr.send(fd); } /*⑥ * 在上传期间，会重复得调用onUploadProgress函数，让它有机会更新进度条 * 更新包括计算已经上传的总字节数比率，与选择文件的总字节数，得到上传比率 * 更新div元素的宽度 */ function onUploadProgress(e) { if (e.lengthComputable) { var percentComplete = parseInt( (e.loaded + totalUploaded) * 100 / totalFileLength); var bar = document.getElementById('bar'); bar.style.width = percentComplete + '%'; bar.innerHTML = percentComplete + ' % complete'; } else { debug('unable to compute'); } } /*⑦ * 上传完成时，调用onUploadComplete函数，这个事件处理函数会增加totalUploaded， * 即已经上传的文件容量，并添加filesUploaded * 如果所有文件已经上传完毕，弹出文件已经成功完成的提示 * 否则再次调用uploadNext */ function onUploadComplete(e) { totalUploaded += document.getElementById('files'). files[filesUploaded].size; filesUploaded++; debug('complete ' + filesUploaded + " of " + fileCount); debug('totalUploaded: ' + totalUploaded); if (filesUploaded &lt; fileCount) { uploadNext(); } else { var bar = document.getElementById('bar'); bar.style.width = '100%'; bar.innerHTML = '100% complete'; alert('Finished uploading file(s)'); } } function onUploadFailed(e) { alert("Error uploading file"); } &lt;/script> &lt;/head> &lt;body> &lt;h1>Multiple file uploads with progress bar&lt;/h1> &lt;div id='progressBar' style='height:20px;border:2px solid green'> &lt;div id='bar' style='height:100%;background:#33dd33;width:0%'> &lt;/div> &lt;/div> &lt;form> &lt;input type="file" id="files" multiple/> &lt;br/> &lt;output id="selectedFiles">&lt;/output> &lt;input id="uploadButton" type="button" value="Upload"/> &lt;/form> &lt;div id='debug' style='height:100px;border:2px solid green;overflow:auto'> &lt;/div> &lt;/body> &lt;/html> 文件下载 只要把图片或者HTML这样的静态资源放在应用程序的目录下，或者放在应用程序目录的子目录下，而不是放在WEB-INF下，Servlet、JSP容器就会将该资源发送到浏览器，在浏览器中打开正确的URL即可下载 有时候静态资源是保存在应用程序目录外，或者保存在某一个数据库，或者有时候需要控制它的访问权限，方式其他网站交叉引用它，必须通过编程发送资源到浏览器 文件下载概览 对请求处理方法使用void返回类型（如果不需要页面跳转的话），并在方法中添加HttpServletResponse参数 将响应的内容类型设为文件的内容类型，例如 response.setContentType(“application/pdf”)，如果不清楚内容类型，希望浏览器始终显示Save as对话框，则将它设为application/octet-stream 添加一个名为Content-Disposition的HTTP响应标题，并赋值attachment; filename=fileName，这里的fileName是默认文件名，应该出现在File Download对话框中 将文件发送到浏览器 范例1：隐藏资源 @RequestMapping(value="/resource_download") public String downloadResource(HttpSession session, HttpServletRequest request, HttpServletResponse response) { /* * 判断用户是否登录 */ if (session == null || session.getAttribute("loggedIn") == null) { return "LoginForm"; } /* * 判断文件是否存在，并将文件发送到浏览器 */ String dataDirectory = request.getSession(). getServletContext().getRealPath("/WEB-INF/data"); File file = new File(dataDirectory, "secret.pdf"); if (file.exists()) { response.setContentType("application/pdf"); response.addHeader("Content-Disposition", "attachment; filename=secret.pdf"); byte[] buffer = new byte[1024]; int len = 0; FileInputStream fis = null; OutputStream os = null; // if using Java 7, use try-with-resources try { fis = new FileInputStream(file); os = response.getOutputStream(); while((len = fis.read(buffer)) != -1){ os.write(buffer, 0, len); } } catch (IOException ex) { // do something, // probably forward to an Error page } finally { if (os != null) { try { os.close(); } catch (IOException e) { } } if (fis != null) { try { fis.close(); } catch (IOException e) { } } } } return null; } 范例2：防止交叉引用 通过编程控制，是的只有当refer标题中包含你的域名时 才发出资源，这样可以防盗链 但还是有办法下载到这些资源，但是绝对不会像以前那么容易得到 ImageController.java 如果直接在浏览器访问http://localhost:8080/SpringMVC_study/image_get/1返回404 not found 若加入注解 @RequestHeader String referer，直接访问，会导致调用getImage函数失败，根本无法进入函数体，也不进行refer是否为空的判断 通过images.html的超链接跳转，能访问到图片 @Controller public class ImageController { private static final Log logger = LogFactory.getLog(ImageController.class); @RequestMapping(value="/image_get/{id}", method = RequestMethod.GET) public void getImage(@PathVariable String id, HttpServletRequest request, HttpServletResponse response, @RequestHeader String referer) { if (referer != null) { String imageDirectory = request.getSession().getServletContext(). getRealPath("/WEB-INF/image"); File file = new File(imageDirectory, id + ".jpg"); if (file.exists()) { response.setContentType("image/jpg"); byte[] buffer = new byte[1024]; int len = -1; FileInputStream fis = null; OutputStream os = null; // if you're using Java 7, use try-with-resources try { fis = new FileInputStream(file); os = response.getOutputStream(); while ((len = fis.read(buffer)) != -1) { os.write(buffer, 0, len); } } catch (IOException ex) { // do something here } finally { if (os != null) { try { os.close(); } catch (IOException e) { } } if (fis != null) { try { fis.close(); } catch (IOException e) { } } } } } } } images.html &lt;a href=&quot;image_get/1&quot;&gt;图片1&lt;/a&gt; 重定向与转发的区别 重定向发生在浏览器，由浏览器重新发出http请求，转发发生web服务器，请求在web服务器转发 重定向可以到外部网站，重定向只能访问WEB应用个资源 方法的返回值为string 如果方法的返回值是string类型，那么此时表示返回值是视图名称viewname 当进行转发时，没有数据的传递，不需要去书写ModelAndView，直接书写返回值是String 重定向的实现 在转发地址前加上redirect：完成重定向，不需要加应用名，直接写URI 转发到外部网站，例 return &quot;redirect:http://www.baidu.com&quot;; 不带参数传递： @RequestMapping(value = &quot;test19&quot;) public String test19(){ System.out.println(&quot;19&quot;); return &quot;redirect:/success.html&quot;; } 参数传递： /* * 1、重定向发生在浏览器，不能直接访问WEB-INF中的文件，书写的URL以/开头 * 2、需要传递的参数会自动拼接在url，本例中http://localhost:8080/SpringMVC_study/login.html?name=zhangsan */ @RequestMapping(value = "/test23") public ModelAndView test23(){ ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName("redirect:/login.html"); modelAndView.addObject("name","zhangsan"); return modelAndView; } 数据传递 使用重定向的一个不便是无法轻松传值给目标页面，而采用转发可以将属性添加到Model，使得目标视图可以轻松访问。重定向经过客户端，Model中的一切都会在重定向时丢失 Spring 3.1版本以及更高版本可以通过Flash属性提供一种重定向传值的方法 使用Flash属性，必须在Spring MVC配置中有一个&lt;mvc:annotation-driven/&gt;，并且在方法上添加一个参数类型org.springframework.web.servlet.mvc.support.RedirectAttributes 使用方法：redirectAttributes.addFlashAttribute(“message”, “The product was successfully added.”);可以在转发页面访问到这个属性 转发的实现★★★★★★ Spring MVC中默认是转发，但返回的值默认是试图名称 如需要实现请求方法间跳转、页面跳转，在试图名称之前添加forward: 要访问的路径 @RequestMapping(value = &quot;/test24&quot;) public ModelAndView test24(){ System.out.println(24); ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;forward:/test25&quot;); return mv; } @RequestMapping(value = &quot;/test25&quot;) public ModelAndView test25(){ System.out.println(25); ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;forward:/login.html&quot;); return mv; } 数据传递 在每次调用请求方法时，都会创建Model类型的一个实例 若打算使用该实例，在请求方法参数中加入org.springframework.ui.Model参数，Spring MVC会在每一个请求方法被调用时创建一个Model实例，用于增加需要显示在视图中的属性 调用model.addAttribute来添加属性 JSP 页面、静态资源url地址（绝对路径和相对路径）Java Web容器中项目部署时的访问路径一般网站部署后，访问路径是不带项目名称的(为什么？一台主机的80端口就运行一个web程序，就没必要写项目名了)，比如最代码的服务器部署目录：/data/www/zuidaima/,在tomcat的conf/server.xml中host的访问配置是： &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;false&quot; autoDeploy=&quot;false&quot; xmlValidation=&quot;false&quot; xmlNamespaceAware=&quot;false&quot;&gt; &lt;Context docBase=&quot;/data/www/zuidaima/&quot; path=&quot;/&quot;&gt; &lt;/Host&gt; 这样http的访问地址就是http://www.zuidaima.com/，而在eclipse jee集成tomcat版本本地开发时，eclipse的配置中path的配置是带有项目路径的，所以访问的时候除了要有端口外，还得带上项目路径，比如：http://localhost:8080/zuidaima/ 建议Path设置为空，这样本地debug时，所有访问路径和线上是一致的，不会出现线上访问404的情况 mvc开发中view层中访问路径的问题比如jsp中配置静态页面的地址： &lt;link href=&quot;/resource/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot; /&gt; 则该文件在项目的本地目录则是：/data/www/zuidaima/resource/css/bootstrap.min.css，则其通过http访问是 http://www.zuidaima.com/resource/css/bootstrap.min.css 其中/resource/css/bootstrap.min.css，以/开头则表示是相对于项目根目录而言，则本地访问中，根目录配置是： /data/www/zuidaima/ ，而web网页http访问中根路径是 http://www.zuidaima.com/ 但是如果出现 resource/css/bootstrap.min.css 的不以/开头的配置，则其访问路径是相对于当前访问目录而言的，比如在首页，这样配置，所有文件都是可以访问的，因为首页当前目录就是/根目录，但是如果访问比如: http://www.zuidaima.com/user/2318804493993984.html ，这样访问就404错误，http真实访问目录是： http://www.zuidaima.com/user/resource/css/bootstrap.min.css ，这样对照到服务器资源明显就是错误的路径，所以出现这样的配置： &lt;link href=&quot;../resource/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot; /&gt; ★★★此时仍相对于页面 http://www.zuidaima.com/user/2318804493993984.html 相当于http://www.zuidaima.com/user/../resource/css/bootstrap.min.css ，这样和http://www.zuidaima.com/resource/css/bootstrap.min.css 是一个作用，是否有点豁然贯通了 所以建议在web开发中，尽量是用相对路径的根目录配置法(通过相对路径，定位到根目录)，这样一目了然，http访问路径和服务器配置路径是一一对应的，当然在很多情况下，静态资源和动态请求是分开域名提供服务的，比如最代码的css是：http://static.zuidaima.com/resource/css/bootstrap.min.css， 这样如果不在同一个域名那只能通过绝对路径访问了。 ★★★URL访问出现404时的思路1、静态页面引入资源的时候建议使用相对路径的根目录配置法，相对于访问该JSP的控制器URL，其中”/“表示主机：端口。比如访问控制器/login/getPage，此时访问的资源路径为/css/bind.css &lt;link href=&quot;../css/bind.css&quot; rel=&quot;stylesheet&quot;&gt; 2、配置静态资源的路径，用 $lt;mvc:resources location=””,mapping=””/&gt;，相对根路径配置，其中 “/“ 表示主机：端口/应用名 &lt;mvc:resources location=&quot;/WEB-INF/resources/js/&quot; mapping=&quot;/js/**&quot;/&gt; &lt;mvc:resources location=&quot;/WEB-INF/resources/css/&quot; mapping=&quot;/css/**&quot;/&gt; &lt;mvc:resources location=&quot;/WEB-INF/resources/image/&quot; mapping=&quot;/image/**&quot;/&gt; 3、若相对路径出现问题，可以使用绝对路径 ${pageContext.request.contextPath} &lt;!--使用绝对路径的方式引入CSS文件--&gt; &lt;link rel=&quot;stylesheet&quot;href=&quot;${pageContext.request.contextPath}/css/ueditor.css&quot; type=&quot;text/css&quot;/&gt; &lt;!--使用绝对路径的方式引入JavaScript脚本--&gt; &lt;script type=&quot;text/javascript&quot;src=&quot;${pageContext.request.contextPath}/js/ueditor.config.js&quot;&gt;&lt;/script&gt; Spring MVC静态资源处理优雅REST风格的资源URL不希望带 .html 或 .do 等后缀.由于早期的Spring MVC不能很好地处理静态资源，所以在web.xml中配置DispatcherServlet的请求映射，往往使用 .do 、 .xhtml等方式。这就决定了请求URL必须是一个带后缀的URL，而无法采用真正的REST风格的URL。 如果将DispatcherServlet请求映射配置为”/“，则Spring MVC将捕获Web容器所有的请求，包括静态资源的请求，Spring MVC会将它们当成一个普通请求处理，因此找不到对应处理器将导致错误。 如何让Spring框架能够捕获所有URL的请求，同时又将静态资源的请求转由Web容器处理，是可将DispatcherServlet的请求映射配置为”/“的前提。由于REST是Spring3.0最重要的功能之一，所以Spring团队很看重静态资源处理这项任务，给出了堪称经典的两种解决方案。 先调整web.xml中的DispatcherServlet的配置，使其可以捕获所有的请求： &lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 通过上面url-pattern的配置，所有URL请求都将被Spring MVC的DispatcherServlet截获。 采用 &lt;mvc:default-servlet-handler /&gt;在 springMVC-servlet.xml 中配置 &lt;mvc:default-servlet-handler /&gt;后，会在Spring MVC上下文中定义一个org.springframework.web.servlet.resource.DefaultServletHttpRequestHandler ，它会像一个检查员，对进入DispatcherServlet的URL进行筛查，如果发现是静态资源的请求，就将该请求转由Web应用服务器默认的Servlet处理，如果不是静态资源的请求，才由DispatcherServlet继续处理。 一般Web应用服务器默认的Servlet名称是”default”，因此DefaultServletHttpRequestHandler可以找到它。如果你所有的Web应用服务器的默认Servlet名称不是”default”，则需要通过default-servlet-name属性显示指定： &lt;mvc:default-servlet-handler default-servlet-name=&quot;所使用的Web服务器默认使用的Servlet名称&quot; /&gt; 此时静态资源放在Web根目录下可以访问到 采用 &lt;mvc:resources /&gt; 推荐！&lt;mvc:default-servlet-handler /&gt;将静态资源的处理经由Spring MVC框架交回Web应用服务器处理。而&lt;mvc:resources /&gt;更进一步，由Spring MVC框架自己处理静态资源，并添加一些有用的附加值功能。 首先，&lt;mvc:resources /&gt;允许静态资源放在任何地方，如WEB-INF目录下、类路径下等，你甚至可以将JavaScript等静态文件打到JAR包中。通过location属性指定静态资源的位置，由于location属性是Resources类型，因此可以使用诸如”classpath:”等的资源前缀指定资源位置。传统Web容器的静态资源只能放在Web容器的根路径下，&lt;mvc:resources /&gt;完全打破了这个限制。 其次，&lt;mvc:resources /&gt;依据当前著名的Page Speed、YSlow等浏览器优化原则对静态资源提供优化。你可以通过cacheSeconds属性指定静态资源在浏览器端的缓存时间，一般可将该时间设置为一年，以充分利用浏览器端的缓存。在输出静态资源时，会根据配置设置好响应报文头的Expires 和 Cache-Control值。 在接收到静态资源的获取请求时，会检查请求头的Last-Modified值，如果静态资源没有发生变化，则直接返回303相应状态码，提示客户端使用浏览器缓存的数据，而非将静态资源的内容输出到客户端，以充分节省带宽，提高程序性能。 在springMVC-servlet中添加如下配置： &lt;mvc:resources location=&quot;/,classpath:/META-INF/publicResources/&quot; mapping=&quot;/resources/**&quot;/&gt; 以上配置将Web根路径”/“及类路径下 /META-INF/publicResources/ 的目录映射为/resources路径。假设Web根路径下拥有images、js这两个资源目录,在images下面有bg.gif图片，在js下面有test.js文件，则可以通过 /resources/images/bg.gif 和 /resources/js/test.js 访问这二个静态资源。 假设WebRoot还拥有images/bg1.gif 及 js/test1.js，则也可以在网页中通过 /resources/images/bg1.gif 及 /resources/js/test1.js 进行引用。 配置案例: &lt;mvc:resources location=&quot;/WEB-INF/resources/js/&quot; mapping=&quot;/js/**&quot;/&gt; &lt;mvc:resources location=&quot;/WEB-INF/resources/css/&quot; mapping=&quot;/css/**&quot;/&gt; &lt;mvc:resources location=&quot;/WEB-INF/resources/image/&quot; mapping=&quot;/image/**&quot;/&gt; 其他注解ModelAttribute每次调用请求响应方法时都会创建Model类的一个实例，可以在方法中添加一个Model类型的参数，也可以在方法中添加ModelAttribute注解类型 来访问Model实例 不加ModelAttribute先看一个没有使用@ModelAttribute的Controller方法： @RequestMapping(&quot;/save&quot;) public String save(User user) { user.setUsername(&quot;U love me&quot;); userService.save(user); return &quot;result&quot;; } 等价于： @RequestMapping(&quot;/save&quot;) public String save(Model model,int id,String username) { User user=new User(); //这里是通过反射从request里面拿值再set到user user.setId(id); user.setUsername(username); model.addAttribute(&quot;user&quot;,user); user.setUsername(&quot;U love me&quot;); userService.save(user); return &quot;result&quot;; } 其中User包含id和username两个私有属性,含有公共setter和getter方法 执行此方法时会将key为”user”(注意:这里即使参数名称是user1，key一样还是”user”)，value为user的对象加入到model 用途一： 带ModelAttribute注解的参数会将对象添加到Model中 与不加ModelAttribute的区别：带ModelAttribute注解会先从model去获取key为”user”的对象，如果获取不到会通过反射实例化一个User对象，再从request里面拿值set到这个对象，然后把这个User对象添加到model(其中key为”user”).使用了@ModelAttribute可修改这个key，不一定是”user”，此情况下，用与不用@ModelAttribute没有区别 /* 本例中将用newOrder键值将Order实例添加到Model对象中； 如果为定义键值，则键值将使用对象类型的名字，即用键值order将Order实例添加到Model中*/ public String summitOrder(@ModelAttribute("newOrder") Order order){ } 用途二： 标注一个非请求的处理方法，Spring MVC会每次在调用请求处理方法之前 调用带@ModelAttribute注解的方法 @ModelAttribute注解的方法可以返回一个对象或一个void类型，如果返回一个对象，则返回对象会自动加到Model中，如未指定键值，键值为对象类型的名字 若返回类型为void，若需要将对象放入Model中，则必须添加一个Model类型的参数，并自行将实例添加到Model中 @ModelAttribute public String test23(){ return new String(&quot;qm&quot;); } @RequestMapping public String test24(Model model){ Map&lt;String, Object&gt; map = model.asMap(); for(Map.Entry&lt;String,Object&gt; entry:map.entrySet()){ System.out.println(entry.getKey() + &quot; &quot; + entry.getValue()); } return &quot;forward:/WEB-INF/views/hello.jsp&quot;; } 国际化在这个全球化的时代，编写能够支持不同语言的国家和地区的应用程序 越来越重要 国际化应用程序的方式国际化应用程序的具体方式取决于有多少静态数据需要以不同的语言显示出来，这里有两种方式： 如果大量数据是静态的，就要针对每一个语言区域单独创建一个资源版本 如果静态数据有限，可以将文本元素，如元件标签和错误消息隔离成为文本，每个文本文件保存着一个语言区域的译文，随后应用程序会自动获取每一个元素 语言区域 Localejava.util.Locale类表示一个语言区域，一个Locale对象包含3个主要原件：language、country、variant language是最主要的部分 语言本身不能区分一个语言区域，比如讲英语的国家很多，但不同国家讲的英语有区别 variant是一个特定于供应商或特定于浏览器的代号，例如用WIN代表Windows 构造器Locale(String language) Locale(String language, String country) Locale(String language, String country, String variant) 创建一个中国所用的中文Locale对象 Locale locale = new Locale(&quot;zh&quot;,&quot;CN&quot;); 利用Locale类的静态方法来创建Local对象 Locale locale = Locale.CHINA; 利用getDefault方法返回计算机的语言区域 Locale locale = Locale.getDefault(); ResourceBundle读取属性文件区域属性文件值 国际化和本地化应用程序时，需要具备以下条件： 1. 将文本文件隔离成属性文件 2. 选择和读取正确的属性文件 1、将文本文件隔离成属性文件，可以利用如下工具：http://javawind.net/tools/native2ascii.jsp?action=transform ，给出以下两个语言区域属性文件，文件的格式为： basename_languageCode_countryCode MyResources_en_US.properties greetings=hello MyResources_zh_CN.properties greetings=\u4f60\u597d 2、使用ResourceBundle类来读取属性文件中的值 ResourceBundle resourceBundle = ResourceBundle.getBundle(&quot;MyResources&quot;, Locale.SIMPLIFIED_CHINESE); System.out.println(resourceBundle.getString(&quot;greetings&quot;));//你好 resourceBundle = ResourceBundle.getBundle(&quot;MyResources&quot;, Locale.US); System.out.println(resourceBundle.getString(&quot;greetings&quot;));//hello 3、在Spring MVC中，不直接使用ResourceBundle，而是利用messageSourceBean告诉Spring MVC要将属性文件保存在哪里 国际化Spring MVC应用程序在Spring MVC中，不直接使用ResourceBundle，而是利用messageSource bean告诉Spring MVC要将属性文件保存在哪里 配置 messageSource bean利用messageSource bean告诉Spring MVC要将属性文件保存在哪里 &lt;bean id="messageSource" class="org.springframework.context.support.ReloadableResourceBundleMessageSource"> //用两个基准名设置basenames的属性 &lt;property name="basenames" > &lt;list> &lt;value>/WEB-INF/resource/messages&lt;/value> &lt;value>/WEB-INF/resource/labels&lt;/value> &lt;/list> &lt;/property> &lt;/bean> 说明，上面定义的bean的类class有两种实现方式： 一种是ReloadableResourceBundleMessageSource，提供了定时刷新功能，允许在不重启系统的情况下，更新资源的信息；它在应用程序目录下搜索这些属性文件，即WEB目录下搜索 另一种是ResourceBundleMessageSource，它是不能重新加载的，如果在任意属性文件中修改了某一个属性的key或者value，那么要使修改生效，就必须重启JVM；属性文件必须放在类路径 下，即src目录下 还有一个说明，如果只有一组属性文件，则可以用basename属性代替basenames，像下面这样： &lt;bean id=&quot;messageSource&quot; class=&quot;org.springframework.context.support.ReloadableResourceBundleMessageSource&quot;&gt; &lt;property name=&quot;basename&quot; value=&quot;resource/messages&quot;/&gt; &lt;/bean&gt; 配置 语言区域解析器bean在Spring MVC中选择语言区域，可以使用语言区域解析器bean，它有几个实现，其中AcceptHeaderLocaleResolver是其中最容易使用的一个 &lt;bean id=&quot;localeResolver&quot; class=&quot;org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolver&quot;&gt; &lt;/bean&gt; 使用message标签使用message标签，要在使用该标签的JSP页面声明这个taglib指令： &lt;%@ taglib prefix=&quot;spring&quot; uri=&quot;http://www.springframework.org/tags&quot; %&gt; 使用message标签： &lt;label for=&quot;description&quot;&gt;&lt;spring:message code=&quot;label.description&quot;/&gt;: &lt;/label&gt; 拦截器 HandlerExecutionChain是一个执行链，从HandlerMapping返回给DispatcherServlet 其中包含Handler对象和Interceptor（拦截器）对象 SpringMVC的拦截器定义了三个方法 preHandler：调用handler之前执行 postHandler：调用handler之后执行 afterCompletion：视图渲染完之后执行 拦截器执行过程 在执行Handler前会经过多个拦截器 每个拦截器的前置方法会按照拦截器的顺序依次执行 每个拦截器的后置方法会从后向前执行 每个拦截器的afterCompletion方法会从后往前执行 编写自定义拦截器 public class MyInterceptor implements HandlerInterceptor { //前置方法，如果返回值是false，后面的拦截器不会执行；如果返回true，执行后面的拦截器 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println("前置方法"); return true; } public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println("后置方法"); } public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println("完成方法"); } } 配置拦截器&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!--配置连接器的路径，/**表示表示拦截所有的请求--&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;!--拦截器的路径--&gt; &lt;bean class=&quot;cn.apeius.springmvc.interceptor.MyInterceptor&quot;&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 配置多个拦截器&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!--配置连接器的路径，/**表示表示拦截所有的请求--&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;!--拦截器的路径--&gt; &lt;bean class=&quot;cn.apeius.springmvc.interceptor.MyInterceptor1&quot;&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;!--配置连接器的路径，/**表示表示拦截所有的请求--&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;!--拦截器的路径--&gt; &lt;bean class=&quot;cn.apeius.springmvc.interceptor.MyInterceptor2&quot;&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 若配置1，2，3，4多个拦截器，如果3的前置方法返回false，则： 拦截器4的所有方法都不会执行 拦截器1，2的完成方法仍会去执行 1，2，3的后置方法不会执行 总结]]></content>
      <categories>
        <category>Spring MVC</category>
      </categories>
      <tags>
        <tag>JavaEE</tag>
        <tag>Spring MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java分层思想——Struts+Hibernate+接口编程的方式]]></title>
    <url>%2F2016%2F08%2F22%2F%5BJava%5DJava%E5%88%86%E5%B1%82%E6%80%9D%E6%83%B3%E2%80%94%E2%80%94Struts%2BHibernate%2B%E6%8E%A5%E5%8F%A3%E7%BC%96%E7%A8%8B%E7%9A%84%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[接口编程 通过接口(使用动态代理)，就达到web层和业务层的解耦（业务层代码改动，web层不需要重写，达到解耦） 数据库有两张表，分别是users表和message表，对应的在业务层有Users对象、UsersService对象；Message对象、MessageService对象 在web层定义UsersServiceInter接口，业务层实现类UsersServiceImp；同理定义MessageServiceInter解耦，业务层实现类MessageServiceImp 定义一个基础接口BaseServiceInter，把一些通用的方法直接定义到该接口内，子接口继承 BaseService类实现BaseServiceInter接口，包含基础方法 留言板工程githubhttps://github.com/rhapsody1290/NoteBook 程序框架图 工程目录]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
        <tag>Java</tag>
        <tag>接口编程</tag>
        <tag>Struts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基础POM配置讲解]]></title>
    <url>%2F2016%2F08%2F18%2F%5BMaven%5DMaven%E5%9F%BA%E7%A1%80POM%E9%85%8D%E7%BD%AE%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Maven坐标maven坐标的主要组成groupId：定义当前maven项目属于哪个项目 artifactId：定义实际项目中的某一个模块 version：定义当前项目的当前版本 packaging：定义当前项目的打包方式 jar、war 根据这些坐标，在maven库中可以找到唯一的jar包 其中groupId、artifactId、version是必须定义的，packaging是可选的（默认是jar） Maven模块概念1、Maven中，一个项目会被划分成很多模块，比如org.SpringFramework项目，对应的Maven模块有很多：spring-core、spring-context 2、groudId不应该只对应到公司（组织）的名称，而应定义到项目名 POM.xml&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; #这个是POM的版本号，现在都是4.0.0 的，必须得有，但不需要修改。 &lt;groupId&gt;com.smart&lt;/groupId&gt; #定义当前maven项目属于哪个项目 &lt;artifactId&gt;smart-demo&lt;/artifactId&gt; #定义实际项目中的某一个模块 &lt;version&gt;1.0&lt;/version&gt; #定义当前项目的当前版本 &lt;packaging&gt;war&lt;/packaging&gt; #定义当前项目的打包方式 &lt;name&gt;smart-demo Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; #name、ur表示该项目的名称与 URL 地址，意义不大，可以省略。 &lt;dependencies&gt; #定义该项目的依赖关系 &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; #表示与构建相关的配置，这里的 finalName 表示最终构建后的名称 smart-demo.war，这里的 finalName 还可以使用另一种方式来定义 &lt;finalName&gt;smart-demo&lt;/finalName&gt; &lt;/build&gt; &lt;/project&gt; 树形图表示POM.xml 可见，除了项目的基本信息（Maven 坐标、打包方式等）以外，每个 pom.xml 都应该包括： Lifecycle（生命周期） Plugins（插件） Dependencies（依赖） Lifecycle 是项目构建的生命周期，它包括 9 个 Phase（阶段）。 大家知道，Maven 是一个核心加上多个插件的架构，而这些插件提供了一系列非常重要的功能，这些插件会在许多阶段里发挥重要作用。 依赖Scope（作用域）★★★★★我们可以在 pom.xml 中定义一些列的项目依赖（构件包），每个构件包都会有一个 Scope（作用域），它表示该构件包在什么时候起作用，包括以下五种： compile：默认作用域，在编译、测试、运行时有效 test：对于测试时有效 runtime：对于测试、运行时有效 provided：对于编译、测试时有效，但在运行时无效（jar包在编译运行时有效，但在发布时由容器提供，不需要发布） system：与 provided 类似，但依赖于系统资源 可以一张表格表示： POM模版&lt;dependencies&gt; &lt;!-- JUnit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- MySQL --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.25&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Servlet --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;4.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- AspectJ --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.7.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.7.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Hibernate4 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;4.3.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- for JPA, use hibernate-entitymanager instead of hibernate-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;4.3.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 以下可选 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-envers&lt;/artifactId&gt; &lt;version&gt;4.3.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-c3p0&lt;/artifactId&gt; &lt;version&gt;4.3.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-proxool&lt;/artifactId&gt; &lt;version&gt;4.3.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-infinispan&lt;/artifactId&gt; &lt;version&gt;4.3.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-ehcache&lt;/artifactId&gt; &lt;version&gt;4.3.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-commons-annotations&lt;/artifactId&gt; &lt;version&gt;3.2.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate.javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpa-2.1-api&lt;/artifactId&gt; &lt;version&gt;1.0.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jboss&lt;/groupId&gt; &lt;artifactId&gt;jandex&lt;/artifactId&gt; &lt;version&gt;1.1.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 为了让Hibernate使用代理模式，需要javassist --&gt; &lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.18.1-GA&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jboss.logging&lt;/groupId&gt; &lt;artifactId&gt;jboss-logging&lt;/artifactId&gt; &lt;version&gt;3.1.3.GA&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jboss.spec.javax.annotation&lt;/groupId&gt; &lt;artifactId&gt;jboss-annotations-api_1.2_spec&lt;/artifactId&gt; &lt;version&gt;1.0.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;antlr&lt;/groupId&gt; &lt;artifactId&gt;antlr&lt;/artifactId&gt; &lt;version&gt;2.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-pool&lt;/groupId&gt; &lt;artifactId&gt;commons-pool&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.transaction&lt;/groupId&gt; &lt;artifactId&gt;jta&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate.javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpa-2.0-api&lt;/artifactId&gt; &lt;version&gt;1.0.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- tomcat7.0.35 数据库连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-dbcp&lt;/artifactId&gt; &lt;version&gt;7.0.35&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 参考文献Maven 那点事儿http://my.oschina.net/huangyong/blog/194583]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven安装及基础功能]]></title>
    <url>%2F2016%2F08%2F18%2F%5BMaven%5DMaven%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E7%A1%80%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[Maven作用★★★★★ 统一开发规范与工具：项目目录结构，配置文件、单元测试代码位置；项目构建工具，自动完成那个编译、测试、打包等工作 统一管理 jar 包：Maven 中央仓库下载jar包 项目构建过程Maven是一个跨平台的项目管理工具，主要用于基于java平台的项目构建，依赖管理。 如图为项目构建的过程 Maven的安装与配置Maven的安装Jdk的情况 Jdk必须1.6以上的版本 从官网下载maven 从http://maven.apache.org/官网上下载最新版本的maven 设定path路径 1、配置M2_HOME的环境变量，新建一个系统变量：M2_HOME，路径是maven的安装目录 2、配置path环境变量，在path值的末尾添加&quot;%M2_HOME%\bin&quot; 建库 打开conf文件夹下的settings.xml文件，找到第53行，把注释去掉，修改成：&lt;localRepository&gt;D:\Maven\repo&lt;/localRepository&gt;，当然了，前提是在某个路径下，手动建立了一个名为 repo的文件夹，然后把本地仓库指向该路径。 利用命令行检查是否成功 mvn -v maven的约定src/main/java 存放项目的java文件 src/main/resources 存放项目的资源文件，如spring，hibernate的配置文件 src/test/java 存放所有的测试的java文件 src/test/resources 存放测试用的资源文件 target 项目输出位置 pom.xml 项目配置文件 maven的命令12345678910mvn archetype:create ：创建 Maven 项目mvn compile ：编译源代码mvn test-compile ：编译测试代码mvn test ： 运行应用程序中的单元测试mvn site ： 生成项目相关信息的网站mvn clean ：清除目标目录中的生成结果mvn package ： 依据项目生成 jar 文件mvn install ：在本地 Repository 中安装 jarmvn eclipse:eclipse ：生成 Eclipse 项目文件mvn -Dmaven.test.skip=true : 忽略测试文档编译 maven项目快速入门hello项目 在myeclipse建立一个项目Hello，删除自动生成的src文件，建立4个Source Folder文件夹，名字如图所示： 创建一个包cn.itcast.maven，并在该包下创建一个类 Hello 12345public class Hello&#123; public void hello()&#123; System.out.println(&quot;say hello&quot;); &#125;&#125; 在src/test/java中创建一个包cn.itcast.maven，创建一个测试类 HelloTest，测试类中调用Hello类 123456public class HelloTest&#123; public void testHello()&#123; Hello hello = new Hello(); hello.hello(); &#125;&#125; 编辑pom.xml文件 123456789101112131415161718&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.itcast.maven&lt;/groupId&gt; &lt;artifactId&gt;Hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;Hello&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 用maven命令编译项目 123mvn compile命令行出现BUILD SUCCESS，表明编译成功 target文件夹的变化，可以看到编译后的文件全部放入到了target里。 clean，执行命令mvn clean,可以看到target的目录没有了。 test，执行mvn test命令，自动生成测试报告 说明： target/classes 存放编译后的类 target/test-classes 存放编译后的测试类 target/surefire-reports 存放测试报告 package，执行mvn package，完成打包工作 说明： target/classes 编译后的类的路径 target/test-classes 编译后的测试类的路径 target/surefire-reports 测试报告 target/maven-archiver 执行package的归档 Hello-0.0.1-SNAPSHOT.jar 执行完package命令后打成的jar包 Hellofriend项目 建立HelloFriend项目工程 建立cn.itcast.maven包及HelloFriend类 编辑HelloFriend类，引用之前编写的Hello类 123456public class HelloFriend &#123; public void helloFriend()&#123; Hello hello = new Hello(); hello.hello(); &#125;&#125; 编写pom.xml文件 12345678910111213141516171819202122232425&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.itcast.maven&lt;/groupId&gt; &lt;artifactId&gt;HelloFriend&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;HelloFriend&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast.maven&lt;/groupId&gt; &lt;artifactId&gt;Hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 执行mvn compile命令 执行这个命令的时候会出错，因为HelloFriend项目是建立在Hello项目基础之上的，但是现在工程中没有引入Hello.java这个类。所以会出错。 执行mvn clean install命令 1、 打开命令行 2、 把当前路径调节到Hello工程的根目录 3、 执行mvn clean install命令，把Hello整个工程放入到仓库中 如果执行成功，则会在仓库中看到 执行mvn package命令打包HelloFriend工程 可以看到成功以后，在target目录下多了一个jar包 该jar包为当前工程的jar包。 建立cn.itcast.maven包和测试类HelloFriendTest类 编辑HelloFriendTest类 1234567public class testHeloFriend &#123; public void testHelloFriend()&#123; HelloFriend helloFriend = new HelloFriend(); helloFriend.helloFriend(); &#125;&#125; 执行mvn package命令 上图中的”say hello”就是输出的结果。 maven的核心概念项目对象模型 说明： maven根据pom.xml文件，把它转化成项目对象模型(POM)，这个时候要解析依赖关系，然后去相对应的maven库中查找到依赖的jar包。 在clean，compile，test，package等阶段都有相应的Plug-in来做这些事情。 而这些plug-in会产生一些中间产物。 插件的位置在maven解压后的位置D:\Maven\apache-maven-3.0.5-bin\apache-maven-3.0.5有一个bin文件夹，里面有一个文件m2.config文件 set maven.home default ${user.home}/m2，其中该路径指明了仓库的存储位置。 其中settings.xml文件中, &lt;localRepository&gt;D:/Maven/repo&lt;/localRepository&gt; 这个说明了仓库中的位置。 D:\Maven\repo\org\apache\maven\plugins 这里的插件就是执行maven的各种命令所需要的插件。 maven坐标maven坐标的主要组成 groupId：定义当前maven项目属于哪个项目 artifactId：定义实际项目中的某一个模块 version：定义当前项目的当前版本 packaging：定义当前项目的打包方式 根据这些坐标，在maven库中可以找到唯一的jar包 依赖管理具体案例在3 Maven项目。 1、项目HelloSuperFriend依赖项目HelloFriend，项目HelloFriend依赖项目Hello。 2、在HelloSuperFriend依赖项中加入 &lt;dependency&gt; &lt;groupId&gt;cn.itcast.maven&lt;/groupId&gt; &lt;artifactId&gt;HelloFriend&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; 3、能够编译通过，体现了依赖的传递性 继承管理★★★★★现有一A项目，B、C项目同时依赖A项目，这是需要用到继承 1、创建一个项目ParentJunit 2、ParentJunit添加一个Junit依赖 3、新建一个项目：HelloJunit，编写POM文件 12345&lt;parent&gt; &lt;groupId&gt;cn.itcast.maven&lt;/groupId&gt; &lt;artifactId&gt;ParentJunit&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 4、只需要继承ParentJunit，所以junit就被引入到HelloJunit中了 仓库管理可以根据maven坐标定义每一个jar包在仓库中的存储位置。 大致为：groupId/artifactId/version/ 仓库的分类： 1、本地仓库 ~/.m2/repository/，每一个用户也可以拥有一个本地仓库 2、远程仓库 2.1 中央仓库：Maven默认的远程仓库，http://repo1.maven.org/maven2 2.2 私服：是一种特殊的远程仓库，它是架设在局域网内的仓库 2.3 镜像：用来替代中央仓库，速度一般比中央仓库快 jar查找顺序]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate笔记]]></title>
    <url>%2F2016%2F08%2F12%2F%5BHibernate%5DHibernate%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Hibernate简介 Hibernate是对jdbc进行轻量级封装的ORM框架，位于数据持久层 ORM全称对象关系映射，框架在Java对象与关系数据库之间建立 映射，以实现 直接存取 Java对象 Hibernate参考资料Hibernate3.2API.chmhttps://github.com/rhapsody1290/Hibernate_Study/blob/master/doc/Hibernate3.2API.chm hibernate3.2_reference.pdfhttps://github.com/rhapsody1290/Hibernate_Study/blob/master/doc/hibernate3.2_reference.pdf ORM概述 传统数据持久化编程中，需要使用JDBC并配合大量的SQL语句。JDBC API与SQL语句夹杂在一起，开发效率都很低下 后来出现DAO模式，所有的JDBC API和SQL语句均移到了DAO层，但仍然需要编写大量的SQL语句 ORM框架的思路是通过配置文件，将Java对象 映射 到关系型数据库，自动生成SQL语句 并执行 举个例子，插入数据 时就是把POJO的各个属性拼装成SQL语句，保存进数据库；读取数据 时，就是用SQL语句读取数据库，然后拼装成POJO对象返回 为什么需要Hibernate？ 使用jdbc操作数据库，SQL语句编写比较麻烦 切换数据库时需要重写SQL语句 我们程序员希望不关注数据库本身，而是关注业务本身 引入Hibernate后，程序员在业务逻辑中使用hql语句（一种万能语句），Hibernate会自动完成数据库的操作，这种方式程序员只需关注业务本身，提高开发效率，程序也具有很好的移植性 学习Hibernate关键是1、Hibernate API 2、Hibernate核心配置文件 3、对象关系映射文件 Hibernate开发的三种方式 数据库中的表与java domain对象，通过Hibernate的对象关系映射文件关联起来，该文件会说明表和对象的关系，以及对象的属性与表的字段的对应关系 开发方式一：由Domain对象 ——&gt; Mapping ——&gt; DB 开发方式二：由DB开始，用工具生成mapping和Domain object（使用较多） 开发方式三：由映射文件开始 Hibernate快速入门（第二种开发方式）★★★★★★github代码https://github.com/rhapsody1290/Hibernate_Study 创建employee表 开发domain对象 建议domain对象 的名称就是对应表的首字母大写，同时 需要一个无参的构造函数(用于hibernate反射该对象) 应当有一个无业务逻辑的主键属性. 给每个属性提供 get/set 方法. 在domian对象中的属性，只有配置到了对象映射文件后，才会被hibernate管理. 属性一般是private范围 该pojo按照规范应当序列化，目的是可以唯一标该对象。同时可以在网络和文件上传输 public class Employee implements Serializable{ private Integer id; private String name; private String email; private java.util.Date hiredate; public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } public Date getHiredate() { return hiredate; } public void setHiredate(Date hiredate) { this.hiredate = hiredate; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } 对象关系映射文件对象关系映射文件作用是用于指定domain对象和表的映射关系，该文件的取名有规范：domain对象.hbm.xml，一般我们放在和domain对象同一个文件夹下(包下) &lt;?xml version=&apos;1.0&apos; encoding=&apos;utf-8&apos;?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&gt; &lt;hibernate-mapping package=&quot;cn.apeius.domain&quot;&gt; &lt;class name=&quot;Employee&quot; table=&quot;employee&quot;&gt; &lt;!--id文件用于指定主键属性--&gt; &lt;id name = &quot;id&quot; column=&quot;id&quot; type=&quot;java.lang.Integer&quot;&gt; &lt;generator class=&quot;increment&quot;/&gt; &lt;/id&gt; &lt;!--对其他属性配置--&gt; &lt;property name=&quot;name&quot; type=&quot;java.lang.String&quot;&gt; &lt;column name=&quot;name&quot; length=&quot;255&quot; not-null=&quot;true&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;email&quot; type=&quot;java.lang.String&quot;&gt; &lt;column name=&quot;email&quot; length=&quot;255&quot; not-null=&quot;false&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;hiredate&quot; type=&quot;java.util.Date&quot;&gt; &lt;column name=&quot;hiredate&quot; length=&quot;255&quot; not-null=&quot;false&quot;/&gt; &lt;/property&gt; &lt;/class&gt; &lt;/hibernate-mapping&gt; 细节 对象关系文件中，有些属性是可以不配，hibernate会采用默认机制，比如 &lt;class table=&quot;?&quot; &gt; table值不配，则以类的小写做表名 &lt;property type=&quot;?&quot;&gt; type不配置，则hibernate会根据类的属性类型，选择一个适当的类型 手动配置我们的hibernate.cfg.xml文件该文件用于配置连接的数据库的类型、driver、用户名、密码、url等，同时管理对象关系映射文件。该文件的名称，我们一般不修改. &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;!DOCTYPE hibernate-configuration PUBLIC &quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot; &quot;http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd&quot;&gt; &lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!--hibernate常用改的配置见：hibernate.properties--&gt; &lt;!-- 配置dialect方言,明确告诉hibernate连接是哪种数据库 --&gt; &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:mysql://localhost:3306/hibernate&lt;/property&gt; &lt;property name=&quot;hibernate.connection.username&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;hibernate.connection.password&quot;&gt;root&lt;/property&gt; &lt;!--显示出对应的SQL语句--&gt; &lt;property name=&quot;show_sql&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;hibernate.format_sql&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/property&gt; &lt;mapping resource=&quot;Employee.hbm.xml&quot;/&gt; &lt;/session-factory&gt; &lt;/hibernate-configuration&gt; 增加用户import cn.apeius.domain.Employee; import org.hibernate.Session; import org.hibernate.SessionFactory; import org.hibernate.Transaction; import org.hibernate.cfg.Configuration; /** * Created by Asus on 2016/8/16. */ public class Main { public static void main(String[] args){ //1、创建configuration，该对象用于读取hibernate.ctf.xml，并完成初始化 Configuration configuration = new Configuration().configure(); //2、创建sessionFactory，这是一个会话工厂，是个重量级的对象，应当保证连接一个数据库SessionFactory是单例 SessionFactory sessionFactory = configuration.buildSessionFactory(); //3、创建session，相当于jdbc connection Session session = sessionFactory.openSession(); //4、在进行增加、删除、修改的时候使用事务提交 Transaction transaction = session.beginTransaction(); //添加一个雇员 Employee employee = new Employee(); employee.setName(&quot;qm1&quot;); employee.setEmail(&quot;qm1@126.com&quot;); employee.setHiredate(new java.util.Date()); //保存 session.save(employee); //提交 transaction.commit(); session.close(); } } 修改用户（先查后改）注意：SessionFactory是个重量级对象，应保证其实单例。在util包中封装了SessionFactory //获取一个会话 Session session = MySessionFactory.getInstatnce().openSession(); Transaction transaction = session.beginTransaction(); //修改用户1、获得要修改的对象2、修改 //load是通过主键属性，获取该对象实例 Employee employee = (Employee) session.load(Employee.class,2);//产生select .. where id = 2 employee.setName(&quot;钱明&quot;);//这句话会产生update语句 transaction.commit(); session.close(); 删除用户//获取一个会话 Session session = MySessionFactory.getInstatnce().openSession(); Transaction transaction = session.beginTransaction(); Employee employee = (Employee) session.load(Employee.class,2); session.delete(employee); transaction.commit(); session.close(); 模版（加入了异常回滚）★★★★★★public static void updateEmployee() { //获取一个会话 //Session session = MySessionFactory.getInstatnce().openSession(); Session session = HibernateUtil.getCurrentSession(); Transaction transaction = null; try{ transaction = session.beginTransaction(); //do... //修改用户1、获得要修改的对象2、修改 //load是通过主键属性，获取该对象实例 Employee employee = (Employee) session.load(Employee.class,3);//产生select .. where id = 2 employee.setName(&quot;钱明&quot;);//这句话会产生update语句 //出现异常 //int i = 9/0; transaction.commit(); }catch (Exception e){ if(transaction != null){ transaction.rollback(); } throw new RuntimeException(e.getMessage()); }finally { //关闭session if(session != null &amp;&amp; session.isOpen()){ session.close(); } } } SessionFactory单例 SessionFactory是个重量级对象，在开发中保证只有一个SessionFactory 一个数据库对应一个SessionFactory对象 //单例模式 public class MySessionFactory { private MySessionFactory(){} private static class HoldClass{ private static final SessionFactory instance = new Configuration().configure().buildSessionFactory(); } public static SessionFactory getInstatnce(){ return HoldClass.instance; } } Maven下载各数据库JDBC及Hibernate配置文件各数据库连接配置与maven依赖安装http://blog.163.com/luowei505050@126/blog/static/119907206201210223827126/ Hibernate切换数据库★★★★★ 使用Hibernate自动完成domain ——&gt; 映射文件 ——&gt; 表的工作 重新配置Hibernate数据库，以sqlserver2000为例 增加属性hibernate.hbm2ddl.auto create : 当我们的应用程序加载hibernate.cfg.xml [ new Configuration().config(); ]就会根据映射文件，创建出数据库, 每次都会重新创建， 原来表中的数据就没有!!! update: 如果数据库中没有该表，则创建，如果有表，则看有没有变化，如果有变化，则更新. create-drop: 在显示关闭 sessionFactory时，将drop掉数据库的schema validate: 相当于每次插入数据之前都会验证数据库中的表结构和hbm文件的结构是否一致 在开发测试中，我们配置哪个都可以测试，但是如果项目发布后，最好自己配置一次，让对应的数据库生成，完后取消配置， 修改主键生成策略 &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;!DOCTYPE hibernate-configuration PUBLIC &quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot; &quot;http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd&quot;&gt; &lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!--hibernate常用改的配置见：hibernate.properties--&gt; &lt;!-- 配置dialect方言,明确告诉hibernate连接是哪种数据库 --&gt; &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.SQLServerDialect&lt;/property&gt; &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;net.sourceforge.jtds.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:jtds:sqlserver://localhost:1433/hibernate&lt;/property&gt; &lt;property name=&quot;hibernate.connection.username&quot;&gt;sa&lt;/property&gt; &lt;property name=&quot;hibernate.connection.password&quot;&gt;sa&lt;/property&gt; &lt;!--显示出对应的SQL语句--&gt; &lt;property name=&quot;show_sql&quot;&gt;true&lt;/property&gt; &lt;!--让hibernate自动创建表 create:如果没有这张表则创建--&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/property&gt; &lt;mapping resource=&quot;Employee.hbm.xml&quot;/&gt; &lt;/session-factory&gt; &lt;/hibernate-configuration&gt; Hibernate的核心类和接口★★★★★★★★★★ Configuration 类 读取hibernate.cfg.xml 加载hibernate的驱动、url、用户.. 管理对象关系映射文件 &lt;mapping resource=&quot;&quot;&gt; 管理hibernate配置信息 SessionFactory （会话工厂） 可以缓存sql语句和数据(称为session级缓存)!! 是一个重量级的类，因此我们需要保证一个数据库，有一个SessionFactory 如果某个应用访问多个数据库，则要创建多个会话工厂，一个数据库一个会话工厂实例 通过SessionFactory接口可以获得Session实例，有两种方式： openSession() 是获取一个新的session getCurrentSession () 获取和当前线程绑定的session,换言之，在同一个线程中，我们获取的session是同一session，这样更利于事务控制 使用 getCurrentSession 需要配置 hibernate.cfg.xml中配置①如果使用本地事务（jdbc事务）&lt;property name=&quot;hibernate.current_session_context_class&quot;&gt;thread&lt;/property&gt;②如果使用全局事务（jta事务）&lt;property name=&quot;hibernate.current_session_context_class&quot;&gt;jta&lt;/property&gt; 如何选择①如果需要在同一线程中，保证使用同一个Session，则使用getCurrentSession()②如果在一个线程中，需要使用不同的Session,则使用opentSession() 通过 getCurrentSession() 获取的session在事务提交后，会自动关闭，通过openSession()获取的session则必须手动关闭 如果是通过getCurrentSession()获取sesssion,进行查询需要事务提交. 使用同一个Session案例 在一个http请求中，需要同时进行操作、更新、删除等操作，三个操作在不同service中进行，但要将三个操作在一个事务中进行控制。三个service分别会调用hibernate，使用getCurrentSession，可以将三个操作在一个事务中进行（http请求只要不结束，就看成一个线程） 本地事务与全局事务 本地事务：增对一个数据库的事务 全局事务：跨数据库的事务（JTA）。以银行转账为例，需要在农行账户中增加10元，在工行账户中减去10元，涉及到多个数据库中的事务 session接口的理解 Session(会话)接口的理解：SessionFactory常驻内存，每次连接数据库会化工厂建立与数据库的session，图中横线就是一个session。 如何查看session是否关闭：查看数据库连接端口是否关闭，如mysql 3306端口是否关闭 session接口它的主要功能和作用是: Session一个实例代表与数据库的一次操作(当然一次操作可以是crud组合) Session实例通过SessionFactory获取，用完需要关闭 Session是线程不同步的(不安全),因此要保证在同一线程中使用,可以用 getCurrentSessiong() Session可以看做是持久化管理器,它是与持久化操作相关的接口 Session查询详解★★★★★★ 如果查询不到数据，get 会返回 null,但是不会报错, load 如果查询不到数据，则报错ObjectNotFoundException Employee employee1 = (Employee) session.load(Employee.class,10); System.out.println(employee1);//ObjectNotFoundException Employee employee2 = (Employee) session.get(Employee.class,10); System.out.println(employee2);//null 使用get去查询数据，先到缓存（session缓存、二级缓存）中去查，如果没有就到DB中取查，即立即向db发出查询请求(select …), 如果你使用的是load查询数据，先到缓存(session缓存、二级缓存)中查询，如果没有则返回一个代理对象（不马上到DB中去查）。等后面使用这个代理对象时才到DB中查询，如果后面没有使用查询结果，它不会真的向数据库发select，这个现象我们称为懒加载(lazy)【load是懒加载，返回代理对象，使用时候才去数据库查询】 Employee employee1 = (Employee) session.load(Employee.class,1); System.out.println(employee1);//如果这句话注释，不会向数据库发送sql语句，等到使用给代理对象时才到DB中查询 通过修改配置文件，我们可以取消懒加载&lt;class name=&quot;Employee&quot; lazy=&quot;false&quot; table=&quot;employee&quot;&gt; 如何选择使用哪个：如果你确定DB中有这个对象就用load(),不确定就用get()（这样效率高） Hibernate缓存原理★★★★★★ 接受到一个load查询，先去session缓存中查询，如果没有再去二级缓存查找，如果还没有，就不查询了，返回一个代理对象proxy obj = load 如果使用这个代理对象后，就会去数据库查询，并把这条记录放入二级缓存 等到下次查询时，先查询session缓存，找不到，然后去二级缓存中取得对象，并返回结果。同时把这条记录放入一级缓存 get查询也类似，先查询一级缓存，再查询二级缓存 Hibernate缓存机制可以减少对数据库的查询 Employee employee1 = (Employee) session.load(Employee.class,1);//发送select语句，放缓存 System.out.println(employee1); Employee employee2 = (Employee) session.get(Employee.class,1);//从缓存中取，没有select语句 System.out.println(employee2); Employee employee3 = (Employee) session.get(Employee.class,100);//缓存中找不到，向数据库发送select语句 System.out.println(employee3); HibernateUtil（线程局部模式：获取全新的Session或与线程绑定的Session）★★★★★★注意：不再需要配置 hibernate.cfg.xml final public class HibernateUtil { //SqlHelper private static SessionFactory sessionFactory = null; //使用线程局部模式 private static ThreadLocal&lt;Session&gt; threadLocal = new ThreadLocal&lt;Session&gt;(); static { sessionFactory=new Configuration().configure().buildSessionFactory(); } private HibernateUtil(){} //获取全新的全新的sesession public static Session openSession(){ return sessionFactory.openSession(); } //获取和线程关联的session public static Session getCurrentSession(){ Session session = threadLocal.get(); //判断是否得到 if(session == null){ session = sessionFactory.openSession(); //把session对象设置到 threadLocal,相当于该session已经和线程绑定 threadLocal.set(session); } return session; } } 测试 System.out.println(HibernateUtil.getCurrentSession().hashCode()); System.out.println(HibernateUtil.getCurrentSession().hashCode()); System.out.println(HibernateUtil.openSession().hashCode()); System.out.println(HibernateUtil.openSession().hashCode()); 结果： 725455968 725455968 1473790157 914784201 线程局部模式 在一个线程中，某个时间点通过set将对象放入ThredLocal，又在某个点通过get方法取出对象。这个变量与线程绑定 query接口★★★★★★通过query接口我们可以完成更加复杂的查询任务举例: 通过用户来查询数据. //获取query引用 Query query = session.createQuery(&quot;from Employee where id = 1&quot;); //通过List方法获取结果，这个list会自动封装成domain对象 List&lt;Employee&gt; list = query.list(); for(Employee e : list){ System.out.println(e.getName() + &quot; &quot; + e.getHiredate()); } 注意：Employee是Java对象而不是表名，id也是类的属性名 Criteria接口（不常用）Criteria接口也可用于面向对象方式的查询，关于它的具体用法我们这里先不做介绍,简单看几个案例. Criteria cri = session.createCriteria(Employee.class) .setMaxResults(2) .addOrder(Order.asc(&quot;id&quot;)); List&lt;Employee&gt; list = cri.list(); for(Employee e : list){ System.out.println(e.getId() + &quot; &quot; + e.getName()); } 工具生成domain对象和对象关系映射文件 使用IntelliJ IDEA开发SpringMVC网站（三）数据库配置★★★http://blog.csdn.net/chenxiao_ji/article/details/50849365 在创建工程的时候勾选上hibernate支持。 在主界面右侧找到database，点击添加数据库 在新界面中添加数据库驱动和数据库链接信息 保存后在主面板左侧有persistence，在hibernate图标上点击右键-Generate Persistence Mapping-By Database Scheme 选好数据库，选好包的位置，在下面勾上要生成的表对应的pojo，并且勾上为每一个pojo生成XML即可 IDEA一对多关系设置 模拟一个学生选课系统 ，创建三张表：student、studCourse、course 数据库备份https://github.com/rhapsody1290/Hibernate_Study/blob/master/doc/hibernate.sql student与studCourse的关系为一对多，即一个学生可以选择多门课程。Student类中有一个studCourse的集合属性，studCourse中有一个Student的成员变量 设置student与studCourse之间的关系 原则：在有外键的表上设置表之间的关系，本例中在studCourse上设置关系 在上图中选中studCourse表，studCourse通过外键sid和cid关联student表和couse表。注意外键不打勾 点击左上角绿色的加号或右键选择add relationship studCourse类中有一个类型为Course的course变量，Course类中有一个名为studCourses的集合，两个表通过cid关联起来 同理设置studCourse与student关系 设置完成后观察属性是否正确 生成的domain对象及hdm文件见githubhttps://github.com/rhapsody1290/Hibernate_Study/tree/master/src/main/java/cn/apeius/domainhttps://github.com/rhapsody1290/Hibernate_Study/tree/master/src/main/resources HQL语句详解★★★★★★关系模型和对象模型映射 studCourse表有两个外键，一个是与student表关联的sid，另一个是与course关联的cid 一个学生可以选择多门课程，一个课程可以被多名学生选择，两个表是多对多的关系 在对象模型中，一个学生可以选择多个课程，所以它有一个set集合的成员变量，存放studcourse 在对象模型中，一个课程可以可以被多名学生选择，所以它有一个set集合的成员变量，存放studcourses 取出部分属性 在讲解jdbc中，要查询什么字段就查询什么字段，不要select * from.. 但是在Hibernate中，建议把整个对象的属性都查询 查询整个对象的属性list方法返回的是整个Student对象 List&lt;Student&gt; list = session.createQuery(&quot;from Student&quot;).list(); for(Student s : list){ System.out.println(s.getSname() + &quot; &quot; + s.getSid()); } 查询部分属性 因为只是查询部分属性，hibernate没有把返回的结果封装成Student对象，而只是Object数组 List list = session.createQuery(&quot;select sname,sid from Student&quot;).list(); for(int i = 0; i &lt; list.size(); i++){ Object[] obj = (Object[]) list.get(i); System.out.println(obj[0] + &quot; &quot; + obj[1]); } 或（推荐） List&lt;Object[]&gt; list = session.createQuery(&quot;select sname,sid from Student&quot;).list(); for(Object[] obj : list){ System.out.println(obj[0] + &quot; &quot; + obj[1]); } 原理：创建list对象，对于每条记录创建一个对象数组，并加入list中 如果我们返回的是一列数据 //这时我们的取法是直接取出list-&gt;object 而不是 list-&gt;Object[] List&lt;Object&gt; list = session.createQuery(&quot;select sname from Student&quot;).list(); for(Object obj : list){ System.out.println(obj); } 对象模型关联查询查询学生就能查出于课程关联的全部信息 List&lt;Student&gt; list = session.createQuery(&quot;from Student&quot;).list(); for(Student s : list){ System.out.print(s.getSname()); if(s.getStudcourses().size() == 0){ System.out.println(&quot;没有选课&quot;); }else{ System.out.print(&quot;选了&quot;); for(Studcourse studcourse : s.getStudcourses()){ System.out.print(studcourse.getCourse().getCname() + &quot; &quot;); } System.out.println(); } } 请显示所有选择了21号课程的学生信息 String sql = &quot;select student.sname,student.sage from Studcourse where course.cid = 21&quot;; List&lt;Object[]&gt; list = HibernateUtil.executeQuery(sql,null); for(Object[] s : list){ System.out.println(s[0] + &quot; &quot; + s[1]); } uniqueResult方法(只有一个对象)当session.createQuery(&quot;from xxx where cardid=&#39;xxx&#39;&quot;).uniqueResult();返回的结果只有一个对象时，可以使用uniqueResult()得到该对象，效率高。但是，如果结果是多条，使用该方法就会抛出异常。 Student student = (Student) session.createQuery(&quot;from Student where id = 20050003&quot;).uniqueResult(); if(student != null) System.out.println(student.getSname()); else System.out.println(&quot;记录不存在&quot;); 模糊查询String sql = &quot;select sname,sage from Student where sname like &apos;林%&apos;&quot;; List&lt;Object[]&gt; list = HibernateUtil.executeQuery(sql,null); for(Object[] s : list){ System.out.println(s[0] + &quot; &quot; + s[1]); } distinct的用法（过滤重复的记录）比如，显示所有学生的性别和年龄 List list=session.createQuery(&quot;select distinct sage,ssex from Student&quot;).list(); for(int i=0;i&lt;list.size();i++){ Object [] objs=(Object[]) list.get(i); System.out.println(objs[0].toString()+&quot; &quot;+objs[1].toString()); } between and年龄在20岁到22岁的学生 List list=session.createQuery(&quot;select distinct sage,ssex,sname from Student where sage between 20 and 22&quot;).list(); for(int i=0;i&lt;list.size();i++){ Object [] objs=(Object[]) list.get(i); System.out.println(objs[0].toString()+&quot; &quot;+objs[1].toString()+objs[2].toString()); } in /not in查询计算机系和外语系的学生信息 List&lt;Student&gt; list=session.createQuery(&quot;from Student where sdept in (&apos;计算机系&apos;,&apos;外语系&apos;)&quot;).list(); for(Student s:list){ System.out.println(s.getSname()+&quot; &quot;+s.getSaddress()+&quot; &quot;+s.getSdept()); } group by使用显示各个系的学生的平均年龄 List&lt;Object[]&gt; list=session.createQuery(&quot;select avg(sage),sdept from Student group by sdept&quot;).list(); for(Object[] obj:list){ System.out.println(obj[0].toString()+&quot; &quot;+obj[1].toString()); } having的使用对分组查询后的结果，进行筛选 1.请显示人数大于3的系名称 //a. 查询各个系分别有多少学生 b.筛选 List&lt;Object[]&gt; list=session.createQuery(&quot;select count(*) as c1,sdept from Student group by sdept having count(*)&gt;3&quot;).list(); //取出1. for 增强 for(Object[] obj:list){ System.out.println(obj[0].toString()+&quot; &quot;+obj[1].toString()); } 2.查询女生少于200人的系 List&lt;Object[]&gt; list = session.createQuery(&quot;select count(*),sdept from Student where ssex = &apos;F&apos;group by sdept having count(*) &lt; 200&quot;).list(); for(Object[] obj : list){ System.out.println(obj[0] + &quot; &quot; + obj[1]); } 聚集函数的使用 count(),avg(),max(),min(),sum()1.查询计算机系共多少人 Long count = (Long) session.createQuery(&quot;select count(*) from Student where sdept=&apos;计算机系&apos;&quot;).uniqueResult(); System.out.println(count); 2.查询选修11号课程的最高分和最低分 List&lt;Object[]&gt; list=session. createQuery(&quot;select 11,max(grade),min(grade) from Studcourse where course.cid=11&quot;).list(); for(Object[] obj:list){ System.out.println(obj[0].toString()+&quot; max=&quot;+obj[1].toString()+&quot; min=&quot;+obj[2].toString()); } 3.计算各个科目不及格的学生数量 List&lt;Object[]&gt; list=session.createQuery(&quot;select count(*),course.cname from Studcourse where grade &lt; 60 group by course.cname&quot;).list(); for(Object[] obj:list){ System.out.println(obj[0].toString()+ &quot; &quot; + obj[1]); } 4.显示各科考试不及格学生的名字，科目和分数 List&lt;Object[]&gt; list=session.createQuery(&quot;select student.sname,course.cname,grade from Studcourse where grade &lt; 60&quot;).list(); for(Object[] obj:list){ System.out.println(obj[0].toString()+ &quot; &quot; + obj[1] + &quot; &quot; + obj[2]); } 分页分页原理见Java基础常用 函数使用 List q=session.createQuery(hql).setFirstResultl(从第几条取//从0开始计算).setMaxResult(取出几条).list(); 据用户输入的pageNow 和pageSize显示对象 Session session = HibernateUtil.getCurrentSession(); Transaction transaction = null; int pageNow = 1; int pageSize = 3; int pageCount = 0; int rowCount = 0; try{ transaction = session.beginTransaction(); //do... rowCount = Integer.parseInt(session.createQuery(&quot;select count(*) from Student&quot;).uniqueResult().toString()); pageCount = (rowCount -1)/pageSize + 1; //遍历 for(int i = 0; i &lt;= pageCount; i++){ System.out.println(&quot;***********************************&quot;); List&lt;Student&gt; list = session.createQuery(&quot;from Student&quot;).setFirstResult(pageSize*i).setMaxResults(pageSize).list(); for(Student s : list){ System.out.println(s.getSname()); } } transaction.commit(); }catch (Exception e){ e.printStackTrace(); if (transaction != null){ transaction.rollback(); } throw new RuntimeException(e.getMessage()); }finally { if(session != null &amp;&amp; session.isOpen()){ session.close(); } } SQL注入select * from student where sage=2412 or 1=1 上面我们使得WHERE恒真，所以该查询中WHERE已经不起作用了 参数绑定使用参数绑定的好处： 可读性提高 效果高 防止sql注入漏洞 面试题: 如果不使用参数绑定，怎样防止登录时， sql注入? 思路: 1. 通过用户名，查询出该用户名在数据库中对应的密码，然后再与用户输入的密码比较，如果相等，则用户和法，否则，非法. 参数绑定有两种形式 Query q=session.createQuery(from Student where sdept=:dept and sage&gt;:age) 如果我们的参数是:冒号形式给出的，则我们的参数绑定应当这样: List&lt;Student&gt; list=session.createQuery(&quot;from Student where sdept=:a1 and sage&gt;:sage&quot;).setString(&quot;a1&quot;, &quot;计算机系&quot;).setString(&quot;sage&quot;, &quot;2&quot;).list(); 还有一种形式: Query q=session.createQuery(from Student where sdept=? and sage&gt;?) 如果我们的参数是以 ? 形式给出的则，参数绑定应当: List&lt;Student&gt; list=session.createQuery(&quot;from Student where sdept=? and sage&gt;?&quot;).setString(0, &quot;计算机系&quot;).setString(1, &quot;2&quot;).list(); 参数的绑定，可以分开写： Query query=session.createQuery(&quot;from Student where sdept=? and sage&gt;?&quot;); query.setString(0, &quot;计算机系&quot;); query.setString(1, &quot;2&quot;); List &lt;Student&gt; list=query.list(); for(int i=0;i&lt;list.size();i++){ Student s= list.get(i); System.out.println(s.getSname()+&quot; &quot;+s.getSage()); } 把HibernateUtil升级了 多表查询★★★在实际项目中，我们不可能只对一张表进行查询，通常有多张表联合查询 hibernate对象之间关系 one – to – one : 身份证&lt;—&gt;人 one – to – many 部门 &lt;—&gt; 员工 many-to-one 员工&lt;—&gt;部门 many-to-many 学生&lt;—&gt;老师 多对多关系转换成两个一对多 一个学生可以选择多门课程，一门课程可以被多名学生选择，在实际开发中应将其转成两个一对多或多两个多对一。这样程序好控制，同时不会有冗余 对象配置文件可以体现出，Student.hbm.xml和Course.xml中是one-to-many，而Studcourse是many-to-one 举个例子请显示林青霞 选择的所有课程名，和成绩 String sql = &quot;select course.cname,grade from Studcourse where student.sname = &apos;林青霞&apos;&quot;; List&lt;Object[]&gt; list = HibernateUtil.executeQuery(sql,null); for(Object[] s : list){ System.out.println(s[0] + &quot; &quot; + s[1]); } Criteria—略讲//查询年龄大于10岁的学生 //获取一个会话 Session session = HibernateUtil.getCurrentSession(); Transaction transaction = null; try { transaction = session.beginTransaction(); Criteria cri = session.createCriteria(Student.class); //增加检索条件 cri.add(Restrictions.gt(&quot;sage&quot;,10)); List&lt;Student&gt; list = cri.list(); for(Student s : list){ System.out.println(s.getSname()); } transaction.commit(); } catch (Exception e) { if (transaction != null) { transaction.rollback(); } throw new RuntimeException(e.getMessage()); } finally { //关闭session if (session != null &amp;&amp; session.isOpen()) { session.close(); } } hibernate对象的三种状态如果判断一个对象处于怎样的状态？主要的依据是: 1. 看该对象是否处于session管理下 2. 看在数据库中有没有对应的记录 瞬时态: 没有session管理，同时数据库没有对应记录 持久态: 有session管理，同时在数据库中有记录。相关联的session没有关闭，事务没有提交，持久对象状态发生改变，在事务提交时会影响到数据库，即hibernate能检测到变化 脱管态/游离态： 没有session管理，但是在数据库中有记录。脱管对象状态发生改变，hibernate不能检测到 对象三种状态//对象三种状态 Course c1 = new Course();//没有在session管理下，数据库没记录，c1就是瞬时态 c1.setCid(100); c1.setCcredit(3); c1.setCname(&quot;php&quot;); Session session = null; Transaction tx = null; try{ session = HibernateUtil.getCurrentSession(); tx = session.beginTransaction(); session.save(c1);//c1这时处于session管理下，同时c1对象被保存到数据库，c1处于持久态 tx.commit(); session.close(); //c1没有处于session管理下，单被保存到数据库中，c1就是脱管态（游离态） System.out.println(c1.getCname()); }catch (Exception e){ e.printStackTrace(); } 持久态中改变属性，反应到数据库中 //对象三种状态 Course c1 = new Course();//c1就是瞬时态 c1.setCid(100); c1.setCcredit(3); c1.setCname("php1"); Session session = null; Transaction tx = null; try{ session = HibernateUtil.getCurrentSession(); tx = session.beginTransaction(); session.save(c1);//c1这时处于session管理下，同时c1对象被保存到数据库，c1处于持久态 c1.setCname("php2");//处于持久态，c1的改变有效，加入的数据php2 tx.commit(); session.close(); //这时c1被保存到数据库中，同时没有处于session管理下，c1就是脱管态（游离态） c1.setCname("php3"); System.out.println(c1.getCname());//结果为php3，但数据库中时php2 }catch (Exception e){ e.printStackTrace(); } 持久态中删除记录Course c1 = new Course();//c1就是瞬时态 c1.setCid(100); c1.setCcredit(3); c1.setCname(&quot;php1&quot;); Session session = null; Transaction tx = null; try{ session = HibernateUtil.getCurrentSession(); tx = session.beginTransaction(); session.save(c1);//c1这时处于session管理下，同时c1对象被保存到数据库，c1处于持久态 c1.setCname(&quot;php2&quot;);//处于持久态，c1的改变有效，加入的数据php2 session.delete(c1);//删除数据库记录，c1处于瞬时态 tx.commit(); session.close(); //c1对应的记录被删除，同时没有处于session管理下，c1处于瞬时态 c1.setCname(&quot;php3&quot;); System.out.println(c1.getCname()); }catch (Exception e){ e.printStackTrace(); } 对象状态 - 完整版 Hibernate关系映射★★★★★★★多对一（内含懒加载问题）★★★★★★★多对一案例 采用开发方式一：从Domain和对象关系映射文件开始写，自动创建对应表 Department.java package cn.apeius.domain; public class Department implements java.io.Serializable { private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } Department.hbm.xml &lt;?xml version="1.0" encoding="utf-8"?> &lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd"> &lt;hibernate-mapping package="cn.apeius.domain"> &lt;class name="Department" lazy="false" table='department'> &lt;!-- 配置主键属性 --> &lt;id name="id" column='id' type="java.lang.Integer"> &lt;!-- 生成策略 --> &lt;generator class="increment"/> &lt;/id> &lt;property name="name" type="java.lang.String"> &lt;column name="name" length="255" not-null="true"/> &lt;/property> &lt;/class> &lt;/hibernate-mapping> Intern.java package cn.apeius.domain; public class Intern implements java.io.Serializable{ private Integer id; private String name; private Department dept; public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public Department getDept() { return dept; } public void setDept(Department dept) { this.dept = dept; } } Intern.hbm.xml &lt;?xml version="1.0" encoding="utf-8"?> &lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd"> &lt;hibernate-mapping package="cn.apeius.domain"> &lt;class name="cn.apeius.domain.Intern" table='intern'> &lt;id name="id" column='id' type="java.lang.Integer"> &lt;generator class="increment"/> &lt;/id> &lt;property name="name" type="java.lang.String"> &lt;column name="name" length="255"/> &lt;/property> &lt;!--对于private Department dept;就不能使用property--> &lt;!--column="dept_id" 表示将来自动生成的表的外键名--> &lt;!--class可选，默认是通过反射得到属性类型--> &lt;many-to-one name="dept" class = 'Department' column="dept_id"/> &lt;/class> &lt;/hibernate-mapping> hibernate.cfg.xml &lt;property name=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/property&gt; Main //创建实习生 Intern intern = new Intern(); intern.setName(&quot;宋江&quot;); //创建部门 Department department = new Department(); department.setName(&quot;财务部&quot;); //实习生分配部门 intern.setDept(department); //保存 session.save(department); session.save(intern); 结论一 应当先保存部门，再保存实习生 保存部门后，产生部门id；当保存实习生时再将部门id存入实习生表中 若先保存实习生，此时还不知道部门id，dept_id的值为null；当保存部门并生成部门id时，在更新实习生表；这样比方式一效率低 懒加载当我们查询一个对象的时候，在默认情况下,返回的只是该对象的普通属性，当用户去使用对象属性 时，才会向数据库 发出再一次的查询.这种现象我们称为lazy现象. Intern intern = (Intern) session.get(Intern.class,3); //System.out.println(intern.getName() + &quot; &quot; + intern.getDept().getName());//可以读出部门名称 transaction.commit(); session.close(); System.out.println(intern.getName() + &quot; &quot; + intern.getDept().getName());//session关闭，不可以读出部门名称 在session未关闭时，可以通过学生名得到部门名 session关闭后，由于懒加载机制，会报错，不能得到部门名 解决懒加载 显示初始化Hibernate.initized(代理对象) Intern intern = (Intern) session.get(Intern.class,3); Hibernate.initialize(intern.getDept()); transaction.commit(); session.close();//关闭session，若没有显示初始化代理对象，则会报错 System.out.println(intern.getName() + " " + intern.getDept().getName());//session关闭，不可以读出部门名称 在department映射文件中加入lazy=’false’ &lt;class name=&quot;Department&quot; lazy=&quot;false&quot;&gt; 通过过滤器(web项目) openSessionInView many-to-one的many这方，如果你配置了 &lt;class name=&quot;Student&quot; lazy=&quot;false&quot;&gt; 那么hibernate就会在 查询学生 many 方时，把它相互关联的对象也查询,这里我们可以看出，对select语句查询影响不大, one-to-many 的one 的这方，如果你配置 &lt;set name=&quot;stus&quot; cascade=&quot;save-update&quot; lazy=&quot;false&quot;&gt; 当你去查询一个部门的时候，该部门关联的学生全部返回，不管你使用否!!! 如果设置lazy=&quot;true&quot;，在session关闭后如果需要查询部门所在的学生就会报错 矛盾: 如何让我们在需要使用的时候才去查询？即如何让我们的session范围更大？ 一个http请求所在一个session，缺点是session关闭会延时 过滤器配合实现 public class MyFilter1 extends HttpServlet implements Filter { public void doFilter(ServletRequest arg0, ServletResponse arg1, FilterChain arg2) throws IOException, ServletException { // TODO Auto-generated method stub Session s=null; Transaction tx=null; try { s =HibernateUtil.getCurrentSession(); tx=s.beginTransaction(); arg2.doFilter(arg0, arg1); //代码运行到这，整个请求结束 tx.commit(); } catch (Exception e) { if(tx!=null){ tx.rollback(); } throw new RuntimeException(e.getMessage()); }finally{ HibernateUtil.closeCurrentSession(); } } } HibernateUtil加入关闭session方法 public static void closeCurrentSession() { Session s = getCurrentSession(); if (s != null &amp;&amp; s.isOpen()) { s.close(); threadLocal.set(null); } } 利用Spring可以更好得解决 一对多（内含级联操作）需求：通过一个部门号1，来获取该部门的所有学生? 案例Department.java package cn.apeius.domain; import java.util.Set; public class Department implements java.io.Serializable { private Integer id; private String name; //配置一个set集合，对应多个学生 private Set&lt;Intern> interns; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public Set getInterns() { return interns; } public void setInterns(Set interns) { this.interns = interns; } public String getName() { return name; } public void setName(String name) { this.name = name; } public static long getSerialVersionUID() { return serialVersionUID; } } Department.hbm.xml &lt;?xml version="1.0" encoding="utf-8"?> &lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd"> &lt;hibernate-mapping package="cn.apeius.domain"> &lt;class name="Department" lazy="false" table = 'department'> &lt;!-- 配置主键属性 --> &lt;id name="id" type="java.lang.Integer" column = 'id' > &lt;!-- 生成策略 --> &lt;generator class="increment"/> &lt;/id> &lt;property name="name" type="java.lang.String"> &lt;column name="name" length="255" not-null="true"/> &lt;/property> &lt;!--配置one-to-many的关系--> &lt;set name="interns" cascade="save-update"> &lt;!--指定intern类对应的外键--> &lt;key column="dept_id"/> &lt;!--集合中的类名--> &lt;one-to-many class="Intern"/> &lt;/set> &lt;/class> &lt;/hibernate-mapping> Intern.java package cn.apeius.domain; public class Intern implements java.io.Serializable{ private Integer id; private String name; private Department dept; public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public Department getDept() { return dept; } public void setDept(Department dept) { this.dept = dept; } } Intern.hbm.xml &lt;?xml version="1.0" encoding="utf-8"?> &lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd"> &lt;hibernate-mapping package="cn.apeius.domain"> &lt;class name="cn.apeius.domain.Intern"> &lt;id name="id" type="java.lang.Integer" column = 'id'> &lt;generator class="increment"/> &lt;/id> &lt;property name="name" type="java.lang.String"> &lt;column name="name" length="255"/> &lt;/property> &lt;!--对于private Department dept;就不能使用property--> &lt;!--column="dept_id" 表示将来自动生成的表的外键名--> &lt;!--class可选，默认是通过反射得到属性类型--> &lt;many-to-one name="dept" class='Department' column="dept_id"/> &lt;/class> &lt;/hibernate-mapping> 查询部门的实习生 Department department = (Department) session.get(Department.class,1); //取出该部门的实习生 Set&lt;Intern&gt; set = department.getInterns(); for(Intern intern : set) System.out.println(intern.getName()); 部门中添加实习生 //创建部门 Department department = new Department(); department.setName("业务部"); //创建实习生 Intern intern1 = new Intern(); intern1.setName("实习生1"); Intern intern2 = new Intern(); intern2.setName("实习生2"); //部门分配学生 Set set = new HashSet(); set.add(intern1); set.add(intern2); //级联添加，在department.hdm.xml中添加cascade属性 &lt;set name="interns" cascade="save-update"> department.setInterns(set); //保存 session.save(department); 级联操作所谓级联操作就是说，当你进行某个操作(添加/修改/删除…)，就由hibernate自动给你完成 案例:如何配置级联操作，当删除某个部门的时候，我们自动删除其学生. 首先我们在 配置文件中修改: &lt;!-- 配置one-to-many关系 cascade=&quot;delete&quot; 当删除该部门的时候(主对象，则级联删除它的学生从对象) --&gt; &lt;set name=&quot;stus&quot; cascade=&quot;delete&quot;&gt; &lt;!-- 指定Student类对应的外键 --&gt; &lt;key column=&quot;dept_id&quot; /&gt; &lt;one-to-many class=&quot;Student&quot; /&gt; &lt;/set&gt; java代码中操作: //演示删除级联 //获取到某个部分 Department department=(Department) s.get(Department.class, 41); s.delete(department); 演示save-update 配置文件: &lt;set name=&quot;stus&quot; cascade=&quot;save-update&quot;&gt; &lt;!-- 指定Student类对应的外键 --&gt; &lt;key column=&quot;dept_id&quot; /&gt; &lt;one-to-many class=&quot;Student&quot; /&gt; &lt;/set&gt; 代码： //添加学生 Department department=new Department(); department.setName(&quot;业务部门3&quot;); Student stu1=new Student(); stu1.setName(&quot;顺平6&quot;); Student stu2=new Student(); stu2.setName(&quot;小明6&quot;); Set&lt;Student&gt; students=new HashSet&lt;Student&gt;(); students.add(stu1); students.add(stu2); department.setStus(students); s.save(department); 说明: ① 在集合属性和普通属性中都能使用cascade ② 一般讲cascade配置在one-to-many(one的一方,比如Employee-Department),和one-to-one(主对象一方) 一对一基于主键的one-to-one 测试代码如下 生成两张表，person表和idCard表。person中id为主键，idCard表中id既为主键，也为外键 person指定id和name，IdCard的主键由person的id指定 IdCard设置外键可以多对一，但当外键同时也为主键时，可以保证一对一 Person p1 = new Person(); p1.setId(100); p1.setName(&quot;成龙&quot;); IdCard idCard = new IdCard(); idCard.setValidateDte(new Date()); //表示idCard对象是属于p1这个对象 idCard.setPerson(p1); session.save(p1); session.save(idCard); 基于外键的one-to-one 在关系模型中，idCard设置外键person_id，则person与idCard是一对多的关系。如何限制约束使得一个person对应一个idCard，只需在references增加约束unique IdCard关系映射文件，在many-to-one中增加约束unique=’true’，外键名为person_id 测试代码 Person p1 = new Person(); p1.setId(10); p1.setName(&quot;成龙&quot;); IdCard idCard = new IdCard(); idCard.setId(100); idCard.setValidateDte(new Date()); //表示idCard对象是属于p1这个对象 idCard.setPerson(p1); session.save(p1); session.save(idCard); 多对多在操作和性能方面都不太理想，所以多对多的映射使用较少，实际使用中最好转换成一对多的对象模型 Hibernate一级缓存缓存原理图 从上图看出: 当我们去查询对象的时候，首先到一级缓存去取数据，如果有，则不到数据库中取，如果没有则到数据库中取，同时在一级缓存中放入对象. 缓存的细节①什么操作会向一级缓存放入数据 save,update,saveOrUpdate,load,get,list,iterate,lock save 案例: //添加一个学生 Student student=new Student(); student.setName(&quot;小东&quot;); s.save(student);//放入一级缓存 //我马上查询 Student stu2=(Student) s.get(Student.class, student.getId()); //select System.out.println(&quot;你刚刚加入的学生名字是&quot;+stu2.getName()); ②什么操作会从一级缓存取数据 get/load/list get/load会首先从一级缓存中取，如没有,再有不同的操作 get会立即向数据库发请求，而load 会返回一个代理对象，直到用户真的去使用数据，才会向数据库发请求 list会不会从session缓存取数据？ //查询45号学生 Student stu=(Student) s.get(Student.class, 45); System.out.println(&quot;|||||||||||||||||||&quot;); String hql=&quot;from Student where id=45&quot;; Student stu2=(Student) s.createQuery(hql).uniqueResult(); System.out.println(stu2.getName()); 从上面的案例，我看出 query.list() query.uniueResut() 不会从一级缓取数据 ! 但是query.list 或者query.uniqueRestu() 会向一级缓存放数据的 ③一级缓存不需要配置，就可以使用,它本身没有保护机制，所以我们程序员要考虑这个问题,我们可以同 evict 或者 clear来清除session缓存中对象. evict 是清除一个对象，clear是清除所有的sesion缓存对象 ④session级缓存中对象的生命周期, 当session关闭后，就自动销毁 ⑤我们自己用HashMap来模拟一个Session缓存，加深对缓存的深入 import java.util.*； public class MyCache { //使用map来模拟缓存 static Map&lt;Integer,Student&gt; maps=new HashMap&lt;Integer,Student&gt;(); public static void main(String[] args) { // TODO Auto-generated method stub getStudent(1); getStudent(1); getStudent(1); getStudent(1); getStudent(3); getStudent(3); } public static Student getStudent(Integer id){ //s.get() //先到缓存去 if(maps.containsKey(id)){ //在缓存有 System.out.println(&quot;从缓存取出&quot;); return maps.get(id); }else{ System.out.println(&quot;从数据库中取&quot;); //到数据库取 Student stu=MyDB.getStudentFromDB(id); //放入缓存 maps.put(id, stu); return stu; } } } //我的数据库 class MyDB{ static List&lt;Student&gt; lists=new ArrayList&lt;Student&gt;(); //初始化数据库,假设有三个学生 static{ Student s1=new Student(); s1.setId(1); s1.setName(&quot;aaa&quot;); Student s2=new Student(); s2.setId(2); s2.setName(&quot;bbb&quot;); Student s3=new Student(); s3.setId(3); s3.setName(&quot;ccc&quot;); lists.add(s1); lists.add(s2); lists.add(s3); } public static Student getStudentFromDB(Integer id){ for(Student s: lists){ if(s.getId().equals(id)){ return s; } } return null;// 在数据库中没有. } } class Student{ private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } Hibernate二级缓存为什么需要二级缓存？因为一级缓存有限(生命周期短),所以我们需要二级缓存(SessionFactory缓存)来弥补这个问题，SessionFactory关闭后缓存才消失 需要配置 二级缓存是交给第三方去处理,常见的Hashtable , OSCache , EHCache 二级缓存的对象可能放在内存，也可能放在磁盘. 二级缓存的原理 快速入门案例使用OsCache来演示二级缓存的使用 1、配置二级缓存 &lt;!-- 启动二级缓存 --&gt; &lt;property name=&quot;cache.use_second_level_cache&quot;&gt;true&lt;/property&gt; &lt;!-- 指定使用哪种二级缓存 --&gt; &lt;property name=&quot;cache.provider_class&quot;&gt;org.hibernate.cache.OSCacheProvider&lt;/property&gt; &lt;mapping resource=&quot;com/hsp/domain/Department.hbm.xml&quot; /&gt; &lt;mapping resource=&quot;com/hsp/domain/Student.hbm.xml&quot; /&gt; &lt;!-- 指定哪个domain启用二级缓存 特别说明二级缓存策略: 1. read-only只读缓存 2. read-write读写缓存 3. nonstrict-read-write不严格读写缓存 4. transcational事务缓存 --&gt; &lt;class-cache class=&quot;com.hsp.domain.Student&quot; usage=&quot;read-write&quot;/&gt; 2、把oscahe.properties文件放在 src目录下，这样你可以指定放入二级缓存的对象capacity 大小默认1000 3、使用 //通过获取一个sesion,让hibernate框架运行(config-&gt;加载hibernate.cfg.xml) Session s=null; Transaction tx=null; try { //我们使用基础模板来讲解. s=HibernateUtil.openSession(); tx=s.beginTransaction(); //查询45号学生 Student stu1=(Student) s.get(Student.class, 45);//45-&gt;一级缓存 System.out.println(stu1.getName()); tx.commit(); } catch (Exception e) { e.printStackTrace(); if(tx!=null){ tx.rollback(); } }finally{ if(s!=null &amp;&amp; s.isOpen()){ s.close(); } } System.out.println(&quot;*********************************&quot;); try { //我们使用基础模板来讲解. s=HibernateUtil.openSession(); tx=s.beginTransaction(); //查询45号学生 Student stu1=(Student) s.get(Student.class, 45); System.out.println(stu1.getName()); Student stu3=(Student) s.get(Student.class, 46); System.out.println(stu3.getName()); tx.commit(); } catch (Exception e) { e.printStackTrace(); if(tx!=null){ tx.rollback(); } }finally{ if(s!=null &amp;&amp; s.isOpen()){ s.close(); } } //完成一个统计，统计的信息在Sessfactory //SessionFactory对象. Statistics statistics= HibernateUtil.getSessionFactory().getStatistics(); System.out.println(statistics); System.out.println(&quot;放入&quot;+statistics.getSecondLevelCachePutCount()); System.out.println(&quot;命中&quot;+statistics.getSecondLevelCacheHitCount()); System.out.println(&quot;错过&quot;+statistics.getSecondLevelCacheMissCount()); 4、在配置了二级缓存后，请大家要注意可以通过 Statistics,查看你的配置命中率高不高 主键增长策略① increment 自增，每次增长1, 适用于所有数据库。但是不要使用在多进程、主键类型是数值型 select max(id) from Student ② identity 自增，每次增长1, 适用于支持identity的数据(mysql,sql server), 主键类型是数值 ③ sequence 依赖于底层数据库系统的序列，前提条件:需要数据库支持序列机制（如:oracle等）,而且OID必须为数值类型,比如long,int,short类型。 ④ native 会根据数据类型来选择，使用identity,sequence,hilo select hibernate_sequence.nextval from dual 主键类型是数值long , short ,int &lt;id name=&quot;id&quot; type=&quot;java.lang.Integer&quot;&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; ⑤ hilo hilo标识符生成器由Hibernate按照一种high/low算法生成标识符 用法: &lt;id name=&quot;id&quot; type=&quot;java.lang.Integer&quot; column=&quot;ID&quot;&gt; &lt;generator class=&quot;hilo&quot;&gt; &lt;param name=&quot;table&quot;&gt;my_hi_value&lt;/param&gt; &lt;param name=”column”&gt;next_value&lt;/param&gt; &lt;/generator&gt; &lt;/id&gt; ⑥ uuid 会根据uuid算法，生成128-bit的字串 主键属性类型不能是数值型，而是字串型 ⑦ assigned 用户自己设置主键值，所以主键属性类型可以是数值，字串 ⑧ 映射复合主键⑨ foreign 在one-to-one的关系中，有另一张表的主键(Person)来决定自己主键/外键(IdCard)[既是主键也是外键] 一个简单选择原则 针对 mysql [主键是 int/long/short 建议使用increment/assigend，如果是字串 UUId/assigned] 针对 sql server [主键是 int/long/short 建议使用 identity/native/assinged，如果主键是字串，使用uuid/assigned ] one-to-one 又是基于主键的则使用foreign Hibernate最佳实践Hibernate不适合的场景 不适合OLAP(On-Line Analytical Processing 联机分析处理 )，以查询分析数据为主的系统；适合OLTP（on-line transaction processing 联机事务处理 ） 对于些关系模型设计不合理的老系统，也不能发挥hibernate优势 数据量巨大，性能要求苛刻的系统，hibernate也很难达到要求, 批量操作数据的效率也不高 Hibernate最佳实践 对于数据量大，性能要求高系统，不太适用使用hiberante 主要用于事务操作比较多的项目(oa/某个行业软件[石油、税务、crm, 财务系统] OLAP-&gt;hibernate用的比较少 OLTP-&gt;hibernate Hibernate开发过程（总结）hibernate.cfg.xml Hibernate快速入门 - hibernate.cfg.xml domain对象 Hibernate快速入门 - 开发domain对象 关系映射文件 Hibernate快速入门 - 手动配置我们的hibernate.cfg.xml文件 基础模版 //获取一个会话 Session session = HibernateUtil.getCurrentSession(); Transaction transaction = null; try{ transaction = session.beginTransaction(); //do... transaction.commit(); }catch (Exception e){ e.printStackTrace(); if(transaction != null){ transaction.rollback(); } throw new RuntimeException(e.getMessage()); }finally { //关闭session if(session != null &amp;&amp; session.isOpen()){ session.close(); } } HibernateUtil（增删改查）https://github.com/rhapsody1290/Hibernate_Study/blob/master/src/main/java/cn/apeius/util/HibernateUtil.java 查询 #查询全部 String sql = &quot;from Student&quot;; List&lt;Student&gt; list = HibernateUtil.executeQuery(sql, null); for(Student s : list) System.out.println(s.getSname()); #条件查询 String sql = &quot;from Student where sdept = ? and sage &gt; ?&quot;; String[] parameters = {&quot;计算机系&quot;, &quot;3&quot;}; List&lt;Student&gt; list = HibernateUtil.executeQuery(sql, parameters); for(Student s : list) System.out.println(s.getSname()); #部分查询 String sql = &quot;select sname, saddress from Student where sdept = ? and sage &gt; ?&quot;; String[] parameters = {&quot;计算机系&quot;, &quot;3&quot;}; List&lt;Object[]&gt; list = HibernateUtil.executeQuery(sql, parameters); for(Object[] s : list) System.out.println(s[0] + &quot; &quot; + s[1]); 分页 String sql = &quot;from Student order by sage&quot;; List&lt;Student&gt; list = HibernateUtil.executeQueryByPage(sql, null,4,2); for(Student s : list) System.out.println(s.getSname()); 添加 Course c = new Course(); c.setCid(61); c.setCname(&quot;servlet&quot;); HibernateUtil.save(c); 修改 String sql = &quot;update Course set ccredit = 2 where cid = 61&quot;; HibernateUtil.executeUpdate(sql,null); 删除 String sql = &quot;delete from Course where cid = 61&quot;; HibernateUtil.executeUpdate(sql,null);]]></content>
      <categories>
        <category>Hibernate</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2笔记]]></title>
    <url>%2F2016%2F08%2F11%2F%5BStruts2%5DStruts2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[什么是Struts2 Struts2是一个MVC框架 Struts2起源于WebWork框架，Struts2就是WebWork2 Struts2是对Struts1的一个补充，而不是替代品 Struts2快速入门(Action、struts.xml、跳转结果)登录功能Actionpackage cn.apeius.action; import com.opensymphony.xwork2.ActionSupport; import com.sun.net.httpserver.Authenticator; /** * Created by Asus on 2016/8/11. */ public class LoginAction extends ActionSupport { private String account; private String password; public String execute(){ if(&quot;admin&quot;.equals(account) &amp;&amp; &quot;admin&quot;.equals(password)){ return SUCCESS; }else{ return LOGIN; } } public String getAccount() { return account; } public void setAccount(String account) { this.account = account; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } } 新建LoginAction，Struts2的Action需要继承com.opensymphony.xwork2.ActionSupport LoginAction中有两个属性account、password，代表JSP表单的两个输入框。Struts2会自动把输入框中的内容通过getter、setter方法设置进来 还有一个execute方法，提交数据后会自动调用该方法 返回值代表结果页面的跳转，具体文件见配置文件 Struts2配置文件&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE struts PUBLIC &quot;-//Apache Software Foundation//DTD Struts Configuration 2.3//EN&quot; &quot;http://struts.apache.org/dtds/struts-2.3.dtd&quot;&gt; &lt;struts&gt; &lt;!--定义一个package，所有的result和action等必须配置到package--&gt; &lt;package name=&quot;main&quot; extends=&quot;struts-default&quot;&gt; &lt;!--所有的全局result--&gt; &lt;global-results&gt; &lt;!--名为login的result--&gt; &lt;result name = &quot;login&quot;&gt;/login.jsp&lt;/result&gt; &lt;/global-results&gt; &lt;!--LoginAction--&gt; &lt;action name=&quot;LoginAction&quot; class=&quot;cn.apeius.action.LoginAction&quot;&gt; &lt;!--名为success的result--&gt; &lt;result name=&quot;success&quot;&gt;/success.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt; &lt;/struts&gt; Struts2所有的result、action等必须配置到package中，自定义的package一般继承struts-default JSP配置在result中。上述配置文件配置了两个result，一个是名为success，配置在action里面，当登录成功后跳转到success.jsp里面；另一个是全局的result，配置在global-results中，名为login，访问任何页面首页跳转到login.jsp JSP登录页面&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt; &lt;%@ taglib uri=&quot;/struts-tags&quot; prefix=&quot;struts&quot;%&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;登录&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;struts:form action=&quot;LoginAction&quot;&gt; &lt;struts:label value=&quot;登录系统&quot;&gt;&lt;/struts:label&gt; &lt;struts:textfield name=&quot;account&quot; label=&quot;帐号&quot;/&gt; &lt;struts:password name=&quot;password&quot; label=&quot;密码&quot;/&gt; &lt;struts:submit value=&quot;登录&quot;&gt;&lt;/struts:submit&gt; &lt;/struts:form&gt; &lt;/body&gt; &lt;/html&gt; 配置web.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;!--struts2的filter，所有请求都被映射到struts上--&gt; &lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;!--匹配所有URL--&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;login.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;/web-app&gt; Struts2使用Filter作为分发器，配置ur-pattern最好配置为/* Struts2工作流程★★★★★ 用户访问JSP页面 login.jsp，跳出登录页面 提交表单后数据提交给LoginAction Struts2拦截所有请求，包括*.action的请求 查找struts.xml，LoginAction对应LoginAction类，生成LoginAction实例，并将提交的数据注入 该实例中（从request中获取参数），调用LoginAction实例的execute方法 根据返回结果，决定跳转 JSP页面 Struts2线程安全 Struts1所有Action都只有一个实例，不是线程安全 Struts2对每个请求生成一个实例，处理完成即销毁，是线程安全的（Struts2是基于类设计的，参数绑定到类的属性，所有的方法都可以使用，Struts2必须是多例的，如果是单例会导致不同用户数据的冲突） Action详解通配符配置ActionBookAction.java public class BookAction extends ActionSupport { public static List&lt;Book&gt; bookList = new ArrayList&lt;Book&gt;(); private String title; private Book book; public String add() { bookList.add(book); title = &quot;&lt;br/&gt;&lt;br/&gt;添加书籍成功&lt;br/&gt;&lt;br/&gt;&quot;; return &quot;success&quot;; } // 书籍列表 @SkipValidation public String list() { return &quot;list&quot;; } // 清空书籍列表 @SkipValidation public String clear() { bookList.clear(); title = &quot;&lt;br/&gt;&lt;br/&gt;清空书籍列表成功&lt;br/&gt;&lt;br/&gt;&quot;; return &quot;list&quot;; } } struts.xml &lt;action name=&quot;*Book&quot; class=&quot;com.helloweenvsfei.struts2.action.BookAction&quot; method=&quot;{1}&quot;&gt; &lt;result&gt;/successBook.jsp&lt;/result&gt; &lt;result name=&quot;{1}&quot;&gt;/{1}Book.jsp&lt;/result&gt; &lt;result name=&quot;input&quot;&gt;/initAddBook.jsp&lt;/result&gt; &lt;result name=&quot;list&quot;&gt;/listBook.jsp&lt;/result&gt; &lt;/action&gt; *代表的内容可以在本Action配置内部使用{1},{2}等引用 举个例子，访问listBook.action时，执行list()方法 常见问题Struts2中关于”There is no Action mapped for namespace / and action name”的总结http://www.cnblogs.com/gulvzhe/archive/2011/11/21/2256632.html]]></content>
      <categories>
        <category>Struts2</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis笔记]]></title>
    <url>%2F2016%2F08%2F11%2F%5Bmybatis%5Dmybatis%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[JDBC回顾JDBC连接数据库分为六步1. 加载驱动 2. 创建连接 3. 获取statement对象 4. 执行sql语句 5. 处理结果集 6. 关闭资源 存在的问题及解决方案1、加载驱动问题： ● 每次执行都加载驱动 ● 驱动名称，硬编码到java代码中，如果需要修改驱动，需要修改java文件 —— 解决方案：将驱动名称放入到外部的配置文件 2、数据库的连接信息，硬编码到java代码中 —— 解决方案：外部配置文件 3、sql语句设置参数的问题： 参数下标硬编码了，需要人为的去判断参数的位置 4、遍历结果集：需要人工的判断字段名，以及个位置参数类型，不方便 —— 是否可以将结果集直接映射到一个pojo对象中 5、频繁的创建连接，关闭连接，导致资源浪费，影响性能 —— 解决：连接池。 mybatis介绍★★ mybatis的前身是ibatis，改名后将版本升级为3.X Mybatis是类似Hiberate的 ORM框架，位于持久层 Mybatis是直接基于JDBC做了简单的封装，性能角度来看JDBC &gt; mybatis &gt; Hiberate mybatis整体架构 mybatis-config.xml全局配置文件，包括数据库的连接参数、全局配置项 mapper.xml有多个，配置sql语句 SqlSessionFactory创建SqlSession SqlSession执行crud操作 executor底层的执行器 Mappered Statement为一个个的sql语句 mybatis快速入门(参考官方文档)★★★★★githubhttps://github.com/rhapsody1290/MybatisStudy 安装 想要使用 MyBatis 只需将 mybatis-x.x.x.jar 文件置于 classpath 中 如果使用 Maven 构建项目，则需将下面的 dependency 置于 pom.xml 中 &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt; &lt;/dependency&gt; 从 XML 中构建 SqlSessionFactory 每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为中心的 SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得 SqlSessionFactoryBuilder 可以从 XML 配置文件或一个预先定制的 Configuration 的实例构建出 SqlSessionFactory 的实例（直接从Java程序中创建配置） 从XML配置文件创建SqlSessionFactory实例 从 XML 文件中构建 SqlSessionFactory 的实例非常简单，建议使用类路径下的资源文件进行配置。但是也可以使用任意的 InputStream 实例，包括字符串形式或 URL 形式的文件路径来配置。MyBatis 包含一个叫 Resources 的工具类，它包含一些静态方法，可使从 classpath 或其他位置加载资源文件更容易。 String resource = &quot;mybatis-config.xml&quot;;//指定配置文件的路径 InputStream inputStream = Resources.getResourceAsStream(resource);//默认会从classes目录下寻找配置文件 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); mybatis-config.xml——XML配置文件核心设置 XML 配置文件（configuration XML）中包含了对 MyBatis 系统的核心设置 ，包含获取数据库连接实例的数据源（DataSource）和决定事务范围和控制方式的事务管理器（TransactionManager）。XML 配置文件的详细内容后面再探讨，这里先给出一个简单的示例： &lt;!-- mybatis-config.xml --&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;${driver}&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;${username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${password}&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=&quot;mapper.xml&quot;/&gt; &lt;/mappers&gt; &lt;/configuration&gt; 注意：上述配置文件采用了Property文件注入的方式，这里为了方便，我们可以直接写死连接数据库的参数 当然，XML 配置文件中还有很多可以配置的，上面的示例指出的则是最关键的部分。要注意 XML 头部的声明，需要用来验证 XML 文档正确性。 environment 元素体中包含了事务管理和连接池的环境配置 mappers 元素是包含一组 mapper 映射器（这些 mapper的 XML 文件包含了 SQL 代码和映射定义信息） mapper.xml——映射文件Mapper.xml映射文件中定义了操作数据库的sql，每个sql是一个statement，映射文件是mybatis的核心 &lt;!-- mapper.xml --&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;!--namespace：名字空间，唯一标识，不需要特别的起名称，只要保证所有的mapper中唯一即可--&gt; &lt;mapper namespace=&quot;cn.apeius.User&quot;&gt; &lt;!--sql语句映射，也称作mapperedStatement resultType：结果集对应的java类型，需要书写类的全路径 #{id}：相当于？，表示参数的占位--&gt; &lt;select id=&quot;selectUser&quot; resultType=&quot;User&quot;&gt; select * from tb_user where id = #{id} &lt;/select&gt; &lt;/mapper&gt; 从 SqlSessionFactory 中获取 SqlSessionSqlSession 完全包含了面向数据库执行 SQL 命令所需的所有方法。你可以通过 SqlSession 实例来直接执行已映射的 SQL 语句 //获取sqlsession SqlSession session = sqlSessionFactory.openSession(); try { //sqlSession.selectOne(&quot;sql的id&quot;,&quot;sql中需要的参数&quot;) User user = (User) session.selectOne(&quot;cn.apeius.User.selectUser&quot;, 1); System.out.println(user); } finally { //关闭session session.close(); } 可能的错误 问题原因：mybatis没有引入 mapper ，需要在 mybatis-config.xml 中使用mapper引入外部的mapper.xml mybatis使用步骤总结 java代码 添加日志支持导入依赖&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; 编写配置文件log4j.properties log4j.rootLogger=DEBUG,A1 log4j.logger.org.mybatis=DEBUG log4j.appender.A1=org.apache.log4j.ConsoleAppender log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss,SSS} [%t] [%c]-[%p] %m%n 完整的CRUD操作(未使用动态代理类)★★★★★创建UserDao接口public interface UserDao { /** * 根据id查询用户信息 * @param id * @return */ public User queryUserById(Long id); /** * 查询所有用户 * @return */ public List&lt;User&gt; queryAllUser(); /** * 添加用户信息 * @param user */ public void addUser(User user); /** * 修改用户信息 * @param user */ public void updateUser(User user); /** * 根据id删除用户信息 * @param id */ public void deleteUserById(Long id); } 创建UserDao的实现类public class UserDaoImpl implements UserDao { private SqlSession sqlSession; public UserDaoImpl(SqlSession sqlSession){ this.sqlSession = sqlSession; } public User queryUserById(Long id) { return sqlSession.selectOne(&quot;user.queryUserById&quot;, id); } public List&lt;User&gt; queryAllUser() { return sqlSession.selectList(&quot;user.queryAllUser&quot;); } public void addUser(User user) { sqlSession.insert(&quot;user.addUser&quot;, user); } public void updateUser(User user) { sqlSession.update(&quot;user.updateUser&quot;, user); } public void deleteUserById(Long id) { sqlSession.delete(&quot;user.deleteUserById&quot;, id); } } 编写User对应的Mapper.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;!-- 1、namespace：名字空间，唯一标识，不需要特别的起名称，只要保证所有的mapper中唯一即可 2、但为了与Mapper接口进行映射，一般为Mapper接口的完全限定名 --&gt; &lt;mapper namespace=&quot;cn.apeius.mybatis.mapper.UserMapper&quot;&gt; &lt;select id=&quot;queryUserById&quot; resultType=&quot;cn.apeius.mybatis.domain.User&quot;&gt; select * from tb_user where id = #{id} &lt;/select&gt; &lt;!-- resultType为结果集映射的java的类型 --&gt; &lt;select id=&quot;queryAllUser&quot; resultType=&quot;cn.apeius.mybatis.domain.User&quot;&gt; select * from tb_user &lt;/select&gt; &lt;!-- #{}中的值为domain类中的属性名 --&gt; &lt;insert id=&quot;addUser&quot;&gt; INSERT INTO tb_user VALUES (NULL,#{user_name},#{password},#{name},#{age},#{sex},#{birthday},NOW(),NOW()) &lt;/insert&gt; &lt;update id=&quot;updateUser&quot;&gt; UPDATE tb_user SET user_name = #{user_name},password = #{password},name = #{name}, age = #{age}, sex = #{sex}, birthday = #{birthday}, updated = NOW() WHERE id=#{id} &lt;/update&gt; &lt;delete id=&quot;deleteUserById&quot;&gt; delete from tb_user where id = #{id} &lt;/delete&gt; &lt;/mapper&gt; 全部配置文件mybatis-config.xml加入UserMapper.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=&quot;UserMapper.xml&quot;/&gt; &lt;/mappers&gt; &lt;/configuration&gt; 编写测试用例JUNIT★★★★★★★ 在UserDao接口中按快捷键Ctrl + Shift + T，快速创建UserDaoTest测试类 add/update/delete需要commit public class UserDaoTest { UserDao userDao; SqlSession sqlSession; //初始操作 @Before public void setUp() throws Exception { String resource = &quot;mybatis-config.xml&quot;; InputStream is = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(is); sqlSession = sqlSessionFactory.openSession(); this.userDao = new UserDaoImpl(sqlSession); } @After public void tearDown() throws Exception{ sqlSession.close(); } @Test public void testQueryUserById() throws Exception { User user = userDao.queryUserById(1l); System.out.println(user); } @Test public void testQueryAllUser() throws Exception { List&lt;User&gt; users = userDao.queryAllUser(); for(User user : users){ System.out.println(user); } } @Test public void testAddUser() throws Exception { User user = new User(); user.setName(&quot;xxx&quot;); user.setAge(18); user.setSex(1); user.setPassword(&quot;123456&quot;); user.setUser_name(&quot;xxxx&quot;); user.setBirthday(new Date()); userDao.addUser(user); //需要事务进行提交 sqlSession.commit(); } @Test public void testUpdateUser() throws Exception { //先查询再更新 User user = userDao.queryUserById(15l); user.setUser_name(&quot;二舅&quot;); userDao.updateUser(user); sqlSession.commit(); } @Test public void testDeleteUserById() throws Exception { userDao.deleteUserById(17l); sqlSession.commit(); } } 解决数据库字段名和实体类属性名不一致的问题查询数据的时候，查不到userName的信息，原因：数据库的字段名是user_name，POJO中的属性名字是username，两端不一致，造成mybatis无法填充对应的字段信息 解决方案1：在sql语句中使用别名 解决方案2： 参考后面的resultMap –mapper具体的配置的时候 解决方案3：参考驼峰匹配 — mybatis-config.xml 的时候 动态代理mapper实现类★★★★★★★思考CURD的dao中的问题 1、上述开发过程为：接口-&gt;实现类-&gt;mapper.xml2、可以发现在实现类中，使用mybatis的方式非常类似 ● 查询 —— selectOne/selectList ● 查询 —— insert ● 修改 —— update ● 删除 —— delete3、sql statement 硬编码到java代码中（举例，函数参数user.queryUserById与mapper.xml中id=”queryUserById对应”） 思考：能否只写接口，不书写实现类，只编写Mapper.xml即可 答：因为在dao（mapper）的实现类中对sqlsession的使用方式很类似，mybatis提供了接口的动态代理 名称空间 mapper.xml 根标签的 namespace 属性 称为名称空间。namespace的定义本身是没有限制的，只要不重复就行 如果希望使用mybatis通过的动态代理的接口，就需要namespace中的值，和需要对应的Mapper(dao)接口的全路径一致 通过sqlSession.getMapper(Class) 在mybatis中，dao层的命名规则，以后都修改成*mapper 要求mapper中的statement,sql中的id 和方法中的名字一模一样才可以去调用 使用步骤定义接口package cn.apeius.mybatis.mapper; public interface UserMapper { /** * 根据id查询用户信息 * @param id * @return */ public User queryUserById(Long id); } 编写mapper.xml文件&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;!--namespace：名字空间，唯一标识，不需要特别的起名称，只要保证所有的mapper中唯一即可--&gt; &lt;mapper namespace=&quot;cn.apeius.mybatis.mapper.UserMapper&quot;&gt; &lt;select id=&quot;queryUserById&quot; resultType=&quot;cn.apeius.mybatis.domain.User&quot;&gt; select * from tb_user where id = #{id} &lt;/select&gt; &lt;/mapper&gt; 调用public class UserMapperTest { UserMapper userMapper; SqlSession sqlSession; @Before public void setUp() throws Exception { String resource = &quot;mybatis-config.xml&quot;; InputStream is = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(is); this.sqlSession = sqlSessionFactory.openSession(); //this.userMapper = new UserDaoImpl(sqlSession); this.userMapper = sqlSession.getMapper(UserMapper.class); } @Test public void testQueryUserById() throws Exception { User user = userMapper.queryUserById(1l); System.out.println(user); } } 使用动态代理总结★★★★★★★★★ 在名字空间”cn.apeius.mybatis.mapper.UserMapper”定义了一个名为”queryUserById”的映射语句，这样它就允许使用指定的完全限定名”cn.apeius.mybatis.mapper.UserMapper.queryUserById”来调用映射语句 User user = sqlSession.selectOne(&quot;cn.apeius.mybatis.mapper.UserMapper.queryUserById&quot;,1L); System.out.println(user); 这和使用完全限定名调用Java对象的方法是相似的，这样命名可以直接映射到命名空间同名的Mapper类，并将select语句中的名字、参数和返回类型映射成Mapper类的方法，这样可以调用对应Mapper接口的方法 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); User user = userMapper.queryUserById(1L); System.out.println(user); 综上所述：namespace与Mapper接口映射，sql语句与mapper接口中的方法映射 一张表对应一个Doamin对象，一个Mapper接口（DAO），一个mapper.xml。例如user表对应User.java、UserMapper.java、UserMapper.xml mybatis-config.xml 配置子标签出现的顺序不能改变 properties(读取外部的资源文件) 编写jdbc.properties文件 driver=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/mybatis username=root password=root mybatis-config.xml属性值注入 &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;${driver}&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;${username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${password}&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; settings（设置）mapUnderscoreToCamelCase用法： 开启驼峰匹配：从经典数据库的命名规则，到经典java命名规则的映射 经典数据库的命名规则： 个单词之间使用下划线分割，例如：user_name java经典命名规则：驼峰样式，多个单词，后续的单词首字母大写 例如：userName 开启驼峰匹配：相当于去掉数据库名字中的下划线，然后在与java中的属性名进行对应 typeAliases类型别名是为 Java 类型命名的一个短的名字。它只和 XML 配置有关，存在的意义仅在于用来减少类完全限定名的冗余 typeAliases的使用1 使用这个配置，”User”可以用在任何使用”cn.apeius.mybatis.domain.User”的地方 大小写不敏感 缺点：每个一个类都去书写别名，麻烦 typeAliases的使用2——扫描包的方式 每一个在包 cn.apeius.mybatis.domain 中的 Java Bean，在没有注解的情况下，会使用 Bean 的首字母小写的非限定类名 来作为它的别名。比如cn.apeius.mybatis.domain.User 的别名为 User，且大小写不敏感 若有注解，则别名为其注解值。 @Alias(&quot;xxx&quot;) public class User { ... } plugins（插件，又名拦截器）MyBatis 允许你在已映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 图：利用拦截器进行分页 environments（环境）为什么要适应多种环境MyBatis 可以配置成适应多种环境，这种机制有助于将 SQL 映射应用于多种数据库之中，现实情况下有多种理由需要这么做 开发环境：开发人员日常开发的时候使用的环境 测试环境：测试人员测试的时候使用环境 预发布环境：几乎和线上环境一模一样，在上线之前在进行一次测试 生成环境：线上环境。 正式的java程序运行的环境 不过要记住：尽管可以配置多个环境，每个 SqlSessionFactory 实例只能选择其一 所以，如果你想连接两个数据库，就需要创建两个 SqlSessionFactory 实例，每个数据库对应一个。而如果是三个数据库，就需要三个实例，依此类推，记起来很简单： 每个数据库对应一个 SqlSessionFactory 实例 指定创建哪种环境配置多个环境 &lt;environments default="development"> &lt;environment id="development"> &lt;transactionManager type="JDBC"/> &lt;dataSource type="POOLED"> &lt;property name="driver" value="${driver}"/> &lt;property name="url" value="${url}"/> &lt;property name="username" value="${username}"/> &lt;property name="password" value="${password}"/> &lt;/dataSource> &lt;/environment> &lt;environment id="online"> &lt;transactionManager type="JDBC"/> &lt;dataSource type="POOLED"> &lt;property name="driver" value="${driver}"/> &lt;property name="url" value="${url}"/> &lt;property name="username" value="${username}"/> &lt;property name="password" value="${password}"/> &lt;/dataSource> &lt;/environment> &lt;/environments> 代码指定创建那种环境 SqlSessionFactory factory = sqlSessionFactoryBuilder.build(reader, environment); mappers映射器mappers映射器将 mapper.xml 文件配置到 mybatis 的环境中 相对于类路径的资源引用 &lt;!-- Using classpath relative resources --> &lt;mappers> &lt;mapper resource="UserMapper.xml"/> &lt;/mappers> 使用mapper接口路径 这里所谓的 mapper接口路径，实际上就是 dao的接口路径 在mybatis中，通常把dao的包叫做mapper类名，也叫做mapper 使用 class 方式去加载的时候，要求 要求 mapper.xml 文件的名字和 mapper 接口的名字一致 要求 mapper.xml 文件和 mapper 接口类在一个目录 &lt;mapper class=&apos;cn.itcast.mybatis.mapper.UserMapper&apos;/&gt; 问题:1、mapper.xml 和 java文件没有分离,明天和 spring 整合之后解决2、需要一个一个的去加载 mapper 使用mapper接口扫描包(常用)扫描指定包下的所有接口，要求mapper.xml和接口在同一个包下，并且名字相同 &lt;!-- Register all interfaces in a package as mappers --> &lt;mappers> &lt;package name="cn.itcast.mybatis.mapper"/> &lt;/mappers> 缺点: 1、如果包的路径有很多？ 明天spring整合的时候解决2、mapper.xml和mapper.java没有分离 Mapper.xml CURD操作select——书写select语句 id属性（必须）：当前名称空间下的statement的唯一标识；要求id和mapper接口中的方法的名字一致 resultType：将结果集映射为java的对象类型，和 resultMap 二选一（必须） parameterType：传入参数类型。可以省略 insert——书写insert语句 id属性：必须的，当前名称空间下的statement的唯一标识(必须属性) parameterType：传入的参数类型，可以省略 标签内部：具体的sql语句 使用#{} 去替换一个变量 如果需要数据库影响的行数，可以直接在接口上定义返回值Integer 即可 获取自增的id的值插入数据后获得自增长的id号 useGenerateKeys：true keyColumn:主键列的名字 keyProperty：实体类对应的属性 测试 update id属性：当前名称空间下的statement的唯一标识(必须属性) parameterType：传入的参数类型，可以省略 标签内部：具体的sql语句 使用#{} 去替换一个变量 delete id属性：当前名称空间下的statement的唯一标识(必须属性) parameterType：传入的参数类型，可以省略 标签内部：具体的sql语句 使用#{} 去替换一个变量 #{}的用法及传入多个参数 #{} 存在mapper.xml中的sql语句部分，标识该位置可以接受参数信息，相当于?占位符 传入的参数和参数名无关，问题：如果有多个参数该怎么办？ 方法一：使用0，1……自然数取出对应的数据，0表示第一个参数 select * from tb_user where user_name = #{0} and password = #{1} 方法二：使用param1，param2……param1表示第一个参数 select * from tb_user where user_name = #{param1} and password = #{param2} 方法三（常用）：在方法的定义上使用@param为传入的参数定义一个名字 在UserMapper接口中声明函数login，使用@param为每个参数定义一个名字 public User login(@Param(&quot;username&quot;) String username, @Param(&quot;password&quot;) String password); sql语句在#{}中填入定义的名字 select * from tb_user where user_name = #{username} and password = #{password} 测试 @Test public void testLogin(){ User user = userMapper.login(&quot;zhangsan&quot;,&quot;123456&quot;); System.out.println(user); } ${}的用法及传入多个参数${}的用法：仍然是接受传递的参数，但是${}是sql语句的拼接 需求 查询表中的信息，有时候从历史表中去查询数据，有时候需要去新的表去查询数据，希望使用1个方法来完成操作 方法一：$在取值时，使用value表示传入的参数值，不建议写 mapper接口public List&lt;User&gt; queryUserByTableName(String tableName); mapper.xmlselect * from ${value} 测试@Test public void testQueryUsersByTableName(){ List&lt;User&gt; users = userMapper.queryUserByTableName(&quot;tb_user&quot;); for(User u : users){ System.out.println(u); } } 方法二（常用）：$在取值时，可以在mapper接口的参数之前使用@Param主键为当前参数指定一个名字 mapper接口public List&lt;User&gt; queryUserByTableName(@Param(&quot;tableName&quot;) String tableName); mapper.xmlselect * from ${tableName} 测试@Test public void testQueryUsersByTableName(){ List&lt;User&gt; users = userMapper.queryUserByTableName(&quot;tb_user&quot;); for(User u : users){ System.out.println(u); } } 面试题：#{}与${}的区别 resultMap与resultType用法★★★★★★★★从SQL查询结果到领域模型实体 从SQL查询结果集到JavaBean或POJO实体的过程： 通过JDBC查询得到ResultSet对象 遍历ResultSet对象并将每行数据暂存到HashMap实例中，以结果集的字段名或字段别名为键，以字段值为值 根据ResultMap标签的type属性通过反射实例化领域模型 根据ResultMap标签的type属性和id、result等标签信息将HashMap中的键值对，填充到领域模型实例中并返回 resultType 在MyBatis进行查询映射的时候，其实查询出来的每一个属性都是放在一个对应的Map里面的，其中键是属性名，值则是其对应的值 当提供的返回类型属性是resultType的时候，MyBatis会将Map里面的键值对取出赋给resultType所指定的对象对应的属性 resultMap返回类型直接是一个ResultMap主要用在进行复杂联合查询上 简单 resultMap 配置 &lt;resultMap id=&quot;BlogResult&quot; type=&quot;com.liulanghan.Blog&quot; &gt; &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;title&quot; property=&quot;title&quot;/&gt; &lt;result column=&quot;content&quot; property=&quot;content&quot;/&gt; &lt;result column=&quot;owner&quot; property=&quot;owner&quot;/&gt; &lt;/resultMap&gt; &lt;select id=&quot;selectBlog&quot; parameterType=&quot;int&quot; resultMap=&quot;BlogResult&quot;&gt; select * from t_blog where id = #{id} &lt;/select&gt; 结果集的列比resultMap多会报错么？ —— 不会,只映射resultMap中有的列 结果集的列比resultMap少会报错么？ —— 不会,只映射结果集中有的列 高级结果映射见高级查询 Mybatis学习路线总结★★★★★★★★★★ 一级缓存在mybatis中，一级缓存默认是开启的，并且无法关闭 一级缓存满足条件： 同一个session中 相同的SQL和参数 测试1、测试代码 2、日志输出 使用session.clearCache()强制查询不缓存1、代码 2、日志输出： 向数据库发送两次查询语句 执行update,delete,insert 语句的时候，会刷新缓存1、代码 2、日志 二级缓存mybatis 的二级缓存的 作用域 是一个mapper的namespace ，同一个namespace中查询sql可以从缓存中命中 开启二级缓存需要在mapper.xml 中加入如下： &lt;cache /&gt; 测试二级缓存 查询一次 关闭sqlSession 重新打开sqlSession 继续查询，观察是否发送sql语句 1、代码 2、日志 二级缓存的高级配置 关闭二级缓存在全局的mybatis-config.xml 中去关闭二级缓存 测试 日志会有两次sql语句查询 高级查询★★★★★★官方文档http://blog.csdn.net/tayanxunhua/article/details/19194607 数据库设计1、用户表2、订单表3、产品表 思路： 一个用户可以有多个订单，某个订单只属于一个用户：需在订单表中设置指向用户表的外键 一个订单中有多个产品，一个产品可以属于多个订单，关系是多对多：建立中间表，指向订单表和产品表的外键 表之间的关系，以订单表作为出发点 订单表与用户表：1：1 一个订单只能属于一个人 1：1 一个用户可以有多个订单 1：N 订单表与商品表：N:N 一个订单可以有多个商品 1：N 一个商品可以属于多个订单表 1：N 订单表与订单详情：1：N 一个订单有多个订单详情 一个订单详情只属于一个订单 总结，以订单的角度看，他们的关系是： 订单和人是一对一关系 订单和订单详情是一对多的关系 订单和商品是多对多的关系 自动映射配置：autoMapping详解http://www.cnblogs.com/TheViper/p/4480765.htmlhttp://www.zhihu.com/question/41983738/answer/98829976 一对一查询 查询订单，并且查询出下单人的信息 核心思想：面向对象的思想，在Order对象中添加User对象 association关联元素处理一对一关联，比如：一个博客只有一个作者，一张订单只属于一个用户 方法一：关联的嵌套查询 （select联合查询，懒加载） Domain public class Order { private int id; private User user;//private int user_id; private String order_number; } 定义OrderMapper接口 public interface OrderMapper { public Order queryOrderAndUserLazy(String orderNumber); } Ordermapper.xml &lt;!--1、查询订单，属性中包含对象必须使用resultMap--&gt; &lt;select id=&quot;queryOrderAndUserLazy&quot; resultMap=&quot;lazyOrderUserResultMap&quot;&gt; SELECT * FROM tb_order WHERE order_number = #{order_number} &lt;/select&gt; &lt;!--2、指定Order中user成员变量的详细装配方式，即根据user_id查询User对象--&gt; &lt;resultMap id=&quot;lazyOrderUserResultMap&quot; type=&quot;Order&quot;&gt; &lt;!-- 一个 ID 结果，标记结果作为 ID 可以帮助提高整体效能 --&gt; &lt;id property=&quot;id&quot; column=&quot;id&quot;&gt;&lt;/id&gt; &lt;!--resultMap必须制定javaType，如果你映射到一个JavaBean，MyBatis通常可以断定类型--&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot; column=&quot;user_id&quot; select=&quot;queryUserById&quot;/&gt; &lt;/resultMap&gt; &lt;!--3、查询用户--&gt; &lt;select id=&quot;queryUserById&quot; resultType=&quot;User&quot;&gt; SELECT * FROM tb_user where id = #{id} &lt;/select&gt; 测试 @Test public void testQueryOrderAndUserByOrderNumber() throws Exception { Order order = orderMapper.queryOrderAndUserLazy(&quot;20140921001&quot;); System.out.println(order); System.out.println(order.getUser()); } 有两个查询语句：一个来加载订单，另外一个来加载用户, 而且订单的结果映射描述了”queryUserById”语句应该被用来加载它的 User 属性。 其他所有的属性将会被自动加载，假设它们的列和属性名相匹配。这种方式很简单, 但是对于大型数据集合和列表将不会表现很好，就会出现”N+1”的问题。 “N+1”的问题可以是这样引起的：你执行了一个单独的 SQL 语句来获取结果列表(就是”+1”)——查询Order语句对返回的每条记录,你执行了一个查询语句来为每个加载细节(就是”N”)——查询User语句这个问题会导致成百上千的 SQL 语句被执行，这通常不是期望的 MyBatis 能延迟加载这样的查询就是一个好处,因此你可以分散这些语句同时运行的消耗。然而,如果你加载一个列表,之后迅速迭代来访问嵌套的数据,你会调用所有的延迟加载,这样的行为可能是很糟糕的。所以还有另外一种方法 方法二：关联查询 方式一：属性全部重命名，手动映射 代替了执行一个分离的语句,我们联合订单表和用户表在一起 所有结果被唯一而且清晰的名字来重命名，这使得映射非常简单 缺点是所有字段都要手动映射，操作简单，但工作量较大，可以使用自动映射 &lt;!--联合查询订单和用户，一对一关系--&gt; &lt;select id=&quot;queryOrderAndUserByOrderNumber&quot; resultMap=&quot;orderUserResultMap&quot;&gt; SELECT o.id as order_id, o.user_id as order_user_id, o.order_number as order_order_number, u.id as user_id, u.user_name as user_user_name, u.password as user_password, u.name as user_name, u.age as user_age, u.sex as user_sex, u.birthday as user_birthday, u.created as user_created, u.updated as user_updated FROM tb_order o LEFT JOIN tb_user u ON u.id = o.user_id WHERE o.order_number = #{order_number} &lt;/select&gt; &lt;resultMap id=&quot;orderUserResultMap&quot; type=&quot;Order&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;result property=&quot;order_number&quot; column=&quot;order_order_number&quot;/&gt;&lt;!-- 有顺序要求，必须放在id后--&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;user_id&quot;/&gt; &lt;result property=&quot;user_name&quot; column=&quot;user_name&quot;/&gt; &lt;result property=&quot;password&quot; column=&quot;user_password&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;user_name&quot;/&gt; &lt;result property=&quot;age&quot; column=&quot;user_age&quot;/&gt; &lt;result property=&quot;sex&quot; column=&quot;user_sex&quot;/&gt; &lt;result property=&quot;birthday&quot; column=&quot;user_birthday&quot;/&gt; &lt;result property=&quot;created&quot; column=&quot;user_created&quot;/&gt; &lt;result property=&quot;updated&quot; column=&quot;user_updated&quot;/&gt; &lt;/association&gt; &lt;/resultMap&gt; 方式二：自动映射，冲突字段自动命名，手动映射，其余元素自动匹配（推荐）★★★★★ 当自动匹配结果的时候，Mybatis会获取列名，并且查找一个相同的属性（忽略大小写）。这意味着命名为ID的列和命名为id的属性被查找到的时候，Mybatis将会把列ID的值赋给属性id 通常数据库列名命名的时候使用大写和下划线并且Java属性常常依据驼峰命名法。为了保证在他们之间的自动匹配要设置属性 mapUnderscoreToCamelCase 为 true 对于每一个result map，所有的在ResultSet中有的并且没有被手动匹配的列将会被自动的匹配。默认不开启，设置 autoMapping=”true”开启 冲突字段重命名，自动赋值，其余元素自动匹配 &lt;!--联合查询订单和用户，一对一关系--&gt; &lt;select id=&quot;queryOrderAndUserByOrderNumber&quot; resultMap=&quot;orderUserResultMap&quot;&gt; SELECT *,u.id as user_id,o.id as order_id FROM tb_order o LEFT JOIN tb_user u ON u.id = o.user_id WHERE o.order_number = #{order_number} &lt;/select&gt; &lt;resultMap id=&quot;orderUserResultMap&quot; type=&quot;Order&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;user_id&quot;/&gt; &lt;/association&gt; &lt;/resultMap&gt; 方式三：外部结果映射 使用外部的结果映射元素来映射关联，使得User结果映射可以重用。如果你不需要重用它的话，或者你仅仅引用你所有的结果映射合到一个单独描述的结果映射中，即方式二 &lt;!--联合查询订单和用户，一对一关系--&gt; &lt;select id=&quot;queryOrderAndUserByOrderNumber&quot; resultMap=&quot;orderUserResultMap&quot;&gt; SELECT *,u.id as user_id,o.id as order_id FROM tb_order o LEFT JOIN tb_user u ON u.id = o.user_id WHERE o.order_number = #{order_number} &lt;/select&gt; &lt;resultMap id=&quot;orderUserResultMap&quot; type=&quot;Order&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot; resultMap=&quot;user&quot;/&gt; &lt;/resultMap&gt; &lt;resultMap id=&quot;user&quot; type=&quot;User&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;user_id&quot;/&gt; &lt;/resultMap&gt; 一对多查询查询订单，查询出下单人信息并且查询出订单详情 订单表、用户表、订单详情三表联合查询 映射结果为Order类，填充user和orderDetails属性对象 Domain public class Order { private int id; private User user;//private int user_id; private String order_number; private List&lt;OrderDetail&gt; orderDetails; } 定义OrderMapper接口 public interface OrderMapper { public Order queryOrderAndUserAndDetailByOrderNumber(String orderNumber); } OrderMapper.xml &lt;!--collection：1：N--&gt; &lt;select id=&quot;queryOrderAndUserAndDetailByOrderNumber&quot; resultMap=&quot;orderUserDetailResultMap&quot;&gt; SELECT *,o.id as order_id,d.id as detail_id FROM tb_order o LEFT JOIN tb_user u ON u.id = o.user_id LEFT JOIN tb_orderdetail d ON o.id = d.order_id WHERE o.order_number = #{order_number} &lt;/select&gt; &lt;resultMap id=&quot;orderUserDetailResultMap&quot; type=&quot;Order&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;user_id&quot;/&gt; &lt;/association&gt; &lt;!--collection 定义集合 property：集合的属性名 javaType：集合的类型 ofType：集合中成员类型 子标签内：填id和result --&gt; &lt;collection property=&quot;orderDetails&quot; javaType=&quot;List&quot; ofType=&quot;OrderDetail&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;detail_id&quot;/&gt; &lt;/collection&gt; &lt;/resultMap&gt; 测试 Order order = orderMapper.queryOrderAndUserAndDetailByOrderNumber(&quot;20140921001&quot;); System.out.println(order); List&lt;OrderDetail&gt; orderDetails = order.getOrderDetails(); for(OrderDetail d : orderDetails) System.out.println(d); 多对多查询查询订单，查询出下单人信息并且查询出订单详情中的商品数据 doamin public class OrderDetail { private int id; private Order order;//private int order_id; private Item item;//private int item_id; private double total_price; private int status; } 定义OrderMapper public interface OrderMapper { public Order queryOrdreAndUserAndDetailAndItemByOrderNumber(String orderNumber); } OrderMapper.xml &lt;!--查询订单，查询出下单人信息并且查询出订单详情中的商品数据 N:N--&gt; &lt;select id=&quot;queryOrdreAndUserAndDetailAndItemByOrderNumber&quot; resultMap=&quot;orderUserDetailItemResultMap&quot;&gt; SELECT * FROM tb_order o LEFT JOIN tb_user u ON u.id = o.user_id LEFT JOIN tb_orderdetail d ON o.id = d.order_id LEFT JOIN tb_item i ON d.item_id = i.id WHERE o.order_number = #{order_number} &lt;/select&gt; &lt;resultMap id=&quot;orderUserDetailItemResultMap&quot; type=&quot;Order&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;user_id&quot;/&gt; &lt;/association&gt; &lt;collection property=&quot;orderDetails&quot; javaType=&quot;List&quot; ofType=&quot;OrderDetail&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;detail_id&quot;/&gt; &lt;association property=&quot;item&quot; javaType=&quot;Item&quot; autoMapping=&quot;true&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;item_id&quot;&gt;&lt;/id&gt; &lt;/association&gt; &lt;/collection&gt; &lt;/resultMap&gt; 测试 @Test public void testQueryOrdreAndUserAndDetailAndItemByOrderNumber(){ Order order = orderMapper.queryOrdreAndUserAndDetailAndItemByOrderNumber(&quot;20140921001&quot;); System.out.println(order); } resultMap的继承 延迟加载(未成功)开启延迟加载&lt;settings&gt; &lt;!-- 打开延迟加载的开关 --&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 将积极加载改为消极加载，即延迟加载 --&gt; &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt; &lt;/settings&gt; lazyLoadingEnabled：true使用延迟加载，false禁用延迟加载，默认为false aggressiveLazyLoading： 默认true，当有一个进行加载的时候，就会把所有没有加载的属性加载进来 false按需加载，只有调用对应的getter的才会去加载 添加cglib&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;/dependency&gt; 接口定义public interface OrderMapper { public Order queryOrderAndUserLazy(String orderNumber); } OrderMapper.xml &lt;mapper namespace="cn.apeius.mybatis.mapper.OrderMapper"> &lt;select id="queryOrderAndUserLazy" resultMap="lazyOrderUserResultMap"> SELECT * FROM tb_order WHERE order_number = #{order_number} &lt;/select> &lt;resultMap id="lazyOrderUserResultMap" type="Order" autoMapping="true"> &lt;id property="id" column="id">&lt;/id> &lt;-- columnw中的user_id作为参数传入queryUserById--> &lt;association property="user" javaType="User" column="user_id" select="queryUserById"/> &lt;/resultMap> &lt;select id="queryUserById" resultType="User"> SELECT * FROM tb_user where id = #{id} &lt;/select> &lt;/mapper> 测试@Test public void testQueryOrderAndUserLazy(){ OrderMapper orderMapper = sqlSession.getMapper(OrderMapper.class); Order order = orderMapper.queryOrderAndUserLazy(&quot;20140921001&quot;); System.out.println(order.getOrder_number()); System.out.println(order.getUser()); } 分页插件 Mybatis提供了plugin机制，允许我们在mybatis的原有流程上加入自己的逻辑，加上分页逻辑可以方便实现分页 原理是利用了拦截器，mybatis支持的拦截接口有四个：Executor、ParameterHandler、ResultSetHandlet、StatementHandler plugin实现原理 原来的sql语句: select * from tb_user 经过拦截器后，变为: selectd * from tb_user limit 1,10 从而实现分页 使用PageHelper实现分页PageHelper实现了通用的分页查询，其支持的数据库有Mysq、Oracle、DB2、PostgreSQL等主流数据库 导入依赖&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;3.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.jsqlparser&lt;/groupId&gt; &lt;artifactId&gt;jsqlparser&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt; &lt;/dependency&gt; 配置插件&lt;plugins&gt; &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;&gt; &lt;!--数据库方言--&gt; &lt;property name=&quot;dialect&quot; value=&quot;mysql&quot;/&gt; &lt;!--设置为true时，使用RowBounds分页会进行count查询，即会去查询出总数--&gt; &lt;property name=&quot;rowBoundsWithCount&quot; value=&quot;true&quot;/&gt; &lt;/plugin&gt; &lt;/plugins&gt; 在执行查询时设置分页参数@Test public void testPage(){ //开启分页，第一个参数：当前的页数；第二个参数：每页几条数据 PageHelper.startPage(2,5); //紧接着的第一个查询会被执行分页 List&lt;User&gt; users = userMapper.queryAllUser(); for(User u : users){ System.out.println(u); } //获取分页信息 PageInfo&lt;User&gt; pageInfo = new PageInfo&lt;User&gt;(users); pageInfo.getList();//与users为同一个引用 System.out.println(&quot;总记录数：&quot; + pageInfo.getTotal()); System.out.println(&quot;总页数 &quot; + pageInfo.getPages()); System.out.println(&quot;当前页数 &quot; + pageInfo.getPageNum()); System.out.println(&quot;每页多少数据 &quot; + pageInfo.getPageSize()); System.out.println(&quot;当前页的数据条目数 &quot; + pageInfo.getSize()); } mybatis和spring整合官方文档https://github.com/rhapsody1290/MybatisStudy/tree/master/doc/%E4%B8%AD%E6%96%87%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/Mybatis-Spring-1.2.2 什么是MyBatis-Spring MyBatis-Spring 会帮助你将 MyBatis 代码 无缝地整合 到 Spring 中，使用这个类库中的类, Spring 将会加载必要的 MyBatis 工厂类和 session 类 这个类库也提供一个简单的方式来注入 MyBatis 数据映射器和 SqlSession 到业务层的 bean 中 它也会处理事务, 翻译 MyBatis 的异常到 Spring 的 DataAccessException 异常中 最终,它并不会依赖于 MyBatis,Spring 或 MyBatis-Spring 来构建应用程序代码 导入依赖mybatis-spring整合包 &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; c3p0依赖，一个开源的JDBC连接池 &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; c3p0.properties(数据源)c3p0.driverClass=com.mysql.jdbc.Driver c3p0.url=jdbc:mysql://localhost:3306/mybatis c3p0.user=root c3p0.password=root 配置spring的配置文件applicationContext.xml 引入配置文件c3p0.properties 配置连接池 配置sqlSessionFactory 引入数据源 引入mybatis的全局配置 包扫描方式配置别名typeAliasesPackage mapper.xml所在路径(Mapper.xml和java代码分离) mapper接口所在的包 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!-- 引入配置文件 --&gt; &lt;bean class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:c3p0.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置连接池 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClass&quot; value=&quot;${c3p0.driverClass}&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;${c3p0.url}&quot;&gt;&lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;${c3p0.user}&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;${c3p0.password}&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置sqlSessionFactory。SqlSessionFactoryBean 是用于创建 SqlSessionFactory 的--&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!--引入数据源--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!--引入mybatis的全局配置--&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt; &lt;!--mybatis别名包--&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;cn.apeius.mybatis.domain&quot;/&gt; &lt;!--mapper.xml所在路径,可以使mapper接口与mapper.xml分离；可以使用通配符，**表示所有目录--&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath*:mapper/**/*.xml&quot; /&gt; &lt;/bean&gt; &lt;!--指定扫描包，mapper接口所在的包--&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!--多个扫描包可以通过逗号或分号进行分割--&gt; &lt;property name=&quot;basePackage&quot; value=&quot;cn.apeius.mybatis.mapper&quot; /&gt; &lt;/bean&gt; &lt;/beans&gt; mybatis-config.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;settings&gt; &lt;!-- 打开延迟加载的开关 --&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 将积极加载改为消极加载，即延迟加载 --&gt; &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt; &lt;/settings&gt; &lt;plugins&gt; &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;&gt; &lt;!--数据库方言--&gt; &lt;property name=&quot;dialect&quot; value=&quot;mysql&quot;/&gt; &lt;!--设置为true时，使用RowBounds分页会进行count查询，即会去查询出总数--&gt; &lt;property name=&quot;rowBoundsWithCount&quot; value=&quot;true&quot;/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/configuration&gt; 问题：为什么配置SqlSessionFactory时，class为SqlSessionFactory 在基本的 MyBatis 中, SqlSessionFactory 可以使用 SqlSessionFactoryBuilder 来创建，而在 MyBatis-Spring 中,则使用 SqlSessionFactoryBean 来替代 SqlSessionFactoryBean 实现了 Spring 的 FactoryBean 接口，这就说明了由 Spring 最终创建的 bean 不是 SqlSessionFactoryBean 本身 , 而是工厂类的 getObject()返回的方法的结果。这种情况下,Spring 将会在应用启动时为你 创建 SqlSessionFactory 对象,然后将它以 SqlSessionFactory 为名来存储 mybatis和spring整合测试ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); UserMapper userMapper = context.getBean(UserMapper.class); List&lt;User&gt; users = userMapper.queryAllUser(); for(User user : users){ System.out.println(user.getId() + &quot; &quot; + user.getUser_name()); } mapper整合servcieservcie接口public interface UserServiceInter { public List&lt;User&gt; queryAll(); } service实现@Service public class UserServiceImp implements UserServiceInter { @Autowired private UserMapper userMapper; @Override public List&lt;User&gt; queryAll() { return userMapper.queryAllUser(); } } applicationContext.xml配置使service属性自动注入 &lt;context:component-scan base-package=&quot;cn.apeius.mybatis.service.imp&quot;&gt;&lt;/context:component-scan&gt; 测试ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); UserServiceInter userServiceInter = context.getBean(UserServiceImp.class); List&lt;User&gt; users = userServiceInter.queryAll(); for(User user : users){ System.out.println(user); } mybatis整合事务管理（未成功）配置事务管理&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd&quot;&gt; &lt;!-- 定义事务管理器 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义事务策略 --&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;!--所有以query开头的方法都是只读的 --&gt; &lt;tx:method name=&quot;query*&quot; read-only=&quot;true&quot; /&gt; &lt;!--其他方法使用默认事务策略 --&gt; &lt;tx:method name=&quot;*&quot; /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;aop:config&gt; &lt;!--pointcut元素定义一个切入点，execution中的第一个星号 用以匹配方法的返回类型， 这里星号表明匹配所有返回类型。 com.abc.dao.*.*(..)表明匹配cn.itcast.mybatis.service包下的所有类的所有方法 --&gt; &lt;aop:pointcut id=&quot;myPointcut&quot; expression=&quot;execution(* cn.apeius.mybatis.service.*.*(..))&quot; /&gt; &lt;!--将定义好的事务处理策略应用到上述的切入点 --&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;myPointcut&quot; /&gt; &lt;/aop:config&gt; &lt;/beans&gt; service@Service public class UserServiceImp implements UserServiceInter { @Autowired protected UserMapper userMapper; @Override public List&lt;User&gt; queryAll() { return userMapper.queryAllUser(); } @Override public void saveUser(User user) { userMapper.addUser(user); //int a = 9 / 0; } } 测试@Before public void setUp(){ ApplicationContext context = new ClassPathXmlApplicationContext(new String[]{&quot;applicationContext.xml&quot;,&quot;applicationContext-transaction.xml&quot;}); userServiceInter = context.getBean(UserServiceImp.class); } @Test public void testSaveUser(){ User user = new User(); user.setUser_name(&quot;陈冠希&quot;); user.setName(&quot;dsfa&quot;); userServiceInter.saveUser(user); }]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>JavaEE</tag>
        <tag>Java</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令行编译Java程序]]></title>
    <url>%2F2016%2F08%2F09%2F%5BJava%5D%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%AF%91Java%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[先说下.java和.class文件，.java文件可以放在任何位置，只要运行javac时，指定你要编译的源文件位置就好，然后javac还有另一个参数是指定.class文件输出到哪个目录。另外javac还有一个option叫 -d，表示编译出来的.class文件，按照包名放进相应层级的目录中去。所以，假设你的.java文件在D:\code\src\com\company\Hello.java，（因为Java要求源文件中的public类与源文件名要相同，类名通常首字母大写，所以源文件通常是Hello.java这样的），并且假如你的Hello.java里写明package com.company;假如你当前置身于D:\code\目录下，执行javac .\src\com\company\Hello.java -d .\bin\表示编译.\src\com\company\Hello.java，将编译好的.class文件按包名层级结构放到.\bin\目录下。于是在D:\code\bin\com\company\下会出现一个Hello.class文件。这时，运行Hello时，跟.java文件就没有关系了。这时如果你置身于D:\code\bin\目录下，最好了，因为我们通常配置环境变量时，CLASSPATH会配置.，也就是当前路径，那你就在D:\code\bin\下执行java，那class也就在当前路径找了：java com.company.Hello，这里java是启动虚拟机的命令，启动时运行哪个类呢？com.company.Hello，这是类名，带着包名，叫全限定名，也就是类的全名，这跟它在哪个目录下没关系，是类名，虚拟机会在CLASSPATH下，也就是当前目录下，去找com.company.Hello这个类，并加载运行。至于它怎么找，你就不用管了。如果你当前正置身于D:\code\下，那你执行java com.company.Hello就失败了，因为虚拟机在CLASSPATH下找不到这个类。那怎么办呢，就要告诉虚拟机，去哪找，也就是要指定CLASSPATH，可以执行：java -classpath .\bin com.company.Hello不知道你能不能理解，你要运行的是com.company.Hello这个类，这是类名，不是目录名，去哪找这个类？用-classpath告诉虚拟机，所以，不能java .\bin\com.company.Hello，这就不伦不类了。 参考http://bbs.csdn.net/topics/390865848]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Log4j笔记]]></title>
    <url>%2F2016%2F08%2F08%2F%5BJava%5DLog4j%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[依赖&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; 快速入门1、新建一个JAva工程，导入包log4j-1.2.17.jar，整个工程最终目录如下 2、src同级创建并设置log4j.properties ### 设置### log4j.rootLogger = debug,stdout,D,E ### 输出信息到控制抬 ### log4j.appender.stdout = org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target = System.out log4j.appender.stdout.layout = org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern = %d{yyyy-MM-dd HH:mm:ss,SSS} [%p] method:%l%n%m%n ### 输出DEBUG级别以上的日志到=E://logs/error.log ### log4j.appender.D = org.apache.log4j.DailyRollingFileAppender log4j.appender.D.File = E://logs/log.log log4j.appender.D.Append = true log4j.appender.D.Threshold = DEBUG log4j.appender.D.layout = org.apache.log4j.PatternLayout log4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n ### 输出ERROR级别以上的日志到=E://logs/error.log ### log4j.appender.E = org.apache.log4j.DailyRollingFileAppender log4j.appender.E.File =E://logs/error.log log4j.appender.E.Append = true log4j.appender.E.Threshold = ERROR log4j.appender.E.layout = org.apache.log4j.PatternLayout log4j.appender.E.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n 3、设置日志内容 package com.mucfc; import org.apache.log4j.Logger; /** *@author linbingwen *@2015年5月18日9:14:21 */ public class Test { private static Logger logger = Logger.getLogger(Test.class); /** * @param args */ public static void main(String[] args) { // System.out.println(&quot;This is println message.&quot;); // 记录debug级别的信息 logger.debug(&quot;This is debug message.&quot;); // 记录info级别的信息 logger.info(&quot;This is info message.&quot;); // 记录error级别的信息 logger.error(&quot;This is error message.&quot;); } } Log4j的架构Log4j由三个重要的组件构成： 日志写入器：控制日志信息的优先级，日志信息的优先级从高到低有ERROR、WARN、 INFO、DEBUG 日志输出终端：指定了日志将打印到控制台还是文件中 日志布局模式：控制日志信息的输出格式 Logger类是日志包的核心，Logger的名称是大小写敏感的，并且名称之间有继承关系。子名由父名做前缀，用点号”.”分隔，如x.y是x.y.z的父亲Logger。 Log4j基本使用方法定义配置文件1、配置根Logger，其语法为： log4j.rootLogger = [ level ] , appenderName, appenderName, … level是日志记录的优先级，Log4j建议只使用四个级别，优先级从高到低分别是ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来 appenderName就是指日志信息输出到哪个地方。您可以同时指定多个输出目的地 2.配置日志信息输出目的地Appender，其语法为： log4j.appender.appenderName = org.apache.log4j.DailyRollingFileAppender 其中，Log4j提供的appender有以下几种： org.apache.log4j.ConsoleAppender（控制台）， org.apache.log4j.FileAppender（文件）， org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）， org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）， org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 3.配置日志信息的格式（布局），其语法为： log4j.appender.appenderName.layout = org.apache.log4j.PatternLayout 其中，Log4j提供的layout有以e几种： org.apache.log4j.HTMLLayout（以HTML表格形式布局）， org.apache.log4j.PatternLayout（可以灵活地指定布局模式）， org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）， org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） 在代码中使用Log4j1.得到记录器 static Logger logger = Logger.getLogger(Class clazz)；//在某对象中，用该对象所属的类作为参数 2.读取配置文件() PropertyConfigurator.configure ( String configFilename) ：读取使用Java的特性文件编写的配置文件 例如： PropertyConfigurator.configure(&quot;config/properties/log4j.properties&quot;); 在项目下面建立一个文件夹名为config即可，这是标准写法。注意log4j默认的相对路径是工程下面，非src或者bin 3.插入记录信息（格式化日志信息） Logger.debug ( Object message ) ; Logger.info ( Object message ) ; Logger.warn ( Object message ) ; Logger.error ( Object message ) ; 配置文件相对路径log4j.appender.R.File=${user.dir}/logs/log.log commons-logging 和 log4j 之间的关系Log4j与通用日志包commons-logging的结合使用其实commons-logging中默认都支持 Log4j，因此只要同时加载commons-logging包和log4j包，可以不用配置即可用在应用中使用commons-logging的接口方法。 当然，标准的应用的是需要的配置，如果你log4j则这个配置是可选的。下面我说明如何通过配置文件来组合commons-logging和log4j。 配置文件内容很简单，就指定一个日志实现类即可，下面是个示例文件commons-logging.properties： org.apache.commons.logging.Log=org.apache.commons.logging.impl.Log4JLogger org.apache.commons.logging.LogFactory=org.apache.commons.logging.impl.LogFactoryImpl commons-logging 和 log4j 之间的关系我们在做项目时，日志的记录是必不可少的一项任务，而我们通常是使用 apache 的 log4j 日志管理工具。然而，在项目中，我们经常会看到两个 jar 包：commons-logging.jar 和 log4j.jar。为什么我们在使用 log4j 的同时还要引入 commons-logging.jar 呢，或者说不用 commons-logging.jar 可不可以，这两者之间到底是怎么的一种关系呢？ 作为记录日志的工具，它至少应该包含如下几个组成部分(组件)： Logger 记录器组件负责产生日志，并能够对日志信息进行分类筛选，控制什么样的日志应该被输出，什么样的日志应该被忽略。它还有一个重要的属性 － 日志级别。不管何种日志记录工具，大概包含了如下几种日志级别：DEBUG, INFO, WARN, ERROR 和 FATAL。 Level 日志级别组件。 Appender 日志记录工具基本上通过 Appender 组件来输出到目的地的，一个 Appender 实例就表示了一个输出的目的地。 Layout Layout 组件负责格式化输出的日志信息，一个 Appender 只能有一个 Layout。 我们再来看看 log4j.jar，打开 jar 包，我们可以看到 Logger.class(Logger)，Level.class(Level), FileAppender.class(Appender)， HTMLLayout.class(Layout)。其它的我们先忽略不看，这几个字节码文件正好是记录日志必不可少的几个组件。 接下来看看 commons-logging 中的 org.apache.commons.logging.Log.java 源码： package org.apache.commons.logging; public interface Log { public boolean isDebugEnabled(); public boolean isErrorEnabled(); public boolean isFatalEnabled(); public boolean isInfoEnabled(); public boolean isTraceEnabled(); public boolean isWarnEnabled(); public void trace(Object message); public void trace(Object message, Throwable t); public void debug(Object message); public void debug(Object message, Throwable t); public void info(Object message); public void info(Object message, Throwable t); public void warn(Object message); public void warn(Object message, Throwable t); public void error(Object message); public void error(Object message, Throwable t); public void fatal(Object message); public void fatal(Object message, Throwable t); } 很显然，只要实现了 Log 接口，它就是一个名副其实的 Logger 组件，也验证了 Logger 组件具有日志级别的属性。继续看 commons-logging org.apache.commons.logging.impl 包下的几个类的源码片段： package org.apache.commons.logging.impl; import org.apache.commons.logging.Log; import org.apache.log4j.Logger; import org.apache.log4j.Priority; import org.apache.log4j.Level; import ...... public class Log4JLogger implements Log, Serializable { // 对 org.apache.commons.logging.Log 的实现 ...... } ------------------------------------------------------------------ package org.apache.commons.logging.impl; import org.apache.commons.logging.Log; import java.io.Serializable; import java.util.logging.Level; import java.util.logging.Logger; public class Jdk14Logger implements Log, Serializable { // 对 org.apache.commons.logging.Log 的实现 ...... } 好了，分析到这里，我们应该知道，真正的记录日志的工具是 log4j 和 sun 公司提供的日志工具。而 commons-logging 把这两个(实际上，在 org.apache.commons.logging.impl 包下，commons-logging 仅仅为我们封装了 log4j 和 sun logger)记录日志的工具重新封装了一遍(Log4JLogger.java 和 Jdk14Logger.java)，可以认为 org.apache.commons.logging.Log 是个傀儡，它只是提供了对外的统一接口。因此我们只要能拿到 org.apache.commons.logging.Log，而不用关注到底使用的是 log4j 还是 sun logger。正如我们经常在项目中这样写： // Run 是我们自己写的类，LogFactory 是一个专为提供 Log 的工厂(abstract class) private static final Log logger = LogFactory.getLog(Run.class); 既然如此，我们向构建路径加了 commons-logging.jar 和 log4j.jar 两个 jar 包，那我们的应用程序到底使用的 log4j 还是 sun logger 呢？我们能不能认为由于加了 log4j.jar 包，就认为系统使用的就是 log4j 呢？事实上当然不是这样的，那我还认为我正在使用 jdk 而认为系统使用的是 sun logger 呢。使用 Spring 的朋友可以在 web.xml 中看到如下 listener 片段： &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt; 这是由 Spring 为我们提供的实现了标准的 servlet api 中的 javax.servlet.ServletContextListener 接口，用于在 web 容器启动时做一些初始化操作。我们逐层进入 Spring 的源码，可以看到如下代码： Log4jConfigurer.initLogging(location, refreshInterval); 终于找到了 org.springframework.util.Log4jConfigurer，这正是 log4j 提供给我们的初始化日志的类。至此，我们终于明白了我们系统的的确确使用的是 log4j 的日志工具。 可是问题又来了，org.apache.commons.logging.Log 和 org.apache.log4j.Logger 这两个类，通过包名我们可以发现它们都是 apache 的项目，既然如下，为何要动如此大的动作搞两个东西(指的是 commons-logging 和 log4j)出来呢？事实上，在 sun 开发 logger 前，apache 项目已经开发了功能强大的 log4j 日志工具，并向 sun 推荐将其纳入到 jdk 的一部分，可是 sun 拒绝了 apache 的提议，sun 后来自己开发了一套记录日志的工具。可是现在的开源项目都使用的是 log4j，log4j 已经成了事实上的标准，但由于又有一部分开发者在使用 sun logger，因此 apache 才推出 commons-logging，使得我们不必关注我们正在使用何种日志工具。 slf4j-api、slf4j-log4j12以及log4j之间的关系几乎在每个jar包里都可以看到log4j的身影，在多个子工程构成项目中，slf4j相关的冲突时不时就跳出来让你不爽，那么slf4j-api、slf4j-log4j12还有log4j是什么关系？ slf4j:Simple Logging Facade for Java，为java提供的简单日志Facade。Facade门面，更底层一点说就是接口。它允许用户以自己的喜好，在工程中通过slf4j接入不同的日志系统。更直观一点，slf4j是个数据线，一端嵌入程序，另一端链接日志系统，从而实现将程序中的信息导入到日志系统并记录。 因此slf4j入口就是众多接口的集合，它不负责具体的日志实现，只在编译时负责寻找合适的日志系统进行绑定。具体有哪些接口，全部都定义在slf4j-api中。查看slf4j-api源码就可以发现，里面除了public final class LoggerFactory类之外，都是接口定义。因此slf4j-api本质就是一个接口定义。 下图比较清晰的描述了它们之间的关系，例子为当系统采用log4j作为日志框架实现的调用关系： ①首先系统包含slf4j-api作为日志接入的接口。compile时slf4j-api中public final class LoggerFactor类中private final static void bind()方法会寻找具体的日志实现类绑定，主要通过StaticLoggerBinder.getSingleton()的语句调用。 ②slf4j-log4j12是链接slf4j-api和log4j中间的适配器。它实现了slf4j-apiz中StaticLoggerBinder接口，从而使得在编译时绑定的是slf4j-log4j12的getSingleton()方法。 ③log4j是具体的日志系统。通过slf4j-log4j12初始化Log4j，达到最终日志的输出。 参考文献http://www.codeceo.com/article/log4j-usage.htmlhttp://blog.csdn.net/hpf911/article/details/5852127http://www.tuicool.com/articles/U7ZjUnihttp://zachary-guo.iteye.com/blog/361177]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dos攻击原理及防御]]></title>
    <url>%2F2016%2F08%2F04%2F%5B%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%5DDos%E6%94%BB%E5%87%BB%E5%8E%9F%E7%90%86%E5%8F%8A%E9%98%B2%E5%BE%A1%2F</url>
    <content type="text"><![CDATA[Dos攻击简介DoS是Denial of Service的简称，即拒绝服务，造成DoS的攻击行为被称为DoS攻击，其目的是使计算机或网络无法提供正常的服务。最常见的DoS攻击有计算机网络 带宽攻击和 连通性攻击。 带宽攻击 指以极大的通信量冲击网络，使得所有可用网络资源都被消耗殆尽，最后导致合法的用户请求无法通过。 连通性攻击 指用大量的连接请求冲击计算机，使得所有可用的操作系统资源都被消耗殆尽，最终计算机无法再处理合法用户的请求。 DDos攻击简介传统上，攻击者所面临的主要问题是网络带宽，由于较小的网络规模和较慢的网络速度的限制，攻击者无法发出过多的请求。但大多数的DoS攻击还是需要相当大的带宽的，而以个人为单位的黑客们很难使用高带宽的资源。为了克服这个缺点，DoS攻击者开发了分布式的攻击。攻击者简单利用工具集合许多的网络带宽来同时对同一个目标发动大量的攻击请求，这就是DDoS(Distributed Denial of Service)攻击。 攻击表现方式★★★无论是DoS攻击还是DDoS攻击，简单的看，都只是一种破坏网络服务的黑客方式，虽然具体的实现方式千变万化，但都有一个共同点，就是其根本目的是使受害主机或网络无法及时接收并处理外界请求，或无法及时回应外界请求。其具体表现方式有以下几种： 1. 制造大流量无用数据，造成通往被攻击主机的网络拥塞，使被攻击主机无法正常和外界通信。 2. 利用被攻击主机提供服务或传输协议上处理重复连接的缺陷，反复高频的发出攻击性的 重复服务请求，使被攻击主机无法及时处理其它正常的请求。 3. 利用被攻击主机所提供服务程序或传输协议的本身实现缺陷，反复发送 畸形的攻击数据 引发系统错误的分配大量系统资源，使主机处于挂起状态甚至死机。 TCP三次连接及重要概念TCP连接三次握手要理解dos攻击，首先要理解TCP连接的三次握手过程(Three-way handshake)。在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接。 第一次握手:建立连接时，客户端发送 SYN 包((SYN=i)到服务器，并进入 SYN_SEND 状态，等待服务器确认; 第二次握手:服务器收到SYN包，必须确认客户的SYN (ACK=i+1 )，同时自己也发送一个SYN包((SYN=j)}即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态; 第三次握手:客户端收到服务器的SYN+ACK包，向服务器发送确认包 ACK (ACK=j+1)，此包发送完毕，客户端和服务器进入 ESTABLISHED 状态，完成三次握手，客户端与服务器开始传送数据。 一些重要概念 半连接：收到SYN包而还未收到ACK包时的连接状态 称为半连接，即尚未完全完成三次握手的TCP连接。 半连接队列：在三次握手协议中，服务器维护一个半连接队列，该队列为每个客户端的SYN包(SYN=i)开设一个条目，该条目表明服务器已收到SYN包，并向客户发出确认，正在等待客户的确认包。这些条目所标识的连接在服务器处于SYN_RECV状态，当服务器收到客户的确认包时，删除该条目，服务器进入ESTABLISHED状态。 Backlog参数：表示半连接队列的最大容纳数目。 SYN-ACK重传次数：服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，如果重传次数超过系统规定的最大重传次数，系统将该连接信息、从半连接队列中删除。注意，每次重传等待的时间不一定相同。 半连接存活时间：是指半连接队列的条目存活的最长时间，也即服务从收到SYN包到确认这个报文无效的最长时间，该时间值是所有重传请求包的最长等待时间总和。有时也称半连接存活时间为Timeout时间、SYN_RECV存活时间。 上面 三个参数 对系统的TCP连接状况有很大影响 常见攻击与防范参考SYN Flood攻击（SYN洪水攻击）大纲： Dos攻击形式解决方法 1、固定源地址发起攻击检测到某个IP地址发起较多报文，加入黑名单 2、伪造IP地址进行攻击方法1失效，原因： 1、单个IP发送的SYN报文不会很多，达不到被拒绝的阈值 2、伪装的IP若被拒绝到，正常用户使用该IP将会无法获得服务 3、可以用三种解决方法方法，如下表 3、僵尸网络固定源地址发起攻击 解决方法问题 方法一：不断监视系统中连接队列，达到阈值就释放系统连接入门级防御SYN Flood方法，正常连接也会淹没在其中而被释放 方法二：延缓TCB分配1、SYS Cache：cache（哈希表）中保存半连接信息，收到正确回应ACK后再分配TCB 2、SYN cookie：根据SYN包按照一定的规则计算SYN+ACK包的初始序列。客户端返回ACK再次校验，若正确才分配TCB 方法三：使用SYN Proxy防火墙防火墙提供SYN代理，验证成功后才放行 原理： 问题就出在TCP连接的三次握手中，假设一个用户向服务器发送了SYN报文后突然死机或掉线，那么服务器在发出SYN+ACK应答报文后是无法收到客户端的ACK报文的(第三次握手无法完成)，这种情况下服务器端一般会重试(再次发送SYN+ACK给客户端)，并等待一段时间后丢弃这个未完成的连接，这段时间的长度我们称为SYN Timeout，一般来说这个时间是分钟的数量级(大约为30秒 - 2分钟); 一个用户出现异常导致服务器的一个线程等待1分钟并不是什么很大的问题，但如果有一个恶意的攻击者大量模拟这种情况，服务器端将为了维护一个非常大的半连接列表而消耗非常多的资源 数以万计的半连接，即使是简单的保存并遍历也会消耗非常多的CPU时间和内存，何况还要不断对这个列表中的IP进行SYN+ACK的重试。实际上如果服务器的TCP/IP栈不够强大，最后的结果往往是堆栈溢出崩溃 即使服务器端的系统足够强大，服务器端也将忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求(毕竟客户端的正常请求比率非常之小)，此时从正常客户的角度看来，服务器失去响应，这种情况我们称作：服务器端受到了SYN Flood攻击(SYN洪水攻击)。 SYN Flood种类： Direct Attack 攻击方使用 固定的源地址 发起攻击，这种方法对攻击方的消耗最小 Spoofing Attack 攻击方使用变化的源地址发起攻击，这种方法需要攻击方 不停地修改源地址，实际上消耗也不大 Distributed Direct Attack 这种攻击主要是使用僵尸网络进行固定源地址的攻击 防范： 对于第一种攻击的防范可以使用比较简单的方法，即对SYN包进行监视，如果发现某个IP发起了较多的攻击报文，直接将这个IP列入黑名单即可。当然下述的方法也可以对其进行防范。对于源地址不停变化的攻击使用上述方法则不行，首先从某一个被伪装的IP过来的Syn报文可能不会太多，达不到被拒绝的阈值，其次从这个被伪装的IP（真实的）的请求会被拒绝掉，即导致正常用户使用该IP将会无法访问服务。因此必须使用其他的方法进行处理。 1． 无效连接监视释放 这种方法不停监视系统的半开连接和不活动连接，当达到一定阈值时拆除这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，而且由于SYN Flood造成的半开连接数量很大，正常连接请求也被淹没在其中被这种方式误释放掉，因此这种方法属于入门级防御SYN Flood方法。 2． 延缓TCB分配方法 从前面SYN Flood原理可以看到，消耗服务器资源主要是因为当SYN数据报文一到达，系统立即分配TCB，从而占用了资源。而SYN Flood由于很难建立起正常连接，因此，当正常连接建立起来后再分配TCB则可以有效地减轻服务器资源的消耗。常见的方法是使用Syn Cache和Syn Cookie技术。 Syn Cache技术： 这种技术是在收到SYN数据报文时不急于去分配TCB，而是先回应一个SYN ACK报文，并在一个专用HASH表（Cache）中保存这种半开连接信息，直到收到正确的回应ACK报文再分配TCB。在FreeBSD系统中这种Cache每个半开连接只需使用160字节，远小于TCB所需的736个字节。在发送的SYN ACK中需要使用一个己方的Sequence Number，这个数字不能被对方猜到，否则对于某些稍微智能一点的Syn Flood攻击软件来说，它们在发送Syn报文后会发送一个ACK报文，如果己方的Sequence Number被对方猜测到，则会被其建立起真正的连接。因此一般采用一些加密算法生成难于预测的Sequence Number。 Syn Cookie技术： 对于SYN攻击，Syn Cache虽然不分配TCB，但是为了判断后续对方发来的ACK报文中的Sequence Number的正确性，还是需要使用一些空间去保存己方生成的Sequence Number等信息，也造成了一些资源的浪费。 Syn Cookie技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS、时间等，在收到对方的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源。(在接收到syn包后不分配TCB资源，而是根据SYN包计算出一个cookie，这个cookie作为将要返回syn+ack包的序号列，服务器中不存储序列号。下次客户端返回ack包时，再根据包头信息计算cookie，与ack包的序号加一进行对比，如果相等，则说明是正常的连接，分配资源建立连接) 3． 使用SYN Proxy防火墙 Syn Cache技术和Syn Cookie技术总的来说是一种主机保护技术，需要系统的TCP/IP协议栈的支持，而目前并非所有的操作系统支持这些技术。因此很多防火墙中都提供一种SYN代理的功能，其主要原理是对试图穿越的SYN请求进行验证后才放行，下图描述了这种过程： 从上图（左图）中可以看出，防火墙在确认了连接的有效性后，才向内部的服务器（Listener）发起SYN请求，在右图中，所有的无效连接均无法到达内部的服务器。而防火墙采用的验证连接有效性的方法则可以是Syn Cookie或Syn Flood等其他技术。 采用这种方式进行防范需要注意的一点就是防火墙需要对整个有效连接的过程发生的数据包进行代理，如下图所示： 因为防火墙代替发出的SYN ACK包中使用的序列号为c，而服务器真正的回应包中序列号为c’，这其中有一个差值|c-c’|，在每个相关数据报文经过防火墙的时候进行序列号的修改。 参考文献什么是Dos攻击？http://blog.csdn.net/justdoitflyer/article/details/12870907SYN Flood攻击及防御方法http://blog.csdn.net/bill_lee_sh_cn/article/details/6065704]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>Dos</tag>
        <tag>DDos</tag>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘分区]]></title>
    <url>%2F2016%2F08%2F01%2F%5BLinux%5D%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[磁盘连接方式与设备文件名的关系 计算机常用的磁盘接口有两种，分别是IDE与SATA接口，目前主流是SATA接口 一个IDE电缆可以连接两个IDE设备，通常主机提供两个IDE接口，因此最多可以接四个IDE设备。IDE设备分为主设备（Master）与从设备（Slave），四个IDE设备的文件名分别是/dev/hda、/dev/hdb、/dev/hdc/、/dev/hdd，对应IDE1的主设备、IDE1的从设备、IDE2的主设备、IDE2的从设备 SATA/USB/SCSI接口的磁盘设备文件名都是/dev/sd[a-p]，与IDE接口不同的是，SATA/USB接口没有一定的顺序，根据Linux内核检测到的磁盘顺序决定，即设备文件名与插槽号无关，Linux内核根据SATA插槽顺序进行检测磁盘，USB在开机候才被系统识别 磁盘组成 磁盘由盘片、机械手臂、磁头与主轴马达组成，数据的写入是在盘片上 盘片上可以细分为扇区与柱面两种单位 磁道：盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道 柱面：硬盘中，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用 扇区：磁盘上的每个磁道被等分为若干个弧段，这些弧段便是磁盘的扇区，每个扇区可以存放512个字节的信息，磁盘驱动器在向磁盘读取和写入数据时，要以扇区为单位 问题1：不同磁道的扇区数是否相同？ 在旧的记录方式，的确每个磁道所拥有的扇区数量都是一样的。因为每个扇区所能容纳的数据量是相同的，都是512字节，而数据量需要平均分配在扇区面积的每个角落，所以外面扇区的数据密度低，里面扇区的速度密度高 新的解决方式认为，既然磁盘越往外面积越大，那就应该划分出更多的扇区，每个扇区的面积都是一样的，容纳的数据量也是一样的 问题2：如果有一块空硬盘，写入一个文件，是不是先写满同一个磁道的所有扇区，然后再换一个磁道写入？ 是的，而且写入的方式是从外到内，先写满最外的磁道，接着再写里面的磁道。为什么硬盘用久了读写速度会变慢？因为外面的磁道使用完了，开始用里面的磁道，越是里面的磁道读写速度越慢，同样的时间，读写头在外面磁道可以扫过10个扇区的面积，读写10个扇区的数据，但在里面的磁道只能扫过1个扇区的面积，读写1个扇区的数据，所以这时该做磁盘整理或者格式化，这会使外面的磁道得到使用 磁盘的第一扇区（主引导分区、分区表）磁盘的第一个扇区记录了两个重要信息，分别是： 主引导分区（MBR），可以安装引导加载程序的地方，有446bytes。MBR是很重要的，系统在开机的时候会主动去读取这个区块的内容，这样系统才知道你的程序放在哪里且如何进行开机。如果你要安装多重引导的系统，MBR这个区块的管理就非常重要了 分区表，记录整块硬盘分区的状态，有64bytes 磁盘分区表 柱面是分割磁盘的最小单位，以开始柱面与结束柱面来标识一个分区 假设上面硬盘的设备文件名为/dev/hda，四个分区的设备文件名会在文件名后再加上一个数字，分别是/dev/hda1，/dev/hda2，/dev/hda3，/dev/hda4 上述硬盘被分为四个分区，第四个分区为301~400柱面的范围，在windows系统中，四个分区分别是C、D、E、F。当你把数据写入F盘时，你的数据会被写入这块磁盘的301~400号柱面之间 分区表总结 所谓的分区就是对64bytes的分区表进行设置而已 分区的最小单位是柱面 分区表默认只能写入四组分区信息，即主分区与扩展分区不超过四个 系统要写入磁盘时，必须参考分区表，才能对某个分区进行数据处理 分区的好处：数据安全，系统性能 分区继续深入 上图中四个分区记录区仅用到两个，P1为主分区，P2为扩展分区 图中这5个由扩展分区切出来的分区叫做逻辑分区 上述分区在Linux下的设备文件名分别是P1：hda1，P2：hda2，L1：hda5，L2：hda6，L3：hda7，L4：hda8，L5：hda9 发现少了hda3，hda4，因为前面四个号码都是保留给主分区和扩展分区用的，所以逻辑分区的设备号从5开始 分区总结 主分区和扩展分区最多有四个 扩展分区最多只有一个（操作系统的限制） 逻辑分区是由扩展分区切割出来的分区 能够被格式化的是主分区和逻辑分区，扩展分区无法格式化 MBR（Master boot Record）主引导分区开机流程 操作系统的作用是控制计算机硬件资源的合理分配，但操作系统也是一个软件，从开机到执行操作系统软件的过程如下： CMOS是记录各项硬件参数且嵌在主板上的存储器，BIOS是写入到主板的一个软件程序，是计算机开机主动执行的第一个的程序 BIOS 会根据用户的设置取得能够开机的硬盘，并读取该硬盘第一个扇区的 MBR 位置，MBR中会放置 引导加载程序，引导加载程序的目的是加载内核文件，内核文件 开始操作系统的功能 多系统 引导加载程序的主要功能是读取内核文件，开始操作系统。在多系统中，引导加载程序能提供用户不同的开机选项，并将加载功能转交给其他引导加载程序 引导加载程序不但可以放置在MBR中，还可以安装在每个分区的引导扇区 如下图是windows和Linux双系统，开机时MBR的引导加载程序提供两个菜单，菜单一（M1）可以直接加载Windows内核文件来开机，菜单二（M2）则将引导加载工作移交给第二个分区的引导加载程序，加载Linux的内核文件来开机 为什么装双系统，最好先装windows再装Linux？ 因为Linux在安装时，可以选择将 引导加载加载程序 安装在MBR还是个别分区的引导扇区 Windows安装时，它的安装程序会主动覆盖掉MBR以及自己所在分区的启动扇区]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Liunx</tag>
        <tag>鸟哥的Linux私房菜</tag>
        <tag>磁盘分区</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的事件监听是怎样实现随时监听的]]></title>
    <url>%2F2016%2F07%2F29%2F%5BJava%5Djava%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC%E6%98%AF%E6%80%8E%E6%A0%B7%E5%AE%9E%E7%8E%B0%E9%9A%8F%E6%97%B6%E7%9B%91%E5%90%AC%E7%9A%84%2F</url>
    <content type="text"><![CDATA[githubhttps://github.com/rhapsody1290/monitor 事件监听机制 Java中的事件监听是整个Java消息传递的基础和关键。牵涉到三类对象：事件源（Event Source）、事件（Event）、事件监听器（Event Listener）。 ● 事件源是事件发生的场所，通常就是各个组件，它可以是一个按钮，编辑框等。 ● 事件监听者负责监听事件源所发生的事件，并对各种事件做出相应的响应。 ● 事件是描述事件源状态改变的对象。 具体实现呢，可以看看Button的源码。可能不好看得懂。那好我们仿照侯捷先生的作法，来模拟一个这样的事件传递： 定义一个自己的事件将事件源中value的最新值告知监听器 public class MyEvent { private int value; public int getValue() { return value; } public void setValue(int value) { this.value = value; } } 做一个监听器接口 Listener当外部响应触发事件源上的事件时，产生一个事件对象，该事件对象会作为参数传递给监听器的事件处理方法 public interface Listener { public void valueChanged(MyEvent e); } 做一个事件发生者 当事件源中的value值发生改变时，会促发事件 监听器在事件源上注册，事件源会保存该监听器，在事件触发时调用监听器的事件处理方法 public class MySource { private int value; private Vector&lt;Listener&gt; listeners = new Vector&lt;Listener&gt;(); /** * 添加监听器 * @param listener */ public void addListener(Listener listener){ listeners.add(listener); } public void setValue(int value){ this.value = value; //发送消息 MyEvent e = new MyEvent(); e.setValue(value); for(int i = 0; i &lt; listeners.size(); i++){ listeners.get(i).valueChanged(e); } } } 注册监听器 如果想监听事件源中value值改变，就在事件源那儿注册一下监听器，然后写消息处理代码就可以了，一般使用匿名内部类的方式定义监听器 这样，当MySource的value真的改变时，就会触发响应 public class Main { /** * @param args */ public static void main(String[] args) { MySource mySource = new MySource(); mySource.addListener(new Listener() { public void valueChange(MyEvent e) { System.out.println(&quot;值改变了：&quot; + e.getValue()); } }); mySource.setValue(1); } } #结果 value changed to:10 Java中AWT/Swing的事件传递的实现，现在版本于上述有所不同，但应该都是这个原理。 总结[图解]★★★★★★ 建议开发顺序： 先编写事件源，事件源中有监听器集合Vector listeners和增加监听器方法addListener 在触发事件源的方法上如setValue，产生事件、并调用监听器方法，将事件以参数传入监听器方法 创建事件类和监听器类 测试，创建事件源——添加监听器——触发事件 思考监听器本质 当调用setValue时，使得value属性的值发生变化，产生事件并调用监听器中对应该属性值改变时做出的处理；而事件不触发时不会产生这个响应，这就起到对一个属性值监控 的作用 使用监听器有什么好处呢？我们可以直接在setValue这个函数中做出响应啊！但是如果直接在serValue中写，这个响应处理不能由程序员自己控制，这是写死的。而采用监听器方法时，通过重写Listener中的事件处理函数，程序员可以自己编写事件处理函数 函数调用顺序是：外界动作调用setValue方法，在这个而方法中去调用监听器中对应的事件处理函数 参考文献[1]. http://www.jcodecraeer.com/a/chengxusheji/java/2012/0822/371.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>事件监听</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面向对象编程的四大特征]]></title>
    <url>%2F2016%2F07%2F29%2F%5BJava%5DJava%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E7%9A%84%E5%9B%9B%E5%A4%A7%E7%89%B9%E5%BE%81%2F</url>
    <content type="text"><![CDATA[抽象 我们在前面去定义一个类时候，实际上就是把一类事物的共有的属性和行为提取出来，形成一个物理模型(模版)。这种研究问题的方法称为抽象。 封装 封装就是把抽象出来的数据和对数据的操作封装在一起。数据被保护在内部，程序的其它部分只有通过被授权的操作(成员方法)，才能对数据进行操作。 ###访问控制修饰符 继承 继承可以解决代码复用，让我们的编程更加靠近人类思维。(变量)和方法时，可以从这些类中抽象出父类(比如刚才的Student)，在父类中定义这些相同的当多个类存在相同的属性属性和方法，所有的子类不需要重新定义这些属性和方法，只需要继承父类,这样子类就会自动拥有父类定义的某些属性和方法。 父类哪些属性、方法被子类继承 父类的public修饰符的属性和方法；protected修饰符的属性和方法；默认修饰符属性和方法被子类继承了，父类的private修饰符的属性和方法不能被子类继承。 注意事项 1. 子类最多只能继承一个父类(指直接继承) 2. java所有类都是Object类的子类 多态方法重载（overload） 简单的说：方法重载就是在类的同一种功能的多种实现方式，具有相同的方法名，但方法的参数类型、个数、顺序不同。到底采用哪种方式，取决于调用者给出的参数。 注意事项 1. 方法返回类型可以不同(只是返回类型不一样，不能构成重载) 2. 方法的修饰符可以不同(只是控制访问修饰符不同，不能构成重载) 方法覆盖（override） 简单的说：方法覆盖就是子类有一个方法，和父类的某个方法的名称、返回类型、参数一样，那么我们就说子类的这个方法覆盖了父类的那个方法。 注意事项： 1、子类的方法的返回类型，参数，方法名称，要和父类的返回类型，参数，方法名称完全一样，否则编译出错。 2、子类方法不能缩小父类方法的访问权限，可以放大访问权限。★★★★ 多态概念 所谓多态，就是指一个引用(类型)在不同情况下的多种状态。也可以理解成：多态是指通过指向父类的指针，来调用在不同子类中实现的方法。 实现多态有两种方式：1、继承；2、接口]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA深复制(深克隆)与浅复制(浅克隆)]]></title>
    <url>%2F2016%2F07%2F29%2F%5BJava%5DJAVA%E6%B7%B1%E5%A4%8D%E5%88%B6(%E6%B7%B1%E5%85%8B%E9%9A%86)%E4%B8%8E%E6%B5%85%E5%A4%8D%E5%88%B6(%E6%B5%85%E5%85%8B%E9%9A%86)%2F</url>
    <content type="text"><![CDATA[参考http://www.cnblogs.com/yxnchinahlj/archive/2010/09/20/1831615.html 浅复制与深复制概念浅复制 被复制的对象的成员变量与原来的对象都有相同的值，但引用其他对象的成员变量仍指向原来的对象，修改引用对象的值，会同时影响原对象与复制对象。换言之，浅复制仅仅复制所考虑的对象，不复制它引用的对象。 深复制 被复制的对象的所有成员变量与原来对象都有相同的值，而且引用其他对象的成员变量将指向被复制过的新对象。换言之，深复制把要复制的对象及所引用的对象都复制了一遍。 java.lang.Object类的clone()方法是浅复制1234567891011121314151617181920212223242526272829303132333435363738394041public class test&#123; public static void main(String[] args)&#123; professor p = new professor(40); student s = new student(&quot;student&quot;, p); student new_s = (student)s.clone(); new_s.p.age = 18; System.out.println(s); System.out.println(new_s); &#125;&#125;class student implements Cloneable&#123; String name; professor p; public student(String name, professor p)&#123; this.name = name; this.p = p; &#125; public Object clone()&#123; Object o = null; try&#123; o = super.clone(); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; return o; &#125; @Override public String toString()&#123; return name + &quot; &quot; + p.age; &#125;&#125;class professor&#123; int age; public professor(int age)&#123; this.age = age; &#125;&#125; 结果： student 18 student 18 因为复制对象中成员变量引用的对象professor不变，当改变新复制对象的成员变量引用值，对原对象也会有影响。 实现深层次克隆方法1 在复制对象时，对引用的对象也进行复制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class test&#123; public static void main(String[] args)&#123; professor p = new professor(40); student s = new student(&quot;student&quot;, p); student new_s = (student)s.clone(); new_s.p.age = 18; System.out.println(s); System.out.println(new_s); &#125;&#125;class student implements Cloneable&#123; String name; professor p; public student(String name, professor p)&#123; this.name = name; this.p = p; &#125; public Object clone()&#123; Object o = null; try&#123; o = super.clone(); ((student)o).p = (professor)this.p.clone();//核心 &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; return o; &#125; @Override public String toString()&#123; return name + &quot; &quot; + p.age; &#125;&#125;class professor implements Cloneable&#123; int age; public professor(int age)&#123; this.age = age; &#125; public Object clone()&#123; Object o = null; try&#123; o = super.clone(); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; return o; &#125;&#125; 实现深层次克隆方法2 利用串行化来做深复制，在Java语言里深复制一个对象，常常可以先使对象实现Serializable接口，然后把对象（实际上只是对象的一个拷贝）写到一个流里，再从流里读出来，便可以重建对象。12345678910111213141516171819202122232425262728293031323334353637383940import java.io.*;public class test&#123; public static void main(String[] args) throws Exception&#123; professor p = new professor(40); student s = new student(&quot;student&quot;, p); student new_s = (student)s.deepClone(); new_s.p.age = 18; System.out.println(s); System.out.println(new_s); &#125;&#125;class student implements Serializable&#123; String name; professor p; public student(String name, professor p)&#123; this.name = name; this.p = p; &#125; public Object deepClone() throws Exception&#123; //将对象写到流里 ByteArrayOutputStream bo = new ByteArrayOutputStream(); ObjectOutputStream oo = new ObjectOutputStream(bo); oo.writeObject(this); //从流里读出来 ByteArrayInputStream bi = new ByteArrayInputStream(bo.toByteArray()); ObjectInputStream oi = new ObjectInputStream(bi); return oi.readObject(); &#125; @Override public String toString()&#123; return name + &quot; &quot; + p.age; &#125;&#125;class professor implements Serializable&#123; int age; public professor(int age)&#123; this.age = age; &#125;&#125; 结果： student 40 student 18]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>深克隆与浅克隆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合]]></title>
    <url>%2F2016%2F07%2F29%2F%5BJava%5DJava%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[集合框架–使用 开发常用 ● 在实际开发过程中，比较常用的是Vector、Stack、ArrayList、LinkedList、HashMap、HashTable ● 集合类基本上在util包中 集合分类 Java集合类主要有以下几种 ● List结构的集合类：ArrayList、LinkedList、Vector、Stack ● Map结构的集合类：HashMap、HashTable ● Set结构的集合类：HashSet、TreeSet ● Queue结构的集合：Queue接口 List结构的集合类ArrayList类的使用(无同步性，线程不安全) 基于动态数组的数据结构，随机访问优于LinkedList123456789101112131415161718192021222324public class ArrayList1. 往list中插入元素 ● boolean add(E e) 元素添加到列表的尾部 ● void add(int index, E element) 元素插入到列表的指定位置2. 返回列表中的元素数 ● int size() 返回列表中的元素数 3. 如果此列表中没有元素，则返回 true ● boolean isEmpty() 4. 返回此列表中指定位置上的元素 ● E get(int index) 5. 用指定的元素替代此列表中指定位置上的元素,返回值是以前位于该位上的元素 ● E set(int index, E element) 6. 移除列表上的元素 ● E remove(int index) 移除此列表中指定位置上的元素 ● boolean remove(Object o) 移除此列表中首次出现的指定元素（如果存在） ● protected void removeRange(int fromIndex, int toIndex) 移除列表中索引在 fromIndex（包括）和 toIndex（不包括）之间的所有元素。 ● void clear() 移除列表中所有元素7. 查找元素 ● contains(Object o) 判断list中是否含有指定元素 ● int indexOf(Object o) 返回list中元素第一次出现的位置,若没有则返回-1 ● int lastIndexOf(Object o) 返回arraylist中元素最后一次出现的位置,若没有则返回-18. 返回包含此列表中所有元素的数组（按顺序），相当于数组API和collection API的桥梁,返回一个object的数组 ● Object[] toArray() LinkedList类的使用 基于链表的数据结构，新增add和删除remove操作优于ArrayList12341. 将指定元素插入此列表的开头 ● void addFirst(E e) 2. 将指定元素添加到此列表的结尾 ● void addLast(E e) Vector同理(线程安全具有同步性)Stack123456789101. 测试堆栈是否为空 boolean empty() 2. 查看堆栈顶部的对象，但不从堆栈中移除它 E peek() 3. 移除堆栈顶部的对象，并作为此函数的值返回该对象 E pop() 4. 把项压入堆栈顶部 E push(E item) 5. 返回对象在堆栈中的位置，以 1 为基数 int search(Object o) ArrayList和Vector的区别123456ArrayList和Vector的区别 ArrayList与Vector都是java的集合类，都可以用来存放java对象，这是他们的相同点，但是他们也有区别：1、同步性 Vector是线程同步的。这个类中的一些方法保证了Vector中的对象是线程安全的。而ArrayList则是线程异步的，因此ArrayList中的对象并不是线程安全的。因为同步的要求会影响执行的效率，所以如果你不需要线程安全的集合那么使用ArrayList是一个很好的选择，这样可以避免由于同步带来的不必要的性能开销。2、数据增长 从内部实现机制来讲ArrayList和Vector都是使用数组(Array)来控制集合中的对象。当你向这两种类型中增加元素的时候，如果元素的数目超出了内部数组目前的长度它们都需要扩展内部数组的长度，Vector缺省情况下自动增长原来一倍的数组长度，ArrayList是原来的50%，所以最后你获得的这个集合所占的空间总是比你实际需要的要大。所以如果你要在集合中保存大量的数据那么使用Vector有一些优势，因为你可以通过设置集合的初始化大小来避免不必要的资源开销。 Map结构的集合类HashMap（线程不同步），HashTable（线程同步）集合类123456789101112void clear() 从此映射中移除所有映射关系。 V get(Object key) 返回指定键所映射的值；如果对于该键来说，此映射不包含任何映射关系，则返回 null。 boolean isEmpty() 如果此映射不包含键-值映射关系，则返回 true。 V put(K key, V value) 在此映射中关联指定值与指定键。 V remove(Object key) 从此映射中移除指定键的映射关系（如果存在）。 int size() 返回此映射中的键-值映射关系数。 Map遍历1. Map.Entry&lt;String, String&gt;的数据类型为键值对。 2. map.entrySet(),返回类型为Set&lt;Entry&lt;String, String&gt;&gt; ，即map中非空元素组成的键值对Set集合，可以用图例（key1,value1）,(key2,value2)...(keyn,valuen)表示。 3. Map.Entry&lt;String, String&gt;类型分别通过getKey()、getValue()方法取出键和值。 4. 可以通过map.keySet()方法取出全部键的Set集合，从而通过map.get(Object key)方法取出值，即方法一。 5. 可以通过map.value()得到Collection&lt;String&gt;集合，得到所有值。即方法四 6、方法二中使用迭代器对数据遍历，类型是Map.Entry&lt;String, String&gt;，即仍旧是键值对，集合是map.entrySet().iterator()，比方法三麻烦。 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put("1", "value1"); map.put("2", "value2"); map.put("3", "value3"); //第一种：普遍使用，二次取值 System.out.println("通过Map.keySet遍历key和value："); for (String key : map.keySet()) &#123; System.out.println("key= "+ key + " and value= " + map.get(key)); &#125; //第二种 System.out.println("通过Map.entrySet使用iterator遍历key和value："); Iterator&lt;Map.Entry&lt;String, String&gt;&gt; it = map.entrySet().iterator(); while (it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = it.next(); System.out.println("key= " + entry.getKey() + " and value= " + entry.getValue()); &#125; //第三种：推荐，尤其是容量大时 System.out.println("通过Map.entrySet遍历key和value"); for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; System.out.println("key= " + entry.getKey() + " and value= " + entry.getValue()); &#125; //第四种 System.out.println("通过Map.values()遍历所有的value，但不能遍历key"); for (String v : map.values()) &#123; System.out.println("value= " + v); &#125; &#125; HashMap和Hashtable集合类的区别HashMap与Hashtable都是java的集合类，都可以用来存放java对象，这是他们的相同点，但是他们也有区别。 1、历史原因 Hashtable是基于陈旧的Dictionary类的，HashMap是java 1.2引进的Map接口的一个实现。 2、同步性 Hashtable是线程同步的。这个类中的一些方法保证了Hashtable中的对象是线程安全的。而HashMap则是线程异步的，因此HashMap中的对象并不是线程安全的。因为同步的要求会影响执行的效率，所以如果你不需要线程安全的集合那么使用HashMap是一个很好的选择，这样可以避免由于同步带来的不必要的性能开销，从而提高效率。 3、值 HashMap可以让你将空值作为一个表的条目的key或value但是Hashtable是不能放入空值的(null) List、Map集合框架的选择★（常用）★★★★如何选用集合类？ 1、要求线程安全，使用Vector、Hashtable 2、不要求线程安全，使用ArrayList,LinkedList,HashMap 3、要求key和value键值，则使用HashMap,Hashtable 4、数据量很大，又要线程安全，则使用Vector Set结构的集合类用法123456789101112131415#添加add(Object)#遍历Iterator&lt;String&gt; iterator = hashSet.iterator();while(iterator.hasNext())&#123; System.out.println(iterator.next());&#125;#删除元素删除一个元素 remove(Object)删除所有元素 clear()#包含contain(Object) HashSet与TreeSet区别 HashSet随机存储对象，不能保证先插入的元素出现在前面；TreeSet中元素默认按照元素自然序进行排列，使用compareTo()方法自定义排序 HashSet内部依靠HashMap，而TreeSet依靠TreeMap HashSet可以存储空对象，但TreeSet不允许 性能，HashSet对基本操作add，remove，size有常数的时间复杂度，TreeSet有log(n)的时间复杂度 TreeSet比起HashSet具有更多丰富的功能，例如pollFirst(),pollLast(),first(),last(),celling(),lower()等 比较，HashSet使用equals()方法进行比较，而TreeSet使用compareTo()方法获得排列顺序 HashSet与TreeSet相同点 只能存储独一无二的元素，不允许任何重复的元素 不是线程安全 Clone方法有相同的实现技术 Queue结构的集合]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java类加载器深入讲解]]></title>
    <url>%2F2016%2F07%2F29%2F%5BJava%5DJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[什么是类加载器? 加载类的工具，把硬盘上.class文件加载到内存，并进行一些处理，得到字节码 类加载器有什么作用? 当程序需要的某个类，那么需要通过类加载器把类的二进制加载到内存中，类加载器也是Java类 类加载器之间的父子关系和管辖范围。 1234567#获得类加载器的名字ClassLoader classLoader = ClassLoaderTest.class.getClassLoader();while (classLoader != null) &#123; System.out.println(classLoader.getClass().getName()); classLoader = classLoader.getParent();&#125;System.out.println(classLoader); ##4. 类加载器的委托机制: 类的加载 当Java虚拟机要加载一个类时，到底派出哪个类加载器去加载呢? ①首先 当前线程的类加载器 去加载线程中的第一个类. ②如果类A中引用了类B，Java虚拟机将使用加载类A的类加载器加载类B ③还可以直接调用ClassLoader.loadClass()方法来指定某个类加载器去加载某个类. 每个类加载器加载类时，又先委托给其上级类加载器 当所有祖宗类加载器没有加载到类，回到发起者类加载器，如果还加载不了，则抛出ClassNotFoundException异常。它不会去找发起者类加载器的儿子，因为没有getChild()方法，即使有，有那么多的儿子交给那一个呢?所以干脆就不交给儿子处理了。 委托机制有什么好处? 集中管理，如果我们写了几个类加载器，都去加载某个类，那么内存中就有多份这个类的字节码 安全。系统类由系统的类加载器加载 能不能自己写一个类叫java.lang.System? 为了不让我们写System类，类加载采用委托机制，这样可以保证爸爸优先，也就是使用的永远是爸爸的(系统的)System类，而不是我们写的System类. 编写自己的类加载器123456789101112131415161718192021222324public static void main(String[] args) throws Exception &#123; String srcPath = args[0]; String destDir = args[1]; FileInputStream fis = new FileInputStream(srcPath); String destFileName = srcPath.substring(srcPath.lastIndexOf('\\')+1); String destPath = destDir + "\\" + destFileName; FileOutputStream fos = new FileOutputStream(destPath); cypher(fis，fos); fis.close(); fos.close(); &#125; /** * 加密方法，同时也是解密方法 * @param ips * @param ops * @throws Exception */ private static void cypher(InputStream ips ，OutputStream ops) throws Exception&#123; int b = -1; while((b=ips.read())!=-1)&#123; ops.write(b ^ 0xff);//如果是1就变成0，如果是0就变成1 &#125; &#125; 然后在新建一个类，通过上面的方法将新建的类的字节码进行加密:12345public class ClassLoaderAttachment extends Date &#123; //为什么要继承Date待会再说? public String toString()&#123; return "hello，itcast"; &#125; &#125; 并在工程里新建一个文件夹，用来保存加密后的class文件. 那么这就需要使用我们自己的类加载器来进行解密了.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MyClassLoader extends ClassLoader&#123; public static void main(String[] args) throws Exception &#123; String srcPath = args[0]; String destDir = args[1]; FileInputStream fis = new FileInputStream(srcPath); String destFileName = srcPath.substring(srcPath.lastIndexOf('\\')+1); String destPath = destDir + "\\" + destFileName; FileOutputStream fos = new FileOutputStream(destPath); cypher(fis，fos); fis.close(); fos.close(); &#125; /** * 加密方法，同时也是解密方法 * @param ips * @param ops * @throws Exception */ private static void cypher(InputStream ips ，OutputStream ops) throws Exception&#123; int b = -1; while((b=ips.read())!=-1)&#123; ops.write(b ^ 0xff);//如果是1就变成0，如果是0就变成1 &#125; &#125; private String classDir; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; String classFileName = classDir + "\\" + name.substring(name.lastIndexOf('.')+1) + ".class"; try &#123; FileInputStream fis = new FileInputStream(classFileName); ByteArrayOutputStream bos = new ByteArrayOutputStream(); cypher(fis，bos); fis.close(); System.out.println("aaa"); byte[] bytes = bos.toByteArray(); return defineClass(bytes， 0， bytes.length); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public MyClassLoader()&#123; &#125; public MyClassLoader(String classDir)&#123; this.classDir = classDir; &#125;&#125; 测试运行代码:12345Class clazz = new MyClassLoader("myClass").loadClass("ClassLoaderAttachment");//此处不能在使用ClassLoaderAttachment因为一旦用了之后，//系统的类加载器就会去加载，导致失败，所以该类就继承了Date类了.Date date = (Date)clazz.newInstance();System.out.println(date); 运行结果： 一个类加载器的高级问题: 我们知道tomcat服务器，是一个大大的java程序，那么它就必须在JVM上运行.这个大大的java程序内部也写了很多类加载器，它用这些类加载器去加载一些特定的类.注入servlet类.下面我们新建一个javaweb工程，新建一个servlet程序.123456789101112public void doGet(HttpServletRequest request， HttpServletResponse response) throws ServletException， IOException &#123; response.setContentType("text/html"); PrintWriter out = response.getWriter(); ClassLoader classload = this.getClass().getClassLoader(); while (classload != null) &#123; out.println(classload.getClass().getName()+"&lt;br&gt;"); classload = classload.getParent(); &#125; out.println(); out.close();&#125; 然后配置服务器，部署应用程序，启动tomcat服务器.在页面访问我们这个servlet，在页面打印的结果如下图所示:这是从小到大排序的.现在呢?我想把该servlet打成jar包，放在ExtClassLoad类加载器加载的路径.通过Eclipse即可完成]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring笔记]]></title>
    <url>%2F2016%2F07%2F15%2F%5BSpring%5DSpring%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Spring是什么 struts是web框架 (jsp/action/actionfrom) hibernate是orm框架，处于持久层 spring是容器框架，用于配置各个层的bean（action/service/domain/dao），并维护bean之间关系的框架 面试回答：Spring就是一个轻量级的控制反转（IoC）和面向切面（AOP）的容器框架。 spring中重要概念★★★★★bean Spring管理的对象为bean bean是java中的任何一种对象（javabean/service/action/数据源/dao），spring作用是配置各个层中的组件（bean），并维持组件（bean）之间的关系 JavaBean必须拥有一个无参的构造器，通过get/set方法访问参数，同时支持持久化 控制反转 ioc(inverse of control，控制反转)，控制反转就是把创建对象（bean）和维护对象（bean）的关系的权利从程序中转移到spring容器中（applicationContext.xml），只需配置一下就能完成 使用Spring，程序中几乎所有重要的组件的创建工作和维护组件之间的依赖关系都移交给Spring 依赖注入 di(dependency injection，依赖注入)，实际上di和ioc是同一概念，spring设计者认为di更准确表示spring核心技术 依赖注入接管对象的创建工作，并将该对象的引用注入需要该对象的组件 /* 有两个组件A和B，A依赖于B，且A中的importantMethod方法调用了B的方法， 使用B前，类A必须先获得组件B的实例（具体类可以new一个B实例，但如果B是接口，使用B的一个实现类，会降低A的可重用性） 使用依赖注入，框架会接管对象B的创建工作，并将B对象的引用注入到A中，具体是类A中的setB方法会被框架调用，注入一个B的实例， 这样类A的importantMethod方法在使用B的userfulMethod方法前不再需要创建一个B的实例 */ public class A { private B b; public B getB() { return b; } public void setB(B b) { this.b = b; } public void importantMethod(){ b.userfulMethod(); } } Spring在程序中的位置 Spring层次图如下图所示 Login.jsp与用户交互，将数据传递给Action.java处理器，Action.java一般与表单ActionForm关联，验证成功跳转到ok.jsp。这一层是web层，Struts位于web层 验证过程中，会调用UserService.java，这是业务层。业务层会有一个domain对象，Users.java[或者叫javabean，pojo] 业务层下是DAO层，它是对数据的操作 下面就是数据持久层，hibernate就位于持久层，它是一个orm框架 最底层的就是数据库 model层分为业务层（Service），DAO层和数据持久层，在开发过程中，可以根据实际情况进行选择组合，并不是必须把model层分得这么细 Spring横跨web层、业务层、DAO层、持久层，可以配置各个层的组件（JavaBean），并且维护各个bean之间的关系 具体的来说，spring可以配置web层的action[解决actin单例问题]，业务层的domain/service/dao以及数据持久层配置数据源 在配置文件中，体现出Spring创建各种组件及维持组件之间的关系 &lt;bean id = "bean1" class = "">配置bean &lt;property name = "" value = "">&lt;/property> &lt;/bean> &lt;bean id = "bean2" class = "">维护bean之间的关系(bean2依赖bean1) &lt;property name = "" ref="">&lt;/property> &lt;/bean> Spring快速入门githubhttps://github.com/rhapsody1290/Spring_Study 引入依赖&lt;properties&gt; &lt;!-- spring版本号 --&gt; &lt;spring.version&gt;4.0.2.RELEASE&lt;/spring.version&gt; &lt;!-- log4j日志文件管理包版本 --&gt; &lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.16&lt;/log4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;!-- 表示开发的时候引入，发布的时候不会加载此包 --&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 导入Mysql数据库链接jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.13&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring核心包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-oxm&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring事务--&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 格式化对象，方便输出日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.1.41&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建组件创建组件A、B，其中A组件依赖B 类A public class A { private B b; public void importantMethod(){ System.out.println(&quot;A:importantMethod&quot;); b.usefulMethod(); } public B getB() { return b; } public void setB(B b) { this.b = b; } } 类B public class B { public void usefulMethod() { System.out.println(&quot;B:usefulMethod&quot;); } } applicationContext.xml中配置beanapplicationContext.xml是spring的一个核心配置文件, [hibernate有核心文件hibernate.cfg.xml struts核心文件 struts-config.xml] &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!-- 在容器文件中配置bean(service/dao/domain/action/数据源) --&gt; &lt;!-- bean元素的作用是，当我们的spring框架加载时候，spring就会自动的创建一个bean对象,并放入内存--&gt; &lt;bean id = &quot;A&quot; class=&quot;hello.A&quot;&gt; &lt;!-- 这里就体现出注入的概念，将B对象的引用注入到A中的b属性--&gt; &lt;property name=&quot;b&quot; ref=&quot;B&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;B&quot; class=&quot;hello.B&quot;/&gt; &lt;/beans&gt; 获得bean并调用方法public class testSpringAPI { private ApplicationContext context; @Before public void setUp() throws Exception { //1.得到spring 的applicationContext对象(容器对象) context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); } @Test public void testName() throws Exception { //2、利用java反射机制获取bean对象 A a = (A) context.getBean(&quot;A&quot;); a.importantMethod(); } } Spring运行原理图 当ApplicationContext ac = new ClassPathXmlApplicationContext(“applicationContext.xml”);执行的时候，Spring容器对象将被创建，同时applicationContext.xml中配置的bean就会被创建 UserService us = (UserService)ac.getBean(‘UserService’);调用后取出bean，取出的bean对象是单例 bean的存储结构类似HashMap/HashTable，分为id和bean对象。id对应配置文件中bean元素的id，对象在Spring容器对象创建时创建并存放。若有引用关系，则指向引用对象的id Spring框架扫描XML文件，利用Java反射机制，创建一个个bean对象 可以利用dom4j+java反射机制模拟Spring运行流程。扫描xml文件，检测到bean元素，利用Java反射机制创建对象，并设置属性值，存入HashMap userService = Class.forName("com.service.UserService"); userService.setName("韩顺平"); applicationContext = new HashMap(); applicationContext.put("userService",userService); Spring接口编程spring开发提倡接口编程,配合di技术可以层与层的解耦 举例说明:现在我们体验一下spring的di配合接口编程的，完成一个字母大小写转换的案例:思路: 创建一个接口 ChangeLetter public interface ChangeLetter { public String change(); } 两个类实现接口 public class LowerLetter implements ChangeLetter { private String str; public String getStr() { return str; } public void setStr(String str) { this.str = str; } @Override public String change() { return str.toLowerCase(); } } public class UpperLeter implements ChangeLetter { private String str; public String getStr() { return str; } public void setStr(String str) { this.str = str; } @Override public String change() { return str.toUpperCase(); } } 把对象配置到spring容器中 &lt;bean id="changeLetter" class="cn.apeius.inter.UpperLeter"> &lt;property name="str" value="abc">&lt;/property> &lt;/bean> &lt;!-- &lt;bean id="changeLetter" class="cn.apeius.inter.LowerLetter"> &lt;property name="str" value="ABC">&lt;/property> &lt;/bean>--> 使用 ApplicationContext ac = new ClassPathXmlApplicationContext("beans.xml"); ChangeLetter us= (ChangeLetter) ac.getBean("changeLetter"); System.out.println(us.change()); 通过上面的案例，我们可以初步体会到di配合接口编程，的确可以减少层(web层) 和 业务层的耦合度. XML配置文件 配置文件的根元素通常为 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;/beans&gt; 如果需要更强的Spring配置能力，可以在schemaLocation属性中添加相应地schema 配置文件可以是一份，也可以是多份，ApplicationContext的实现类支持读取多份配置文件 ApplicationContext context = new ClassPathXmlApplicationContext(new String[]{&quot;applicationContext.xml&quot;,&quot;applicationContext2.xml&quot;}); 三种获取ApplicationContext对象引用的方法ApplicationContext对象代表一个Spring控制反转容器，org.springframework.context.ApplicationContext接口有多个实现，包括： 1、ClassPathXmlApplicationContext -&gt; 通过类路径加载配置文件 ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); 2、FileSystemXmlApplicationContext -&gt; 通过文件路径加载配置文件 ApplicationContext context = new FileSystemXmlApplicationContext("配置文件绝对路径"); 3、XmlWebApplicationContext 从web系统中加载 两个获取bean的方式★★★从ApplicationContex应用上下文容器中获取bean基本模式创建一个bean实例★★★★★Spring通过默认无参的构造器来创建一个bean实例 配置文件 &lt;bean id=&quot;B&quot; class=&quot;hello.B&quot;/&gt; 获取bean //1.得到spring 的applicationContext对象(容器对象) ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); //从容器中取出一个bean的实例 B b = ac.getBean(&quot;B&quot;, B.class); b.usefulMethod(); 工厂模式创建一个bean实例1、定义一个接口 public interface Animal { public void sayHello(); } 2、接口的两个实现类 Cat public class Cat implements Animal { public void sayHello() { System.out.println(&quot;Cat&quot;); } } Dog public class Dog implements Animal { public void sayHello() { System.out.println(&quot;Dog&quot;); } } 3、AnimalFactory工厂中包含了一个getAnimal的静态方法，该方法将根据传入的参数决定创建哪个对象。这是典型的静态工厂设计模式 public class AnimalFactory { public static Animal getAnimal(String type){ if(&quot;Cat&quot;.equals(type)){ return new Cat(); }else if(&quot;Dog&quot;.equals(type)){ return new Dog(); } return null; } } 4、Spring配置文件中作如下配置 &lt;bean id=&quot;cat&quot; class=&quot;Factory.AnimalFactory&quot; factory-method=&quot;getAnimal&quot;&gt; &lt;constructor-arg value=&quot;Cat&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;dog&quot; class=&quot;Factory.AnimalFactory&quot; factory-method=&quot;getAnimal&quot;&gt; &lt;constructor-arg value=&quot;Dog&quot;/&gt; &lt;/bean&gt; 使用静态工厂方法创建Bean实例时，class属性也必须指定，但此时class属性并不是指定Bean实例的实现类，而是静态工厂类 需要使用factory-method来指定静态工厂方法名，Spring将调用静态工厂方法来返回一个Bean实例，使用元素来为静态工厂方法指定参数 当使用静态工厂方法来创建Bean时，这个factory-method必须要是静态的 从bean工厂容器中获取bean//如果我们使用beanfactory去获取bean，当你创建Spring容器时bean不被实例化,只有当你去使用getBean某个bean时，才会实时的创建 BeanFactory factory = new XmlBeanFactory( new ClassPathResource(&quot;applicationContext.xml&quot;)); factory.getBean(&quot;A&quot;); 结论 如果使用ApplicationContext ，则配置的bean如果是singlton不管你用不用，都被实例化.(好处就是可以预先加载,缺点就是耗内存) 如果是 BeanFactory ,则当你获取beanfacotry时候，配置的bean不会被马上实例化，当你使用的时候，才被实例(好处节约内存,缺点就是速度) 规定: 一般没有特殊要求，应当使用ApplicatioContext完成(实际项目中90%都采用这种方式) bean的生命周期为什么总是一个生命周期当做一个重点? 例如我们经常需要知道Servlet的生命周期，初始化init和销毁destroy，还有讨论java对象生命周期 不懂servlet的生命周期，你一样可以做开发。但是只有把一个新的技术对应的对象的生命周期弄清楚时，你才能真正的驾驭他。你知道Servlet创建的时候会调用init，才会把初始化工作放在init中，你知道Servlet销毁时会调用destroy，才会把文件备份的工作放在destroy中 bean的生命周期 bean被载入到容器中时，它的生命周期就开始了 ① 实例化★ 当我们的程序加载beans.xml文件，把我们的bean实例化到内存 默认调用无参的构造方法 以上我们考虑的是scope=singleton，单例模式最复杂 ② 调用set方法设置属性★③ 如果你实现了bean名字关注接口BeanNameAware则，可以通过setBeanName获取id号④ 如果你实现了bean工厂关注接口BeanFactoryAware,则可以获取BeanFactory⑤ 如果你实现了ApplicationContextAware接口，则可以获得应用程序上下文 //该方法传递ApplicationContext public void setApplicationContext(ApplicationContext arg0) throws BeansException { // TODO Auto-generated method stub System.out.println(&quot;setApplicationContext&quot;+arg0); } ⑥ 如果bean和一个后置处理器关联，则实例化一个bean时，会自动去调用before方法。体现AOP（面向切片编程），放置一些公共方法，例如过滤ip，给对象添加属性等★ 自定义一个类myBeanPostProcessor，实现BeanPostProcessor接口，重写before和after两个方法 # myBeanPostProcessor.java public class myBeanPostProcessor implements BeanPostProcessor { @Override public Object postProcessBeforeInitialization(Object o, String s) throws BeansException { //对象o对实例化的bean对象，s为bean的id System.out.println("postProcessBeforeInitialization"); return o; } @Override public Object postProcessAfterInitialization(Object o, String s) throws BeansException { System.out.println("postProcessAfterInitialization"); return o; } } xml文件中配置 &lt;bean id = &quot;myBeanPostProcessor&quot; class=&quot;cn.apeius.beanlift.myBeanPostProcessor&quot;&gt;&lt;/bean&gt; 运行 ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); PersonService personService = (PersonService) ac.getBean(&quot;PersonService&quot;); personService.sayHi(); 结果：bean对象创建后会自动调用before和after方法。类似JavaWeb中的过滤器 构造函数被调用 调用set方法 postProcessBeforeInitialization postProcessAfterInitialization 你好啊 钱钱 ⑦ 如果你实现InitializingBean接口，则会调用afterPropertiesSet⑧ 如果自己配置&lt;bean init-method=&quot;init&quot; /&gt;，则可以在bean定义自己的初始化方法init。也可以通过注解的方式@PostConstruct⑨ 如果bean和一个后置处理器关联,则会自动去调用Object postProcessAfterInitialization方法⑩ 使用我们的bean⑪ 容器关闭⑫ 可以通过实现DisposableBean接口来调用方法destory⑬ 可以在&lt;bean destory-method=&quot;fun1&quot;/&gt;调用定制的销毁方法。可以通过注解的方式@PreDestroy 小结: 我们实际开发中往往，没有用的这么的过程,常见的是:1-&gt;2-&gt;6-&gt;10-&gt;9-&gt;11 问题:通过BeanFactory来获取bean对象，bean的生命周期是否和 Applicationcontext 是一样吗? 不是一样的，bean是工厂中创建的生命周期会简单一些: 比起ApplicationContext创建bean，通过BeanFactory少了一下步骤 ⑤ 如果你实现了ApplicationContextAware接口，则可以获得应用程序上下文 ⑥ 如果bean和一个后置处理器关联，则实例化一个bean时，会自动去调用before方法。 ⑨ 如果bean和一个后置处理器关联,则会自动去调用Object postProcessAfterInitialization方法 bean装配的细节注入的写法★基础数据类型注入 一个标签 &lt;property name="name" value="财务部"/> 两个标签 &lt;property name="name"> &lt;value>财务部&lt;/value> &lt;/property> 对象注入 # 方法一：利用property的ref属性，这是一种简写方式 &lt;bean id="Department" class="cn.apeius.collections.Department"> &lt;property name="emp" ref="Emp"/> &lt;/bean> &lt;bean id="Emp" class="cn.apeius.collections.Emp"> &lt;property name="id" value="1"/> &lt;property name="name" value="qm"/> &lt;/bean> # 方法二：ref标签 &lt;bean id="Department" class="cn.apeius.collections.Department"> &lt;property name="emp"> &lt;ref bean="Emp"/> &lt;/property> &lt;/bean> &lt;bean id="Emp" class="cn.apeius.collections.Emp"> &lt;property name="id" value="1"/> &lt;property name="name" value="qm"/> &lt;/bean> # 方法三：内部配置 &lt;bean id="Department" class="cn.apeius.collections.Department"> &lt;property name="emp"> &lt;bean class="cn.apeius.collections.Emp"> &lt;property name="id" value="1"/> &lt;property name="name" value="qm"/> &lt;/bean> &lt;/property> &lt;/bean> bean的作用域scope singleton(默认)，单态，尽量使用scope=”singleton”,不要使用prototype,因为这样对我们的性能影响较大，除非有必要. //获取两个student Student s1=(Student) ac.getBean("student"); Student s2=(Student) ac.getBean("student"); System.out.println(s1 == s2);//一样 prototype //获取两个student Student s1=(Student) ac.getBean("student"); Student s2=(Student) ac.getBean("student"); System.out.println(s1 == s2);//不一样 request session global-session 是在web开发中才有意义 如何给集合类型注入值java中主要的集合有几种: map set list / 数组 给数组注入值 &lt;property name=&quot;empName&quot;&gt; &lt;list&gt; &lt;value&gt;小明&lt;/value&gt; &lt;value&gt;小明小明&lt;/value&gt; &lt;value&gt;小明小明小明小明&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; 给list注入值 list 中可以有相同的对象 &lt;property name=&quot;empList&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;emp2&quot; /&gt; &lt;ref bean=&quot;emp1&quot;/&gt; &lt;ref bean=&quot;emp1&quot;/&gt; &lt;/list&gt; &lt;/property&gt; &lt;bean id=&quot;emp1&quot; class=&quot;com.hsp.collection.Employee&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;北京&quot;/&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;emp2&quot; class=&quot;com.hsp.collection.Employee&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;天津&quot;/&gt; &lt;property name=&quot;id&quot; value=&quot;2&quot;/&gt; &lt;/bean&gt; 给set注入值set不能有相同的对象 &lt;property name=&quot;empsets&quot;&gt; &lt;set&gt; &lt;ref bean=&quot;emp1&quot; /&gt; &lt;ref bean=&quot;emp2&quot;/&gt; &lt;ref bean=&quot;emp2&quot;/&gt; &lt;/set&gt; &lt;/property&gt; 给map注入值，key为索引，value指定值，如果为Java对象，则使用ref指定，或者使用bean定义。如果key为对象，使用key-ref属性 &lt;property name=&quot;empMaps&quot;&gt; &lt;map&gt; &lt;entry key=&quot;11&quot; value-ref=&quot;emp1&quot; /&gt; &lt;entry key = &quot;12&quot; value = &quot;emp2&quot; /&gt; &lt;entry key-ref=&quot;13&quot; value=&quot;emp3&quot; /&gt; &lt;entry key-ref=&quot;14&quot; value-ref=&quot;emp4&quot; /&gt; &lt;/map&gt; &lt;/property&gt; 给属性集合配置，即Property对象 &lt;property name=&quot;pp&quot;&gt; &lt;props&gt; &lt;prop key=&quot;pp1&quot;&gt;abcd&lt;/prop&gt; &lt;prop key=&quot;pp2&quot;&gt;hello&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; 内部bean&lt;bean id=&quot;foo&quot; class=&quot;....Foo&quot;&gt; &lt;property name=&quot;属性&quot;&gt; &lt;!—第一方法引用--&gt; &lt;ref bean=&quot;bean对象名&quot;/&gt; &lt;!—第二种方法，内部bean--&gt; &lt;bean&gt; &lt;properyt name=&quot;&quot; value=&quot;&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; 继承配置public class Student public class Gradate extends Student 在beans.xml文件中体现配置 &lt;!-- 配置一个学生对象 --&gt; &lt;bean id=&quot;student&quot; class=&quot;com.hsp.inherit.Student&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;顺平&quot; /&gt; &lt;property name=&quot;age&quot; value=&quot;30&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置Grdate对象 --&gt; &lt;bean id=&quot;grdate&quot; parent=&quot;student&quot; class=&quot;com.hsp.inherit.Gradate&quot;&gt; &lt;!-- 如果自己配置属性name,age,则会替换从父对象继承的数据 --&gt; &lt;property name=&quot;name&quot; value=&quot;小明&quot;/&gt; &lt;property name=&quot;degree&quot; value=&quot;学士&quot;/&gt; &lt;/bean&gt; 通过构造函数注入值★★★ 目前我们都是通过set方式给bean注入值，spring还提供其它的方式注入值，比如通过构造函数注入值! set注入的缺点是无法清晰表达哪些属性是必须的，哪些是可选的；构造注入的优势是通过构造器强制依赖关系 每个constructor-arg配置一个参数，参数有先后顺序，顺序要与构造函数相同 通过参数名传递参数&lt;bean id=&quot;product&quot; class=&quot;constructor.Product&quot;&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;洗衣机&quot;/&gt; &lt;constructor-arg name=&quot;description&quot; value=&quot;家用洗衣服的工具&quot;/&gt; &lt;/bean&gt; 通过指数方式传递参数&lt;bean id=&quot;product&quot; class=&quot;constructor.Product&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;洗衣机&quot;/&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;家用洗衣服的工具&quot;/&gt; &lt;/bean&gt; 初始化bean和销毁bean的时候执行某个方法方法一：通过注解@PostConstruct 和 @PreDestroy 方法 实现初始化和销毁bean之前进行的操作 public class DataInitializer{ @PostConstruct public void initMethod() throws Exception { System.out.println(&quot;initMethod 被执行&quot;); } @PreDestroy public void destroyMethod() throws Exception { System.out.println(&quot;destroyMethod 被执行&quot;); } } 方法二：通过 在xml中定义 init-method 和 destory-method 方法★★★★★ DataInitializer public class DataInitializer{ public void initMethod() throws Exception { System.out.println(&quot;initMethod 被执行&quot;); } public void destroyMethod() throws Exception { System.out.println(&quot;destroyMethod 被执行&quot;); } } applicationContext.xml &lt;bean id=&quot;dataInitializer&quot; class=&quot;com.somnus.demo.DataInitializer&quot; init-method=&quot;initMethod&quot; destory-method=&quot;destroyMethod&quot;/&gt; 方法三：通过bean实现InitializingBean和 DisposableBean接口 public class DataInitializer implements InitializingBean，DisposableBean{ @Override public void afterPropertiesSet() throws Exception { System.out.println("afterPropertiesSet 被执行"); } @Override public void destroy() throws Exception { System.out.println("destroy 被执行"); } } 原理 //判断该bean是否实现了实现了InitializingBean接口，如果实现了InitializingBean接口，则只掉调用bean的afterPropertiesSet方法 boolean isInitializingBean = (bean instanceof InitializingBean); if(isInitializingBean) ((InitializingBean) bean).afterPropertiesSet(); 注解装配Bean引入context名称空间，并配置扫描包&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.5.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;annotation&quot;/&gt; &lt;/beans&gt; @Component@Component(value = &quot;a&quot;)等价于&lt;bean id = &quot;a&quot; class = &quot;A&quot;&gt; @Component(value = &quot;a&quot;) public class A { public void say(){ System.out.println(&quot;A&quot;); } } 依赖注入简单类型数据注入spring3.0 提供 @Value 注解，可以注入简单数据类型 @Component(value = &quot;a&quot;) public class A { @Value(value = &quot;qm&quot;) private String name; public void say(){ System.out.println(&quot;A&quot; + name); } } 复杂对象类型数据注入第一种：按类型注入，@Autowired A @Component(value = &quot;a&quot;) public class A { @Autowired B b; public void say(){ b.say(); } } B @Component(value = &quot;b&quot;) public class B { public void say(){ System.out.println(&quot;B&quot;); } } 第二种：按名称注入，使用@Autowired 结合 @Qualifier 注解 (Spring 2.0 ) A： @Component(value = &quot;a&quot;) public class A { @Autowired @Qualifier(value = &quot;c_qualifier&quot;) B b; public void say(){ b.say(); } } B： @Component(value = &quot;c_qualifier&quot;) public class B { public void say(){ System.out.println(&quot;B&quot;); } } 第三种： 使用@Resouce注解 （JSR-250标准 ） 按照名称注入 第四种： 使用 @Inject 注解 （JSR-330标准 ） 导入 javax.inject-1.jar 自动装配bean的属性值自动装配只有在属性没有设置时，才会进行 byName的用法:&lt;!-- 配置一个master对象 --&gt; &lt;bean id=&quot;master&quot; class=&quot;com.hsp.autowire.Master&quot; autowire=&quot;byName&quot;&gt; &lt;property name=&quot;name&quot;&gt; &lt;value&gt;顺平&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置dog对象 --&gt; &lt;bean id=&quot;dog&quot; class=&quot;com.hsp.autowire.Dog&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;小黄&quot;/&gt; &lt;property name=&quot;age&quot; value=&quot;3&quot;/&gt; &lt;/bean&gt; 原理图: property中没有注入dog值，master中的dog为null。但当设置属性autowire=”byName”后，通过检测发现内存中有一个名字为dog的对象，则自动进行引用连接 byType的用法寻找和属性类型相同的bean，此时id为dog11也能够找到并进行装配；找不到、装不上、找到多个抛异常 &lt;!-- 配置一个master对象 --&gt; &lt;bean id=&quot;master&quot; class=&quot;com.hsp.autowire.Master&quot; autowire=&quot;byType&quot;&gt; &lt;property name=&quot;name&quot;&gt; &lt;value&gt;顺平&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置dog对象 --&gt; &lt;bean id=&quot;dog11&quot; class=&quot;com.hsp.autowire.Dog&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;小黄&quot;/&gt; &lt;property name=&quot;age&quot; value=&quot;3&quot;/&gt; &lt;/bean&gt; constructor的用法与byType类似， 查找和bean的构造参数一致的一个或多个bean，若找不到或找到多个，抛异常。按照参数的类型装配 master写构造函数 public master(Dog dog){ this.dog = dog; } 配置 &lt;!-- 配置一个master对象 --&gt; &lt;bean id=&quot;master&quot; class=&quot;com.hsp.autowire.Master&quot; autowire=&quot;constructor&quot;&gt; &lt;property name=&quot;name&quot;&gt; &lt;value&gt;顺平&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置dog对象 --&gt; &lt;bean id=&quot;dog&quot; class=&quot;com.hsp.autowire.Dog&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;小黄&quot;/&gt; &lt;property name=&quot;age&quot; value=&quot;3&quot;/&gt; &lt;/bean&gt; autodetect的用法autowire=&quot;autodetect&quot;(3)和(2)之间选一个方式。不确定性的处理与(3)和(2)一致 defualt这个需要在&lt;beans defualt-autorwire=&quot;指定&quot; /&gt;当你在&lt;beans&gt;指定了default-atuowrite后，所有的bean的默认的autowire就是指定的装配方法;如果没有在&lt;beans defualt-autorwire=&quot;指定&quot; /&gt;没有defualt-autorwire=”指定”，则默认是defualt-autorwire=”no” no: 不自动装配这是autowire的默认值 使用spring的特殊bean,完成分散配置将配置文件分成几个分散的配置文件，如一个项目中连接多个数据库，每个数据库各对应一个db.properties文件 引入我们的db.properties文件，并在要注入值的地方用$占位符 &lt;context:property-placeholder location=&quot;classpath:com/hsp/dispatch/db.properties,classpath:com/hsp/dispatch/db2.properties&quot;/&gt; &lt;!-- 配置一DBUtil对象 $占位符号 --&gt; &lt;bean id=&quot;dbutil&quot; class=&quot;com.hsp.dispatch.DBUtil&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;${name}&quot; /&gt; &lt;property name=&quot;drivername&quot; value=&quot;${drivername}&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot; /&gt; &lt;property name=&quot;pwd&quot; value=&quot;${pwd}&quot; /&gt; &lt;/bean&gt; 注意：当通过context:property-placeholder引入属性文件的时候，有多个需要使用,间隔. db.properties name=scott drivername=oracle:jdbc:driver:OracleDirver url=jdbc:oracle:thin:@127.0.0.1:1521:hsp pwd=tiger 测试 ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); DBUtil dBUtil = (DBUtil) ac.getBean(&quot;dbutil&quot;); System.out.println(dbUtil.getDrivername()); AOP编程 AOP(Aspect Oriented Programming )，面向切面编程：AOP编程就是将共有的代码，如日志记录、权限控制、事务控制等全部抽取出来，放在某个地方集中管理，若需要使用这些功能，由容器动态织入这些共有代码，这样的好处：1、程序员在编写业务逻辑时只需关心核心的业务逻辑处理方法，提高工作效率，使代码变得简洁2、业务逻辑代码和共有代码分开存放，使维护工作变得轻松 举个例子，在开发过程中，很多对象需要做同一类的操作，例如权限控制、日志记录、事务控制等，AOP编程就是把相同工作剥离出来，若对象需要使用其中的一个功能，则将其织入进去 AOP编程，实际上在开发框架本身用的多，在实际项目中，用的不是很多，但是将来会越来越多，这是一个趋势 参考：http://blog.csdn.net/liujiahan629629/article/details/18864211 AOP技术的实现原理 AOP技术是建立在 Java语言的反射机制 与 动态代理机制 之上的 业务逻辑组件在运行过程中，AOP容器 会动态创建一个 代理对象(Service的代理对象) 供使用者调用，该代理对象已经按Java EE程序员的意图将 切面 成功切入到 目标对象 的 连接点 上，从而使 切面的功能 与 业务逻辑的功能 同时得以执行 从原理上讲，调用者直接调用的其实是AOP容器动态生成的代理对象，再由代理对象调用目标对象完成原始的业务逻辑处理，而代理对象则已经将切面与业务逻辑方法进行了合成 现将图6-6中涉及到的一些概念解释如下：(切面包括通知和切入点，容器将切面切入到目标对象的连接点上，返回一个代理对象，这个过程叫做织入) 切面（Aspect）：其实就是共有功能的实现，包括通知和切入点,如日志切面、权限切面、事务切面等。在实际应用中通常是一个存放共有功能实现的普通Java类，之所以能被AOP容器识别成切面，是在配置中指定的。通知（Advice）： 是切面的具体实现。以目标方法为参照点，根据 放置的地方不同，可分为前置通知（Before）、后置通知（AfterReturning）、环绕通知（Around）、异常通知（AfterThrowing）、最终通知（After）5种。在实际应用中通常是切面类中的一个方法，具体属于哪类通知，同样是在配置中指定的。、切入点（Pointcut）：*用于定义通知应该切入到哪些连接点上。不同的通知通常需要切入到不同的连接点上，这种精准的匹配是由切入点的 正则表达式* 来定义的 连接点（Joinpoint）：就是程序在运行过程中能够插入切面的地点。例如，方法调用、异常抛出或字段修改等目标对象（Target）：就是那些即将切入切面的对象，也就是那些被通知的对象。这些对象中已经只剩下干干净净的核心业务逻辑代码了，所有的共有功能代码等待AOP容器的切入。代理对象（Proxy）：将通知应用到目标对象之后被动态创建的对象。可以简单地理解为，代理对象的功能等于目标对象的核心业务逻辑功能加上共有功能。代理对象对于使用者而言是透明的，是程序运行过程中的产物。织入（Weaving）： 将切面应用到目标对象从而创建一个新的代理对象的过程。这个过程可以发生在编译期、类装载期及运行期，当然不同的发生点有着不同的前提条件。譬如发生在编译期的话，就要求有一个支持这种AOP实现的特殊编译器；发生在类装载期，就要求有一个支持AOP实现的特殊类装载器；只有发生在运行期，则可直接通过Java语言的反射机制与动态代理机制来动态实现。 举个例子解释术语： AOP编程可以在不增加原来业务逻辑方法代码的情况下，扩展某个方法，传统的方法是采用 继承 的方式，现在可以采用动态代理技术 连接点表示哪些方法 可以被扩展（拦截）；切入点表示哪些方法 需要被扩展（拦截）；织入是把通知应用到目标上，生成动态代理类的过程；切面表示公用的业务逻辑，包括多个切入点和多个通知 AOP底层实现JDK动态代理动态代理可以让一个类 代理多个不同的目标类，而且可以 代理不同的方法 详见Java——设计模式版块~http://qianmingxs.com/2016/07/06/[%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F]%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%89%BA%E6%9C%AF%E4%B9%8B%E9%81%93%E7%AC%94%E8%AE%B0/ 1、必须针对接口进行代理2、生成代理对象，通过Proxy类进行代理，传入目标对象类加载器、目标对象接口 、处理类3、自己实现InvocationHandler 接口 说明： Cglib动态代理机制JDK只能对接口进行代理，如果目标对象没有接口，无法使用JDK动态代理，则可以使用cglib 什么是CGLIB？ CGLIB(Code Generation Library)是一个开源项目！是一个强大的，高性能，高质量的Code生成类库，它可以在运行期扩展Java类与实现Java接口。Cglib可以对接口或者类进行代理 ！ Spring AOPSpring AOP 就是基于JDKProxy 和 CglibProxy 1、如果目标对象有接口，优先使用JDK Proxy2、如果目标对象没有接口， 使用CglibProxy 面试题：spring的aop中，当你通过代理对象去实现aop的时候，获取的ProxyFactoryBean是什么类型？答: 返回的是一个代理对象,如果目标对象实现了接口，则spring使用jdk 动态代理技术,如果目标对象没有实现接口，则spring使用CGLIB技术. Spring AOP三种配置详细介绍AOP框架三足鼎立： AspectJ Jboss AOP Spring AOP Spring提供4种AOP支持 基于代理的经典AOP 纯POJO切面（使用XML） @AspcetJ注解驱动的切面 注入式AspcetJ切面 基于代理的经典AOP 现在有个需求，在调用sayHello()方法前写日志，思路如下： 1、面向接口编程，定义一个TestServiceInter接口，声明函数sayHello()2、两个类Test1Service和Test2Service实现这两个接口3、传统的方式很简单，在sayHello()方法前加入日志操作的代码，但如果有多个业务逻辑方法都需要写日志操作，是会有很多冗余代码。可以引入一个类，它的功能是写日志， Test1Service t1 = new Test1Service(); //采用传统方法，此处写日志操作 t1.sayHello(); Test2Service t2 = new Test2Service(); //采用传统方法，此处写日志操作 t2.sayHello(); 4、Service类与日志类如何关联起来呢，需引入一个代理类，Spring提供一个代理对象类ProxyFactoryBean 步骤1、定义接口 TestServiceInter.java public interface TestServiceInter { public void sayHello(); } 2、编写对象(也称作被代理对象或目标对象)，实现接口 Test1Service.java public class Test1Service implements TestServiceInter { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public void sayHello() { System.out.println(&quot;Hi &quot; + name); } } 3、编写通知（以前置通知为例，前置通知在目标方法调用前调用） # MyMethodBeforeAdvice.java public class MyMethodBeforeAdvice implements MethodBeforeAdvice { @Override public void before(Method method, Object[] objects, Object o) throws Throwable { System.out.println(&quot;记录日志：&quot; + method.getName()); } } 4、在beans.xml文件配置（分三部分：通知、被代理对象、代理对象） 4.1 配置目标对象 4.2 配置通知 4.3 配置代理对象 是 ProxyFactoryBean的对象实例 4.3.1 代理接口集 4.3.2 织入通知 4.3.3 配置目标对象 &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!--配置前置通知，比如日志--&gt; &lt;bean id=&quot;MyMethodBeforeAdvice&quot; class=&quot;cn.apeius.AOP.MyMethodBeforeAdvice&quot;&gt;&lt;/bean&gt; &lt;!--配置目标对象--&gt; &lt;bean id=&quot;Test1Service&quot; class=&quot;cn.apeius.AOP.Test1Service&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;钱明&quot;/&gt; &lt;/bean&gt; &lt;!--配置代理对象,spring提供--&gt; &lt;bean id=&quot;proxyFactoryBean&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!--配置代理接口集--&gt; &lt;property name=&quot;proxyInterfaces&quot;&gt; &lt;list&gt; &lt;value&gt;cn.apeius.AOP.TestServiceInter&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!--通知--&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;!--相当于包MyMethodBeforeAdvice前置通知和代理对象关联，我们也可以把通知看成拦截器--&gt; &lt;value&gt;MyMethodBeforeAdvice&lt;/value&gt; &lt;/property&gt; &lt;!--配置被代理对象--&gt; &lt;property name=&quot;target&quot; ref=&quot;Test1Service&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; 通知类型除了四种基本通知外，还有引入通知 前置通知 public class MyMethodBeforeAdvice implements MethodBeforeAdvice { @Override public void before(Method method, Object[] objects, Object o) throws Throwable { System.out.println(&quot;记录日志：&quot; + method.getName()); } } 后置通知 public class MyAfterReturningAdvice implements AfterReturningAdvice { @Override public void afterReturning(Object o, Method method, Object[] objects, Object o1) throws Throwable { System.out.println(&quot;关闭资源&quot;); } } 环绕通知 public class MyMethodInterceptor implements MethodInterceptor { @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable { System.out.println(&quot;环绕前&quot;); Object o = methodInvocation.proceed(); System.out.println(&quot;环绕后&quot;); return o; } } 异常通知 ThrowsAdvice为标记接口，在接口中没有任何方法，因为方法被反射机制调用，实现类必须实现以下形式，见文档 public class MyThrowsAdvice implements ThrowsAdvice { public void afterThrowing(Exception e){ System.out.println(&quot;出大事了&quot; + e.getMessage()); } } 引入通知 引入通知不需要编写相应的类，只需要进行配置，目的是用来指定哪些方法需要执行相应的通知，如，我们想指定只有sayHello（）方法执行前置通知， &lt;bean id=&quot;myMethodBeforeAdviceFilter&quot; class=&quot;org.springframework.aop.support.NameMatchMethodPointcutAdvisor&quot;&gt; &lt;property name=&quot;advice&quot; ref=&quot;myMethodBeforeAdvice&quot;&gt;&lt;/property&gt; &lt;property name=&quot;mappedNames&quot;&gt; &lt;list&gt; &lt;value&gt;sayHello&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 拦截器名集中引入 &lt;value&gt;myMethodBeforeAdviceFilter&lt;/value&gt; 传统AOP切面编程极大简化了spring切面的配置工作，同时也让程序透明化，隐藏了切面的很多细节。上面所有内容都可以作为理解 spring配置AOP的基础，是最原始的配置方式，也体现了spring处理的过程。 使用ProxyFactoryBean配置有些欠优雅，在spring2.0里新的xml配置元素体现了改进。Spring2.0在aop命名空间里提供了一些配置元素，简化了把类转化为切面的操作。 本质的使用同上，只是简化配置，隐藏细节 AspectJ切入点传统AOP切入点，使用正则表达式语法，不推荐使用。AspectJ切入点，是通过函数进行配置 常用语法说明简介:execution 执行，语法：execution(&lt;访问修饰符&gt;?&lt;返回类型&gt;&lt;方法名&gt;(&lt;参数&gt;)&lt;异常&gt;) execution(* *(..)) 第一个* 任意返回类型 ， 第二个* 任意方法名 , .. 任意参数 execution(* cn.itcast.service.UserService.*(..)) 匹配UserService所有方法 第一个星 任意返回类型 execution(* cn.itcast.service.UserService+.*(..)) 匹配UserService子类所有方法 + 子类 execution(* cn.itcast.service..*.*(..)) 第一个.. 任意子包 *.*任何类的任何方法 within 根据包匹配 语法：within(包名..*) within(cn.itcast.service..*) 拦截service下所有类的方法 this根据目标类型匹配 语法：this(类名) this(cn.itcast.service.UserService) 拦截 UserService所有方法 (包括代理对象) target 根据目标类型匹配 语法 ：target(类名) target(cn.itcast.service.UserService) 拦截UserService所有方法 （不包括代理对象 ） args 根据参数匹配 args(java.lang.String) 拦截所有参数为String类的方法 bean 根据bean name匹配 bean(userService) 拦截bean id/name为userService对象所有方法 步骤接口 public interface IAopService { public void withAop() throws Exception; } 实现 public class AopServiceImpl implements IAopService { public void withAop() throws Exception { System.out.println(&quot;业务逻辑处理中&quot;); } } 通知 public class MyMethodInterceptor implements MethodInterceptor{ public Object invoke(MethodInvocation methodInvocation) throws Throwable { System.out.println(&quot;环绕前&quot;); Object o = methodInvocation.proceed(); System.out.println(&quot;环绕后&quot;); return o; } } 配置文件 &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!--1、目标--&gt; &lt;bean id=&quot;aopServiceImpl&quot; class=&quot;AOP.AopServiceImpl&quot;/&gt; &lt;!--2、通知--&gt; &lt;bean id=&quot;myMethodInterceptor&quot; class=&quot;AOP.MyMethodInterceptor&quot;/&gt; &lt;!--&lt;aop:config&gt; 配置切面=通知+切入点--&gt; &lt;aop:config&gt; &lt;!--aop:pointcut配置切入点--&gt; &lt;aop:pointcut id=&quot;service&quot; expression=&quot;execution(* AOP.*.*(..))&quot;/&gt; &lt;!--aop:advisor配置传统Spring AOP切面，只能有一个切入点和一个通知--&gt; &lt;aop:advisor advice-ref=&quot;myMethodInterceptor&quot; pointcut-ref=&quot;service&quot;/&gt; &lt;/aop:config&gt; &lt;/beans&gt; 测试 public class AopRun { public static void main(String[] args) throws Exception { ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); IAopService hello = (IAopService) context.getBean(&quot;aopServiceImpl&quot;); hello.withAop(); } } AspectJ AOP切面编程接口 public interface IAopService { public void withAop() throws Exception; } 实现 public class AopServiceImpl implements IAopService { public void withAop() throws Exception { System.out.println(&quot;业务逻辑处理中&quot;); } } 通知 public class MyAspect { public void before1(JoinPoint jointPoint){ System.out.println(&quot;before1&quot;); } public void before2(JoinPoint jointPoint){ System.out.println(&quot;before2&quot;); } } 配置 &lt;!--1、目标--&gt; &lt;bean id=&quot;aopServiceImplAspectJ&quot; class=&quot;AOP.AspectJ.AopServiceImpl&quot;/&gt; &lt;!--2、通知--&gt; &lt;bean id=&quot;myMethodInterceptorAspectJ&quot; class=&quot;AOP.AspectJ.MyAspect&quot;/&gt; &lt;!--配置切面--&gt; &lt;aop:config&gt; &lt;aop:aspect ref=&quot;myMethodInterceptorAspectJ&quot;&gt; &lt;!--标签before决定前置通知--&gt; &lt;aop:before method=&quot;before1&quot; pointcut-ref=&quot;serviceAspectJ&quot;/&gt; &lt;aop:before method=&quot;before2&quot; pointcut-ref=&quot;serviceAspectJ&quot;/&gt; &lt;!--切入点--&gt; &lt;aop:pointcut id=&quot;serviceAspectJ&quot; expression=&quot;execution(* AOP.AspectJ.*.*(..))&quot; /&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; 测试 public class AopRun { public static void main(String[] args) throws Exception { ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); IAopService hello = (IAopService) context.getBean(&quot;aopServiceImplAspectJ&quot;); hello.withAop(); } } @AspcetJ注解驱动的切面★★★★★★★★★1、接口 public interface IAopService { public void withAop() throws Exception; } 2、实现 @Service public class AopServiceImpl implements IAopService { public void withAop() throws Exception { System.out.println(&quot;业务逻辑处理中&quot;); } } 3、切面，包括切入点和通知 @Aspect //表示当前类是一个通知 public class MyAspect { private static final Logger logger = Logger.getLogger(MyAspect.class); //定义切入点方法一：定义在一个空方法上 @Pointcut(&quot;execution(* *.*(..)))&quot;) private void myPointcut() { } //定义切点方法二：直接在通知上定义切入点 @Before(&quot;execution(* *.*(..)))&quot;) public void before(JoinPoint joinPoint) { String className = joinPoint.getTarget().getClass().getName(); String methodName = joinPoint.getSignature().getName(); logger.warn(className + &quot;的&quot; + methodName + &quot;执行了&quot;); Object[] args = joinPoint.getArgs(); StringBuilder log = new StringBuilder(&quot;参数为：&quot;); for (Object arg : args) { log.append(arg + &quot; &quot;); } logger.warn(log.toString()); } @AfterReturning(value = &quot;execution(* *.*(..)))&quot;, returning = &quot;returnVal&quot;) public void afterReturin(Object returnVal) { logger.warn(&quot;方法正常结束了,方法的返回值:&quot; + returnVal); } @AfterThrowing(value = &quot;myPointcut()&quot;, throwing = &quot;e&quot;) public void afterThrowing(Throwable e) { logger.error(&quot;AfterThrowing&quot; + e.getMessage(),e); } @Around(value = &quot;myPointcut()&quot;) public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { logger.warn(&quot;Around:前置增强&quot;); Object result = null; try { result = proceedingJoinPoint.proceed(); } catch (Exception e) { logger.error(&quot;Around:&quot; + e.getMessage(),e); } logger.warn(&quot;Around:后置增强&quot;); return result; } } 4、配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;AOP&quot;/&gt; &lt;!--1、开启AspectJ注解开发的配置--&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!--配置切面--&gt; &lt;bean id = &quot;MyAspect&quot; class=&quot;AOP.AspectJAnnotation.MyAspect&quot;/&gt; 5、测试 public class AopRun { public static void main(String[] args) throws Exception { ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); IAopService aopService = (IAopService) context.getBean(IAopService.class); aopService.withAop(); } } spring 的环绕通知和前置通知，后置通知有着很大的区别，主要有两个重要的区别： 目标方法的调用由环绕通知决定，即你可以决定是否调用目标方法，而前置和后置通知 是不能决定的，他们只是在方法的调用前后执行通知而已，即目标方法肯定是要执行的。 环绕通知可以控制返回对象，即你可以返回一个与目标对象完全不同的返回值，虽然这很危险，但是你却可以办到。而后置方法是无法办到的，因为他是在目标方法返回值后调用]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>JavaEE</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSP笔记]]></title>
    <url>%2F2016%2F07%2F14%2F%5BServlet%5DJSP%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[常用Java片段 &lt;%! %&gt; jsp声明，在这里面声明的变量是全局变量，也可以函数定义 &lt;% %&gt; Java片段，在这里面声明的变量是局部变量， 注释 &lt;%-- --%&gt;，&lt;%// % &gt;，&lt;%/* */% &gt; &lt;%= %&gt; 表达式 JSP简介 在web开发过程中，发现servlet做界面比较麻烦（out.println），于是又有一个新的技术JSP JSP（Java Servlet Page）运行在服务器的语言，响应客户端请求，动态生成网页的技术 JSP原理 如果是第一次访问jsp文件，web服务器就会把showTime.jsp 翻译 成一个showTime_jsp.java（IDEA中showTIme_jsp.java的目录：C:\Users\Asus\.IntelliJIdea15\system\tomcat\Unnamed_JSP_Study\work\Catalina\localhost\JSP_Study\org\apache\jsp\showTime_jsp.java） 再将其编译成一个showTime_jsp.class，并把class加载到内存 然后创建一个该Servlet的实例，调用其jspInit方法，该方法在Servlet生命周期中只被执行一次，并调用实例的jspService()方法 如果是第二次或者以后，就直接访问内存中的实例的jspService()方法。JSP也是单例，所以第一次访问JSP网站速度比较慢，后面访问JSP的速度就变快了 如果某个JSP文件被修改了，就相当于重新访问JSP（相当于第一次访问） JSP显示页面Jsp页面中的html排版标签是如何被发送到客户端的？答：JSP中被翻译成Servlet时，HTML标签会以out.write()的形式打印出来，例如： out.write(&quot;&lt;table border=1&gt;\r\n&quot;); out.write(&quot;&lt;tr&gt;&lt;td&gt;apple&lt;/td&gt;&lt;td&gt;melon&lt;/td&gt;&lt;td&gt;orange&lt;/td&gt;&lt;/tr&gt;\r\n&quot;); out.write(&quot;&lt;tr&gt;&lt;td&gt;apple&lt;/td&gt;&lt;td&gt;melon&lt;/td&gt;&lt;td&gt;orange&lt;/td&gt;&lt;/tr&gt;\r\n&quot;); out.write(&quot;&lt;tr&gt;&lt;td&gt;apple&lt;/td&gt;&lt;td&gt;melon&lt;/td&gt;&lt;td&gt;orange&lt;/td&gt;&lt;/tr&gt;\r\n&quot;); out.write(&quot;&lt;tr&gt;&lt;td&gt;apple&lt;/td&gt;&lt;td&gt;melon&lt;/td&gt;&lt;td&gt;orange&lt;/td&gt;&lt;/tr&gt;\r\n&quot;); out.write(&quot;&lt;/table&gt;\r\n&quot;); JSP中的Java片段Jsp页面中的java代码，服务器是如何执行的？比如JSP中的Java代码: &lt;% int i=90; int j=i+90; %&gt; &lt;h1&gt;测试.&lt;/h1&gt; &lt;% out.println(&quot;j=&quot;+j); %&gt; 当被翻译成Servlet后，格式如下 public void _jspService(HttpServletRequest request, HttpServletResponse response) throws java.io.IOException, ServletException { int i=90; int j=i+90; out.println(&quot;j=&quot;+j); } 就是有多个&lt;% %&gt; 其实相当于是一个大的 &lt;% %&gt;，所有代码会放在一个_jspService函数中 在&lt;% %&gt; 中定义的变量，会成为service函数的局部变量. JSP九大内置对象Web服务器在调用jsp时，会给jsp提供一些内置对象，这些内置对象无需创建可直接使用。前五个较常用，分别与Servlet中的几个对象对应 对象名 类型 作用域 request：请求对象 javax.servlet.ServletRequest的子类 Request response：响应对象 javax.servlet.ServletResponse的子类 Page pageContext：页面上下文对象，也是一个域对象，可以setAttribute，其作用范围只是本页面 javax.servlet.jsp.PageContext Page session：会话对象，用于保存用户信息，跟踪用户行为 javax.servlet.http.HttpSession Session application：应用程序对象，多个用户共享该对象，可以做计数器 javax.servlet.ServletContext Application out：输出对象 javax.servlet.jsp.JspWriter Page config：配置对象 javax.servlet.ServletConfig Page page：页面对象，代表JSP实例本身，使用较少 java.lang.Object Page exception：异常对象 java.lang.Throwable Page JSP的语法指令元素 概念: 用于从jsp发送一个信息到容器，比如设置全局变量,文字编码,引入包 ①page指令&lt;%@ page contentType=&quot;text/html;charset=utf-8&quot;%&gt; 常用的属性 language = &quot;xx&quot;，jsp中嵌入代码语言，通常是java import = &quot;包.类名&quot;，在jsp页面引入类 errorPage=&quot;err.jsp&quot;，当JSP页面出现错误时，自动跳转到指定页面 contentType 和 pageEncoding的区别： contentType = &quot;text/html;charset=utf-8&quot; 指定网页以什么方式显示页面 pageEncoding=&quot;utf-8&quot; 指定Servlet引擎以什么方法翻译jsp-&gt;servlet并指定网页以什么方式显示页面 ②include指令 &lt;%@ include file="文件路径" %&gt; 该指令用于引入一个文件（通常是JSP文件），JSP引擎会把两个JSP文件翻译成一个Servlet文件，因此也称为静态引入 被引入的JSP文件，只需保留page指令即可，html，body等均可省略★★★ ③taglib指令 允许在JSP页面使用自定义的标签 &lt;mytag:yourTag num1 = &quot;123&quot; /&gt; 脚本元素(理解为脚本片段)java片段&lt;% java 代码 %&gt; 表达式&lt;%=表达式 %&gt;，例如&lt;%=i*78-23%&gt; 定义变量全局变量 &lt;%! int i=90; %&gt; 局部变量 &lt;% int i=90;%&gt; 定义函数★★★★★&lt;%! public int getResult(int a,int b){ return a+b; } %&gt; 注意：函数不能在&lt;% %&gt; 定义. 动作元素jsp:forward &lt;jsp:forword file=&quot;xxx&quot;&gt;&lt;/jsp:forword&gt;页面跳转 在开发JSP的过程中，我们通常把JSP放入WEB-INF目录，目的是为了防止用户直接访问这些jsp文件. 在WebRoot下我们有一个入口页面,它的主要转发 &lt;jsp:forword file=&quot;/WEB-INF/xx.jsp&quot;&gt;&lt;/jsp:forword&gt; jsp:incluce &lt;%@ include file=&quot;&quot;%&gt; 静态引入 &lt;jsp:incluce file=&quot;&quot;&gt;&lt;/jsp:incule&gt; 动态引入 相同点： 把一个文件引入到另外一个文件 区别： 静态引入，把两个jsp翻译成一个Servlet,所以被引入的文件不要包含&lt;body&gt;&lt;html&gt; 动态引入，把两个jsp分别翻译,所以被引入的jsp包含有&lt;html&gt;&lt;body&gt;也可以 EL表达式语言 EL表达式语言可以方便读取应用程序中的数据，JSP2.0以上版本即使没有JSTL（JSP标准标签库）也能使用EL EL表达式以 ${ 开头，并以 } 结束，如${x + y}，从左向右取值，返回结果类型为String EL表达式写在JSP的HTML代码中，而不能写在”&lt;%%&gt;”引起的JSP脚本中 使用 [] 和 . 运算符来访问对象的属性，形式可以是${object.peopertyName}或${object[“peopertyName”]} EL内置对象我们知道jsp有九个内置对象，而EL表达式有11个对象，这些内置对象无需创建可直接使用 pageContextpageContext对象表示当前JSP页面的javax.servlet.jsp.PageContext，包含了9大JSP内置对象 对象名 类型 作用域 request：请求对象 javax.servlet.ServletRequest的子类 Request response：响应对象 javax.servlet.ServletResponse的子类 Page pageContext：页面上下文对象，也是一个域对象，可以setAttribute，其作用范围只是本页面 javax.servlet.jsp.PageContext Page session：会话对象，用于保存用户信息，跟踪用户行为 javax.servlet.http.HttpSession Session application：应用程序对象，多个用户共享该对象，可以做计数器 javax.servlet.ServletContext Application out：输出对象 javax.servlet.jsp.JspWriter Page config：配置对象 javax.servlet.ServletConfig Page page：页面对象，代表JSP实例本身，使用较少 java.lang.Object Page exception：异常对象 java.lang.Throwable Page 例：获得客户端IP ${pageContext.request.remoteAddr} initParam包含所有初始化参数的Map，可以获取初始化参数 例，设置初始化参数 &lt;context-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/context-param&gt; 获得初始化参数 ${initParam.encoding} param包含所有参数的Map，可以获取参数，返回String 例：url http://localhost:8080/SpringMVC_study/?name=xxx 获得参数 ${param.name} paramValues包含所有参数的Map，可获取参数数组，返回String[] 例：请求url http://localhost:8080/SpringMVC_study/?name=aaa&amp;name=bbb 提交的参数name有多个值{“aaa”,”bbb”}，使用param只能获取第一个值，二使用paramValues能够获得其他的值 ${paramValues.name[0]} ${paramValues.name[1]} header包含所有头信息的Map，可以获取头信息 例：获得请求主机 ${header.host} cookie包含所有Cookie的Map，key为Cookie的name ${cookie.JSESSIONID.value} applicationScope，sessionScope，requestScope，pageScope分别是包含application，session，request，page作用域变量的Map 以requestScope为例： 使用声明person对象后，${pageScope.person.age}将输出person的age属性，useBean域默认的作用域为request 若输出session域中的变量，声明使 JSTLJSP标准标签库，用来解决遍历map或集合，格式化数字和日期等常见问题 依赖&lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; JSTL核心标签库JSTL 核心标签库标签共有13个，功能上分为4类： 表达式控制标签：out、set、remove、catch 流程控制标签：if、choose、when、otherwise 循环标签：forEach、forTokens URL操作标签：import、url、redirect JSTL核心库使用标签时，一定要在jsp文件头加入以下代码： &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt; 完整JSTL标签使用http://www.cnblogs.com/lihuiyy/archive/2012/02/24/2366806.html 遍历行为：&lt;c:forEach&gt;语法：&lt;c:forEach var=”name” items=”Collection” varStatus=”statusName” begin=”begin” end=”end” step=”step”&gt;&lt;/c:forEach&gt; 该标签根据循环条件遍历集合 Collection 中的元素。 var 用于存储从集合中取出的元素；items 指定要遍历的集合； 遍历list &lt;% List a=new ArrayList(); a.add("贝贝"); a.add("晶晶"); a.add("欢欢"); a.add("莹莹"); a.add("妮妮"); request.setAttribute("a",a); %> &lt;c:forEach var="fuwa" items="${a}"> &nbsp;&lt;c:out value="${fuwa}"/>&lt;br> &lt;/c:forEach> 遍历Map &lt;% Map&lt;String, String&gt; capitals = new HashMap&lt;String,String&gt;(); capitals.put(&quot;Indonesia&quot;,&quot;Jakarta&quot;); capitals.put(&quot;Malaysia&quot;,&quot;Kuala Lumpur&quot;); capitals.put(&quot;Thailand&quot;,&quot;Bangkok&quot;); request.setAttribute(&quot;capitals&quot;,capitals); %&gt; &lt;c:forEach var=&quot;capital&quot; items=&quot;${capitals}&quot;&gt; ${capital.key} ${capital.value} &lt;br/&gt; &lt;/c:forEach&gt; forEach嵌套 &lt;% Map&lt;String, String[]&gt; bigCities = new HashMap&lt;String,String[]&gt;(); bigCities.put(&quot;Australia&quot;,new String[]{&quot;Sydney&quot;,&quot;Melbourne&quot;,&quot;Perth&quot;}); bigCities.put(&quot;New Zealand&quot;,new String[]{&quot;Auckland&quot;,&quot;Christchurch&quot;,&quot;Wellington&quot;}); bigCities.put(&quot;Indonesia&quot;,new String[]{&quot;Jakarta&quot;,&quot;Surabaya&quot;,&quot;Medan&quot;}); request.setAttribute(&quot;bigCities&quot;,bigCities); %&gt; &lt;c:forEach var=&quot;mapItem&quot; items=&quot;${bigCities}&quot;&gt; ${mapItem.key} : &lt;c:forEach var=&quot;city&quot; items=&quot;${mapItem.value}&quot;&gt; ${city} &lt;/c:forEach&gt; &lt;br/&gt; &lt;/c:forEach&gt; 格式化日期和时间&lt;b&gt;格式化日期&lt;/b&gt;&lt;br/&gt; default：&lt;fmt:formatDate value=&quot;${now}&quot;/&gt; &lt;br/&gt; short：&lt;fmt:formatDate value=&quot;${now}&quot; dateStyle=&quot;short&quot;/&gt; &lt;br/&gt; medium：&lt;fmt:formatDate value=&quot;${now}&quot; dateStyle=&quot;medium&quot;/&gt; &lt;br/&gt; long：&lt;fmt:formatDate value=&quot;${now}&quot; dateStyle=&quot;long&quot;/&gt; &lt;br/&gt; full：&lt;fmt:formatDate value=&quot;${now}&quot; dateStyle=&quot;full&quot;/&gt; &lt;br/&gt;&lt;br/&gt; &lt;b&gt;格式化时间&lt;/b&gt;&lt;/br/&gt; default：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;time&quot;/&gt; &lt;br/&gt; short：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;time&quot; timeStyle=&quot;short&quot;/&gt; &lt;br/&gt; medium：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;time&quot; timeStyle=&quot;medium&quot;/&gt; &lt;br/&gt; long：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;time&quot; timeStyle=&quot;long&quot;/&gt; &lt;br/&gt; full：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;time&quot; timeStyle=&quot;full&quot;/&gt; &lt;br/&gt;&lt;br/&gt; &lt;b&gt;格式化日期和时间&lt;/b&gt;&lt;/br/&gt; default：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;both&quot;/&gt; &lt;br/&gt; short：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;both&quot; timeStyle=&quot;short&quot;/&gt; &lt;br/&gt; medium：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;both&quot; timeStyle=&quot;medium&quot;/&gt; &lt;br/&gt; long：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;both&quot; timeStyle=&quot;long&quot;/&gt; &lt;br/&gt; full：&lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;both&quot; timeStyle=&quot;full&quot;/&gt; &lt;br/&gt;&lt;br/&gt; &lt;b&gt;定制格式化日期和时间&lt;/b&gt;&lt;/br/&gt; &lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;both&quot; pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;/&gt; &lt;br/&gt; &lt;fmt:formatDate value=&quot;${now}&quot; type=&quot;both&quot; pattern=&quot;yy/MM/dd HH:mm:ss&quot;/&gt; &lt;br/&gt; 浏览器显示：]]></content>
      <categories>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>Servlet</tag>
        <tag>JSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中配置文件放在哪里]]></title>
    <url>%2F2016%2F07%2F13%2F%5BJava%5DJava%E4%B8%AD%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%94%BE%E5%9C%A8%E5%93%AA%E9%87%8C%2F</url>
    <content type="text"><![CDATA[绝对路径与相对路径 Java中路径可分为相对路径和绝对路径两种方式。相对路径是相对当前工作目录，例如当使用命令 C:\Users\Asus&gt;java MyClass xxx.properties 要求在C:\Users\Asus目录下有xxx.properties文件，而在使用 C:\&gt;java MyClass xxx.properties 时则要求在C盘根目录下有xxx.properties文件，所以使用相对路径是飘忽不定的，不建议使用。 但如果给出绝对路径，D:\xxx.properties,当工程给用户时，若用户没有D盘，就会出现问题。 综上所述，仍旧采用绝对路径的方式来确定资源文件的地址，但是需要通过函数方法得到项目路径,在通过字符串连接的方式拼接得到绝对路径。 //此时config.properties文件放在工程文件根目录下，即选择工程右键后，新建config.properties文件 InputStream ips = new FileInputStream(&quot;config.properties&quot;); Properties properties = new Properties(); properties.load(ips); System.out.println(properties.getProperty(&quot;name&quot;)); Java中比较常用的加载资源的方式 类加载器把字节码加载到内存中，即它可以加载.class文件，也可以加载普通文件。 当工程完成后，不会将工程目录下中的Src目录给用户（怎么可能会把源代码给用户），而是将bin目录下的文件，一些字节码等文件在用户电脑上运行。 eclipse会自动将Java文件编译，并存放字节码在 工程目录/bin/包名目录下，Java文件对应编译后的字节码，普通文件(如config.properties文件)仍原封不动拷贝过去。 类加载器会在classPath中搜索。 使用类加载器时，默认的主目录是src public class ReflectTest { public static void main(String[] args) throws Exception{ /*InputStream ips = new FileInputStream(&quot;config.properties&quot;); Properties properties = new Properties(); properties.load(ips); System.out.println(properties.getProperty(&quot;name&quot;)); */ InputStream ipsInputStream = ReflectTest.class.getClassLoader().getResourceAsStream(&quot;com/qianming/config.properties&quot;); //在class类中直接有一个getResourceAsStream方法，路径名相对当前包名的相对路径，所以这里可以直接写config.properties //InputStream ipsInputStream = ReflectTest.class.getResourceAsStream(&quot;config.properties&quot;); //如果路径中写上&apos;/&apos;，则此时需相对根目录写路径 //InputStream ipsInputStream = ReflectTest.class.getResourceAsStream(&quot;/com/qianming/config.properties&quot;); Properties properties = new Properties(); properties.load(ipsInputStream); System.out.println(properties.getProperty(&quot;name&quot;)); } } 注意: 这里使用的路径是com/qianming/config.properties，即在包/资源文件的形式不能在com前加 “/“,记忆就行，否则会报错。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA分层思想]]></title>
    <url>%2F2016%2F07%2F08%2F%5BJava%5DJAVA%E5%88%86%E5%B1%82%E6%80%9D%E6%83%B3%2F</url>
    <content type="text"><![CDATA[用户管理系统系统框架【需改造】存在的问题 LoginClServlet中太过臃肿，既有业务逻辑，又有对数据库的操作，后期难以进行维护 指导思想① 业务逻辑代码和界面分离② 把常用的代码(对数据库的连接和操作)封装到工具类SqlHelper【有时也称为DAO，数据访问对象，是对数据库进行操作】 具体的方法① 每一张表对应一个domain类(表示数据)，还要对应一个Service类（表示操作）比如 users 表 对应 Users 类(domain 类)，UserService类(该类会封装对users表的各种操作) 每个表对应一个domain对象和Service类，将关系模型转化为对象模型（如下图），实际上这里体现出数据和操作分离的思想② view负责与用户进行交互，并将数据传递给controller③ controller接收view中传递的数据，进行数据校验，并调用service方法，根据返回结果的不同跳转到不同的显示页面 改造后系统框架 web层，structs位于web层，体现MVC的数据输入、数据处理、数据显示分离，当然web层需要调用service层中的方法完成数据处理。显示页面为MVC中的V，控制器为MVC中的C model层可以划分为业务层（service）、DAO层、数据持久层，这里强调一下，在一个项目中不一定全部有，可以根据实际情况选择 hiberate（orm框架），处于数据持久层，主要解决关系模型和对象模型之间的阻抗，体现oop 详细文档 https://github.com/rhapsody1290/servlet_study_usersmanager_MVC_change/blob/master/doc/%E5%88%86%E5%B1%82.xls 举个例子完成分页的mvc模式改写 首先在UsersService类中添加方法getUsersByPage,然后再为什么要返回ArrayList ,而不是我们想到 ResultSet? 1. ArrayList 中封装 User对象，更加符合面向对象的编程方式 OOP 2. 我们通过Resulst-&gt;User对象-&gt;ArrayList这样ArrayList和 Resultset没有关系，就可以及时关闭数据库资源 //按照分页来获取用户列表 public ArrayList&lt;Users&gt; getUsersByPage(int pageNow, int pageSize){ ArrayList&lt;Users&gt; al = new ArrayList&lt;Users&gt;(); ResultSet rs = SqlHelper.executeQuery(&quot;select * from users limit &quot; + (pageNow - 1) * pageSize + &quot;,&quot; + pageSize, null); try { while(rs.next()){ Users user = new Users(); user.setId(rs.getInt(&quot;id&quot;)); user.setUsername(rs.getString(&quot;username&quot;)); user.setEmail(rs.getString(&quot;email&quot;)); user.setGrade(rs.getInt(&quot;grade&quot;)); user.setPasswd(rs.getString(&quot;passwd&quot;)); al.add(user); } } catch (SQLException e) { e.printStackTrace(); }finally { SqlHelper.close(rs,SqlHelper.getPs(),SqlHelper.getCt()); } return al; } Web-Service-DAO（数据访问层）大讨论 mvc规定我们应该怎样去开发软件（把数据输入，数据处理，数据显示分离） web(jsp V/Servlet C)-servie(M)-dao(M)这是一种mvc的具体实现 web(jsp V/Servlet C)-service(M)开发方式也是一种具体的实现 举个例子，UserService.java中只包含业务逻辑，UserBean.java为数据对象，而对数据库的操作放在UserDao.java中 这种分层的好处是使数据和操作分离 将整个model层分为service层和dao层（数据访问层） 若UserService中业务需要对多张表进行操作，可以通过多个DAO的组合操作来实现 但在实际项目中，很多持久化逻辑本身就是业务逻辑（比如增加一个用户，增加用户信息到数据库时持久化逻辑，增加用户是业务逻辑），省略DAO层有时候更方便，更实用]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础常用]]></title>
    <url>%2F2016%2F07%2F08%2F%5BJava%5DJava%E5%9F%BA%E7%A1%80%E5%B8%B8%E7%94%A8%2F</url>
    <content type="text"><![CDATA[读取文件根目录根目录在工程目录 InputStream ips = new FileInputStream(&quot;src/xx.properties&quot;); 类加载器根目录在src下 InputStream ips = test.class.getClassLoader().getResourceAsStream(&quot;xx.properties&quot;); maven项目根目录为resources InputStream ips = test.class.getClassLoader().getResourceAsStream(&quot;xx.properties&quot;); 读取文本文件//读取文件 String realPath = this.getServletContext().getRealPath(&quot;record.txt&quot;); FileReader fileReader = new FileReader(realPath); BufferedReader br = new BufferedReader(fileReader); String nums = br.readLine(); //一定要关闭流 br.close(); fileReader.close(); out.println(nums); //写入文件 FileWriter fileWriter = new FileWriter(realPath); BufferedWriter bw = new BufferedWriter(fileWriter); bw.write(String.valueOf(Integer.parseInt(nums) + 1)); bw.close(); fileWriter.close(); 从控制台读取数据BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); System.out.println(br.readLine()); Java读取资源文件/** * 文件类型是UTF-8，在String生成字符时需指定解码方式为utf-8； */ InputStream ips = null; try { ips = MyServer.class.getClassLoader().getResourceAsStream(&quot;com/main/戏曲.txt&quot;); int hasRead = 0; byte[] buffer = new byte[1024]; StringBuffer content = new StringBuffer(); while((hasRead = ips.read(buffer)) &gt; 0){ content.append(new String(buffer, 0, hasRead, &quot;utf-8&quot;)); } System.out.println(content); } catch (Exception e) { e.printStackTrace(); }finally{ if (ips != null) { try { ips.close(); } catch (IOException e) { e.printStackTrace(); } } } 字符串四舍五入 float totalMoney = 123.124f; BigDecimal b = new BigDecimal(totalMoney); totalMoney = b.setScale(2,BigDecimal.ROUND_HALF_UP).floatValue(); 保留两位小数 String.format(&quot;%.2f&quot;, totalMoney) 生成指定长度的随机字符串//生成指定长度的随机字符串 public static String GenRandomString(int length){ Random random = new Random(); char[] charArray = &quot;abcdefghijklmnopqrstuvwxyz1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;.toCharArray(); char[] randomChar = new char [length]; for(int i = 0; i &lt; randomChar.length; i++){ randomChar[i] = charArray[random.nextInt(charArray.length)]; } return new String(randomChar); } JDBCMAVEN依赖：http://blog.csdn.net/earbao/article/details/44900083 连接步骤：http://www.cnblogs.com/hongten/archive/2011/03/29/1998311.html JDBC查询 //到数据库中验证 /* * 1.加载驱动 * 2.得到连接 * 3.创建PrepareStatment * 4.执行操作 * 5.根据结果做处理 * */ Connection connection = null; PreparedStatement ps = null; ResultSet rs = null; try { //1.加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //2.获得连接 connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/servlet_users_manager&quot;,&quot;root&quot;,&quot;root&quot;); //3.创建prepareStatement ps = connection.prepareStatement(&quot;select * from users where username = ? and passwd = ?&quot;); ps.setObject(1,username); ps.setObject(2,password); //4.执行操作 rs = ps.executeQuery(); //5.根据结果做处理 if(rs.next()){ //说明用户合法 System.out.println(rs.getString(&quot;username&quot;) + &quot; &quot; + rs.getString(&quot;passwd&quot;)); request.getRequestDispatcher(&quot;/MainFrame&quot;).forward(request,response); }else{ request.getRequestDispatcher(&quot;/Login&quot;).forward(request,response); } } catch (Exception e) { e.printStackTrace(); }finally { //关闭资源 if(rs != null){ // 关闭记录集 try{ rs.close(); }catch(Exception e){ e.printStackTrace() ; } } if(ps != null){ // 关闭声明 try{ ps.close() ; }catch(Exception e){ e.printStackTrace() ; } } if(connection != null){ // 关闭连接对象 try{ connection.close() ; }catch(Exception e){ e.printStackTrace() ; } } } 分页定义四个分页变量 pageNow 表示第几页,该变量是由用户来决定,因此变化 pageSize 每页显示几条记录,由程序指定,也可以由用户定制 pageCount 表示共有多少页, 该变量是计算出来-&gt;思考 怎样确定 rowCount 共有多少条记录,该变量是查询数据库得到 如何确定pageCount (1) if(rowCount% pageSize==0){ pageCount=rowCount/pageSize; }else{ pageCount= rowCount/pageSize+1; } 试试: 比如 users表 9 条记录 pageSize=3 =&gt;pageCount=3 比如 users表 10 条记录 pageSize=3 =&gt;pageCount=4 (2) 上面的算法等价于 pageCount=rowCount% pageSize==0 ? rowCount/pageSize: rowCount/pageSize+1; 该运算称为三目运算 (3) 更简单的算法是:★★★★★ pageCount=(rowCount-1)/pageSize+1; 试试: 比如 users表 9 条记录 pageSize=3 =&gt;pageCount=3 比如 users表 11 条记录 pageSize=3 =&gt;pageCount=4 为什么？ 如果pageSize整除rowCount，值不需要加一； 如果pageSize不整除rowCount，值需要加一。 我们可以使rowCount-1，保证每次都不能整除，这样可以得到统一公式: pageCount = （rowCount-1）/pageSize + 1 项目中传递参数客户端传递：pageNow、pageSize（为保证程序健壮性，服务器中设置pageNow和pageSize的默认值）服务器传递：数据和rowCount MD5利用Java自带的MD5加密 class MD5Util { public final static String MD5(String s) { char hexDigits[] = { &apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos; }; try { byte[] strTemp = s.getBytes(); MessageDigest mdTemp = MessageDigest.getInstance(&quot;MD5&quot;); mdTemp.update(strTemp); byte[] md = mdTemp.digest(); int j = md.length; char str[] = new char[j * 2]; int k = 0; for (int i = 0; i &lt; j; i++) { byte byte0 = md[i]; str[k++] = hexDigits[byte0 &gt;&gt;&gt; 4 &amp; 0xf]; str[k++] = hexDigits[byte0 &amp; 0xf]; } return new String(str); } catch (Exception e) { return null; } } public static void main(String[] args) { // MD5_Test aa = new MD5_Test(); System.out.print(MD5Util.MD5(&quot;qm&quot;)); } } 验证码public class check_code extends HttpServlet { protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 7.禁止浏览器缓存随机图片 response.setDateHeader(&quot;Expires&quot;, -1); response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;); response.setHeader(&quot;Pragma&quot;, &quot;no-cache&quot;); // 6.通知客户机以图片方式打开发送过去的数据 response.setHeader(&quot;Content-Type&quot;, &quot;image/jpeg&quot;); // 1.在内存中创建一副图片 BufferedImage image = new BufferedImage(60,30,BufferedImage.TYPE_INT_RGB); // 2.向图片上写数据 Graphics g = image.getGraphics(); // 设背景色 g.setColor(Color.BLACK); g.fillRect(0, 0, 60, 30); // 3.设置写入数据的颜色和字体 g.setColor(Color.RED); g.setFont(new Font(null, Font.BOLD, 20)); // 4.向图片上写数据 String num = makeNum(); //这句话就是把随机生成的数值，保存到session request.getSession().setAttribute(&quot;check_code&quot;, num); //通过session就可以直接去到随即生成的验证码了 g.drawString(num, 5, 22); // 5.把写好数据的图片输出给浏览器 ImageIO.write(image, &quot;jpg&quot;, response.getOutputStream()); } //该函数时随机生成4位数字 public String makeNum() { Random r = new Random(); //9999999 可以生成7位 String num = r.nextInt(9999) + &quot;&quot;; StringBuffer sb = new StringBuffer(); //如果不够4位，前面补零 for (int i = 0; i &lt; 4 - num.length(); i++) { sb.append(&quot;0&quot;); } num = sb.toString() + num; return num; } protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { this.doPost(request, response); } } list转string[]方法一：单个元素转换 //ArrayList ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;(); array.add(&quot;aaa&quot;); array.add(&quot;bbb&quot;); array.add(&quot;ccc&quot;); //转化成Object数组 Object[] objs = array.toArray(); //新建数组 String[] strings = new String[array.size()]; //每个元素类型转换 int i = 0; for(Object obj : objs){ if(obj instanceof String){ strings[i++] = (String)obj; } } for(String s : strings){ System.out.println(s); } 方法二：整个转 //ArrayList ArrayList&lt;String&gt; array = new ArrayList&lt;String&gt;(); array.add(&quot;aaa&quot;); array.add(&quot;bbb&quot;); array.add(&quot;ccc&quot;); String[] strings = new String[array.size()]; array.toArray(strings); for(String s : strings){ System.out.println(s); }]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA快捷键]]></title>
    <url>%2F2016%2F07%2F08%2F%5BIDEA%5DIDEA%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[参考http://blog.csdn.net/dc_726/article/details/42784275 智能提示 Alt + /基本代码提示 CTRL+空格(和系统输入法冲突，请在Settings-&gt;Keymap-&gt;mainmenu -&gt; code -Completion-&gt;basic，右键添加自己的快捷键)，可以设置为Alt + / Ctrl + Alt + /更智能地按类型信息提示 默认为Ctrl+Shift+Space ALT + Enter 快速修复，类似Eclipse中的Quick Fix功能 Ctrl+Shift+Enter 自动补全末尾的字符，例如敲完if/for时也可以自动补上{}花括号 F2/ Shift+F2 移动到有错误的代码 重构 Ctrl+Shift+Alt+T 重构功能大汇总快捷键，叫做Refactor This Shift+F6 直接就是改名 Ctrl+Alt+V 提取变量 代码生成 Ctrl+J 可以查看所有模板 Alt+Insert，在编辑窗口中点击可以生成构造函数、toString、getter/setter、重写父类方法等 编辑 Ctrl + Shift + 上下 ： 上下移动当前行 Ctrl + Shift + 左右 ：代替鼠标选中代码 Ctrl + Alt + 上下 ： 复制一行 Alt + 上下 ： 光标函数间跳转 Alt + 左右 ： tab切换 Ctrl + D ： 删除一行 Ctrl + / ： 注释 Ctrl + / Ctrl + Shift + / ： 折叠代码 Ctrl + ‘+’ Ctrl + Shift + ‘+’： 展开代码 Ctrl+N / Ctrl+Shift+N 可以打开类或资源 Shift+Shift 在一个弹出框中搜索任何东西，包括类、资源、配置项、方法等等 Ctrl+F/Ctrl+Shift+F 在当前窗口或全工程中查找 F3/Shift+F3前后移动到下一匹配处 格式化代码 格式化import列表：Ctrl+Alt+O 格式化代码：Ctrl+Alt+L 自动代码 CTRL+ALT+L 格式化代码 CTRL+E或者ALT+SHIFT+C 最近更改的代码 CTRL+SHIFT+SPACE 自动补全代码 CTRL+ALT+SPACE 类名或接口名提示 CTRL+P 方法参数提示 CTRL+ALT+T 代码模版 Ctrl+Shift+T 自动生成测试类 其他 CIRL+U 大小写切换 CTRL+Z 倒退 CTRL+SHIFT+Z 向前 CTRL+ALT+F12 资源管理器打开文件夹在WINDOW窗口快速定位到文件或者文件夹的位置 ALT+F1 查找文件所在目录位置 SHIFT+ALT+INSERT 竖编辑模式 CTRL+/ 注释// CTRL+SHIFT+/ 注释 CTRL+B 快速打开光标处的类或方法 page up 和 page down ALT+ ←/→ 切换代码视图 ALT+ ↑/↓ 在方法间快速移动定位 CTRL+ALT ←/→ 返回上次编辑的位置 SHIFT+F6 重构-重命名 CTRL+H 显示类结构图 CTRL+Q 显示注释文档 ALT+1 快速打开或隐藏工程面板 ALT + 4 Run Console ALT + 5 Debug Console 在任何工具窗口里使用Escape键都可以把焦点移到编辑器上,Shift-Escape不仅可以把焦点移到编辑器上而且还可以隐藏当前（或最后活动的）工具窗口 CTRL+W 选中代码，连续按会有其他效果（我去掉了） CTRL+F4 关闭当前打开文件（我修改为CTRL + W） Ctrl + Shift + F12 关闭所有工具栏 Ctrl+H 查看类的继承关系，打开类层次窗口 Ctrl+F12 查看当前类的所有方法 Ctrl+B/Ctrl+Alt+B 在继承层次上跳转，分别对应父类或父方法定义和子类或子方法实现 Ctrl + tab 切来切去 Ctrl + Shift + A 发号施令 CTRL+G 定位行 JDK doc绑定CTRL + Q 查看注释文档]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>JavaEE</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij IDEA15创建Maven管理的Java Web项目（使用IDEA启动方式，较复杂）]]></title>
    <url>%2F2016%2F07%2F07%2F%5BServlet%5DIntellij%20IDEA%E5%88%9B%E5%BB%BAMaven%E7%AE%A1%E7%90%86%E7%9A%84Java%20Web%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%BD%BF%E7%94%A8IDEA%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%EF%BC%8C%E8%BE%83%E5%A4%8D%E6%9D%82%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本文的思路是先创建Maven项目，再加上Java Web模块支持 创建Maven项目File - New - Project，创建Maven项目 Next，填写GroupId，ArtifactId和Version Next，这里在Properties中添加一个参数archetypeCatalog=internal，不加这个参数，在maven生成骨架的时候将会非常慢，有时候会直接卡住。 来自网上的解释： archetypeCatalog表示插件使用的archetype元数据，不加这个参数时默认为remote，local，即中央仓库archetype元数据，由于中央仓库的archetype太多了，所以导致很慢，指定internal来表示仅使用内部元数据。 Next，填写项目名和module名称，项目名和模块名可以不一样（还不是很清楚两者的区别） 点击Finsh，项目的目录结构如下： Maven规定，src文件下有main和test两个文件夹。其中： main文件为项目主体目录，main下的java文件夹为源代码目录，resource为所需资源目录 test为项目测试目录，test下的java文件夹为测试代码目录，resources为测试所需资源目录 发现生成的Maven项目，没有Web目录！在项目名称右击，选择Add Framework Support 在Add Framework Support对话框中勾选Web Application，版本选择3.0并勾选Create web.xml 点击OK后，看到如下界面，项目中出现了web文件夹，是不是很熟悉了，和MyEclipse中的项目结构类似 配置Tomcat服务器点击右上角的倒三角，选择Edit Configurations，弹出服务器配置页面 如下图，选择Local，然后点击Configure，在弹出的对话框中选择Tomcat安装目录 选择Tomcat Server，然后点击绿色的“+”号 点击“+”后选择Local，刚刚已经配置好了Local的Tomcat服务器 这里会新建一个Tomcat服务，输入任意名字即可。Update的快捷键是Ctrl+F10 点击Deployment，然后点击右边的“+”，添加Artifact部署 输入应用程序Context，输入路径:/工程名 点击界面上方的启动按钮就可以启动Tomcat服务器，启动后服务器自动打开浏览器 回到主界面，如图，点击Run打开服务器视图，能看到项目的部署情况了，而且可以完成服务器重启/关闭，项目部署等操作]]></content>
      <categories>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet笔记]]></title>
    <url>%2F2016%2F07%2F06%2F%5BServlet%5DServlet%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[常用#网页输出 PrintWriter out = response.getWriter(); out.println(&quot;Hello World&quot;); #请求头 request.getHeader(&quot;host&quot;)//参数见http请求头那节 //获取所有请求体 Enumeration&lt;String&gt; names = request.getHeaderNames(); while(names.hasMoreElements()){ String name = names.nextElement(); System.out.println(name + &quot;：&quot; + request.getHeader(name)); } #浏览器返回 response.setContentType(&quot;text/html;charset=utf-8&quot;); response.setCharacterEncoding(&quot;utf-8&quot;); #获得请求参数 String username = request.getParameter(&quot;username&quot;); Enumeration&lt;String&gt; e = request.getParameterNames() #跳转 1、request.getRequestDispatcher(&quot;/资源URI&quot;).forward(request,response) 2、response.sendRedirect(&quot;/web应用/资源URI&quot;); #获得web应用根路径 String path = this.getServletContext().getRealPath(&quot;/&quot;); #获得资源路径 String path = this.getServletContext().getRealPath(&quot;/image/无标题.png&quot;); #session，可以存字符串和对象 request.getSession().setAttribute(&quot;username&quot;,username); request.getSession().getAttribute(&quot;username&quot;) 为什么需要Servlet技术？ 普通的java技术很难完成网站开发，sun 就开发了servlet技术供程序员使用 servlet的介绍 servlet 其实就是java程序(java类) 该 java程序(java 类)要遵循servlet开发规范，继承servlet类 serlvet是运行在服务端 serlvet功能强大,几乎可以完成网站的所有功能 是学习jsp基础 Tomcat 和 servlet 在网络中的位置 Tomcat三大功能 Web服务器，与浏览器通信，解析和处理HTTP请求，处理静态页面 Servlet容器（Catalina），处理Servlet JSP容器，把JSP页面翻译成一般的Servlet Servlet容器与Servlet关系★★★★★ Servlet技术的核心是Servlet，所有的Servlet类必须直接或间接实现Servlet接口 Servlet接口定义了Servlet与Servlet容器之间的契约，即Servlet容器将Servlet类载入内存，并在Servlet实例是调用具体的方法，如用户请求时Servlet调用Servlet的Service方法，并传入一个ServletRequest实例和一个ServletResponse实例 Web程序目录结构 静态页面、jsp直接放在web目录下 Servlet是Java程序，必须放在WEB-INF/classes目录下 Servlet工作流程★★★ 用户输入的URL为http://localhost:8088/hspWeb1/MyFirstServlet 浏览器解析主机名（host文件，dns） 浏览器尝试连接web服务器（三次握手） 浏览器发送http请求 web服务器开始工作，首先解析主机名，选择使用哪个主机（引擎下有多个主机，有默认主机） web服务器解析web应用，确定使用主机下的context web服务器解析资源名，一个web应用下有多个资源，这里是MyFirstServlet 查询web.xml文件，确定MyFirstServlet在哪个包下 Web服务器利用反射机制，创建实例，并调用init方法（该方法只调用一次） web服务器把接收到的http请求封装成Request对象，作为service的参数传入。service会被调用多次，没访问一次Servlet，它的service就会被调用一次 Servlet获得response对象，返回结果 web服务器把request的信息拆除，形成http响应格式 当在某些情况下（tomcat重启、reload该webapp、重启电脑）web服务器会调用Servlet的destroy方法，将该servlet销毁 面试题: 请简述servlet的生命周期(工作流程)答: 当第一次访问某个servlet，web服务器将会创建一个该servlet的实例，并且调用 servlet的init()方法，init函数只会被调用一次；如果当服务器已经存在了一个servlet实例，那么，将直接使用此实例；每次请求都会调用service()方法，service()方法将根据客户端的请求方式来决定调用对应的doXXX()方法；当 web应用 reload 或者 关闭 tomcat 或者 关机，web服务器将调用destroy()方法，将该servlet从服务器内存中删除。 开发Servlet程序开发servlet有三种方法★★★ (1) 实现 Servlet接口(对Servlet的工作过程有清晰的认识) (2) 通过继承 GenericServlet (3) 通过继承 HttpServlet ①实现servlet接口的方式需求如下: 请使用实现接口的方式，来开发一个Servlet，要求该Servlet可以显示Hello，world，同时显示当前时间 步骤1、在webapps下建立一个web应用my2、在my下建立 WEB-INF-&gt;web.xml [web.xml可以从 ROOT/WEB-INF/web.xml拷贝]3、在WEB-INF下建立 classes 目录(我们的Servlet 就要在该目录开发)，建立lib文件夹4、开发MyServlet.java package com.apeius; import java.io.*; import javax.servlet.*; import javax.servlet.http.*; public class MyServlet implements Servlet { //该函数用于初始化servlet,就是把该servlet装载到内存中,该函数只会被调用一次 /*调用这个方法，Servlet容器会传入一个ServletConfig， * 一般会将ServletConfig赋给一个类级对象，这样可以在Servlet类中其他点来使用， * 但Servlet实例会被一个应用程序的所有用户共享，使用类级变量须是只读的，或者是 * java.util.concurrent.atomic包的成员 * / public void init(ServletConfig config) throws ServletException{ } //得到ServletConfig对象 public ServletConfig getServletConfig(){ return null; } //该函数是服务函数,我们的业务逻辑代码就是写在这里 //该函数每次都会被调用 public void service(ServletRequest req, ServletResponse res) throws ServletException, java.io.IOException{ //在控制台输出时间 System.out.println(new java.util.Date()); } //该函数时得到servlet配置信息 public java.lang.String getServletInfo(){ return null; } //销毁该servlet,从内存中清除,该函数被调用一次 public void destroy(){ } } 5、编译 如果使用javac去编译一个带package的java文件，则需要带命令参数javac –d . java文件 6、根据Servlet规范，我们还需要部署Servlet &lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt; &lt;web-app xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; version=&quot;2.5&quot;&gt; &lt;!--根据serlvet规范，需要将Servlet部署到web.xml文件,该部署配置可以从examples下拷贝--&gt; &lt;servlet&gt; &lt;!--servlet-name 给该Servlet取名, 该名字可以自己定义:默认就使用该Servlet的名字--&gt; &lt;servlet-name&gt;MyServlet&lt;/servlet-name&gt;&lt;!--③--&gt; &lt;!--servlet-class要指明该Servlet 放在哪个包下 的,形式是 包/包/../类--&gt; &lt;servlet-class&gt;com.apeius.MyServlet&lt;/servlet-class&gt; &lt;!--注意:后面不要带.java④--&gt; &lt;/servlet&gt; &lt;!--Servlet的映射--&gt; &lt;servlet-mapping&gt; &lt;!--这个Servlet-name要和上面的servlet-name名字一样--&gt; &lt;servlet-name&gt;MyServlet&lt;/servlet-name&gt;&lt;!--②--&gt; &lt;!--url-pattern 这里就是将来访问该Servlet的资源名部分，默认命名规范就是Servlet的名字--&gt; &lt;url-pattern&gt;/ABC&lt;/url-pattern&gt;&lt;!--①则访问的url为localhost:8080/my/ABC--&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 服务器调用流程：http://localhost:8088/my/ABC---&gt;①---&gt;②---&gt;③---&gt;④ 7、在浏览器中测试 在浏览器中输入http://localhost:8080/my/ABC ②使用GenericServlet开发servlet（了解即可）为什么使用GenericServlet1、实现Servlet接口必须实现接口中的所有方法，即使有一些方法根本没有包含任何代码2、此外还需要将ServletConfig对象保存到类级变量中 GenericServlet完成的任务 将init方法中个ServletConfig赋给一个类级变量，以便可以通过getServletConfig获取 为Servlet接口中的所有方法提供默认的实现 提供方法，包围ServletConfig中的方法 GenericServlet原理GenericServlet通过将ServletConfig赋给init方法中的类级变量private transient ServletConfig config；来保存ServletConfig public void init(ServletConfig config) throws ServletException { this.config = config; this.init(); } 但是，如果在子类中覆盖了这个方法，就会调用Servlet中的init方法，并且还必须调用super.init(servletConfig)来保存ServletConfig，为了避免上述麻烦，GenericServlet提供了第二个init方法，它不带参数。这个方法是在ServletConfig被赋给servletConfig后，由第一个init方法调用，子类改写后调用的是子类的无参数init方法 总结：Tomcat调用Servlet接口的init(ServletConfig config)方法，其实现类是用户继承的子类，该子类重写了无参数的init方法进行初始化工作。首先调用父类中的init(ServletConfig config)方法，将config对象保存为类级变量，然后调用this.init()方法，this指针指向子类实例，init方法被重写，所以调用子类的init方法，若需要访问GenericServlet中的无参数init方法，则需要在子类中使用super.init()； 开发步骤继承GenericServlet package com.hsp; import javax.servlet.*; import javax.servlet.http.*; import java.io.*; public class MyGenericServlet extends GenericServlet { public void service(ServletRequest req, ServletResponse res) throws ServletException, java.io.IOException{ res.getWriter().println(&quot;hello,world,i am geneirc servlet&quot;); } } 将该Servlet部署到web.xml文件中: &lt;!--根据serlvet规范，需要将Servlet部署到web.xml文件,该部署配置可以从examples下拷贝--&gt; &lt;servlet&gt; &lt;!--servlet-name 给该Servlet取名, 该名字可以自己定义:默认就使用该Servlet的名字--&gt; &lt;servlet-name&gt;MyGenericServlet&lt;/servlet-name&gt; &lt;!--servlet-class要指明该Servlet 放在哪个包下 的,形式是 包/包/../类--&gt; &lt;servlet-class&gt;com.hsp.MyGenericServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;!--Servlet的映射--&gt; &lt;servlet-mapping&gt; &lt;!--这个Servlet-name要和上面的servlet-name名字一样--&gt; &lt;servlet-name&gt;MyGenericServlet&lt;/servlet-name&gt; &lt;!--url-pattern 这里就是将来访问该Servlet的资源名部分,默认命名规范: 就是该Servlet的名字--&gt; &lt;url-pattern&gt;/MyGenericServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; ③使用继承 HttpServlet 的方法来开发Serlvet 在软件公司 90%都是通过该方法开发. 举例说明，还是显示 hello,world 当前日期 原理 HttpServlet类继承了GenericServlet类，并重写了service(ServletRequest req,ServletResponse res)方法，Tomcat调用Servlet接口的service(ServletRequest req,ServletResponse res)方法，实际调用的是HttpServlet类中的的service(ServletRequest req,ServletResponse res)方法，方法体内将ServletRequest和ServletResponse强转成HttpServletRequest和HttpServletResponse，并调用新添加的service方法 public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException { HttpServletRequest request; HttpServletResponse response; try { request = (HttpServletRequest) req; response = (HttpServletResponse) res; } catch (ClassCastException e) { throw new ServletException(&quot;non-HTTP request or response&quot;); } service(request, response); } HttpServlet中扩展了一个protected void service(HttpServletRequest req, HttpServletResponse resp)方法，根据不同的请求方法，调用不同的doXXX方法 protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { long lastModified = getLastModified(req); if (lastModified == -1) { // servlet doesn&apos;t support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); } else { long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) { // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); } else { resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); } } } else if (method.equals(METHOD_HEAD)) { long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp); } else if (method.equals(METHOD_PUT)) { doPut(req, resp); } else if (method.equals(METHOD_DELETE)) { doDelete(req, resp); } else if (method.equals(METHOD_OPTIONS)) { doOptions(req,resp); } else if (method.equals(METHOD_TRACE)) { doTrace(req,resp); } else { // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); } } 子类继承后，通过改写doGet和doPost方法，实现方法的调用 开发步骤代码 package com.apeius; import javax.servlet.*; import javax.servlet.http.*; import java.io.*; public class MyHttpServlet extends HttpServlet { //在HttpServlet 中，设计者对post 提交和 get提交分别处理 //回忆 &lt;form action=&quot;提交给?&quot; method=&quot;post|get&quot;/&gt;,默认是get protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, java.io.IOException{ resp.getWriter().println(&quot;i am httpServet doGet()&quot;); } protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, java.io.IOException{ resp.getWriter().println(&quot;i am httpServet doPost() post name=&quot;+req.getParameter(&quot;username&quot;)); } } 还有一个login.html &lt;html&gt; &lt;body&gt; &lt;form action=&quot;/my/MyHttpServlet&quot; method=&quot;post&quot;&gt; u:&lt;input type=&quot;text&quot; name=&quot;username&quot;/&gt; &lt;input type=&quot;submit&quot; value=&quot;login&quot;/&gt; &lt;/body&gt; &lt;/html&gt; 部署 &lt;!--根据serlvet规范，需要将Servlet部署到web.xml文件,该部署配置可以从examples下拷贝--&gt; &lt;servlet&gt; &lt;!--servlet-name 给该Servlet取名, 该名字可以自己定义:默认就使用该Servlet的名字--&gt; &lt;servlet-name&gt;MyHttpServlet&lt;/servlet-name&gt;&lt;!--③--&gt; &lt;!--servlet-class要指明该Servlet 放在哪个包下 的,形式是 包/包/../类--&gt; &lt;servlet-class&gt;com.apeius.MyHttpServlet&lt;/servlet-class&gt; &lt;!--注意:后面不要带.java④--&gt; &lt;/servlet&gt; &lt;!--Servlet的映射--&gt; &lt;servlet-mapping&gt; &lt;!--这个Servlet-name要和上面的servlet-name名字一样--&gt; &lt;servlet-name&gt;MyHttpServlet&lt;/servlet-name&gt;&lt;!--②--&gt; &lt;!--url-pattern 这里就是将来访问该Servlet的资源名部分，默认命名规范就是Servlet的名字--&gt; &lt;url-pattern&gt;/MyHttpServlet&lt;/url-pattern&gt;&lt;!--①则访问的url为localhost:8080/my/ABC--&gt; &lt;/servlet-mapping&gt; 使用myeclipse来开发servlet，IDEA类似(1) 建立web工程 (2) 在Src 目录下创建了一个包 com.hsp.servlet 添加Package，方法一般只需创建doGet()和doPost()方法，修改Servlet/JSP Mapping URL (3) 开发一个Servlet MySerlvet 的代码: public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html&quot;); PrintWriter out = response.getWriter(); out.println(&quot;hello &quot;+new java.util.Date().toString() ); } public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { this.doGet(request, response); } } 使用IDEA来开发Servlet程序 见另一篇博文:Intellij IDEA15创建Maven管理的Java Web项目 Servlet的细节问题[映射、单例、通配符、自启动]① 一个已经注册的Servlet可以被多次映射即:&lt;servlet&gt; &lt;description&gt;This is the description of my J2EE component&lt;/description&gt; &lt;display-name&gt;This is the display name of my J2EE component&lt;/display-name&gt; &lt;!-- servlet的注册名 --&gt; &lt;servlet-name&gt;MyServlet1&lt;/servlet-name&gt; &lt;!-- servlet类的全路径(包名+类名) --&gt; &lt;servlet-class&gt;com.hsp.servlet.MyServlet1&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;!-- 对一个已经注册的servlet的映射 --&gt; &lt;!-- 映射1 --&gt; &lt;servlet-mapping&gt; &lt;!-- servelt的注册名 --&gt; &lt;servlet-name&gt;MyServlet1&lt;/servlet-name&gt; &lt;!-- servlet的访问路径 --&gt; &lt;url-pattern&gt;/MyServlet1&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 映射2 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;MyServlet1&lt;/servlet-name&gt; &lt;url-pattern&gt;/hsp&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; ② 映射一个servlet时候，可以多层，比如&lt;url-pattern&gt;/servlet/index.html&lt;/url-pattern&gt; 从这里还可以看出，后缀名是 html 不一定就是 html,可能是假象. ③ 用通配符在servlet映射到URL中有两种格式: 第一种格式 *.扩展名，比如 *.do，*.ss 第二种格式 以 / 开头，同时以 /* 结尾。比如 /*,/news/* 在匹配的时候，要参考的标准: 看谁的匹配度高，谁就被选择 *.do的优先级最低 通配符练习题： ● Servlet1 映射到 /abc/* ● Servlet2 映射到 /* ● Servlet3 映射到 /abc ● Servlet4 映射到 *.do 问题(面试题)： 当请求URL为&apos;/abc/a.html&apos;，&apos;/abc/*&apos;和&apos;/*&apos;都匹配，哪个servlet响应 Servlet引擎将调用Servlet1。 当请求URL为&apos;/abc&apos;时，&apos;/abc/*&apos;和&apos;/abc&apos;都匹配，哪个servlet响应 Servlet引擎将调用Servlet3。 当请求URL为“/abc/a.do”时，“/abc/*”和“*.do”都匹配，哪个servlet响应 Servlet引擎将调用Servlet1。 当请求URL为“/a.do”时，“/*”和“*.do”都匹配，哪个servlet响应 Servlet引擎将调用Servlet2。 当请求URL为“/xxx/yyy/a.do”时，“/*”和“*.do”都匹配，哪个servlet响应 Servlet引擎将调用Servlet2。 ④Servlet单例问题 当Servlet被第一次访问后，就被加载到内存，以后该实例对各个请求服务，即在使用中是单例 Servlet实例会在一个应用程序中被所有用户共享，因此不建议使用类级变量 ，除非它们是只读的，或者是java.util.concurrent.atomic包的成员 证明： 在Servlet中定义一个变量i，当浏览器访问时i++，并输出i；如果Servlet是单例，则每次输出i都会增加 问题： 因为 Servlet是单例，因此会出现线程安全问题: 比如:售票系统. 如果不加同步机制，则会出现问题: 原则: （1）如果一个变量需要多个用户共享，则应当在访问该变量的时候，加同步机制 synchronized (对象){ //同步代码 } （2）如果一个变量不需要共享，则直接在 doGet() 或者 doPost()定义.这样不会存在线程安全问题 ⑤servlet中的&lt;load-on-startup&gt;配置需求 当我们的网站启动的时候，可能会要求初始化一些数据，(比如创建临时表), 在比如：我们的网站有一些要求定时完成的任务[ 定时写日志，定时备份数据.. 定时发送邮件..] 解决方法 可以通过 &lt; load-on-startup &gt; 配合线程知识搞定. 一般在有用户访问该Servlet时才会被加载进内存，现在需要在网站启动的时候自动启动Servlet。首先在web.xml下，该Servlet下进行配置&lt;load-on-startup &gt;1（数字Servlet启动优先级）&lt;/load-on-startup&gt; 这样该Servlet在网站启动时将会被自动创建. ServletConfig对象 调用Servlet的init方法时，Servlet容器会传入一个ServletConfig实例，该对象主要用于读取 servlet的配置信息 案例 &lt;servlet&gt; &lt;servlet-name&gt;ServletConfigTest&lt;/servlet-name&gt; &lt;servlet-class&gt;com.hsp.servlet.ServletConfigTest&lt;/servlet-class&gt; &lt;!-- 这里可以给servlet配置信息,这里配置的信息，只能被该servlet 读取 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; 获得配置参数 String encoding=this.getServletConfig().getInitParameter(&quot;encoding&quot;); 补充说明 这种配置参数的方式，只能被某个Servlet独立使用.如希望让所有的Servlet都去读取某个参数,这样配置: &lt;!-- 如果这里配置参数，可被所有servlet读取 --&gt; &lt;context-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/context-param&gt; 获得配置参数 String encoding = this.getServletContext().getInitParameter(&quot;encoding&quot;) 如果要把所有的参数都读取，则使用 如下方法 ： Enumeration&lt;String&gt; names=this.getServletConfig().getInitParameterNames(); while(names.hasMoreElements()){ String name=names.nextElement(); System.out.println(name); System.out.println(this.getServletConfig().getInitParameter(name)); } ServletContext★★★★★（包含读取文件路径）在访问某个网站时，首页会显示您是第几个浏览者，这个怎么实现的？除了数据库，文件等方式，最方便的是使用ServletContext。 ServletContext是一个公共的空间，可以被所有客户访问 Web容器在启动时，它会为每个Web应用程序创建一个对应的ServletContext对象，它代表当前Web应用。当web应用关闭/tomcat关闭/对web应用reload会造成servletContext销毁. ServletContext对象通过ServletConfig.getServletContext方法获得对ServletContext对象的引用，也可以通过this.getServletContext()来获得其对象的引用 每个Web应用程序只有一个上下文，一个Web应用中所有的Servlet共享同一个ServletContext对象，因此Servlet对象之间可以通过ServletContext对象实现通讯。ServletContext对象通常也被称为context域对象，公共聊天室就会用到它 基本使用获取: this.getServletContext(); #在HttpServlet中直接获取 this.getServletConfig().getServletContext(); # 在ServletConfig中获取 request.getSession().getServletContext(); #通过HttpRequest获得 添加属性: servletcontext.setAttribute(string,object); 取出属性 servletcontext.getAttribute(“属性名”) 删除 setvletContext.removeAttribute(“属性名”); ServletContext的应用获取WEB应用的初始化参数&lt;!-- 如果希望所有的servlet都可以访问该配置. --&gt; &lt;context-param&gt; &lt;param-name&gt;name&lt;/param-name&gt; &lt;param-value&gt;scott&lt;/param-value&gt; &lt;/context-param&gt; 如何获取 String val= this.getServletContext().getInitParameter(&quot;name&quot;); 使用ServletContext实现跳转//目前我们跳转到下一个页面的方法 //1 response.sendRedirect(&quot;/web应用名/资源名&quot;); //2 request.getRequestDispatcher(&quot;/资源名&quot;).forward(request, response); /* * 区别1. getRequestDispatcher 一个跳转发生在web服务器 sendRedirect发生在浏览器 * 2. 如果request.setAttribute(&quot;name&quot;,&quot;顺平&quot;) 希望下一个页面可以使用 属性值，则使用 getRequestDispatcher * 3. 如果session.setAttribute(&quot;name2&quot;,&quot;顺平3&quot;), 希望下一个页面可以使用 属性值，则两个方法均可使用,但是建议使用 getRequestDispatcher * 4. 如果我们希望跳转到本web应用外的一个url,应使用sendRedirect */ //3.这种方法和2一样 this.getServletContext().getRequestDispatcher(&quot;/资源url&quot;).forward(request, response); 读取文件，和获取文件全路径 读Web目录下和WEB-INF目录下的文件 //首先读取到文件dbinfo.properties放在web根目录下 InputStream inputStream=this.getServletContext().getResourceAsStream(&quot;dbinfo.properties&quot;); //创建Properties Properties pp=new Properties(); pp.load(inputStream); out.println(&quot;name=&quot;+pp.getProperty(&quot;username&quot;)); 如果文件放在src目录下(如果是maven项目，则resources目录下为根目录)，则使用类加载器 //如果文件放在上述目录下，我们应该使用类加载器来读取 InputStream is=Servlet5.class.getClassLoader().getResourceAsStream(&quot;dbinfo.properties&quot;) //如果放在包下，则带上包名，例如cn/apeius/xx.properties 获取文件全路径（以WEB目录为根目录） //如果读取到一个文件的全路径（dbinfo.properties在web目录下） String path=this.getServletContext().getRealPath(&quot;dbinfo.properties&quot;); out.println(&quot;paht = &quot;+path); 网站计数器 我们建立一个文件recoder.txt文件，用于保存访问量,可以可以保证稳定增长. 建立InitServlet,Web项目启动时自动加载该Servlet，读取record.txt，初始化Servletcontext中的访问量，和在关闭tomcat时保存访问量如record.txt 如果我们的tomcat异常退出，使用线程定时把ServletContext的值，刷新到recorder.txt http请求消息头1. Accept: text/html,image/* [告诉服务器，我可以接受 文本，网页，图片] 2. Accept-Charset: ISO-8859-1 [接受字符编码 iso-8859-1] 3. Accept-Encoding: gzip,compress [可以接受 gzip,compress压缩后数据.] 4. Accept-Language: en-us,zh-cn [浏览器支持中，英文] 5. Host: www.sohu.com:80 [我要找主机是 www.sohu.com:80] 6. If-Modified-Since: Tue, 11 Jul 2000 18:23:51 GMT [ 告诉服务器，我的缓冲中有这个资源文件，该文件的时间是 。。。，文件有更新才发送] 7. Referer: http://www.sohu.com/index.jsp [告诉服务器，我来自哪里,该消息头，常用于防止盗链] 8. User-Agent: Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0)[告诉服务器，浏览器内核] 9. Cookie [cookie后面介绍] 10. Connection: close/Keep-Alive [保持连接，发完数据后，我不关闭连接] 11. Date: Tue, 11 Jul 2000 18:23:51 GMT [浏览器发送该http请求的时间] http响应消息头Location: http://www.baidu.org/index.jsp 【让浏览器重新定位到url】 Server:apache tomcat 【告诉浏览器我是tomcat】 Content-Encoding: gzip 【告诉浏览器我使用 gzip】 Content-Length: 80 【告诉浏览器会送的数据大小80节】 Content-Language: zh-cn 【支持中文】 Content-Type: text/html; charset=GB2312 [内容格式text/html; 编码gab2312] Last-Modified: Tue, 11 Jul 2000 18:23:51 GMT 【告诉浏览器，该资源上次更新时间】 Refresh: 1;url=http://www.baidu.com 【过多久去，刷新到 http://www.baidu.com】 Content-Disposition: attachment; filename=aaa.zip 【告诉浏览器，有文件下载】 Transfer-Encoding: chunked [传输的编码] Set-Cookie:SS=Q0=5Lb_nQ; path=/search[后面详讲] Expires: -1[告诉浏览器如何缓存页面IE] Cache-Control: no-cache [告诉浏览器如何缓存页面火狐] Pragma: no-cache [告诉浏览器如何缓存页面] Connection: close/Keep-Alive [保持连接 1.1是Keep-Alive] Date: Tue, 11 Jul 2000 18:23:51 GMT http响应的状态行200 就是整个请求和响应过程没有发生错误，这个最常见. 302: 表示当你请求一个资源的时候，服务器返回302 表示，让浏览器转向到另外一个资源，比如: response.sendRedirect(“/web应用/资源名”) 案例: response.setStatus(302); response.setHeader(&quot;Location&quot;, &quot;/servletPro/Servlet2&quot;); // 上面两句话等价 response.sendRedirect(&quot;/servletPro/Servlet2&quot;); 404： 找不到资源 500: 服务器端错误 http响应头应用★★★[防盗链、定时、文件下载、缓存]防盗链 - Referer//获取用户浏览器Referer String referer=request.getHeader(&quot;Referer&quot;); if(referer==null||!referer.startsWith(&quot;http://localhost:8088/servletPro&quot;)){ response.sendRedirect(&quot;/servletPro/Error&quot;); return; } 定时刷新Refresh使用response.setHeader(&quot;Refresh&quot;, &quot;5;url=/servletPro/Servlet2&quot;); 文件下载 Content-Dispositionpublic void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html&quot;); //★★★需要注释 //PrintWriter out = response.getWriter(); //演示下载文件 response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment; filename=winter.jpg&quot;); //打开文件.说明一下web 站点下载文件的原理 //1.获取到要下载文件的全路径 String path=this.getServletContext().getRealPath(&quot;/images/Winter.jpg&quot;); //System.out.println(&quot;path=&quot;+path); //2创建文件输入流 FileInputStream fis=new FileInputStream(path); //做一个缓冲字节数组 byte buff[]=new byte[1024]; int len=0;//表示实际每次读取了多个个字节 OutputStream os=response.getOutputStream(); while((len=fis.read(buff))&gt;0){ os.write(buff, 0, len); } //关闭 os.close(); fis.close(); } 缓存讲解 提出问题：浏览器默认情况下，会缓存我们的页面，这样出现一个问题：如果我们的用户习惯把光标停留在地址栏，然后回车来取页面，就会默认调用cache中取数据（刷新还是会重新向服务器请求数据）。 （1）有些网站要求及时性很高，因此要求我们不缓存页面 //指定该页面不缓存 Ie response.setDateHeader(&quot;Expires&quot;, -1);//【针对IE浏览器设置不缓存】 //为了保证兼容性. response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;);//【针对火狐浏览器等】 response.setHeader(&quot;Pragma&quot;, &quot;no-cache&quot;);//【其他浏览器】 （2）有些网站要求网页缓存一定时间,比如缓存一个小时 response.setDateHeader(&quot;Expires&quot;, System.currentTimeMillis()+3600*1000*24);后面一个参数表示设置的缓存保持时间，-1表示永远缓存 HttpServletResponse的再说明HttpServletResponse中输出流两个方法： getWriter() getOutputStream() 区别 1、 getWriter() 用于向客户机回送字符数据 PrintWriter out = response.getWriter(); out.println(&quot;hello,world&quot;); 2、 getOutputStream() 返回的对象，可以回送字符数据，也可以回送字节数据(二进制数据)，但也可以输出文本内容 OutputStream os=response.getOutputStream(); os.write(&quot;hello,world&quot;.getBytes()); 如何选择: 如果我们是回送字符数据，则使用PrintWriter对象,效率高 如果我们是回送字节数据(binary date),则只能使用OutputStream 这两个流不能同时使用. 比如： OutputStream os=response.getOutputStream(); os.write(&quot;hello,world&quot;.getBytes()); PrintWriter out=response.getWriter(); out.println(&quot;abc&quot;); 就会报错: java.lang.IllegalStateException: getOutputStream() has already been called for this response 注意： Web服务器会自动检查并关闭流，为什么我们没有主动关闭流，程序也没有问题的原因.当然：你主动关闭流，更好. 参数的传递方式sendRedirect()和session() 需求: 当用户登录成功后，把该用户名字显示在登录成功页面; 解决方法 使用 java 基础 static，专门用一个类来存储静态数据 使用 sendRedirect()，在url上加上需要传递的参数 response.sendRedirect("/UsersManager/MainFrame?uname="+username+"&pwd="+password); 说明: 基本格式: response.sendRedirect("/Context/servlet的?参数名=参数值&参数名=参数值..."); 使用session传递 session既可以传递字符串，也可以传递对象 A.传递字符串 放入session request.getSession.setAttribute(&quot;loginUser&quot;,username); 取出session 在JSP中通过session取出 request.getSession.getAttribute(&quot;loginUser&quot;); B．传递对象 User user= new User(); user.setName(&quot;xiaoli&quot;); user.setPassWord(“123”); 放入session request.getSession.setAttribute(&quot;userObj&quot;,userObj); 取出session User user=(User)request.getSession.getAttribute(&quot;userObj&quot;); 中文乱码处理 发生中文乱码有三种情况，我们应当尽量使用post方式提交 ①表单form (1)表单以post方式提交 浏览器把请求发送给web服务器[utf-8]，web服务器以ISO-8859-1编码方式进行接收，产生乱码，之后进行传递也都是乱码。 在接收参数时，采用正确的编码，即可解决问题，在服务器端设置成浏览器端的编码方式。 request.setCharacterEncoding("utf-8"); //gbk gb2312 big5 (2)表单以get方式提交 请求内容是以请求行URL进行提交，而不是用请求体，所以使用setCharacterEncoding无效 写一个工具类: package com.hsp.utils; public class MyTools { public static String getNewString(String str) { String newString=&quot;&quot;; try { newString=new String(str.getBytes(&quot;iso-8859-1&quot;),&quot;utf-8&quot;); } catch (Exception e) { e.printStackTrace(); // 把iso-8859-1 转换成 utf-8 } return newString; } } ②超链接 数据以get方式进行传递，该方法和get处理方法一样. &lt;a href=”http://www.sohu.com?name=函数后”&gt;测试&lt;/a&gt; ③sendRedirect() 发生乱码 客户端会重新发送一个http请求，该方法和get处理方法一样 response.sendRedirect(&quot;servlet地址?username=顺平&quot;); 版本低导致的乱码 特别说明，如果你的浏览器是 ie6 或以下版本，则我们的 ② 和 ③中情况会出现乱码(当中文是奇数的时候)解决方法是 ： String info=java.net.URLEncoder.encode(&quot;你好吗.jpg&quot;, &quot;utf-8&quot;); &lt;a href=&quot;http://www.sohu.com?name=&quot;+ info &gt;测试&lt;/a&gt; response.sendRedirect(&quot;servlet地址?username=&quot; + info); ★★★★返回浏览器显示乱码 在服务端是中文，在response的时候，也要考虑浏览器显示是否正确,一般我们通过 response.setContentType(&quot;text/html;charset=utf-8&quot;); 下载提示框中文乱码 补充一个知识点: 当我们下载文件的时候，可能提示框是中文乱码 String temp=java.net.URLEncoder.encode(&quot;传奇.mp3&quot;,&quot;utf-8&quot;); response.setHeader(&quot;Content-Disposition&quot;,&quot;attachment; filename=&quot;+temp); HttpServletRequest对象的详解 该对象表示浏览器的请求(http请求), 当web服务器得到该请求后，会把请求信息封装成一个HttpServletRequest 对象 getRequestURL方法返回客户端发出请求时的完整URL。 getRequestURI方法返回请求行中的资源名部分。 getQueryString方法返回请求行中的参数部分(参数名+值)。该函数可以获取请求部分的数据，比如http://localhost/web名?username=abc&amp;pwd=123request.getQueryString();就会得到 username=abc&amp;pwd=123 getRemoteAddr方法返回发出请求的客户机的IP地址 getRemoteHost方法返回发出请求的客户机的完整主机名，如果该客户机没有在dns注册，则返回ip地址 getRemotePort方法返回客户机所使用的网络端口号，客户机的端口号是随机选择的，web服务器的端口号是一定的 getLocalPort方法返回web服务器所使用的网络端口号 getLocalAddr方法返回WEB服务器的IP地址。 getLocalName方法返回WEB服务器的主机名 url 和 uri 的区别比如： Url=http://localhost:8088/servletPort3/GetinfoServlet 完整的请求 Uri=/servletPort3/GetinfoServlet web应用的名称+资源的名称 请求转发getRequestDispatcher#请求转发 requeset.getRequestDispatcher(资源地址).forward(request,response); #可以在request的域对象中存储数据，request中的attribute在一次请求中有效 request.setAttribute(&quot;username&quot;,username); 资源地址：不需要项目名。因为它只是在WEB服务器内部转发。 Servlet接收到数据后，可以把数据放入到request域对象，Request中的Attribute在一次请求有效。 一次请求：浏览器发送一次http请求到接收到响应成为一次http请求，只要没有停止，也没有回到浏览器重定向，就算一次 请求转发的的(uml)图 使用forward不能转发到该web应用外的url 因为 forward 是发生在web服务器，所以 Servlet1 和 Servlet 2使用的是用一个request 和response. 使用sendRedirect() 方法不能通过request.setAttribute() 把 属性传递给下一个Servlet 面试题：请问sendRedirect和 forward的区别是什么？答: 1. 叫法sendRedirect()请求重定向，转发forward()叫请求转发 2. 实际发生的位置不一样 sendRedirect发生在浏览器，由浏览器重新发出http请求 forward发生web服务器，请求在web服务器转发 3. 用法不一样 request.getRequestDispatcher(“/资源URI”).forward(request,response) response.sendRedirect(“/web应用/资源URI”); 4. 能够去URL范围不一样 sendRedirect可以去外边URL forward只能去当前的WEB应用的资源 会话技术cookie什么是会话 基本概念: 指用户开一个浏览器，访问一个网站,只要不关闭该浏览器，不管该用户点击多少个超链接，访问多少资源，直到用户关闭浏览器，整个这个过程我们称为一次会话。比如打电话 为什么需要cookie技术(会话技术) 如何保存用户上次登录时间 如何显示用户浏览历史 如何把登录的用户名和密码电脑，下次登录，不需要重新输入 cookie的原理图 创建cookie//创建cookie Cookie cookie = new Cookie(&quot;name&quot;,&quot;qm&quot;); //设置cookie的生命周期 cookie.setMaxAge(3600); //把cookie会写给浏览器 response.addCookie(cookie); 读取cookieCookie[] cookies = request.getCookies(); System.out.println(cookies.length); for(Cookie c : cookies){ out.println(c.getName() + &quot; &quot; + c.getValue() + &quot;&lt;br/&gt;&quot;); } cookie的小结★★★ cookie 是在服务端创建 cookie 是保存在浏览器这端 cookie 的生命周期可以通过cookie.setMaxAge(2000);如果不设置setMaxAge则该cookie的生命周期当浏览器关闭时，就消亡 同一个浏览器多个实例共享cookie，若cookie没到期，关闭浏览器后还能共享该cookie。当然不同浏览器之间是不能共享cookie的，因为每个浏览器存放cookie的路径不一样(与session的区别，session在关闭浏览器后，不采取任何方式，无法访问到session) 我们可以把cookie想成一张表 如果cookie重名就会替换存在的cookie值 一个web应用可以保存多个cookie,但保存在客户端浏览器下同一个cookie文本中 浏览器访问web应用时，会携带该web应用相关的cookie cookie存放的时候是以明文方式存放，因此安全较低，我们可以通过加密后保存[MD5算法见Java基础常用-MD5] 举例 - 保存上次登录时间★★★//先获取cookie // 假设我们 保存上次登录时间的cookie &quot;lasttime&quot; &quot;2011-11-11 12:12:12&quot;; // 这里我们要考虑一个情况: 用户第一次登录 &apos;您是第一次登录..&apos; Cookie[] cookies = request.getCookies(); boolean b = false;//假设没有lasttime cookie if (cookies != null) { //保证有cookie,取遍历 for (Cookie cookie : cookies) { //取出名 String name = cookie.getName(); if (&quot;lasttime&quot;.equals(name)) { //显示 out.println(&quot;您上次登录时间是 &quot; + cookie.getValue()); //更新时间 //把当前日期保存cookie SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String nowTime = simpleDateFormat.format(new java.util.Date()); cookie.setValue(nowTime); cookie.setMaxAge(7 * 3600 * 24);//保存一周 response.addCookie(cookie); b = true; break; } } } if (!b) { //没有找到 out.println(&quot;您是第一次登录..&quot;); //把当前日期保存cookie SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String nowTime = simpleDateFormat.format(new java.util.Date()); Cookie cookie = new Cookie(&quot;lasttime&quot;, nowTime); cookie.setMaxAge(7 * 3600 * 24);//保存一周 response.addCookie(cookie); } cookie的细节★★★① 一个浏览器最多放入300cookie，一个web站点，最多20cookie，而且一个cookie大小限制子4k② cookie生命周期的再说明: cookie默认生命周期是会话级别，即浏览器关闭，cookie生命周期结束 通过setMaxAge() 可以设置生命周期 setMaxAge(正数)，即多少秒后该cookie失效 setMaxAge(0)，删除该cookie setMaxAge(负数)，相当于该cookie生命周期是会话级别 cookie的生命周期，指的是累计时间，例如设置生命周期为30s，那么在30s之后cookie消亡（与session区别，session是发呆时间，即在一段时间内没有访问session就会消亡） 案例 ： //先得到该cookie Cookie cookies[]=request.getCookies(); for(Cookie cookie: cookies){ if(cookie.getName().equals(&quot;id&quot;)){ System.out.println(&quot;id&quot;); //删除 cookie.setMaxAge(0); response.addCookie(cookie);//一定带上这句话，否则不能删除 } } 特别说明: 如果该web应用只有一个cookie ，则删除该cookie后，在浏览器的临时文件夹下没有该cookie文件，如果该web应用有多个cookie,则删除一个cookie后，文件还在，只是该cookie没有 ③ cookie存放中文，怎么处理 进行URLEncoder 存放: String val=java.net.URLEncoder.encode(&quot;顺平&quot;,&quot;utf-8&quot;); Cookie cookie=new Cookie(&quot;name&quot;,val); 取出: String val=java.net.URLDecoder.decode(cookie.getValue(), &quot;utf-8&quot;); out.println(&quot;name =&quot;+val); 会话技术session（生成验证码）session有什么用? 问题1: 如何实现在不同的页面，可以去查看信息(比如说购物车)，同时还要实现不同的用户看到的信息是自己. Session是服务端技术，可以为每一个用户的浏览器创建一个独享的session对象 session工作原理图 session对象一行就代表一个属性，键值对 request.getSession()获得session，若第一次访问session会自动被创建，该浏览器第二次访问时将字节返回之前创建的session，不会创建新的。 一个浏览器关联一个session。如果此时有新的浏览器2访问Servlet1，那么就会创建一个新的sesssion与浏览器2对应 session默认的生命周期是30分钟 session中使用setAttribute时使用相同的属性名，属性值会被替换 session基本使用//访问session[当发现没有session时候，就会自动创建session] HttpSession session = request.getSession(); //向session中添加属性 session.setAttribute(&quot;name&quot;,&quot;姓名&quot;); //从session中得到某个属性 String name = (String) session.getAttribute(&quot;name&quot;); out.println(name + &quot;&lt;br/&gt;&quot;); //从session中删除某个属性 session.removeAttribute(&quot;name&quot;); out.println((String) session.getAttribute(&quot;name&quot;) + &quot;&lt;br/&gt;&quot;); session小结① session是存在服务器的内存中② 一个用户浏览器，独享一个session域对象（不能浏览器会创建新的session）③ session中的属性的默认生命周期是30min，你可以通过web.xml来修改④ 3种session生命周期的设置 （1）一个地方是 tomcat/conf/web.xml &lt;session-config&gt; &lt;session-timeout&gt;30&lt;/session-timeout&gt;//表示30分钟的意思 &lt;/session-config&gt; 对所有的web应用生效 （2）另外一个地方，就是在单个web应用的下去修改 web.xml &lt;session-config&gt; &lt;session-timeout&gt;30&lt;/session-timeout&gt;session精确到分钟,cookie精确到秒 &lt;/session-config&gt; 如果发生冲突，则以自己的web应用优先级高 （3）session.setMaxInactiveinterval(60) 六十秒为发呆时间，即在这六十秒内没有访问过session，则session中所有属性失效 session周期是发呆时间，如果我们设置session是10s，是指在10s内，没有访问过session，session属性失效，如果在9s时候，你访问session，session就会重新计时 如果重启tomcat，或者reload web应用，或者关机了，session失效 我们也可以通过函数，让session失效。invalidate()方法让所有属性失效，通常用于用户安全退出 如果你希望某个session属性失效，可以使用方法removeAttribute ⑤ session中可以存放多个属性⑥ session可以存放对象⑦ 如果session.setAttribute(“name”,val)，如果名字重复，则会替换该属性. session的更深入理解为什么服务器能够为不同的浏览器提供不同session？ 图中浏览器A第一次访问Servlet1的时候，没有携带JSESSIONID，调用getSession()就会自动给你创建一个session，id为110，并创建cookie：JSESSIONID=110. 第二次浏览器访问Servlet2时，携带cookie：JSESSIONID=110，说明session已经创建，getSession（）方法返回id=110的session，能够获得session中的数据 同理，浏览器B访问servlet1时会新建一个新的session，id=119 每个浏览器独享一个session对象 session自动返回的cookie不会被写入文件，所以不同浏览器访问servlet会获取不同的session 生成验证码案例public class check_code extends HttpServlet { protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 7.禁止浏览器缓存随机图片 response.setDateHeader(&quot;Expires&quot;, -1); response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;); response.setHeader(&quot;Pragma&quot;, &quot;no-cache&quot;); // 6.通知客户机以图片方式打开发送过去的数据 response.setHeader(&quot;Content-Type&quot;, &quot;image/jpeg&quot;); // 1.在内存中创建一副图片 BufferedImage image = new BufferedImage(60,30,BufferedImage.TYPE_INT_RGB); // 2.向图片上写数据 Graphics g = image.getGraphics(); // 设背景色 g.setColor(Color.BLACK); g.fillRect(0, 0, 60, 30); // 3.设置写入数据的颜色和字体 g.setColor(Color.RED); g.setFont(new Font(null, Font.BOLD, 20)); // 4.向图片上写数据 String num = makeNum(); //这句话就是把随机生成的数值，保存到session request.getSession().setAttribute(&quot;check_code&quot;, num); //通过session就可以直接去到随即生成的验证码了 g.drawString(num, 5, 22); // 5.把写好数据的图片输出给浏览器 ImageIO.write(image, &quot;jpg&quot;, response.getOutputStream()); } //该函数时随机生成4位数字 public String makeNum() { Random r = new Random(); //9999999 可以生成7位 String num = r.nextInt(9999) + &quot;&quot;; StringBuffer sb = new StringBuffer(); //如果不够4位，前面补零 for (int i = 0; i &lt; 4 - num.length(); i++) { sb.append(&quot;0&quot;); } num = sb.toString() + num; return num; } protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { this.doPost(request, response); } } IE上购买商品后关闭，再打开IE，要求上次的商品还在分析 设session生命周期为30min,该session不会随浏览器的关闭而自动销毁。而会到30min后，才会被服务器销毁 关闭浏览器后，再打开。由于服务器端传回来的cookie：JSESSIONID没有设置生命周期，那么在浏览器关闭后cookie的生命周期结束。下次打开浏览器时，没有携带cookie：JSESSIONID，访问Servlet又会创建一个新的session 我们使用代码来实现该功能(session + cookie结合使用) 分析实现的思路: public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html;charset=utf-8&quot;); PrintWriter out = response.getWriter(); //创建一个session，并放入一个属性 HttpSession session = request.getSession(); session.setAttribute(&quot;name&quot;, &quot;xxx&quot;); out.println(&quot;创一个session并放入姓名属性&quot;); //把session_id保存在cookie，cookie名字必须按照规范命名，必须大写JSESSIONID Cookie cookie = new Cookie(&quot;JSESSIONID&quot;, session.getId()); ////如果不设置时间生命周期，cookie在浏览器关闭后就消亡 cookie.setMaxAge(60*30); response.addCookie(cookie); } ie禁用cookie后使用session的方法简易购物车的实例 思路 当用户点击购买商品时，我们把该商品保存到session中，该session的结构是: name val mybookds hashMap对象 而hashmap的结构是 key val 书号 书对象. 若禁用cookie后，每次访问Servlet不携带cookie数据，创建一个新的session，购物车商品不能保存 解决方法 URL重写 response.encodeURL(java.lang.String url)用于对表单action和超链接的url地址进行重写 response.encodeRedirectURL(java.lang.String url)用于对sendRedirect方法后的url地址进行重写 Servlet.java request.getSession();//必须访问一下sesion String url = response.encodeURL(&quot;/ServletStudy/cl&quot;); out.println(&quot;&lt;form method = &apos;post&apos; action = &apos;&quot;+url+&quot;&apos;&gt;&quot;); out.println(&quot;&lt;input type = &apos;submit&apos;/&gt;&quot;); out.println(&quot;&lt;/form&gt;&quot;); cl.java HttpSession session = request.getSession(); ArrayList&lt;String&gt; array = (ArrayList&lt;String&gt;) session.getAttribute(&quot;array&quot;); if(null == array){ array = new ArrayList&lt;String&gt;(); session.setAttribute(&quot;array&quot;,array); } SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String time = simpleDateFormat.format(new java.util.Date()); array.add(time); for(String s : array){ out.println(s + &quot;&lt;br/&gt;&quot;); } String url = response.encodeURL(&quot;/ServletStudy/Servlet&quot;); out.println(&quot;&lt;a href = &apos;&quot;+url+&quot;&apos;&gt;返回&lt;/a&gt;&quot;); cookie vs session存在的位置 cookie存在客户端的临时文件夹 session存在服务器的内存中，一个sessio与对象为一个用户浏览器服务 安全性 cookie是以明文方式存放在客户端，安全性弱，可以通过加密md5再存放 session是存放在服务端的内存中，安全性好 网络传输量 cookie会传递信息，给服务端 session的属性值不会给客户端 生命周期 cookie的生命周期是累计时间，即如果我们给cookie设置setMaxAge（30），则cookie在30s后失效 session额生命周期是间隔时间，如果我们设置session 20min，指在20min内，如果没有访问session，则session失效（指的是session属性失效），在关闭tomcat,reload web应用，时间到，invalidate也会让session失效 使用原则 因为session会占用服务器的内存，因此不要向session存放过多的对象，会影响性能 过滤器 Filter 客户端请求request在抵达Servlet之前、服务器响应response在从Servlet抵达客户端浏览器会经过过滤器，过滤器用于在Servlet之外对request或者response进行修改 Filter体现的是设计模式中的Filter模式 过滤器链 FilterChain一个过滤器链包括多个Filter，客户端请求request在抵达Servlet之前会经过FilterChain里的所有Filter，服务器响应response在从Servlet抵达客户端浏览器之前也会经过FilterChain里的所有Filter 防盗链Filterpublic class ImageRedirectFilter implements Filter { public void init(FilterConfig config) throws ServletException { } public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; // 禁止缓存 response.setHeader(&quot;Cache-Control&quot;, &quot;no-store&quot;); response.setHeader(&quot;Pragrma&quot;, &quot;no-cache&quot;); response.setDateHeader(&quot;Expires&quot;, 0); // 链接来源地址 String referer = request.getHeader(&quot;referer&quot;); if (referer == null || !referer.contains(request.getServerName())) { /** * 如果 链接地址来自其他网站，则返回错误图片 */ request.getRequestDispatcher(&quot;/error.gif&quot;).forward(request, response); } else { /** * 图片正常显示 */ chain.doFilter(request, response); } } public void destroy() { } } 配置： &lt;filter&gt; &lt;filter-name&gt;imageRedirectFilter&lt;/filter-name&gt; &lt;filter-class&gt; com.helloweenvsfei.filter.ImageRedirectFilter &lt;/filter-class&gt; &lt;/filter&gt; 字符编码 Filter自定义public class CharacterEncodingFilter implements Filter { private String characterEncoding; private boolean enabled; @Override public void init(FilterConfig config) throws ServletException { characterEncoding = config.getInitParameter(&quot;characterEncoding&quot;); enabled = &quot;true&quot;.equalsIgnoreCase(characterEncoding.trim()) || &quot;1&quot;.equalsIgnoreCase(characterEncoding.trim()); } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { if (enabled || characterEncoding != null) { request.setCharacterEncoding(characterEncoding); response.setCharacterEncoding(characterEncoding); } chain.doFilter(request, response); } @Override public void destroy() { characterEncoding = null; } } 配置： &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt; com.helloweenvsfei.filter.CharacterEncodingFilter &lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;characterEncoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;enable&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; Spring mvc自带&lt;!-- 编码过滤器，UTF8编码，对POST有效 --&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 异常捕捉 Filterpublic class ExceptionHandlerFilter implements Filter { public void destroy() {} public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { try { chain.doFilter(request, response); } catch (Exception e) { Throwable rootCause = e; while (rootCause.getCause() != null) { rootCause = rootCause.getCause(); } String message = rootCause.getMessage(); message = message == null ? &quot;异常：&quot; + rootCause.getClass().getName() : message; request.setAttribute(&quot;message&quot;, message); request.setAttribute(&quot;e&quot;, e); if (rootCause instanceof AccountException) { request.getRequestDispatcher(&quot;/accountException.jsp&quot;).forward( request, response); } else if (rootCause instanceof BusinessException) { request.getRequestDispatcher(&quot;/businessException.jsp&quot;).forward( request, response); } else { request.getRequestDispatcher(&quot;/exception.jsp&quot;).forward(request, response); } } } public void init(FilterConfig arg0) throws ServletException { } } 内容替换 Filter需求：有时候需要对网站的内容进行控制，防止输出非法内容或者敏感内容解决方案： 方案一：在Servlet里输出到客户端时进行内容替换，这种方案需要对每个Servlet都进行替换，工作量大，业务耦合比较严重 方案二：在Servlet将内容输出到response时，response将内容缓存起来，在Filter中进行替换，然后再输出到客户端浏览器。但是默认的response并不能严格的缓存输出内容，因此需要自定义一个具有缓存功能的response 要点：自定义的一个response只是一个伪装的response。Servlet会通过它输出内容到客户端，但是它内部只是将内容缓存起来了（使用自己创建的PrintWriter），并没有真正输出到客户端。最终输出到客户端还是通过原来的resonse完成的 框图： 具体操作： 1、通过扩展HttpServletResponseWrapper类来实现自定义的response，该类覆盖了getWriter()方法，当Servlet使用该response对象调用getWriter()莱输出内容时，内容将被输出到CharArrayWriter对象中，达到缓存的效果 public class HttpCharacterResponseWrapper extends HttpServletResponseWrapper { private CharArrayWriter charArrayWriter = new CharArrayWriter(); public HttpCharacterResponseWrapper(HttpServletResponse response) { super(response); } @Override public PrintWriter getWriter() throws IOException { return new PrintWriter(charArrayWriter); } public CharArrayWriter getCharArrayWriter() { return charArrayWriter; } } 2、Filter将自定义的response传进Servlet中 public class OutputReplaceFilter implements Filter { private Properties pp = new Properties(); public void init(FilterConfig config) throws ServletException { String file = config.getInitParameter("file"); String realPath = config.getServletContext().getRealPath(file); try { pp.load(new FileInputStream(realPath)); } catch (IOException e) { } } public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { // 自定义的 response HttpCharacterResponseWrapper response = new HttpCharacterResponseWrapper( (HttpServletResponse) res); // 提交给 Servlet 或者下一个 Filter chain.doFilter(req, response); // 得到缓存在自定义 response 中的输出内容 String output = response.getCharArrayWriter().toString(); // 修改，替换 for (Object obj : pp.keySet()) { String key = (String) obj; output = output.replace(key, pp.getProperty(key)); } // 输出 PrintWriter out = res.getWriter(); out.write(output); out.println(""); } public void destroy() { } } GZIP 压缩 FilterServlet中操作输入输出流： String path = request.getSession().getServletContext().getRealPath("/error.jpg"); InputStream inputStream = new FileInputStream(path); int len = -1; byte[] buffer = new byte[1024]; OutputStream outputStream = response.getOutputStream(); while((len = inputStream.read(buffer)) != -1){ outputStream.write(buffer,0,len); } outputStream.close(); inputStream.close(); 要点：1、替换response，并且替换的response中重写response中的getOutputStream()方法[也需要重写getWrite()，因为除了压缩二进制文件，还要压缩文本文件]2、重写ServletOutputStream，当调用write方法时，使用JDK自带的GZIPOutputStream类进行数据压缩★★★★★★★★（核心） 总体操作框图： ①自定义的GZipResponseWrapper替换tomcat传入的respone GZipResponseWrapper gzipResponse = new GZipResponseWrapper(response); chain.doFilter(request, gzipResponse); ②Servlet中调用response中的getOutputStream()获得输出流，数据写入缓存，调用close方法进行压缩 OutputStream outputStream = response.getOutputStream(); while((len = inputStream.read(buffer)) != -1){ outputStream.write(buffer,0,len); } outputStream.close(); inputStream.close(); ③输出压缩数据 gzipResponse.finishResponse(); GZIPOutputStream类API： void finish() 完成将压缩数据写入输出流的操作，无需关闭底层流。 void write(byte[] buf, int off, int len) 将字节数组写入压缩输出流。 1、GZipFilter，如果客户端支持GZip自动解压，则进行GZIP压缩，否则不压缩 public class GZipFilter implements Filter { public void destroy() { } public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; String acceptEncoding = request.getHeader("Accept-Encoding"); System.out.println("Accept-Encoding: " + acceptEncoding); if (acceptEncoding != null && acceptEncoding.toLowerCase().indexOf("gzip") != -1) { // 如果客户浏览器支持 GZIP 格式, 则使用 GZIP 压缩数据 GZipResponseWrapper gzipResponse = new GZipResponseWrapper(response); chain.doFilter(request, gzipResponse); /* * 输出压缩数据，一般由用户在调用outputStream.close()自己关闭输出流， * 此处调用是为了防止用户忘记 */ gzipResponse.finishResponse(); } else { // 否则, 不压缩 chain.doFilter(request, response); } } public void init(FilterConfig arg0) throws ServletException { } } 2、GZipResponseWrapper伪装response，GZipOutputStream为它的成员变量，Servlet中的输出就是对GZipOutputStream的操作 GZipResponseWrapper为自定义的response类，内部将对输出的内容进行GZIP压缩。它继承HttpServletResponseWrapper，也是一个伪装的response，不真正输出内容到客户端 由于该response要处理二进制内容，又要处理字符内容，因此需要覆盖getOutputStream和getWriter GZipResponseWrapper中的方法是实现对GZipOutputStream的操作 public class GZipResponseWrapper extends HttpServletResponseWrapper { /* * 传入默认的response，保存起来作为成员变量 */ private HttpServletResponse response; /* * 可以不保存，如果用户自己关闭输入流，则无需调用finishResponse方法来关闭文本或二进制输出流。 * 但是为了增加可靠性，在response抵达客户端浏览器前进行关闭流操作 */ // 自定义的 outputStream, 执行close()的时候对数据压缩，并输出 private GZipOutputStream gzipOutputStream; // 自定义 printWriter，将内容输出到 GZipOutputStream 中 private PrintWriter writer; public GZipResponseWrapper(HttpServletResponse response) throws IOException { super(response); this.response = response; } public ServletOutputStream getOutputStream() throws IOException { if (gzipOutputStream == null) gzipOutputStream = new GZipOutputStream(response); return gzipOutputStream; } public PrintWriter getWriter() throws IOException { if (writer == null) writer = new PrintWriter(new OutputStreamWriter( new GZipOutputStream(response), "UTF-8")); return writer; } // 压缩后数据长度会发生变化 因此将该方法内容置空 public void setContentLength(int contentLength) { } public void flushBuffer() throws IOException { gzipOutputStream.flush(); } public void finishResponse() throws IOException { if (gzipOutputStream != null) gzipOutputStream.close(); if (writer != null) writer.close(); } } 3、自定义GZipOutputStream类，继承ServletOutputStream，使用JDK自带的GZIP压缩类将数据缓存起来，之后调用finish函数进行数据压缩，并输出到客户端浏览器 public class GZipOutputStream extends ServletOutputStream { private HttpServletResponse response; // JDK 自带的压缩数据的类 private GZIPOutputStream gzipOutputStream; // 将压缩后的数据存放到 ByteArrayOutputStream 对象中 private ByteArrayOutputStream byteArrayOutputStream; /* * GZipResponseWrapper中调用构造函数，创建实例，数据缓存在ByteArrayOutputStream */ public GZipOutputStream(HttpServletResponse response) throws IOException { this.response = response; byteArrayOutputStream = new ByteArrayOutputStream(); gzipOutputStream = new GZIPOutputStream(byteArrayOutputStream); } /* * Servlet中调用write方法，将数据写入缓存 */ public void write(int b) throws IOException { gzipOutputStream.write(b); } /* * Servlet中调用close方法，并不是直接关闭输入流，而是先执行压缩操作，然后调用浏览器本身的输出流，在写入到客户端浏览器 */ public void close() throws IOException { // 压缩完毕 一定要调用该方法 gzipOutputStream.finish(); // 将压缩后的数据输出到客户端 byte[] content = byteArrayOutputStream.toByteArray(); // 设定压缩方式为 GZIP, 客户端浏览器会自动将数据解压 response.addHeader("Content-Encoding", "gzip"); response.addHeader("Content-Length", Integer.toString(content.length)); // 输出 ServletOutputStream out = response.getOutputStream(); out.write(content); out.close(); } public void flush() throws IOException { gzipOutputStream.flush(); } public void write(byte[] b, int off, int len) throws IOException { gzipOutputStream.write(b, off, len); } public void write(byte[] b) throws IOException { gzipOutputStream.write(b); } } 图像水印 Filter使用Filter在图像上动态打上一个水印LOGO，工作原理与GZIP压缩类似，先把图像数据缓存起来，然后对图像进行水印处理后输出到客户端浏览器 图像水印Filter需要自定义response与servletOutputStream 1、WaterMarkFilter，在Filter初始化参数里设置水印图片文件路径 public class WaterMarkFilter implements Filter { // 水印图片，配置在初始化参数中 private String waterMarkFile; public void init(FilterConfig config) throws ServletException { String file = config.getInitParameter("waterMarkFile"); waterMarkFile = config.getServletContext().getRealPath(file); } public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; // 自定义的response WaterMarkResponseWrapper waterMarkRes = new WaterMarkResponseWrapper(response, waterMarkFile); chain.doFilter(request, waterMarkRes); // 打水印，输出到客户端浏览器 waterMarkRes.finishResponse(); } public void destroy() { } } 2、WaterMarkResponseWrapper继承HttpServletResponseWrapper，改写了getOutputStream方法，finishResponse方法将缓存的数据进行水印处理，并输出到客户端浏览器。水印处理的代码被封装到ImageUtil类的静态方法waterMark()中 public class WaterMarkResponseWrapper extends HttpServletResponseWrapper { // 水印图片位置 private String waterMarkFile; // 原response private HttpServletResponse response; // 自定义servletOutputStream，用于缓冲图像数据 private WaterMarkOutputStream waterMarkOutputStream; public WaterMarkResponseWrapper(HttpServletResponse response, String waterMarkFile) throws IOException { super(response); this.response = response; this.waterMarkFile = waterMarkFile; this.waterMarkOutputStream = new WaterMarkOutputStream(); } // 覆盖getOutputStream()，返回自定义的waterMarkOutputStream public ServletOutputStream getOutputStream() throws IOException { return waterMarkOutputStream; } public void flushBuffer() throws IOException { waterMarkOutputStream.flush(); } // 将图像数据打水印，并输出到客户端浏览器 public void finishResponse() throws IOException { // 原图片数据 byte[] imageData = waterMarkOutputStream.getByteArrayOutputStream() .toByteArray(); // 打水印后的图片数据 byte[] image = ImageUtil.waterMark(imageData, waterMarkFile); // 将图像输出到浏览器 response.setContentLength(image.length); response.getOutputStream().write(image); waterMarkOutputStream.close(); } } 3、WaterMarkOutputStream类将图像数据缓存起来 public class WaterMarkOutputStream extends ServletOutputStream { // 缓冲图片数据 private ByteArrayOutputStream byteArrayOutputStream; public WaterMarkOutputStream() throws IOException { byteArrayOutputStream = new ByteArrayOutputStream(); } public void write(int b) throws IOException { byteArrayOutputStream.write(b); } public void close() throws IOException { byteArrayOutputStream.close(); } public void flush() throws IOException { byteArrayOutputStream.flush(); } public void write(byte[] b, int off, int len) throws IOException { byteArrayOutputStream.write(b, off, len); } public void write(byte[] b) throws IOException { byteArrayOutputStream.write(b); } public ByteArrayOutputStream getByteArrayOutputStream() { return byteArrayOutputStream; } } 4、ImageUtil类使用JDK的图像处理类完成添加水印的操作 public class ImageUtil { /** * * @param imageData * JPG 图像文件 * @param waterMarkFile * 水印图片 * @return 加水印后的图像数据 * @throws IOException */ public static byte[] waterMark(byte[] imageData, String waterMarkFile) throws IOException { // 水印图片的右边距 下边距 int paddingRight = 10; int paddingBottom = 10; // 原始图像 Image image = new ImageIcon(imageData).getImage(); int imageWidth = image.getWidth(null); int imageHeight = image.getHeight(null); // 水印图片 Image waterMark = ImageIO.read(new File(waterMarkFile)); int waterMarkWidth = waterMark.getWidth(null); int waterMarkHeight = waterMark.getHeight(null); // 如果图片尺寸过小，则不打水印，直接返回 if (imageWidth < waterMarkWidth + 2 * paddingRight || imageHeight < waterMarkHeight + 2 * paddingBottom) { return imageData; } BufferedImage bufferedImage = new BufferedImage(imageWidth, imageHeight, BufferedImage.TYPE_INT_RGB); Graphics g = bufferedImage.createGraphics(); // 绘制原始图像 g.drawImage(image, 0, 0, imageWidth, imageHeight, null); // 绘制水印图片 g.drawImage(waterMark, imageWidth - waterMarkWidth - paddingRight, imageHeight - waterMarkHeight - paddingBottom, waterMarkWidth, waterMarkHeight, null); g.dispose(); // 转成JPEG格式 ByteArrayOutputStream out = new ByteArrayOutputStream(); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); encoder.encode(bufferedImage); byte[] data = out.toByteArray(); out.close(); return data; } } 5、配置文件 &lt;filter&gt; &lt;filter-name&gt;imageRedirectFilter&lt;/filter-name&gt; &lt;filter-class&gt; com.helloweenvsfei.filter.ImageRedirectFilter &lt;/filter-class&gt; &lt;/filter&gt; &lt;filter&gt; &lt;filter-name&gt;waterMarkFilter&lt;/filter-name&gt; &lt;filter-class&gt; com.helloweenvsfei.watermark.WaterMarkFilter &lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;waterMarkFile&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/logo.png&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; 内容替换、GZIP、图像水印 Filter 总结★★★★★★以图像水印 Filter 为例 1、过滤器中自定义response包裹类，将原生response作为参数传入。自定义的response替换原生response传入Servlet；response返回客户端之前，调用新定义的finishResponse方法，输出到客户端浏览器 // 自定义的response WaterMarkResponseWrapper waterMarkRes = new WaterMarkResponseWrapper(response, waterMarkFile); chain.doFilter(request, waterMarkRes); // 打水印，输出到客户端浏览器 waterMarkRes.finishResponse(); 2、自定义response包裹类有一个存放原生response的成员变量，一个自定义的输出流，起到缓存数据的功能。重写getOutputStream()方法或getWriter()方法，返回自定义输出流，添加finishResponse方法，将缓存中的数据进行处理，输出到客户端浏览器 3、重写ServletOutputStream类对数据进行，对数据缓存 缓存 Filter对于访问量比较大的网站（淘宝），反复地查询数据库要消耗很多时间。如果第一次访问某页面查询了数据库，那么就可以把页面的内容缓存起来，下一次访问的时候直接返回缓存结果就行。使用缓存能将数据库读写次数较少都最少，从而提高服务器的响应速度 缓存Filter的工作流程：1、截获浏览器提交的request2、如果request为POST方式，则不进行缓存3、如果request为GET方式，且请求的页面有缓存并且缓存没有过期，则直接返回缓存结果，这样就避免读取数据库4、如果没有缓存或者缓存已过期，则重新请求Servlet，将Servlet返回的内容缓存并输出到客户端浏览器 使用缓存注意点： 1、缓存Filter不易用于数据会实时变化的数据，如报表、股票等，它适用于数据变化不大，但是访问次数多的内容，如论坛、博客、新闻等2、缓存Filter不能用于POST方式提交数据，如登录、发表文章等3、当缓存更新后，要更新缓存，或者直接将缓存删掉4、被缓存的内容不能依赖于Session，而要依赖于Cookie。即要使用Cookie来记录客户身份而不要使用Session，并且无论客户身份是管理员还是普通浏览者，Servlet输出内容都是一样的，只能在浏览器使用js根据cookie来决定显示什么内容。但是注意：由于菜单的显示与否并没有在服务器端进行权限检查，因此当客户单击链接操作的时候，一定要做权限检查，否则会引发安全问题 框图： ①如果存在缓存文件，直接缓存文件中读取数据并输出到客户端浏览器，不进入Servlet②没有缓存或缓存过期，在Servlet将输出的内容缓存起来③缓存Filter将缓存内容写入到缓存文件，并读取缓存文件将数据输出 程序流程图： 1、缓存Filter public class CacheFilter implements Filter { private ServletContext servletContext; // 缓存文件夹，使用Tomcat工作目录 private File temporalDir; // 缓存时间，配置在Filter初始化参数中 private long cacheTime = Long.MAX_VALUE; public void init(FilterConfig config) throws ServletException { temporalDir = (File) config.getServletContext().getAttribute( "javax.servlet.context.tempdir"); servletContext = config.getServletContext(); cacheTime = new Long(config.getInitParameter("cacheTime")); } public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; // 如果为 POST, 则不经过缓存 if ("POST".equals(request.getMethod())) { chain.doFilter(request, response); return; } // 请求的 URI，忽略应用程序名称 String uri = request.getRequestURI(); if (uri == null) uri = ""; uri = uri.replace(request.getContextPath() + "/", ""); uri = uri.trim().length() == 0 ? "index.jsp" : uri; uri = request.getQueryString() == null ? uri : (uri + "?" + request .getQueryString()); // 对应的缓存文件 File cacheFile = new File(temporalDir, URLEncoder.encode(uri, "UTF-8")); System.out.println(cacheFile); // 如果缓存文件不存在 或者已经超出缓存时间 则请求 Servlet if (!cacheFile.exists() || cacheFile.length() == 0 || cacheFile.lastModified() < System.currentTimeMillis() - cacheTime) { CacheResponseWrapper cacheResponse = new CacheResponseWrapper( response); chain.doFilter(request, cacheResponse); // 将内容写入缓存文件 char[] content = cacheResponse.getCacheWriter().toCharArray(); temporalDir.mkdirs();//递归创建文件夹 cacheFile.createNewFile();//创建文件 Writer writer = new OutputStreamWriter(new FileOutputStream( cacheFile), "UTF-8"); writer.write(content); writer.close(); } // 请求的ContentType String mimeType = servletContext.getMimeType(request.getRequestURI()); response.setContentType(mimeType); // 读取缓存文件的内容，写入客户端浏览器 Reader ins = new InputStreamReader(new FileInputStream(cacheFile), "UTF-8"); StringBuffer buffer = new StringBuffer(); char[] cbuf = new char[1024]; int len; while ((len = ins.read(cbuf)) > -1) { buffer.append(cbuf, 0, len); } ins.close(); // 输出到客户端 response.getWriter().write(buffer.toString()); } public void destroy() { } } 2、CacheResponseWrapper强Servlet中输出的内容缓存起来，然后被缓存Filter写入到缓存文件中。本缓存Filter只缓存字符类网页，因此只覆盖了getWriter()方法 public class CacheResponseWrapper extends HttpServletResponseWrapper { // 缓存字符类输出 private CharArrayWriter cacheWriter = new CharArrayWriter(); public CacheResponseWrapper(HttpServletResponse response) throws IOException { super(response); } @Override public PrintWriter getWriter() throws IOException { return new PrintWriter(cacheWriter); } @Override public void flushBuffer() throws IOException { cacheWriter.flush(); } public void finishResponse() throws IOException { cacheWriter.close(); } public CharArrayWriter getCacheWriter() { return cacheWriter; } public void setCacheWriter(CharArrayWriter cacheWriter) { this.cacheWriter = cacheWriter; } } 3、配置 &lt;filter&gt; &lt;filter-name&gt;cacheFilter&lt;/filter-name&gt; &lt;filter-class&gt; com.helloweenvsfei.cache.CacheFilter &lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;cache&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cacheTime&lt;/param-name&gt; &lt;param-value&gt;1000000&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;cacheFilter&lt;/filter-name&gt; &lt;url-pattern&gt;*.jsp&lt;/url-pattern&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;/filter-mapping&gt; XSLT 转换 FilterXSLT转换时XML文件的功能之一，是利用XSLT样式文件将XML文件转换成其他格式，使用XSLT 转换 Filter，浏览器访问请求XML格式，返回浏览器时已经是转换后的HTML文件了 1、该Filter使用JDK自带的标准XML工具包进行XML格式转换。MSN的聊天记录是用XML形式保存的，浏览器访问XML格式，返回转换后的HTML文件 public class XSLTFilter implements Filter { private ServletContext servletContext; public void init(FilterConfig config) throws ServletException { servletContext = config.getServletContext(); } public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; // 格式样本文件：/book.xsl Source styleSource = new StreamSource(servletContext .getRealPath(&quot;/MessageLog.xsl&quot;)); // 请求的 xml 文件 Source xmlSource = new StreamSource(servletContext.getRealPath(request .getRequestURI().replace(request.getContextPath() + &quot;&quot;, &quot;&quot;))); try { // 转换器工厂 TransformerFactory transformerFactory = TransformerFactory .newInstance(); // 转换器 Transformer transformer = transformerFactory .newTransformer(styleSource); // 将转换的结果保存到该对象中 CharArrayWriter charArrayWriter = new CharArrayWriter(); StreamResult result = new StreamResult(charArrayWriter); // 转换 transformer.transform(xmlSource, result); // 输出转换后的结果 response.setContentType(&quot;text/html&quot;); response.setContentLength(charArrayWriter.toString().length()); PrintWriter out = response.getWriter(); out.write(charArrayWriter.toString()); } catch (Exception ex) { } } public void destroy() { } } 2、配置 &lt;filter&gt; &lt;filter-name&gt;xsltFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.helloweenvsfei.xml.XSLTFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;xsltFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/msn/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 监听器 ListenerListener用于监听Java Web程序中的事件，例如创建、修改、删除Session、request、context等 Listener使用使用Listener需要实现相应的Listener接口，触发Listener事件时，Tomcat会自动调用Listener的方法 实现Listener接口创建Session服务器会调用sessionCreated()方法，销毁Session（包括sesson超时自动销毁）服务器会调用sessionDestroyed()方法 public class SessionListenerTest implements HttpSessionListener { @Override public void sessionCreated(HttpSessionEvent httpSessionEvent) { //Session创建时被调用 HttpSession session = httpSessionEvent.getSession(); System.out.println(&quot;创建了一个session：&quot; + session); } @Override public void sessionDestroyed(HttpSessionEvent httpSessionEvent) { //销毁Session前被调用 HttpSession session = httpSessionEvent.getSession(); System.out.println(&quot;销毁了一个Session：&quot; + session); } } Listener配置&lt;listener&gt;标签一般配置在&lt;servlet&gt;前面 &lt;listener&gt; &lt;listener-class&gt;cn.apeius.listener.SessionListenerTest&lt;/listener-class&gt; &lt;/listener&gt; Listener的分类★★★★★★监听对象的创建与销毁 HttpSessionListener：监听Session的创建与销毁。创建Session时执行sessionCreated方法，超时或执行session.invalidate()时执行sessionDestroyed方法。该Listener可以收集在线者信息 ServletContextListener：监听context的创建与销毁。context代表当前的Web应用程序，服务器启动或者热部署war包时执行contextInitialized，服务器关闭或关闭该Web时会执行contextDestroyed方法。该Listener可用于启动时读取web.xml里配置的初始化参数 ServletRequestListener：监听request的创建与销毁，用户每次请求都会执行requestInitialized方法，request处理完毕自动销毁前执行requestDestroyed。注意如果一个HTML页面包含多个图片，则一次请求可能会多次触发request事件 实例：监听Session、request、servletContext自定义监听器类同时实现HttpSessionListener、ServletContextListener、ServletRequestListener接口，使得多种监听器一块工作 public class SessionListenerTest implements HttpSessionListener, ServletContextListener, ServletRequestListener { //Log log = LogFactory.getLog(getClass()); Logger log = Logger.getLogger(SessionListenerTest.class); // 创建 session public void sessionCreated(HttpSessionEvent se) { HttpSession session = se.getSession(); log.info(&quot;新创建一个session, ID为: &quot; + session.getId()); } // 销毁 session public void sessionDestroyed(HttpSessionEvent se) { HttpSession session = se.getSession(); log.info(&quot;销毁一个session, ID为: &quot; + session.getId()); } // 加载 context public void contextInitialized(ServletContextEvent sce) { ServletContext servletContext = sce.getServletContext(); log.info(&quot;即将启动&quot; + servletContext.getContextPath()); } // 卸载 context public void contextDestroyed(ServletContextEvent sce) { ServletContext servletContext = sce.getServletContext(); log.info(&quot;即将关闭&quot; + servletContext.getContextPath()); } // 创建 request public void requestInitialized(ServletRequestEvent sre) { HttpServletRequest request = (HttpServletRequest) sre .getServletRequest(); String uri = request.getRequestURI(); uri = request.getQueryString() == null ? uri : (uri + &quot;?&quot; + request .getQueryString()); request.setAttribute(&quot;dateCreated&quot;, System.currentTimeMillis()); log.info(&quot;IP &quot; + request.getRemoteAddr() + &quot; 请求 &quot; + uri); } // 销毁 request public void requestDestroyed(ServletRequestEvent sre) { HttpServletRequest request = (HttpServletRequest) sre .getServletRequest(); long time = System.currentTimeMillis() - (Long) request.getAttribute(&quot;dateCreated&quot;); log.info(request.getRemoteAddr() + &quot;请求处理结束, 用时&quot; + time + &quot;毫秒. &quot;); } } 配置到web.xml &lt;listener&gt; &lt;listener-class&gt;cn.apeius.listener.SessionListenerTest&lt;/listener-class&gt; &lt;/listener&gt; 监听对象的属性变化 另一类Listener用于监听Session、context、request的属性变化，接口名称格式为xxxAttributeListener，包括HttpSessionAttributeListener、ServletContextAttributeListener、ServletRequestAttributeListener 当想被监听对象中添加、更新、移除属性时，会分别执行xxxAdded()、xxxReplace()、xxxRemoved()方法，xxx分别代表Session、Context、request public class SessionAttributeListenerTest implements HttpSessionAttributeListener { Log log = LogFactory.getLog(getClass()); // 添加属性 public void attributeAdded(HttpSessionBindingEvent se) { HttpSession session = se.getSession(); String name = se.getName(); log.info(&quot;新建session属性：&quot; + name + &quot;, 值为：&quot; + se.getValue()); } // 删除属性 public void attributeRemoved(HttpSessionBindingEvent se) { HttpSession session = se.getSession(); String name = se.getName(); log.info(&quot;删除session属性：&quot; + name + &quot;, 值为：&quot; + se.getValue()); } // 修改属性 public void attributeReplaced(HttpSessionBindingEvent se) { HttpSession session = se.getSession(); String name = se.getName(); Object oldValue = se.getValue(); log.info(&quot;修改session属性：&quot; + name + &quot;, 原值：&quot; + oldValue + &quot;, 新值：&quot; + session.getAttribute(name)); } } 监听Session内的对象除了上面的6中Listener，有两种Listener用于监听Session内的对象，分别是HttpSessionBindingListener、HttpSessionActivationListener，他们的触发时机是： HttpSessionBindingListener：当对象被放到Session里是执行valueBound方法，当对象从Session里移除时执行valueUnbound，对象必须实现该Listener接口 HttpSessionActivationListener：服务器关闭时，会将Session里的内容保存到硬盘上，这个过程叫做钝化。服务器重启时，会将Session里的内容从硬盘上重新加载，钝化时会执行sessionWillPassivate方法，对象被重新加载时执行sessionDidActivate方法，对象必须实现该Listener接口 这两个Listener监听的是Session中的对象而非Session等，因此不需要再web.xml中声明 PersonInfo对象被放进、移出Session或者启动、关闭服务器都会触发PersonInfo内的Listener时间： public class PersonInfo implements HttpSessionActivationListener, HttpSessionBindingListener, Serializable { private static final long serialVersionUID = -4780592776386225973L; Log log = LogFactory.getLog(getClass()); private String name; private Date dateCreated; public String getName() { return name; } public void setName(String name) { this.name = name; } public Date getDateCreated() { return dateCreated; } public void setDateCreated(Date dateCreated) { this.dateCreated = dateCreated; } // 从硬盘加载后 public void sessionDidActivate(HttpSessionEvent se) { HttpSession session = se.getSession(); log.info(this + &quot;已经成功从硬盘中加载。sessionId: &quot; + session.getId()); } // 即将被钝化到硬盘时 public void sessionWillPassivate(HttpSessionEvent se) { HttpSession session = se.getSession(); log.info(this + &quot;即将保存到硬盘。sessionId: &quot; + session.getId()); } // 被放进session前 public void valueBound(HttpSessionBindingEvent event) { HttpSession session = event.getSession(); String name = event.getName(); log.info(this + &quot;被绑定到session \&quot;&quot; + session.getId() + &quot;\&quot;的&quot; + name + &quot;属性上&quot;); // 记录放到session中的时间 this.setDateCreated(new Date()); } // 从session中移除后 public void valueUnbound(HttpSessionBindingEvent event) { HttpSession session = event.getSession(); String name = event.getName(); log.info(this + &quot;被从session \&quot;&quot; + session.getId() + &quot;\&quot;的&quot; + name + &quot;属性上移除&quot;); } @Override public String toString() { return &quot;PersonInfo(&quot; + name + &quot;)&quot;; } } Listener使用案例单态登录 单态登录就是一个账号只能在一台机器上登录，如果在其他机器上登录了，则原来的登录无效 单态登录的目的是为了防止多台机器同时使用一个账号 Listener方式实现 见JavaWeb王者归来205页 思路：当成功验证用户信息，准备往session中存放用户的信息时，被监听器监听到，调用attributeAdded或attributeReplaced方法，方法中需要判断用户是否在别的机器上登录过，如果登录了则使以前的登录失效 使用这种方式Listener与登录模块没有代码耦合，部署Listener后将实现单态登录，拆掉该Listener后登录模块照常工作，只是不再保证是单态登录 public class LoginSessionListener implements HttpSessionAttributeListener { Log log = LogFactory.getLog(this.getClass()); Map map = new HashMap(); public void attributeAdded(HttpSessionBindingEvent event) { String name = event.getName(); // 登录 if (name.equals("personInfo")) { PersonInfo personInfo = (PersonInfo) event.getValue(); if (map.get(personInfo.getAccount()) != null) { // map 中有记录，表明该帐号在其他机器上登录过，将以前的登录失效 HttpSession session = map.get(personInfo.getAccount()); PersonInfo oldPersonInfo = (PersonInfo) session .getAttribute("personInfo"); log.info("帐号" + oldPersonInfo.getAccount() + "在" + oldPersonInfo.getIp() + "已经登录，该登录将被迫下线。"); session.removeAttribute("personInfo"); session.setAttribute("msg", "您的帐号已经在其他机器上登录，您被迫下线。"); } // 将session以用户名为索引，放入map中 map.put(personInfo.getAccount(), event.getSession()); log.info("帐号" + personInfo.getAccount() + "在" + personInfo.getIp() + "登录。"); } } public void attributeRemoved(HttpSessionBindingEvent event) { String name = event.getName(); // 注销 if (name.equals("personInfo")) { // 将该session从map中移除 PersonInfo personInfo = (PersonInfo) event.getValue(); map.remove(personInfo.getAccount()); log.info("帐号" + personInfo.getAccount() + "注销。"); } } public void attributeReplaced(HttpSessionBindingEvent event) { String name = event.getName(); // 没有注销的情况下，用另一个帐号登录 if (name.equals("personInfo")) { // 移除旧的的登录信息 PersonInfo oldPersonInfo = (PersonInfo) event.getValue(); map.remove(oldPersonInfo.getAccount()); // 新的登录信息 PersonInfo personInfo = (PersonInfo) event.getSession() .getAttribute("personInfo"); // 也要检查新登录的帐号是否在别的机器上登录过 if (map.get(personInfo.getAccount()) != null) { // map 中有记录，表明该帐号在其他机器上登录过，将以前的登录失效 HttpSession session = map.get(personInfo.getAccount()); session.removeAttribute("personInfo"); session.setAttribute("msg", "您的帐号已经在其他机器上登录，您被迫下线。"); } map.put("personInfo", event.getSession()); } } } 自己的实现 如果没有要求单态登录，成功验证用户信息后，返回客户端token，在服务器端创建session，并将用户信息存入到session，之后客户端再次访问，根据token恢复session，如果session中存放了用户信息，则用户合法，否则退回登录页面 实现单态登录，需要在验证用户信息后，判断账号是否在别的机器上登录。 具体实现：用一个HashMap存储在线用户信息，主键为用户名，键值为session。成功验证用户信息后，根据用户名获取session，如果session不为空，说明用户已经在别的机器上登录，则使sesson无效，在HashMap上移除该值，这样之前登录的用户操作前，会检查session中没有用户信息，则必须重新登录，做到强制退出的目的 图示：红框是单态登录加入的模块 protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { request.setCharacterEncoding("utf-8"); response.setCharacterEncoding("utf-8"); response.setContentType("text/html;charset=utf-8"); PrintWriter out = response.getWriter(); String action = request.getParameter("action"); if("login".equalsIgnoreCase(action)){ String name = request.getParameter("name"); String password = request.getParameter("password"); User user = new User(); user.setName(name); user.setPassword(password); if("qm".equals(name) && "123".equals(password)){ //判断帐号是否在别的机器登录 HttpSession oldSession = map.get(name); if(oldSession != null){//1、别的机器登录 2、重复登录 oldSession.removeAttribute("user"); //oldSession.invalidate();不要删除session除了用户信息的其他属性，下次用户在本机登录还能获得先前的数据 map.remove(name); } HttpSession session = request.getSession(); session.setAttribute("user",user); map.put(name,session); out.println("登录成功"); }else{ out.println("登录失败"); } }else if("logout".equalsIgnoreCase(action)){ HttpSession session = request.getSession(); User user = (User) session.getAttribute("user"); if(user == null){ out.println("请先登录"); return; } //session.invalidate(); session.removeAttribute("user"); map.remove(user.getName()); out.println("注销成功"); }else if("main".equalsIgnoreCase(action)){ HttpSession session = request.getSession(); User user = (User) session.getAttribute("user"); if(user == null){ out.println("请先登录"); return; } //往session添加其他属性 Integer count = (Integer) session.getAttribute("count"); if(count == null){ count = 0; session.setAttribute("count", count); } count ++; session.setAttribute("count",count); //在线用户 out.println(session.getAttribute("count")); } } 显示在线用户存放服务器信息、用户信息的类： public class ApplicationConstants { // 所有的 Session，session_id与session组成键值对 public static Map&lt;String, HttpSession&gt; SESSION_MAP = new HashMap&lt;String, HttpSession&gt;(); // 当前登录的用户总数 public static int CURRENT_LOGIN_COUNT = 0; // 历史访客总数 public static int TOTAL_HISTORY_COUNT = 0; // 服务器启动时间 public static Date START_DATE = new Date(); // 最高在线时间 public static Date MAX_ONLINE_COUNT_DATE = new Date(); // 最高在线人数 public static int MAX_ONLINE_COUNT = 0; } 使用ServletContextListener来监听服务器的启动与关闭，记录服务器启动时间等 public class MyContextListener implements ServletContextListener { public void contextInitialized(ServletContextEvent event) { // 启动时，记录服务器启动时间 ApplicationConstants.START_DATE = new Date(); } public void contextDestroyed(ServletContextEvent event) { // 关闭时，将结果清除。也可以将结果保存到硬盘上，下次启动时再加载到ApplicationConstants中 ApplicationConstants.START_DATE = null; ApplicationConstants.MAX_ONLINE_COUNT_DATE = null; } } 对Session的监听，维护在线用户列表、总访问人数： 使用Map来索引所有的Session，Session创建的时候放到Map中，Session销毁时从Map中剔除 什么时候用户数改变？成功验证用户信息后往session中存入用户信息、用户注销、用户被强退，attributeAdded和attributeReplaced的区别就是用户人数是否需要增加 public class MySessionListener implements HttpSessionListener, HttpSessionAttributeListener { public void sessionCreated(HttpSessionEvent sessionEvent) { HttpSession session = sessionEvent.getSession(); // 将 session 放入 map ApplicationConstants.SESSION_MAP.put(session.getId(), session); // 总访问人数++ ApplicationConstants.TOTAL_HISTORY_COUNT++; // 如果当前在线人数超过历史记录，则更新最大在线人数，并记录时间 if (ApplicationConstants.SESSION_MAP.size() > ApplicationConstants.MAX_ONLINE_COUNT) { ApplicationConstants.MAX_ONLINE_COUNT = ApplicationConstants.SESSION_MAP .size(); ApplicationConstants.MAX_ONLINE_COUNT_DATE = new Date(); } } public void sessionDestroyed(HttpSessionEvent sessionEvent) { HttpSession session = sessionEvent.getSession(); // 将session从map中移除 ApplicationConstants.SESSION_MAP.remove(session.getId()); } public void attributeAdded(HttpSessionBindingEvent event) { if (event.getName().equals("personInfo")) { // 当前登录用户数++ ApplicationConstants.CURRENT_LOGIN_COUNT++; HttpSession session = event.getSession(); // 查找该帐号有没有在其他机器上登录 for (HttpSession sess : ApplicationConstants.SESSION_MAP.values()) { // 如果该帐号已经在其他机器上登录，则以前的登录失效 if (event.getValue().equals(sess.getAttribute("personInfo")) && session.getId() != sess.getId()) { sess.invalidate(); } } } } public void attributeRemoved(HttpSessionBindingEvent event) { // 注销 当前登录用户数-- if (event.getName().equals("personInfo")) { ApplicationConstants.CURRENT_LOGIN_COUNT--; } } public void attributeReplaced(HttpSessionBindingEvent event) { // 重新登录，但人数不用增加 if (event.getName().equals("personInfo")) { HttpSession session = event.getSession(); for (HttpSession sess : ApplicationConstants.SESSION_MAP.values()) { // 如果新帐号在其他机器上登录过，则以前登录失效 if (event.getValue().equals(sess.getAttribute("personInfo")) && session.getId() != sess.getId()) { sess.invalidate(); } } } } } 监听request主要是记录客户的IP地址、访问次数等，也可以记录用户访问的URI： public class MyRequestListener implements ServletRequestListener { public void requestDestroyed(ServletRequestEvent event) { } public void requestInitialized(ServletRequestEvent event) { HttpServletRequest request = (HttpServletRequest) event .getServletRequest(); /* * 如果session为空，则重新创建一个session，主要是之前session.invalidate()会销毁session */ HttpSession session = request.getSession(true); // 记录IP地址 session.setAttribute("ip", request.getRemoteAddr()); // 记录访问次数，只记录访问 .html, .do, .jsp, .action 的累计次数 String uri = request.getRequestURI(); String[] suffix = { ".html", ".do", ".jsp", ".action" }; for (int i=0; i&lt;suffix.length; i++) { if (uri.endsWith(suffix[i])) { break; } if(i == suffix.length-1) return; } Integer activeTimes = (Integer) session.getAttribute("activeTimes"); if (activeTimes == null) { activeTimes = 0; } session.setAttribute("activeTimes", activeTimes + 1); } }]]></content>
      <categories>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>JavaEE</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat笔记]]></title>
    <url>%2F2016%2F07%2F06%2F%5BTomcat%5DTomcat%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Tomcat的目录结构文件 bin: 启动和关闭tomcat的bat文件 conf: 配置文件 --&gt;server.xml : 该文件用于配置和 server 相关的信息, 比如 tomcat启动端口后,配置Host, 配置Context 即web应用 --&gt;web.xml : 该文件配置与 web应用(web应用就相当于是一个 web站点) --&gt;tomcat-users.xml: 该文件用户配置tomcat 的用户密码 和 权限 lib目录: 该目录放置运行tomcat 运行需要的jar包 logs目录：存放日志, 当我们需要去查看日志的时候，很有用!,当我们启动tomcat错误时候，可以查询信息. webapps目录: 该目录下，放置我们的web应用(web 站点) work: 工作目录: 该目录用于存放jsp被访问后 生成的对应的 server文件 和.class文件 首页面设置及目录规范结构 配置访问首目录 ①在web文件夹下配置WEB-INF文件夹 ②在 web.xml 文件中添加配置的代码: &lt;welcome-file-list&gt; &lt;welcome-file&gt;hello1.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; ③通过http://localhost:8088/web1来访问hello1.html 目录结构 web-inf目录下的 classes目录将来是存放 class文件 lib 目录将来时存放 jar文件 web.xml 配置当前这个web应用的信息. Tomcat体系 理解服务、引擎、host（主机）、Web应用[Context]概念 查看Tomcat中的server.xml文件，最外面节点为Server，Service下一个节点服务&lt;Service name = &quot;Catalina&quot;&gt;，所以我们有时把Tomcat服务叫做Catalina服务。 服务下有引擎（engine）&lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;，它可以管理多个主机host。 主机下有多个Web应用[Context] 与引擎并列的有连接器（connector），有支持不同类型协议（http、https等）的连接器。不同协议使用不同的连接器 配置默认主机 当我们在浏览器中输入http://127.0.0.1:8080/web应用，引擎是如何知道用户要访问那个`主机`下的web应用？答：配置一个默认主机 在tomcat/conf/server.xml 文件 &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;主机名&quot;&gt; 默认是localhost，即在webapps目录下，查找web应用 &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot; xmlValidation=&quot;false&quot; xmlNamespaceAware=&quot;false&quot;&gt; 配置域名[host]步骤： (1) 在C:\WINDOWS\system32\drivers\etc 下的host文件 添加127.0.0.1 www.sina.com.cn[浏览器向Tomcat发送请求，但Tomcat认为自己不是www.sina.com，可以拒绝，所以需添加主机名] (2) 在tomcat 的server.xml文件添加主机名 &lt;Host name=&quot;www.sina.com&quot; appBase=&quot;d:\web3”&gt; &lt;Context path=&quot;/&quot; docBase=&quot;d:\web3&quot; /&gt; &lt;/Host&gt; (3) 在d:\web3 加入了一个 /WEB-INF/web.xml 把 hello2.html设为首页面 如果连端口都不希望带，则可以吧tomcat的启动端口设为80即可. (4) 重启生效 CATALINA_BASE与CATALINA_HOME的区别 CATALINA_HOME是Tomcat的安装目录，CATALINA_BASE是Tomcat的工作目录 如果我们想要运行Tomcat的多个实例，但是不想安装多个Tomcat软件副本。那么我们可以配置多个工作目录，每个运行实例独占一个工作目录，但是共享同一个安装目录 Tomcat每个运行实例需要使用自己的conf、logs、temp、webapps、work和shared目录，因此CATALINA_BASE就指向这些目录。 而其他目录主要包括了Tomcat的二进制文件和脚本，CATALINA_HOME就指向这些目录 Tomcat管理虚拟目录[context]需求 当我们把 web 应用放到 webapps目录，tomcat会自动管理，如果我们希望tomcat可以管理其它目录下的web应用? -&gt; 虚拟目录配置 假设我在d盘有一个web应用文件夹web2 步骤 1、找到server.xml文件 2、编辑host节点，在Host节点中添加Context 在server.xml中添加：&lt;Context path=&quot;/myweb2&quot; docBase=&quot;d:\web2&quot;/&gt; myweb2：是访问时输入的web名,实际取出的是web2中的资源（★★★★url与文件夹有映射关系） &quot;d:\web2&quot;：web应用文件夹在计算机中绝对路径 实际访问时输入的地址：http://localhost:8088/myweb2/hello2.html 定义上下文显式定义1、在Tomcat的conf/Catalina/localhost目录下创建一个XML文件。例如把一个commerce.xml文件放在conf/Catalina/localhost目录下，那么应用程序的上下文路径就是commerce，下面给出一个范例： &lt;Context docBase=&quot;C://apps/commerce&quot; reloadable=&quot;true&quot;/&gt; docBase是必要的属性，用来定义应用程序的位置；reloadable属性是可选的，如果值为true，一旦应用程序中Java类文件或者其他资源有增加、减少或者更新，Tomcat都会侦测到，就会重新加载应用程序 2、在Tomcat的conf/server.xml文件中添加一个Context元素[同Tomcat管理虚拟目录] &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot; xmlValidation=&quot;false&quot; xmlNamespaceAware=&quot;false&quot;&gt; &lt;Context path = &quot;/commerce&quot; docBase=&quot;C:/apps/commerce&quot; reloadable=&quot;true&quot; /&gt; &lt;/Host&gt; 隐式定义通过将一个war文件或者整个应用程序复制到Tomcat的webapps目录下，就可以隐式地部署应用程序]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>JavaEE</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式的艺术之道笔记]]></title>
    <url>%2F2016%2F07%2F06%2F%5B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%5D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%89%BA%E6%9C%AF%E4%B9%8B%E9%81%93%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Java反射Java反射(Java Reflection)是指在程序运行时获取已知名称的类或已有对象的相关信息的一种机制，包括类的方法、属性、父类等信息，还包括实例的创建和实例类型的判断等。 在反射中使用最多的类是Class，Class类的实例表示正在运行的Java应用程序中的类和接口，其forName(String className)方法可以返回与带有给定字符串名的类或接口相关联的 Class对象，再通过Class对象的newInstance()方法创建此对象所表示的类的一个新实例，即通过一个类名字符串得到类的实例 XMLUtil//工具类XMLUtil.java import javax.xml.parsers.*; import org.w3c.dom.*; import org.xml.sax.SAXException; import java.io.*; public class XMLUtil { //该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象 public static Object getBean() { try { //创建DOM文档对象 DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = dFactory.newDocumentBuilder(); Document doc; doc = builder.parse(new File(&quot;config.xml&quot;)); //获取包含类名的文本节点 NodeList nl = doc.getElementsByTagName(&quot;className&quot;); Node classNode=nl.item(0).getFirstChild(); String cName=classNode.getNodeValue(); //通过类名生成实例对象并将其返回 Class c=Class.forName(cName); Object obj=c.newInstance(); return obj; } catch(Exception e) { e.printStackTrace(); return null; } } } 文件 &lt;!— config.xml --&gt; &lt;?xml version=&quot;1.0&quot;?&gt; &lt;config&gt; &lt;className&gt;FileLoggerFactory&lt;/className&gt; &lt;/config&gt; 单例模式：确保一个类只有一个实例1、构造方法私有，外部不能通过new创建对象2、静态变量保存唯一实例3、静态的getInstance方法，是外部能够访问 饿汉模式:在类加载的时候已经创建了单例对象 //staic final静态常量 private static final Singleton instance = new Singleton(); private Singleton(){} public static Singleton getInstance(){return instance;} 懒汉模式：第一次调用的时候创建对象实例 private static Singleton instatnce = null; private Singleton(){} //注意同步控制关键字 Synchronized synchronized public Singleton getInstance(){ if(instance == null){ instance = new Singleton(); } return instance; } 方法二：synchronized同步控制代码块，双重检查锁定（单次判断实例不为空，如果一个线程正在创建对象但还未创建完成，另一个线程进入实例不为空的判断，最终产生两个实例，未被单一对象的原则） //使用volatile保证可见性 private volatile static Singleton instatnce = null; private Singleton(){} public static Singleton getInstance(){ //第一重判断 if(instance == null){ synchronized(Singleton.class){ //第二重判断 if(instance == null){ instance = new Singleton(); } } } return instance; } 为什么需要使用volatile？不是同步快结束完之后，会将instance对象写入内存？ 答：主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 instance 分配内存 调用 Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了） 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 解析： 线程1创建调用getInstance（）方法执行到instance=new Singleton()，但是这条语句不是原子性的，他分为三个步骤：1、分配内存 2、初始化 3、instance对象指向内存空间，执行完这步后instance为非空了。 但是jvm存在指令重排序的优化，如果指令按照1，3，2的执行方式，但是线程1在执行3之后，但未执行2之前，此时instance已经不为null了，这时候线程2调用getInstance（）方法（注意这时线程2可以调拥这个方法，因为只有进入一重检查锁之后才是临界区。）执行第一重判断if(instance == null){，此时instance不为null，直接调用return instance语句返回对象，但对象并没有真正得实例化完毕，调用就会出现错误 我们只需要将 instance 变量声明成 volatile 就可以了。 有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，读操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。 方法三（最优）：静态内部类中保持对象的实例，在第一次调用的时候创建单例对象 private static class Hold{ private static final Singleton instance = new Singleton(); } private Singleton(){} public static Singleton getInstance(){ return Hold.inistance; } 饿汉式和懒汉式对比：饿汉式在类加载的时候创建，不管用不用，都占据内存；懒汉式在第一次使用的时候创建，必须加锁，多线程时性能受影响 第4章：集中式工厂的实现——简单工厂模式设计思想1、定义抽象产品类，将产品 公共的代码 移至抽象产品类，并在抽象产品类中声明一些 抽象方法，供不同的具体产品类来实现2、具体产品类继承抽象产品类，实现抽象类中抽象方法3、工厂类提供一个创建产品的工厂方法，根据传入参数不同创建不同具体产品的对象 类图 抽象产品类 abstract class Product { //所有产品类的公共业务方法 public void methodSame() { //公共方法的实现 } //声明抽象业务方法 public abstract void methodDiff(); } 具体产品类 class ConcreteProduct extends Product { //实现业务方法 public void methodDiff() { //业务方法的实现 } } 工厂类 class Factory { //静态工厂方法 public static Product getProduct(String arg) { Product product = null; if (arg.equalsIgnoreCase(&quot;A&quot;)) { product = new ConcreteProductA(); //初始化设置product } else if (arg.equalsIgnoreCase(&quot;B&quot;)) { product = new ConcreteProductB(); //初始化设置product } return product; } } 简单工厂模式的简化 将抽象产品类和工厂类合并，将静态工厂方法移至抽象产品类中 创建对象与使用对象与一个对象相关的职责通常有3类：对象本身所具有的职责、创建对象的职责、使用对象的职责 在Java语言中，通常有以下几种创建对象的方式： 1、使用new关键字直接创建对象2、通过反射机制创建对象3、通过clone方法创建对象4、通过工厂类创建对象 第5章：多态工厂的实现——工厂方法模式简单工厂虽然简单，但存在一个很严重的问题，当系统中需要引入新产品时，由于静态工厂方法 通过传入参数的不同来创建不同的产品，这必定要修改工厂类的源代码，违背开闭原则 在工厂方法模式中，不再提供一个统一的工厂类来创建所有的产品对象，而是针对不同的产品提供不同的工厂 工厂方法模式结构图 具体产品实现抽象产品接口，具体产品和具体工厂之间一一对应 与简单工厂模式相比，工厂方式模式组重要的区别是引入了抽象工厂角色，在抽象工厂中声明工厂方法，由具体工厂类实现 客户端针对抽象工厂编程，在运行时再指定具体工厂类，不同的具体工厂可以创建不同的具体产品 具体工厂类在实现工厂方法时除了创建具体产品对象之外，还可以 负责产品对象的初始化工作以及一些资源和环境配置工作，例如连接数据库、创建文件等。 使用工厂方法模式设计的日志记录器 抽象产品： //日志记录器接口：抽象产品 interface Logger { public void writeLog(); } 具体产品： //数据库日志记录器：具体产品 class DatabaseLogger implements Logger { public void writeLog() { System.out.println(&quot;数据库日志记录。&quot;); } } //文件日志记录器：具体产品 class FileLogger implements Logger { public void writeLog() { System.out.println(&quot;文件日志记录。&quot;); } } 抽象工厂： //日志记录器工厂接口：抽象工厂 interface LoggerFactory { public Logger createLogger(); } 具体工厂： //数据库日志记录器工厂类：具体工厂 class DatabaseLoggerFactory implements LoggerFactory { public Logger createLogger() { //连接数据库，代码省略 //创建数据库日志记录器对象 Logger logger = new DatabaseLogger(); //初始化数据库日志记录器，代码省略 return logger; } } //文件日志记录器工厂类：具体工厂 class FileLoggerFactory implements LoggerFactory { public Logger createLogger() { //创建文件日志记录器对象 Logger logger = new FileLogger(); //创建文件，代码省略 return logger; } } 客户端测试: class Client { public static void main(String args[]) { LoggerFactory factory; Logger logger; factory = new FileLoggerFactory(); //可引入配置文件实现 logger = factory.createLogger(); logger.writeLog(); } } 第6章：产品族的创建——抽象工厂模式工厂方法模式中每个工厂只生产一类产品，可能会导致系统中存在大量的工厂类，势必会增加系统的开销，此时可以考虑将一些相关的产品组成一个”产品族”，由同一个工厂统一生产（抽象工厂中声明多个工厂方法，用于创建不同类型的产品，这些产品构成了一个产品族） 产品等级结构与产品族(1) 产品等级结构：产品等级结构即产品的继承结构，如一个抽象类是电视机，其子类有海尔电视机、海信电视机、TCL电视机，则 抽象电视机与具体品牌的电视机之间构成了一个产品等级结构，抽象电视机是父类，而具体品牌的电视机是其子类。 (2) 产品族：在抽象工厂模式中，产品族是指由同一个工厂生产的，位于不同产品等级结构中的一组产品，如 海尔电器工厂生产的海尔电视机、海尔电冰箱，海尔电视机 位于电视机产品等级结构中，海尔电冰箱位于电冰箱产品等级结构中，海尔电视机、海尔电冰箱构成了一个产品族。 不同颜色的多个正方形、圆形和椭圆形分别构成了三个不同的产品等级结构，而相同颜色的正方形、圆形和椭圆形构成了一个产品族，每一个形状对象都位于某个产品族，并属于某个产品等级结构 抽象工厂模式结构图 在抽象工厂模式中，每一个具体的工厂都提供了 多个工厂方法 用于产生多种不同类型的产品，这些产品构成了一个产品族 抽象工厂的典型代码如下： abstract class AbstractFactory { public abstract AbstractProductA createProductA(); //工厂方法一 public abstract AbstractProductB createProductB(); //工厂方法二 …… } 具体工厂实现了抽象工厂，每一个具体的工厂方法可以返回一个特定的产品对象，而同一个具体工厂创建的产品对象构成了一个产品族： class ConcreteFactory1 extends AbstractFactory { //工厂方法一 public AbstractProductA createProductA() { return new ConcreteProductA1(); } //工厂方法二 public AbstractProductB createProductB() { return new ConcreteProductB1(); } …… } 完整解决方案使用抽象工厂模式来重构界面皮肤库的设计，要求同一风格的具体界面组件要一起显示，其基本结构如图所示： 总结优点： 能够保证客户端始终使用只使用同一个产品族中的产品 增加新的产品族很方便，无需修改已有系统 缺点： 增加新的等级结构麻烦，需要对原有系统进行较大的修改，甚至需要修改抽象层的代码 使用场景： 属于同一产品族的产品要在一起使用，这一约束必须在系统的设计中体现出来，例如： 1、同一操作系统下的按钮和文本，按钮和文本没有直接关系，但他们都属于某一操作系统，此时具有一个 约束条件 就是：同一个操作系统 第8章：复杂对象的组装与创建——建造者模式建造者模式是为了解决这类问题：如何一步一步地创建一个包含多个组个组成部分的复杂对象 建造者模式将包含多个组成部分的复杂对象的创建过程分离 不同具体的建造者定义了不同的创建过程 建造新的建造者非常方便，无需修改已有代码，系统具有较好的扩展性 有Director的建造者模式Director类有两个作用： 隔离了客户与创建过程，客户只要与Director类进行交互 控制产品的创建过程，传入不同具体的建造者，输出产品 Builder类的作用：创建对象的各个组件 Actor：定义输出的对象类型 public class Actor { private String type; private String sex; public String getSex() { return sex; } public void setSex(String sex) { this.sex = sex; } public String getType() { return type; } public void setType(String type) { this.type = type; } @Override public String toString() { return &quot;Actor{&quot; + &quot;sex=&apos;&quot; + sex + &apos;\&apos;&apos; + &quot;, type=&apos;&quot; + type + &apos;\&apos;&apos; + &apos;}&apos;; } } AbstractActorBuilder：抽象的对象创建方法，对象的组建过程分为两步：buildtType、buildSex，然后调用getResult方法输出，组建方法需要由子类改写 public abstract class AbstractActorBuilder{ protected Actor actor = new Actor(); public abstract void buildtType(); public abstract void buildSex(); public Actor getResult() { return actor; } } HeroActorBuilder、AngelActorBuilder：定义了不同的组建过程 public class HeroActorBuilder extends AbstractActorBuilder{ @Override public void buildtType() { actor.setType(&quot;英雄&quot;); } @Override public void buildSex() { actor.setSex(&quot;男&quot;); } } public class AngelActorBuilder extends AbstractActorBuilder{ @Override public void buildtType() { actor.setType(&quot;Angle&quot;); } @Override public void buildSex() { actor.setSex(&quot;女&quot;); } } Director：导演类封装了复杂对象的组建过程，客户端只需调用contruct方法，并传入对应的组建类，就可以得到所需要创建的类 public class Director { public Actor contruct(AbstractActorBuilder builder){ builder.buildtType(); builder.buildSex(); return builder.getResult(); } } 省略DirectorAbstractActorBuilder需要承担创建复杂对象各个部分的职责，还要控制整个对象组建的顺序，但对系统的灵活性和可扩展性并没有任何影响 建议将construct方法单独封装在Director中，这样做更符合单一职责原则 public abstract class AbstractActorBuilder{ protected Actor actor = new Actor(); public abstract void buildtType(); public abstract void buildSex(); public Actor construct() { buildtType(); buildSex(); return actor; } } 钩子方法的引入通过Director类可以更加精细地控制产品的创建过程，比如说增加一类钩子方法来控制是否调用某个build方法 钩子方法的返回类型一般是boolena类型，方法名一般是isXXX（） 钩子方法定义在抽象建造类中 下面案例，定义了一个钩子方法hasType()，默认都是返回true；可以在子类中改写 public abstract class AbstractActorBuilder{ protected Actor actor = new Actor(); public abstract void buildtType(); public abstract void buildSex(); public Actor getResult() { return actor; } public boolean hasType(){ return true; } } 在Director中调用钩子方法hasType，如果返回结果是true，则调用buildType方法，否则不调用 public class Director { public Actor construct(AbstractActorBuilder builder){ if(builder.hasType()){ builder.buildtType(); } builder.buildSex(); return builder.getResult(); } } 第9章：适配器模式背景有的笔记本电脑的工作电压是20V，而我国的家庭用电是220V，如何才能让20V的笔记本电脑能够在220V的电压下工作，答案是引入一个电源适配器 适配器模式的使用场景 应用程序定义了一个接口，且已经有开发人员面向该接口进行编程，所以目标接口不能修改 代码库中有已经实现类似该接口的功能，但接口不一致（请求参数、方法名不同），为了开发效率决定重用代码库中的类 引入一个适配器类，通过适配器类来调用代码库中的接口 类图 应用程序调用适配器的方法时，适配器内部将调用适配者类的方法 适配器模式可以将一个类的接口和另一个类的接口匹配起来，而无须修改原来适配者接口和抽象目标类的接口 具体实现代码请见清单 1-4。清单 1. 客户端使用的接口 /* * 定义客户端使用的接口，与业务相关 */ public interface Target { /* * 客户端请求处理的方法 */ public void request(); } 清单 2. 被适配的对象 /* * 已经存在的接口，这个接口需要配置 */ public class Adaptee { /* * 原本存在的方法 */ public void specificRequest(){ //业务代码 } } 清单 3. 适配器实现 /* * 适配器类 */ public class Adapter implements Target{ /* * 持有需要被适配的接口对象 */ private Adaptee adaptee; /* * 构造方法，传入需要被适配的对象 * @param adaptee 需要被适配的对象 */ public Adapter(Adaptee adaptee){ this.adaptee = adaptee; } @Override public void request() { // TODO Auto-generated method stub adaptee.specificRequest(); } } 清单 4. 客户端代码 /* * 使用适配器的客户端 */ public class Client { public static void main(String[] args){ //创建需要被适配的对象 Adaptee adaptee = new Adaptee(); //创建客户端需要调用的接口对象 Target target = new Adapter(adaptee); //请求处理 target.request(); } } 电脑适配器的例子电 public interface Electricity { public void support(); } public class ElectricityImpl implements Electricity { private Integer value; public ElectricityImpl(Integer value){ this.value = value; } public void support(){ System.out.println(&quot;提供&quot;+ value +&quot;电&quot;); } } 适配器 public interface Adapter { public void transform(); } public class Adapter220To12V implements Adapter{ private Electricity electricity; public Adapter220To12V(Electricity electricity){ this.electricity = electricity; } public void transform(){ electricity.support(); System.out.println(&quot;220V电压转成12V&quot;); } } public class Adapter330To12V implements Adapter{ Electricity electricity; public Adapter330To12V(Electricity electricity){ this.electricity = electricity; } @Override public void transform() { electricity.support(); System.out.println(&quot;330V转成12V&quot;); } } 电脑 public interface Computer { public void work(); } public class ComputerImpl implements Computer{ private Adapter adapter; public ComputerImpl(Adapter adapter){ this.adapter = adapter; } public void work(){ adapter.transform(); System.out.println(&quot;电脑运行需要12v&quot;); } } 测试 public class App { public static void main(String[] args){ //电 Electricity electricity = new ElectricityImpl(220); //适配器 Adapter adapter = new Adapter220To12V(electricity); //电脑 ComputerImpl computer = new ComputerImpl(adapter); computer.work(); System.out.println(&quot;---------------------------&quot;); //电 electricity = new ElectricityImpl(330); //适配器 adapter = new Adapter330To12V(electricity); //电脑 computer = new ComputerImpl(adapter); computer.work(); } } 结果 提供220电 220V电压转成12V 电脑运行需要12v --------------------------- 提供330电 330V转成12V 电脑运行需要12v 本质面向接口编程，程序有扩展性和灵活性 缺省适配器模式当不需要实现一个接口所提供的所有方法时，可先设计一个抽象类实现该接口，并未接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可以选择性覆盖父类的某些方法来实现需求，它适用于不想使用一个接口中的所有方法的情况，又称单接口适配器模式 第12章：扩展系统功能——装饰模式http://blog.csdn.net/lovelion/article/details/7425873 根据合成复用的原则，在实现功能复用的时候，要多用关联，少用继承 装饰模式可以在不改变一个对象本身功能的基础上给对象增加额外的新行为 装饰模式是一种用于替代继承的技术，它通过一种无须定义子类的方式来给对象动态增加职责，使用对象之间的关联关系取代类之间的继承关系 装饰模式结构图 1、可以将一个具体构件注入装饰器类，再通过具体装饰类进行装饰2、可以将一个已经装饰过Decorator子类的对象再注入其中进行多次装饰，从而对原有功能进行多次扩展 客户端调用： Component c = new ConcreteComponent(); Component component = new ConcreteDecoratorA(c); component.operation(); 只有一个具体构建类的装饰模式 优点 对于扩展一个对象的功能，装饰模式比继承更加灵活，不会导致类的个数急剧增加 可以对一个对象进行多次装饰，采用继承的方式在单继承语言中无法复用多个父类的功能 课后题Sunny软件公司欲开发了一个数据加密模块，可以对字符串进行加密。最简单的加密算法通过对字母进行移位来实现，同时还提供了稍复杂的逆向输出加密，还提供了更为高 级的求模加密。用户先使用最简单的加密算法对字符串进行加密，如果觉得还不够可以对加密之后的结果使用其他加密算法进行二次加密，当然也可以进行第三次加 密。试使用装饰模式设计该多重加密系统。 类图： 抽象构件类 /** * 抽象构件类&lt;br&gt; * 加密字符串抽象类 * */ public abstract class StrEncrypt { /** * 加密字符串 * * @param str 需要加密的字符串 * @return String 加密后的字符串 */ public abstract String encryptStr(String str); } 具体构件类 /** * 具体构件类&lt;br&gt; * 加密字符串实现类 * */ public class StrEncryptOperate extends StrEncrypt { @Override public String encryptStr(String str) { String encrypt = &quot;**&quot; + str + &quot;**&quot;; return encrypt; } } 抽象装饰类 /** * 抽象装饰类&lt;br&gt; * 加密字符串抽象装饰类 * */ public class StrEncryptDecorator extends StrEncrypt { private StrEncrypt strEncrypt; public StrEncryptDecorator(StrEncrypt strEncrypt){ this.strEncrypt = strEncrypt; } @Override public String encryptStr(String str) { return strEncrypt.encryptStr(str); } } 具体装饰类 - 逆向加密字符串 /** * 具体装饰类&lt;br&gt; * 逆向加密字符串实现类 * */ public class ReverseEncryptDecorator extends StrEncryptDecorator { public ReverseEncryptDecorator(StrEncrypt strEncrypt) { super(strEncrypt); } @Override public String encryptStr(String str) { return this.reverseStr(super.encryptStr(str)); } /** * 逆向加密字符串 * * @param str 需要加密的字符串 * @return String 加密后的字符串 */ public String reverseStr(String str){ String encrypt = &quot;$$&quot; + str + &quot;$$&quot;; return encrypt; } } 具体装饰类 - 高级加密字符串 /** * 具体装饰类&lt;br&gt; * 高级加密字符串实现类 * */ public class AdvanceEncryptDecorator extends StrEncryptDecorator { public AdvanceEncryptDecorator(StrEncrypt strEncrypt) { super(strEncrypt); } @Override public String encryptStr(String str) { return this.advanceStr(super.encryptStr(str)); } /** * 高级加密字符串 * * @param str 需要加密的字符串 * @return String 加密后的字符串 */ public String advanceStr(String str){ String encrypt = &quot;&amp;&amp;&quot; + str + &quot;&amp;&amp;&quot;; return encrypt; } } 测试 public class Test { public static void main(String[] args) { String str = &quot;aa&quot;; //加密字符串 StrEncrypt strEncrypt = new StrEncryptOperate(); //逆向加密 StrEncrypt reverse = new ReverseEncryptDecorator(strEncrypt); //高级加密 StrEncrypt advance = new AdvanceEncryptDecorator(reverse); System.out.println(advance.encryptStr(str)); } } 执行结果：&amp;&amp;$$aa$$&amp;&amp; 第13章：提供统一入口——外观模式有时候客户端需要与多个子系统进行复杂的交互，而增加一个外观角色后，客户端只需要直接与外观角色交互，客户端与子系统之间原有的复杂关系由外观角色来实现，从而降低了系统的耦合度 总结： 外观模式通过引入一个外观角色来简化客户端与子系统之间的交互，为复杂的子系统调用提供一个统一的入口，使子系统与客户端的耦合度降低，且客户端调用非常方便 外观模式并不给系统增加任何新功能，它的作用就是简化调用接口 第15章：代理模式客户端使用对象时，返回这个对象的代理对象，这个代理对象控制对原对象的引用，对于客户端的使用是透明的 实现步骤 1、定义接口Subject public interface Subject { public void request(); } 2、实现接口 public class Proxy implements Subject{ public void request() { } } public class RealSubject implements Subject{ public void request() { System.out.println(&quot;处理请求&quot;); } } 3、代理类中存放目标类的实例，并且添加新的方法、调用目标类的方法 public class Proxy implements Subject{ private RealSubject realSubject; public Proxy(RealSubject realSubject){ this.realSubject = realSubject; } public void request() { preRequest(); realSubject.request(); postRequest(); } private void postRequest() { System.out.println(&quot;记录时间&quot;); } private void preRequest() { System.out.println(&quot;日志记录&quot;); } } 4、测试 public class Run { public static void main(String[] args){ RealSubject realSubject = new RealSubject(); Subject proxy = new Proxy(realSubject); proxy.request(); } } 结果： 日志记录 处理请求 记录时间 在不增加目标类的情况下，扩展了方法 Java 动态代理 通常情况下，代理类所实现的接口和所代理的方法都被固定，这种代理称之为 静态代理 静态代理若需要对不同目标对象进行代理，或者对同一目标类代理不同的方法，都需要增加新的代理类，这就造成类的个数急剧增加 动态代理可以让一个类 代理多个不同的目标类，而且可以 代理不同的方法 步骤1、调用处理函数程序类，传入目标对象、调用目标函数的方法、扩展方法 class SubjectHandler implements InvocationHandler{ //目标类的引用，通过构造方法传入对象 private Object target; public SubjectHandler(Object target){ this.target = target; } /* * 调用代理对象的方法时，调用此方法 * Object proxy是代理的对象, Method method是真实对象中调用方法的Method类, Object[] args是真实对象中调用方法的参数 */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { preHandler(); Object o = method.invoke(target, args); postHandler(); return o; } private void postHandler() { System.out.println(&quot;后置方法&quot;); } private void preHandler() { System.out.println(&quot;前置方法&quot;); } } 2、创建动态代理 public class Client { public static void main(String[] args){ //目标类 RealSubject realSubject = new RealSubject(); //调用处理处理程序 InvocationHandler invocationHandler = new SubjectHandler(realSubject); /** 创建代理类的实例 * 第一个参数表示代理类的类加载器 * 第二个参数表示代理类所实现的接口列表 * 第三个参数为调用处理程序类，可以是new Class[]{Subject.class}， * 也可以 RealSubject.class.getInterfaces() */ Subject proxy = (Subject) Proxy.newProxyInstance(Client.class.getClassLoader(), new Class[]{Subject.class},invocationHandler); proxy.request(); } } 原理： http://www.cnblogs.com/flyoung2008/p/3251148.html Proxy静态方法newProxyInstance-&gt;类Proxy的getProxyClass方法调用ProxyGenerator的 generateProxyClass方法产生ProxySubject.class的二进制数据，需要传入参数类名和实现接口，以下为测试ProxyGenerator的generateProxyClass方法： byte[] proxyClassFile = ProxyGenerator.generateProxyClass(&quot;xxx&quot;, new Class[]{Subject.class}); OutputStream o = new FileOutputStream(&quot;xxx.class&quot;); o.write(proxyClassFile,0,proxyClassFile.length); o.close(); 产生字节码，经反编译后得到的结果：生成的类继承Proxy，而且实现传入的接口方法request，每次调用接口方法，将会调用InvocationHandler的invoke方法 // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // import Proxy.Subject; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class xxx extends Proxy implements Subject { private static Method m1; private static Method m3; private static Method m0; private static Method m2; public xxx(InvocationHandler var1) throws { super(var1); } public final boolean equals(Object var1) throws { try { return ((Boolean)super.h.invoke(this, m1, new Object[]{var1})).booleanValue(); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } //接口实现的方法 public final void request() throws { try { //调用h为InvocationHandler类型，为Proxy的成员变量，创建代理对象的时候作为参数传入 super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final int hashCode() throws { try { return ((Integer)super.h.invoke(this, m0, (Object[])null)).intValue(); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() throws { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { try { m1 = Class.forName("java.lang.Object").getMethod("equals", new Class[]{Class.forName("java.lang.Object")}); m3 = Class.forName("Proxy.Subject").getMethod("request", new Class[0]); m0 = Class.forName("java.lang.Object").getMethod("hashCode", new Class[0]); m2 = Class.forName("java.lang.Object").getMethod("toString", new Class[0]); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } } 总结： 使用：1、创建目标对象 2、自定义类实现InvocationHandler接口，构造函数中传入目标对象，在实现的接口方法Invoke中对根据选择对方法进行代理 3、调用Proxy.newProxyInstance方法中传入是三个参数，分别是类加载器，代理的接口和自定义InvocationHandler实例，返回代理对象 原理：1、调用ProxyGenerator的generateProxyClass方法产生ProxySubject.class的二进制数据，需要传入参数类名和实现接口，生成的代理类在调用接口方法时，会调用传入的InvocationHandler的invoke方法 2、利用反射创建代理对象的实例，并且传入InvocationHandler参数，返回代理对象实例 设计： 为什么这么设计1、动态代理需要 代理不同的目标对象 和 同一目标对象的不同方法，所以动态代理类中需要传入代理方法（接口）和代理对象2、在Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h)方法中直接传入接口，和InvocationHandler的实例，其中实例中传入目标对象，和调用处理方法，根据要求对不同方法进行代理 其他的代理类型1、远程代理：位于不同地址空间的对象提供一个本地的代理对象，这个不同的地址空间可以在同一台主机，也可以在另一台主机中。在Java语言中，可以通过RMI机制来实现远程代理 2、虚拟代理：如果需要创建一个资源消耗较大的资源，先创建一个消耗相对较小的对象来表示，真是对象只是在需要时才会被真正创建。在真实对象创建成功之前虚拟代理扮演真实对象的替身，而当真实对象创建之后，虚拟代理将用户的请求转发给真实对象 第22章：对象间的联动——观察者模式观察者模式定义对象之间的一种一对多依赖关系，使得 当一个对对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新 在观察者模式中，发生改变的对象称为观察目标，而被通知的对象称为观察者 观察者模式示意代码定义一个抽象目标Subject import java.util.*; abstract class Subject { //定义一个观察者集合用于存储所有观察者对象 protected ArrayList observers&lt;Observer&gt; = new ArrayList(); //注册方法，用于向观察者集合中增加一个观察者 public void attach(Observer observer) { observers.add(observer); } //注销方法，用于在观察者集合中删除一个观察者 public void detach(Observer observer) { observers.remove(observer); } //声明抽象通知方法 public abstract void notify(); } 具体目标类ConcreteSubject（如果无须扩展目标类，则具体目标类可省略） class ConcreteSubject extends Subject { //实现通知方法 public void notify() { //遍历观察者集合，调用每一个观察者的响应方法 for(Object obs:observers) { ((Observer)obs).update(); } } } 抽象观察者角色一般定义为一个接口，通常只声明一个update()方法 interface Observer { //声明响应方法 public void update(); } 具体观察者ConcreteObserver中实现了update()方法 class ConcreteObserver implements Observer { //实现响应方法 public void update() { //具体响应代码 } } 多人联机对战游戏结构图 抽象观察类 interface Observer { public String getName(); public void setName(String name); public void help(); //声明支援盟友方法 public void beAttacked(AllyControlCenter acc); //声明遭受攻击方法 } 战队成员类：具体观察者类 class Player implements Observer { private String name; public Player(String name) { this.name = name; } public void setName(String name) { this.name = name; } public String getName() { return this.name; } //支援盟友方法的实现 public void help() { System.out.println(&quot;坚持住，&quot; + this.name + &quot;来救你！&quot;); } //遭受攻击方法的实现，当遭受攻击时将调用战队控制中心类的通知方法notifyObserver()来通知盟友 public void beAttacked(AllyControlCenter acc) { System.out.println(this.name + &quot;被攻击！&quot;); acc.notifyObserver(name); } } 战队控制中心类：目标类 abstract class AllyControlCenter { protected String allyName; //战队名称 protected ArrayList&lt;Observer&gt; players = new ArrayList&lt;Observer&gt;(); //定义一个集合用于存储战队成员 public void setAllyName(String allyName) { this.allyName = allyName; } public String getAllyName() { return this.allyName; } //注册方法 public void join(Observer obs) { System.out.println(obs.getName() + &quot;加入&quot; + this.allyName + &quot;战队！&quot;); players.add(obs); } //注销方法 public void quit(Observer obs) { System.out.println(obs.getName() + &quot;退出&quot; + this.allyName + &quot;战队！&quot;); players.remove(obs); } //声明抽象通知方法 public abstract void notifyObserver(String name); } 具体战队控制中心类：具体目标类 class ConcreteAllyControlCenter extends AllyControlCenter { public ConcreteAllyControlCenter(String allyName) { System.out.println(allyName + &quot;战队组建成功！&quot;); System.out.println(&quot;----------------------------&quot;); this.allyName = allyName; } //实现通知方法 public void notifyObserver(String name) { System.out.println(this.allyName + &quot;战队紧急通知，盟友&quot; + name + &quot;遭受敌人攻击！&quot;); //遍历观察者集合，调用每一个盟友（自己除外）的支援方法 for(Object obs : players) { if (!((Observer)obs).getName().equalsIgnoreCase(name)) { ((Observer)obs).help(); } } } } 编写如下客户端测试代码： class Client { public static void main(String args[]) { //定义观察目标对象 AllyControlCenter acc; acc = new ConcreteAllyControlCenter(&quot;金庸群侠&quot;); //定义四个观察者对象 Observer player1,player2,player3,player4; player1 = new Player(&quot;杨过&quot;); acc.join(player1); player2 = new Player(&quot;令狐冲&quot;); acc.join(player2); player3 = new Player(&quot;张无忌&quot;); acc.join(player3); player4 = new Player(&quot;段誉&quot;); acc.join(player4); //某成员遭受攻击 Player1.beAttacked(acc); } } JDK对观察者模式的支持 (1)Observer接口在java.util.Observer接口中只声明一个方法，它充当抽象观察者，其方法声明代码如下所示： void update(Observable o, Object arg); 当观察目标的状态发生变化时，该方法将会被调用，在Observer的子类中将实现update()方法，即具体观察者可以根据需要具有不同的更新行为。当调用观察目标类Observable的notifyObservers()方法时，将执行观察者类中的update()方法。 (2)Observable类java.util.Observable类充当观察目标类，在Observable中定义了一个向量Vector来存储观察者对象 实例： 观察者： public class Listener implements Observer { @Override public void update(Observable o, Object arg) { System.out.println(&quot;update&quot;); } } 观察目标： public class Source extends Observable { public void fire(){ setChanged(); notifyObservers(); } } 测试： public class APP { public static void main(String[] args){ Observer listener = new Listener(); Source source = new Source(); source.addObserver(listener); source.fire(); } } ThreadLocal设计模式https://my.oschina.net/pingpangkuangmo/blog/376321 ThreadLocal设计模式：（1）ThreadLocal所操作的数据是线程间不共享的。它不是用来解决多个线程竞争同一资源的多线程问题（2）ThreadLocal所操作的数据主要用于线程内共享数据，可以避免同一线程内函数间的传参数问题 ThreadLocal更像是一个操作线程数据的工具类，哪个线程调用它，它就操作哪个线程的数据。 其中ThreadUtil就是用ThreadLocal来实现的，ThreadLocal完全可以这样理解，它就是操作线程数据的工具类，哪个线程调用它的get或set方法，它就会操作调用它的线程中的数据如下： public class ThreadUtil { private static ThreadLocal&lt;String&gt; nameLocal=new ThreadLocal&lt;String&gt;(); public static String getName(){ return nameLocal.get(); } public static void setName(String name){ nameLocal.set(name); } }]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
</search>